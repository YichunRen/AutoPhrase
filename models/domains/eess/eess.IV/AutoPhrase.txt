0.9790340563	discrete cosine transform
0.9778242941	positron emission tomography
0.9754915128	augmented reality
0.9737467151	unmanned aerial vehicles
0.9725823189	virtual reality
0.9715987163	alzheimer's disease
0.9714257693	hausdorff distance
0.9712461680	remote sensing
0.9705079351	colorectal cancer
0.9699203612	optical coherence tomography
0.9698994232	left ventricle
0.9697406147	electron microscopy
0.9697228251	parkinson's disease
0.9687426234	synthetic aperture radar
0.9685170772	fluorescence microscopy
0.9684806972	diabetic retinopathy
0.9683051255	random forest
0.9680829314	compressive sensing
0.9676433053	autonomous driving
0.9675269880	kalman filter
0.9656915574	artificial intelligence
0.9656132778	computed tomography
0.9653279941	compressed sensing
0.9651684665	optic disc
0.9651643035	breast cancer
0.9651091234	euclidean distance
0.9649640948	polymerase chain reaction
0.9645505273	jaccard index
0.9635436839	question answering
0.9633122484	sheet music
0.9631077201	logistic regression
0.9629753964	mobile phones
0.9626249273	anomaly detection
0.9625251149	coronary artery
0.9623842204	myocardial infarction
0.9618306548	chest radiographs
0.9617708811	social media
0.9614748135	left atrium
0.9611342774	optic nerve
0.9609222204	traumatic brain injury
0.9607803894	maximum likelihood
0.9607613676	point cloud
0.9606870070	quantitative susceptibility mapping
0.9604209501	nuclear norm
0.9596157224	capsule endoscopy
0.9595795347	support vector machine
0.9593028941	satellite imagery
0.9592211159	land cover
0.9590473583	ischemic stroke
0.9589094275	histogram equalization
0.9588383186	mild cognitive impairment
0.9579765217	gradient descent
0.9579208238	densely connected
0.9579089478	coronary arteries
0.9572369598	chest radiography
0.9568488416	bit allocation
0.9565654801	receptive field
0.9564591990	autonomous vehicles
0.9564107763	gray matter
0.9562564299	adipose tissue
0.9559630442	correlation coefficient
0.9558029152	earth observation
0.9555327858	acoustic impedance
0.9554178991	viral pneumonia
0.9552252918	magnetic resonance fingerprinting
0.9551104579	domain adaptation
0.9546483847	facial expression
0.9543248860	monte carlo
0.9543157652	metal artifact reduction
0.9542879877	point clouds
0.9541297641	total variation
0.9539052705	digital breast tomosynthesis
0.9538667281	radiation therapy
0.9536688811	spinal cord
0.9536602374	pulmonary nodules
0.9535553076	multiple sclerosis
0.9535406598	hepatocellular carcinoma
0.9528431478	white matter
0.9526075790	wavelet transform
0.9525061694	red blood cells
0.9519574130	variational autoencoders
0.9519245010	bundle adjustment
0.9518883432	variational autoencoder
0.9518411779	machine learning
0.9514779409	social distancing
0.9514310482	receiver operating characteristic
0.9509817359	dice similarity coefficient
0.9508496440	electrical impedance
0.9508189015	world health organization
0.9508065596	cohen's kappa
0.9507617215	lung cancer
0.9506939192	prostate cancer
0.9506451448	optical flow
0.9500691276	dipole inversion
0.9496085979	hough transform
0.9493368081	skin lesion
0.9492640757	gene expression
0.9491656627	minimally invasive
0.9485719114	climate change
0.9485562951	principal component analysis
0.9481673649	motion compensation
0.9481560181	persistence diagrams
0.9481310639	ductal adenocarcinoma
0.9481188436	lung nodules
0.9480217915	magnetic resonance
0.9476560053	raspberry pi
0.9475300304	dimensionality reduction
0.9472785349	autism spectrum disorder
0.9472688792	remotely sensed
0.9472474401	knowledge distillation
0.9469118404	coded aperture
0.9464208347	point spread function
0.9459062438	acute ischemic stroke
0.9458695163	magnetic resonance imaging
0.9454386260	project page
0.9449121088	fourier ptychographic microscopy
0.9448102308	false alarm
0.9447878252	sparsifying transform
0.9447346036	active contour
0.9444471284	support vector machines
0.9439992015	phase retrieval
0.9438767448	arterial spin labeling
0.9435763792	rain removal
0.9430850771	ejection fraction
0.9430482580	eye gaze
0.9426467649	pascal voc
0.9422847093	style transfer
0.9417112303	tone mapping
0.9416464427	reinforcement learning
0.9416364035	heart rate
0.9414350428	nutrient intake
0.9412166142	lower bound
0.9411737516	monocular depth estimation
0.9410171828	skip connection
0.9409987164	attenuated inversion recovery
0.9405395271	mitral valve
0.9405309417	receptive fields
0.9401333124	dice coefficient
0.9389843099	gastric cancer
0.9389488438	open access
0.9386068361	fourier transform
0.9380754345	breast masses
0.9377615690	persistent homology
0.9376301112	augmented lagrangian
0.9371671718	dilated convolutions
0.9370702127	fourier ptychography
0.9369883734	feature extraction
0.9368888449	radiology reports
0.9366104679	disease neuroimaging initiative
0.9354994490	neural networks
0.9354291858	radio frequency
0.9352553506	ultrasound elastography
0.9351612075	nonnegative matrix factorization
0.9351509035	knee osteoarthritis
0.9348535662	blood vessels
0.9347830014	proximal femur
0.9345080205	unmanned aerial vehicle
0.9344381156	light field
0.9340934813	neural network
0.9337475020	mode collapse
0.9337382041	densely sampled
0.9336204798	conditional random field
0.9335310582	radon transform
0.9334960777	google earth
0.9334688882	lossless compression
0.9333598452	ct scans
0.9333180502	electric field
0.9328139262	ductal carcinoma
0.9326223835	cranial implant
0.9324236215	emotion recognition
0.9321179049	genome atlas
0.9318265954	celiac disease
0.9316094243	markov random field
0.9313385462	batch normalization
0.9312928233	inverse problems
0.9312171648	skip connections
0.9310597035	blood flow
0.9310487401	ghost imaging
0.9310181409	adversarial examples
0.9309934992	macular edema
0.9307041273	radiation dose
0.9306143084	structural similarity index
0.9302545378	simulated annealing
0.9301607111	floating point
0.9300839927	steady state
0.9299550881	community acquired pneumonia
0.9297092667	depthwise separable
0.9296162149	plant disease
0.9294869086	matrix factorization
0.9294221312	multimode fiber
0.9293562768	optic nerve head
0.9293188085	principal component
0.9289244739	optimal transport
0.9288454372	consensus equilibrium
0.9285562997	lge cmr
0.9284348271	dice score
0.9284165754	mobile devices
0.9283947865	porous media
0.9282834263	adversarial attacks
0.9281578062	mixed reality
0.9280589596	shear wave
0.9277889869	progressive growing
0.9275465929	bounding box
0.9274663481	diabetic macular edema
0.9274504044	thalamic nuclei
0.9273423848	bokeh effect
0.9264551390	attention mechanism
0.9262662642	weather conditions
0.9262086420	chest radiograph
0.9261127477	decision tree
0.9260692945	energy compaction
0.9257345187	f1 score
0.9255200312	skin cancer
0.9254115566	nearest neighbors
0.9253772514	weakly supervised
0.9252809327	digital micromirror
0.9252380162	refractive index
0.9250484919	background subtraction
0.9248833310	ionizing radiation
0.9247116320	material decomposition
0.9232968498	coronary angiography
0.9231162104	rain streaks
0.9230890780	false positive
0.9225885549	spatial light modulators
0.9223814388	rain streak
0.9222622483	lung nodule
0.9219060896	cardiac cine
0.9218094741	quality control
0.9217872222	transfer learning
0.9213848691	false negatives
0.9213270763	cone beam
0.9213217697	class imbalance
0.9212967405	free breathing
0.9202130874	stain normalization
0.9201827252	action units
0.9201390069	deep learning
0.9200655596	versatile video coding
0.9198107795	latent space
0.9195226995	nearest neighbor
0.9194808610	blood vessel
0.9191212408	inception v3
0.9187452189	synthetic aperture
0.9186730028	generative adversarial networks
0.9186021439	spatial pyramid pooling
0.9184469343	conditional random fields
0.9182181397	change detection
0.9174127761	frame rate
0.9170473247	lossy compression
0.9166520193	age related macular degeneration
0.9163276152	reversible data hiding
0.9162494317	gold standard
0.9160036900	ad hoc
0.9159440215	genetic algorithm
0.9158738321	memory footprint
0.9158523839	primal dual
0.9156105787	facial expressions
0.9154726757	edge detection
0.9152144835	complex valued
0.9151693543	functional connectivity
0.9146844329	feature extractor
0.9145416575	fully connected
0.9142218092	privacy preserving
0.9141182956	particle swarm
0.9141081123	retinal vessels
0.9141073019	latent variable
0.9140683728	cortical bone
0.9139743849	visually pleasing
0.9136327629	late gadolinium
0.9135423947	frequency domain
0.9132084961	spatially varying
0.9128943940	high fidelity
0.9127932362	neural architecture search
0.9126663392	structural similarity
0.9124188107	sparsely sampled
0.9112931174	vessel wall
0.9108218800	confocal laser
0.9108200346	uncertainty quantification
0.9105819202	medical imaging
0.9105625806	lossy image compression
0.9105290943	laplacian pyramid
0.9103207988	neurological disorders
0.9100810683	lip reading
0.9100780854	rt pcr
0.9096612988	diffusion mri
0.9094232047	deformable image registration
0.9091226559	presentation attack
0.9089160301	urban areas
0.9088958219	action recognition
0.9087065707	data augmentation
0.9086081026	pearson correlation
0.9085203886	spectral unmixing
0.9082018134	` `
0.9079660438	breast mass
0.9079538102	ct scan
0.9079104253	user interface
0.9076580404	pose estimation
0.9076192392	metal artifact
0.9070481722	cerebrospinal fluid
0.9066416996	spin echo
0.9063151285	channel attention
0.9062992598	sliding window
0.9061427577	fundus photography
0.9060963823	dynamic range
0.9059196434	colorectal polyps
0.9054567612	magnetic susceptibility
0.9052273810	differential equations
0.9049729198	single shot
0.9048714405	support vector
0.9048056732	gesture recognition
0.9047483291	deformable registration
0.9035733711	irregularly sampled
0.9034165314	phase unwrapping
0.9031916518	image processing
0.9029343397	motion correction
0.9027749457	fine grained
0.9024209135	projection profilometry
0.9023904094	cryo em
0.9023457054	loss function
0.9021333054	brain tumor
0.9019789397	high dynamic range
0.9015739347	long short term memory
0.9014556824	instance segmentation
0.9013273715	latent variables
0.9011637409	night vision
0.9010332939	uk biobank
0.9009853613	cycle consistency
0.9008979275	left ventricular
0.9008305500	disease progression
0.9008160831	loss functions
0.9003412107	adversarial attack
0.9001874368	rotation invariant
0.8997872552	convolutional neural networks
0.8990699304	tongue contour
0.8990211150	object detection
0.8990203251	forward pass
0.8988860878	opinion scores
0.8988727553	airborne lidar
0.8988352592	iterative reconstruction
0.8987731392	unsupervised learning
0.8984847251	crowd counting
0.8984250272	pulmonary nodule
0.8983936129	numerical aperture
0.8983283570	domain shift
0.8983283284	latent codes
0.8983206305	l1 norm
0.8982451183	led array
0.8981676384	gerchberg saxton
0.8980096235	generative models
0.8979849524	contrast agent
0.8978005986	positron emission
0.8977072153	reverse transcription
0.8976732656	optical coherence tomography angiography
0.8976154419	iris recognition
0.8975989321	digital elevation
0.8975012440	bounding boxes
0.8972697101	skin lesions
0.8968612686	face recognition
0.8967634666	cross modal
0.8964725740	public health
0.8962674633	generative adversarial network
0.8961923695	depth estimation
0.8961757863	bit rate
0.8957849282	single molecule
0.8957682914	fetal brain
0.8953501730	triplet loss
0.8945412969	digital pathology
0.8944635708	false positives
0.8937875040	focal plane
0.8933980677	scattering media
0.8930771754	chest ct scans
0.8929663452	bd rate
0.8929588898	quality assessment
0.8929568112	open source
0.8929349386	myocardial perfusion
0.8925834904	ct volumes
0.8924503511	knowledge transfer
0.8924257234	cervical cancer
0.8923991232	semantic segmentation
0.8921600036	lidc idri
0.8921499296	point spread functions
0.8920930026	feed forward
0.8919378968	pattern recognition
0.8917035493	machine vision
0.8916196988	mri scans
0.8915285158	residual blocks
0.8914179617	grand challenge
0.8914086407	generative adversarial
0.8913191492	cycle consistent
0.8912618712	motion estimation
0.8912321270	closed loop
0.8910361524	fractional anisotropy
0.8909326111	artificial neural networks
0.8906931927	deep neural networks
0.8906589131	computerized tomography
0.8904883718	federated learning
0.8903824950	black box
0.8899576146	fully automatic
0.8896511746	photon counting
0.8894448626	photoacoustic microscopy
0.8892673521	soft tissue
0.8891863643	scanning transmission electron microscopy
0.8890929056	auto encoder
0.8890134939	visual odometry
0.8889185199	unsupervised domain adaptation
0.8882934515	filter array
0.8882880159	resting state
0.8882294954	principle component
0.8879063787	convolutional sparse coding
0.8877480825	t2 weighted
0.8875004837	feature selection
0.8872321467	low rank
0.8867754520	memory consumption
0.8867463221	fringe patterns
0.8865859479	ablation studies
0.8865797740	root mean square error
0.8864965625	cross entropy
0.8864938473	skin disease
0.8864755589	bi directional
0.8863494563	convolutional neural network
0.8862631910	high efficiency video coding
0.8859737403	perceptual quality
0.8856645242	grad cam
0.8855056147	confocal microscopy
0.8853124025	object detectors
0.8852938172	artifact reduction
0.8847025043	post operative
0.8845110982	view synthesis
0.8840652112	attention module
0.8839915958	fast fourier transform
0.8837680198	single image deraining
0.8837405977	sar despeckling
0.8837294878	blood pool
0.8836273361	super resolution
0.8835723323	post hoc
0.8831788401	video compression
0.8831200972	gaussian mixture
0.8826709095	auto encoders
0.8825209692	magnetic particle imaging
0.8821996192	perceptual loss
0.8820481717	neuro oncology
0.8818248237	photoacoustic tomography
0.8815164281	contrast enhancement
0.8814692287	feature space
0.8811534746	bright field
0.8810187910	image denoising
0.8807253642	video coding
0.8805634590	t1 weighted
0.8804985570	physics informed
0.8803863826	hyperparameter tuning
0.8803813897	sparsity promoting
0.8803509969	dice loss
0.8801862979	encoder decoder
0.8800357938	error rate
0.8798538528	discrete wavelet transform
0.8793529956	fully automated
0.8793211279	late gadolinium enhancement
0.8792735447	high definition
0.8791967414	mr fingerprinting
0.8789552009	feature fusion
0.8789045559	anti spoofing
0.8786258338	region proposal
0.8781322409	brain tumors
0.8780942320	image compression
0.8780820449	human connectome project
0.8780680723	body parts
0.8780508701	computationally expensive
0.8776579842	inter observer
0.8774631578	ray tracing
0.8771437296	previously published
0.8769986968	content based image retrieval
0.8768353539	false negative
0.8764175000	sparse coding
0.8761887479	cancer types
0.8760931179	teacher student
0.8758885164	intra operative
0.8758688502	average precision
0.8758084607	photo realistic
0.8757504848	robot assisted
0.8755108184	power consumption
0.8752697190	gaussian noise
0.8751480569	multi modal
0.8750829587	upper bound
0.8750502534	residual connections
0.8749719333	noise removal
0.8748730384	diffraction limit
0.8747948437	higher order
0.8746343335	bi rads
0.8744393394	prostate biopsies
0.8743126314	unmanned aerial
0.8742024958	variable rate
0.8741541278	daily life
0.8739800997	low dose ct
0.8739306833	signal processing
0.8738735164	visual perception
0.8737383222	light fields
0.8736756308	diffraction tomography
0.8735104955	shearlet transform
0.8734794342	cross sectional
0.8732803328	scanning transmission electron
0.8727613335	labor intensive
0.8727357854	aerial imagery
0.8726006316	vessel segmentation
0.8725885024	depth map
0.8725445056	super resolve
0.8723876025	life threatening
0.8723444958	filter banks
0.8722689047	dictionary learning
0.8722525504	compares favorably
0.8721607601	fixed point
0.8720128125	resonance imaging
0.8719408407	closed form
0.8718412672	fine tuning
0.8718023344	future directions
0.8717594331	single photon
0.8717134708	lighting conditions
0.8716681731	true positive
0.8715053254	high resolution
0.8714935191	limited angle
0.8714627344	computationally efficient
0.8711939131	diffusion weighted
0.8711214490	double compressed
0.8709820299	wasserstein distance
0.8708954974	traffic sign
0.8708131177	parameter tuning
0.8705801760	regularization term
0.8705665079	class activation
0.8705606193	fully sampled
0.8704933977	sparse representation
0.8704810559	image registration
0.8704558348	chest ct
0.8704061233	depthwise convolution
0.8703625910	brain metastases
0.8703618611	object recognition
0.8702583933	artificial neural network
0.8702438899	retinal vessel
0.8702147881	spatio temporal
0.8700788122	supervised learning
0.8700440027	cardiac magnetic resonance
0.8694332462	fully connected layers
0.8693775213	adversarial training
0.8692908981	echet inception distance
0.8692608568	contrast enhanced
0.8691713705	wgan gp
0.8690519016	clinically relevant
0.8686727467	fold cross validation
0.8686646766	saliency maps
0.8685285036	semi supervised
0.8683824984	medical image analysis
0.8683590870	gauss newton
0.8681745391	transmission matrix
0.8680514482	convolutional layer
0.8679512213	convolutional neural
0.8678846455	hyperspectral unmixing
0.8674462391	hand crafted
0.8672159681	dynamic scenes
0.8670720831	mask rcnn
0.8670150880	frame rates
0.8669040268	phase shifting
0.8668844107	structured illumination microscopy
0.8667138302	spatially variant
0.8666099723	multiple instance learning
0.8665167855	scattering medium
0.8665066556	latent vectors
0.8664920250	random forests
0.8662807603	natural language
0.8661438393	ms ssim
0.8660224179	medical image segmentation
0.8660052742	convex optimization
0.8658255761	single image super resolution
0.8657879576	digital holography
0.8657474600	cardiac mri
0.8656967542	hand gesture recognition
0.8656302221	speech recognition
0.8655981524	cross modality
0.8655164771	cell phone
0.8649128086	cortical plate
0.8648577287	variational auto encoder
0.8647654966	inverse tone mapping
0.8647604058	anatomically plausible
0.8642983747	early stage
0.8641075741	statistically significant
0.8627209922	additive white gaussian noise
0.8624665770	pre operative
0.8624512304	adversarial loss
0.8624321117	ct images
0.8624062058	mr images
0.8623965229	decision making
0.8623850498	medical images
0.8620984397	vfa fleet
0.8620162274	driver assistance
0.8619446570	ground truth
0.8619244530	edge computing
0.8617893502	landmark detection
0.8616450572	inter rater
0.8614601101	shift exchange
0.8613224334	jpeg compression
0.8612277263	coronavirus disease
0.8611746248	computationally intensive
0.8611046447	long standing
0.8610279353	large scale
0.8605681524	photo response non uniformity
0.8600781395	alternating direction
0.8600610753	underwater image enhancement
0.8595396894	partially annotated
0.8593725068	multiple sclerosis lesion
0.8591418000	image restoration
0.8590479584	semi automatic
0.8589867814	active learning
0.8588227766	low light image enhancement
0.8588006302	natural language processing
0.8586715948	high throughput
0.8580011709	real world
0.8579036122	ms coco
0.8572184820	transcription polymerase chain reaction
0.8570329349	pan sharpening
0.8569579934	1p 19q
0.8567961195	light source
0.8564881922	street view
0.8564880993	cardiac mr
0.8563685266	low bitrates
0.8561437194	adversarial perturbations
0.8559433709	weak supervision
0.8558425216	contrast agents
0.8558423012	extensively studied
0.8553506423	brain tumour
0.8551000185	fetal head
0.8548736346	activity recognition
0.8547063050	mimic cxr
0.8542286768	low power
0.8541377707	metal artifacts
0.8540125659	cryo electron microscopy
0.8532960422	low rank tensor
0.8531804788	image quality assessment
0.8528419492	swarm optimization
0.8527212389	lesion segmentation
0.8523650562	deep neural network
0.8522168575	synthetically generated
0.8521455273	feature representation
0.8520295288	treatment planning
0.8519764366	structured light
0.8519350137	long term
0.8518713662	regularization terms
0.8518503738	variable density
0.8517372358	vice versa
0.8516971444	computational complexity
0.8516325172	lv myocardium
0.8513418447	artery stenosis
0.8512825878	healthy volunteers
0.8512734239	fine tune
0.8509076426	sampling pattern
0.8508706925	specially designed
0.8508450908	transfer function
0.8506783620	multi scale
0.8506683070	fully convolutional
0.8506090844	log likelihood
0.8504637626	perfusion roi
0.8504390653	dark field
0.8504193850	max pooling
0.8501399257	real valued
0.8501361209	optical coherence
0.8500736359	project website
0.8500358134	traffic sign detection
0.8496734457	short axis
0.8496020068	image generation
0.8494997230	resonance fingerprinting
0.8493323798	high dimensional
0.8490488879	board certified
0.8488094245	synthetic data
0.8486284248	performs favorably
0.8483032617	magnetic field
0.8479944086	tight frame
0.8476719663	radiomic features
0.8474971928	natural scenes
0.8472718948	fluid attenuated inversion
0.8472074466	case study
0.8469835649	vq vae
0.8469658436	short term
0.8469228898	low dose
0.8467667064	linear regression
0.8466447700	post processing
0.8464956216	motion blur
0.8463001767	speckle noise
0.8460268840	polyp detection
0.8459709863	healthy controls
0.8459055137	weakly labeled
0.8459045178	ground glass
0.8457676450	nr iqa
0.8457305411	convolutional layers
0.8456771731	health care
0.8456685590	tomographic reconstruction
0.8455730245	clinical trials
0.8455333808	survival prediction
0.8454122805	false positive rate
0.8452131837	hyperspectral imagery
0.8451288140	fiber orientation
0.8447181511	artifact removal
0.8446287721	dice similarity
0.8445711238	computational ghost imaging
0.8442400910	inception score
0.8440659232	frame prediction
0.8440396737	parameter estimation
0.8439043619	solving inverse problems
0.8438030035	uncertainty estimation
0.8437674903	blind deblurring
0.8437643642	image analysis
0.8437265027	imaging modalities
0.8435689978	rain snow
0.8434259121	sperm cells
0.8433686402	great progress
0.8433305339	deep image prior
0.8432842812	wide field
0.8432472725	multi site
0.8432403756	dynamic contrast enhanced magnetic resonance
0.8432123605	widely adopted
0.8431060940	feature maps
0.8430023336	video streaming
0.8428029416	noise reduction
0.8426682644	image quality
0.8424341328	big data
0.8423321858	mutual information
0.8419959058	fine tuned
0.8417448639	similarity index
0.8416338078	cross domain
0.8414532249	brain tumor segmentation
0.8411047597	chest computed tomography
0.8410623472	biomedical imaging
0.8410598546	color fundus
0.8408764767	recurrent neural network
0.8408604560	decision support
0.8408590588	tensor decomposition
0.8408543756	retinal vessel segmentation
0.8398358707	compression ratio
0.8398107286	neurodegenerative diseases
0.8398088192	human perception
0.8397464180	edge devices
0.8397013246	shadow removal
0.8395384519	paramount importance
0.8394700120	previous works
0.8392710378	memory usage
0.8390715833	sickle cell
0.8390420099	opinion score
0.8388006505	data set
0.8387737255	neural style transfer
0.8386996711	bit rates
0.8386304585	feature extractors
0.8382811366	hand gesture
0.8380123028	conditional generative adversarial networks
0.8378684892	fully convolutional networks
0.8378140365	standard deviation
0.8374773897	test set
0.8374201731	intersection over union
0.8371770969	impulse noise
0.8371581384	energy efficiency
0.8369790783	cone beam ct
0.8369617123	cross validation
0.8368267430	edge preserving
0.8367861268	energy consumption
0.8367599632	evaluation metrics
0.8367409782	virtual staining
0.8365227136	image reconstruction
0.8363358951	cost function
0.8362227762	search space
0.8361521269	radiation exposure
0.8360565923	fast spin echo
0.8360435208	proximal gradient
0.8360356929	open set
0.8358766642	fashion mnist
0.8357488578	computational resources
0.8355623020	context aware
0.8352394597	universal style transfer
0.8350895498	attention guided
0.8348198324	bit depth
0.8344989698	mini batch
0.8343013337	template matching
0.8342233041	residual block
0.8341047101	breast density
0.8338391579	deep belief
0.8335919811	rate distortion
0.8334142234	error prone
0.8334011476	bayesian inference
0.8333650108	predictive uncertainty
0.8332141470	brain mri
0.8325521291	alternating minimization
0.8324295040	low cost
0.8323394589	defect detection
0.8322196432	high frequency
0.8317652776	computational pathology
0.8314482010	squared error
0.8313640267	main contributions
0.8312805840	channel pruning
0.8312474267	cross correlation
0.8308256789	multi view
0.8307941804	dce mri
0.8307360556	dense blocks
0.8306638630	severity assessment
0.8304217772	motion artifacts
0.8301771278	instance normalization
0.8300773619	latent representation
0.8297516616	quality metric
0.8296633770	remote sensing imagery
0.8285343780	adversarial learning
0.8285230717	light detection and ranging
0.8284625405	differential equation
0.8284491358	recurrent neural networks
0.8281198754	surgical instruments
0.8280617237	clinical practice
0.8280464577	field programmable gate
0.8278235041	high speed
0.8275533674	inverse problem
0.8272964314	low dimensional
0.8270331865	diffusion tensor imaging
0.8268875860	evaluation metric
0.8268108102	future research directions
0.8266323544	bcd net
0.8265273675	single particle
0.8264443889	blur kernel
0.8263739610	tumor growth
0.8262035115	optimization problem
0.8260524386	video frames
0.8259544963	source code
0.8258899368	frame interpolation
0.8258238771	diffraction patterns
0.8257710440	pancreatic ductal
0.8256948460	blind spot
0.8254871924	coronary artery disease
0.8252871322	ego motion
0.8250280530	parallel imaging
0.8249875630	audio visual
0.8249189038	quality metrics
0.8248567917	radiological findings
0.8246792963	remarkable success
0.8245284710	capsule network
0.8244893771	surface distance
0.8243746406	deep learning models
0.8242704229	acute ischemic
0.8240427916	filter pruning
0.8237598269	great promise
0.8237144285	line segment
0.8234251422	fundus images
0.8231548643	arterial spin
0.8230812006	posterior distribution
0.8230755724	data sets
0.8230114964	hyperspectral image
0.8228091757	visible light
0.8227491533	data collection
0.8224690377	image segmentation
0.8224484812	predictive coding
0.8224309116	ocular diseases
0.8224138916	computational cost
0.8223907032	manually annotated
0.8222274342	physics guided
0.8221387394	global context
0.8221378782	low rankness
0.8215331174	depth completion
0.8214192582	user friendly
0.8211623496	capsule networks
0.8211158871	domain knowledge
0.8210967293	attack success rate
0.8210801291	contextual information
0.8210696759	vector field
0.8210478612	learned image compression
0.8204398798	satellite images
0.8203290608	root mean square
0.8203115378	ultrasound imaging
0.8202209069	pixel wise
0.8200357088	previously unseen
0.8199812939	embedded devices
0.8198623327	poisson gaussian
0.8196879564	fine details
0.8194910913	data driven
0.8192159586	dual path
0.8191933214	cross entropy loss
0.8191931580	lip movements
0.8189795277	cross sections
0.8188973738	receiver operating
0.8188251529	ultrasound tongue
0.8187448966	extreme low light
0.8185623813	feature vector
0.8185563927	computational burden
0.8185134096	higher resolution
0.8184977891	inter observer variability
0.8183429898	voxel wise
0.8182651494	phase contrast
0.8181356611	adversarial networks
0.8179726258	manually labeled
0.8179038312	transmission electron microscopy
0.8177579949	convolution neural network
0.8176763678	treatment response
0.8174026910	failure modes
0.8173917457	salient object detection
0.8173687784	multi slice
0.8173554814	malignant tumors
0.8171137436	facial landmark
0.8169506760	generalization ability
0.8166810781	aerial vehicles
0.8165855539	video streams
0.8165460439	low resolution
0.8163426465	long axis
0.8162355467	speckle patterns
0.8160563083	risk assessment
0.8155334916	conditional gan
0.8155084766	f1 scores
0.8153273029	anatomical landmarks
0.8149760366	multi atlas
0.8149403219	cryo electron
0.8148461362	variational auto encoders
0.8148445639	attention modules
0.8148284354	speckle tracking
0.8147874890	respiratory syndrome
0.8147564598	photoacoustic imaging
0.8146751291	image enhancement
0.8145320593	random access
0.8143214641	tumor segmentation
0.8142758627	numerical simulations
0.8142277940	histopathology images
0.8140691438	root mean squared error
0.8138357871	video sequence
0.8136041282	fringe pattern
0.8135920591	automatic differentiation
0.8135680982	low light
0.8135117518	head mounted
0.8132194819	multi label
0.8131134470	spatial frequency
0.8130706260	recent advances
0.8130639337	training samples
0.8127035200	medical image
0.8126723989	lung infection
0.8126056960	dense connections
0.8125479800	connectome project
0.8120256651	roc auc
0.8117716468	subjective quality
0.8117667758	early stages
0.8117582648	blind deconvolution
0.8117048841	singular value decomposition
0.8116597296	poor generalization
0.8114082564	lesion detection
0.8112739304	fully connected layer
0.8112386587	poisson noise
0.8109386978	recent works
0.8106754246	deformable convolution
0.8101410279	conjugate gradient
0.8100661421	audio visual speech enhancement
0.8099439767	high performance computing
0.8096396784	multi modality
0.8093936325	low contrast
0.8093918862	proton density
0.8092212754	partial volume effects
0.8091668861	lower dimensional
0.8089923418	electron microscope
0.8089637021	histopathological images
0.8088317247	operating characteristic curve
0.8087662449	image synthesis
0.8084217512	ct angiography
0.8083623588	multi coil
0.8083361413	discrete cosine
0.8082544106	super resolved
0.8082355765	hierarchical clustering
0.8081540833	multi channel
0.8081034081	fourier domain
0.8080565301	success rate
0.8076758985	electron tomography
0.8076360564	single particle cryo
0.8076182922	deep neural
0.8074834023	computational imaging
0.8074735548	fuzzy c means
0.8073979327	anatomical structures
0.8073921457	liver tumor segmentation
0.8073416511	deep learning based
0.8072810352	latent representations
0.8072306644	activation functions
0.8071556530	dark channel
0.8070437742	health monitoring
0.8068678471	validation set
0.8066567206	person re identification
0.8065503165	filtered back projection
0.8064352130	multi sequence
0.8061080375	enhancing tumor
0.8060213958	real life
0.8059486473	discrete wavelet
0.8057509493	recent years
0.8057039488	boundary conditions
0.8055872927	wide area
0.8053852818	conditional generative
0.8053299520	shot epi
0.8053262289	trade offs
0.8052566175	lossless image compression
0.8051715643	emission tomography
0.8046518471	cortical surface
0.8045549015	brain anatomy
0.8045102169	blind denoising
0.8043632446	matrix completion
0.8042021698	fully supervised
0.8041261874	long range
0.8039604553	convolution layers
0.8038801673	retinal fluid
0.8038747364	computational costs
0.8036714296	short term memory
0.8035906056	disentangled representations
0.8035878968	video sequences
0.8035318676	deep convolutional neural networks
0.8033182769	speech separation
0.8028587490	face verification
0.8027953830	path planning
0.8026734626	cardiac cine mri
0.8026424126	mode decomposition
0.8026302378	visual tracking
0.8026221534	multi path
0.8025311821	acceleration factors
0.8025060013	respiratory motion
0.8024515713	coherence tomography
0.8022888089	spatio spectral
0.8022187796	eye tracking
0.8020934044	transparent objects
0.8019561364	manual annotations
0.8019558926	network architecture
0.8019175165	adaptive optics
0.8012588477	low dynamic range
0.8011584469	skeleton based action recognition
0.8010843094	video quality assessment
0.8009920114	cost effective
0.8009350411	gradient penalty
0.8008032728	median filter
0.8007942425	multi exposure image fusion
0.8007437584	mr image reconstruction
0.8005373670	safety critical
0.8004978201	hyper parameter
0.8004770735	cardiovascular diseases
0.8003884890	convolutional autoencoder
0.8002204756	crack detection
0.8001988480	adaptive weighting
0.7999285714	organs at risk
0.7998908067	masked face
0.7996398196	total variation regularization
0.7994595952	scene flow
0.7993588547	color difference
0.7991985345	mouse brain
0.7990409603	image inpainting
0.7989570400	gradient echo
0.7988281365	video quality
0.7987817499	convolutional networks
0.7985915603	significantly improves
0.7985011424	pre processing
0.7984094007	superior performance
0.7982989563	high spatial resolution
0.7982910265	video codec
0.7982002702	entropy coding
0.7980154990	spatial resolution
0.7979979212	human body
0.7979633611	perceived quality
0.7978120989	action unit
0.7977645566	screening mammography
0.7974220590	blood cells
0.7973755827	retinal fundus images
0.7973238963	single frame
0.7970230341	rate control
0.7969184397	basis functions
0.7968680866	starting point
0.7967282049	pixel level
0.7966170415	pet ct
0.7965399156	high accuracy
0.7962604876	surgical planning
0.7960743543	graph signal processing
0.7959717097	landmark localization
0.7959024800	multi centre
0.7957609166	patch based
0.7957187134	eeg signals
0.7956241958	coherent diffraction imaging
0.7955025148	generalization capability
0.7954390119	blood cell
0.7953626453	sampling rate
0.7950690883	biomedical image analysis
0.7946443385	cell nuclei
0.7945794924	noise levels
0.7943548793	discriminant analysis
0.7941920025	extensive experiments
0.7941398009	block matching
0.7940768501	tensor train
0.7938646796	focal loss
0.7938419362	deformation fields
0.7938138212	forgery detection
0.7937863608	medical diagnosis
0.7935201775	fully convolutional network
0.7933858134	holographic microscopy
0.7933271897	artifact free
0.7933225402	structural information
0.7933015230	objective functions
0.7931036606	building blocks
0.7930590023	binary classification
0.7929530241	visual inspection
0.7927405858	autism spectrum
0.7926513716	multi institutional
0.7925680583	source domain
0.7925575294	event driven
0.7925469208	moving objects
0.7925308948	micro ct
0.7925256662	label free
0.7924760607	severe acute respiratory
0.7923274817	conditional generative adversarial network
0.7922224733	image translation
0.7920587999	medical image registration
0.7918948956	faster convergence
0.7917875073	reverse transcription polymerase
0.7916388481	convolution neural networks
0.7915408567	speckle pattern
0.7914671623	receiver operating characteristic curve
0.7910987510	motion corrected
0.7910097864	randomly selected
0.7909901083	image classification
0.7907799286	intra observer
0.7905816201	breast cancer screening
0.7905031653	locally linear
0.7904331525	stereo vision
0.7903210801	multi dimensional
0.7899393222	patient specific
0.7898224802	level co occurrence matrix
0.7898032060	training set
0.7897333393	high quality
0.7897124580	intra class
0.7896380431	inception distance
0.7896250003	general purpose
0.7895866631	benchmark datasets
0.7895557009	gaussian distribution
0.7894896478	past decade
0.7894006560	gait recognition
0.7893520902	saliency prediction
0.7889633797	multi class
0.7888800968	mask r cnn
0.7888740777	quantitative phase
0.7885271707	piece wise
0.7882892377	similarity measure
0.7882806847	recent studies
0.7878907286	similarity coefficient
0.7876801854	unlabeled data
0.7876413919	contrastive learning
0.7873592505	image formation
0.7872244326	functional magnetic resonance imaging
0.7871633448	resource constrained
0.7869072967	pre trained
0.7864544024	spectral variability
0.7864273585	saliency map
0.7864162513	feature pyramid
0.7863386526	models genesis
0.7862448093	incremental learning
0.7862347334	biomedical image segmentation
0.7858383589	patch wise
0.7857941699	high level semantics
0.7855900139	smartphone camera
0.7853840855	conditional generative adversarial
0.7853205195	power spectrum
0.7853016129	lidar point cloud
0.7850014097	fake face
0.7849747051	experimental results confirm
0.7849632530	memory efficient
0.7848994068	video frame
0.7846726204	cycle consistency loss
0.7841809466	parameter selection
0.7841273033	semi automated
0.7839235184	evolutionary algorithm
0.7839200390	infected regions
0.7838624179	post processed
0.7836776993	microscopic images
0.7833943658	inter class
0.7831765679	cerebral blood
0.7831524975	prior art
0.7829889636	intel
0.7829723510	picture quality
0.7821536832	newly developed
0.7820453547	high sensitivity
0.7815827142	illumination pattern
0.7815087331	biological samples
0.7814352821	breast tomosynthesis
0.7811386082	physics based
0.7810223817	bias field
0.7809951578	multitask learning
0.7809632936	recent developments
0.7808479600	outcome prediction
0.7807926936	hardware friendly
0.7803427724	element wise
0.7802961459	cancer genome
0.7802717051	low complexity
0.7800420593	ultrasound images
0.7799976064	achieved great success
0.7799612431	meta learning
0.7797477940	low dose computed tomography
0.7796922234	objective quality metrics
0.7795050952	single pixel
0.7793806143	disparity map
0.7790374225	gaze estimation
0.7789076502	bernoulli
0.7789076502	microsoft
0.7788301949	high frame rate
0.7788178093	computational efficiency
0.7786677045	optical microscopy
0.7785080823	deep generative models
0.7785040556	prior knowledge
0.7783553470	numerical experiments
0.7782596421	graph laplacian
0.7782460776	environmental conditions
0.7782381157	spectral bands
0.7780743624	dual energy ct
0.7779543448	phase shift
0.7779506068	quantitative phase imaging
0.7778210499	maxwell
0.7777509412	carefully designed
0.7777324114	coherent diffraction
0.7776950403	space exploration
0.7776810972	channel wise
0.7775147024	human pose estimation
0.7774695705	pls net
0.7774656687	landsat
0.7774225993	tikhonov
0.7773918136	africa
0.7773682260	uv
0.7771741242	visual object tracking
0.7771550245	stanford
0.7769406536	deep unfolding
0.7769075931	memory requirements
0.7768256800	residual dense
0.7767567222	retinal fundus
0.7767331813	low rank property
0.7766604497	image dehazing
0.7763063404	anchor free
0.7760604172	kidney tumor segmentation
0.7760026366	markov random
0.7757744686	multimodal brain tumor
0.7756730774	pair wise
0.7756649164	correlation coefficients
0.7755662234	multi source
0.7755597904	discrete fourier
0.7754750507	false negative rate
0.7751118139	precision recall
0.7749727602	gray level
0.7749585614	end users
0.7748654628	dynamic contrast enhanced
0.7748227458	computed tomography angiography
0.7747224061	tesla
0.7744966883	cine mri
0.7743610955	key points
0.7742315369	iso
0.7739939990	spectral domain
0.7738217704	wasserstein generative adversarial
0.7733586247	coding efficiency
0.7733018697	nvidia
0.7732882418	empirical study
0.7731618815	early diagnosis
0.7728759188	dilated convolution
0.7728630632	cycle gan
0.7724417072	experimental results
0.7723672317	skin lesion segmentation
0.7720874352	diffractive optical
0.7716454709	spatial transformer
0.7716044397	european
0.7715691873	jacobian
0.7715628648	lr hr
0.7712613014	target domain
0.7711817268	birds
0.7710148083	handcrafted features
0.7710126456	fully annotated
0.7708450998	panoptic segmentation
0.7707093130	ccd
0.7706909648	radon
0.7706902031	aperture radar
0.7702079143	natural images
0.7700739413	manual annotation
0.7699842689	minimization problem
0.7698289995	shown promise
0.7696989028	cauchy
0.7696492543	high precision
0.7695408893	cutting edge
0.7692894562	programmable gate
0.7692311133	object detector
0.7692166188	significantly outperforms
0.7691225148	hilbert
0.7691162372	hyper parameters
0.7690337439	lidar point clouds
0.7689195775	data science
0.7686376667	differential diagnosis
0.7685695785	multi level
0.7685381009	activation maps
0.7684871063	ge
0.7684721351	dual energy
0.7683852546	dice scores
0.7682601585	similarity metric
0.7682401485	brain atlas
0.7681923770	domain specific
0.7681517326	video codecs
0.7680275698	graph convolutional networks
0.7680145105	deepfake detection
0.7679857158	turing
0.7679173568	bipartite
0.7678104617	hamming
0.7676933429	localization microscopy
0.7676124514	human activity recognition
0.7676035306	qr
0.7675130431	wasserstein gan
0.7674282142	kidney tumor
0.7673037765	missing modalities
0.7670892335	limited view
0.7670382148	scene text
0.7669347946	future research
0.7666689019	retinal oct
0.7665391876	gibbs
0.7665243478	fisher
0.7664830275	tropical
0.7664810334	diagnostic tool
0.7664017323	multi task
0.7663693304	jointly optimize
0.7663387058	wheat
0.7663335633	denoising autoencoder
0.7661604561	convolutional autoencoders
0.7660628613	temporal resolution
0.7656139600	delay and sum
0.7655919982	multi task learning
0.7655809349	comparative analysis
0.7655458988	higher quality
0.7654892389	layer wise
0.7654180109	illumination patterns
0.7653616062	geophysics
0.7652786216	institute
0.7650359163	conduct extensive experiments
0.7650092297	matters
0.7647994209	chest x ray
0.7647296924	vehicle detection
0.7646358709	italy
0.7646224373	signal recovery
0.7646165849	spiking neural network
0.7645901508	rate distortion optimization
0.7645721943	avc
0.7644663211	ball
0.7644473106	image pairs
0.7643668418	teaching
0.7643660046	ntire
0.7643383205	single stage
0.7643191515	isotropic resolution
0.7642543413	chain reaction
0.7640843645	embedded systems
0.7639518214	inverse scattering
0.7636738140	genesis
0.7636292096	motion artefacts
0.7635492911	pareto
0.7634781090	graph convolution
0.7634601322	hand pose
0.7632576545	raman
0.7631016293	step size
0.7630242305	hyperspectral imaging
0.7629279572	subject specific
0.7627085692	inter frame
0.7624744946	dimension reduction
0.7624472416	affective
0.7620383208	esophageal
0.7620010963	tumor core
0.7619667468	wasserstein gans
0.7618324383	clinical routine
0.7616463666	nyquist
0.7615485217	intra coding
0.7614779392	space variant
0.7611279827	theta
0.7610888967	high order
0.7607196010	brain mris
0.7607019209	visual slam
0.7606202451	remains challenging
0.7603345049	region growing
0.7596715559	high performance
0.7596466205	lagrangian
0.7596462402	fewer parameters
0.7596138572	video clip
0.7595923783	gaussian mixture model
0.7595591158	aerial images
0.7594701593	multi contrast
0.7594143065	low delay
0.7593283665	significantly improve
0.7591482250	highly accurate
0.7591185546	unrolled network
0.7590785653	cnn based
0.7590665081	imbalanced data
0.7590599653	probability distribution
0.7589732011	faster r cnn
0.7587792555	comparative study
0.7586327402	age estimation
0.7585343239	late fusion
0.7583831788	body pose
0.7583683454	mixed precision
0.7582785093	cartesian
0.7582058347	soft tissues
0.7581219118	education
0.7579832501	deep convolutional neural network
0.7579467077	mnist dataset
0.7579111300	informatics
0.7578991817	github
0.7578664077	laplace
0.7578103182	google
0.7577492850	anterior
0.7576549556	chest x rays
0.7573575464	san
0.7573425969	additive white
0.7573147453	fresnel
0.7572807420	detachment
0.7569519181	gpu accelerated
0.7568901864	sars cov
0.7567679826	convolution layer
0.7567604890	pleural
0.7567318343	machine learning techniques
0.7566308452	acid
0.7566014957	disease diagnosis
0.7565936660	covid net
0.7565670122	generative model
0.7561361748	memory effect
0.7560138232	polar
0.7559155579	amazon
0.7558242511	complex scenes
0.7557138405	computational overhead
0.7556389618	gauss
0.7556249604	significantly improved
0.7555681954	national
0.7555480824	orbital
0.7554977013	saliency detection
0.7554247704	results suggest
0.7552542523	compact representation
0.7550523870	visual quality
0.7547461350	spatial spectral
0.7545331019	force estimation
0.7544137983	gas
0.7543343441	abdominal ct
0.7542509325	license
0.7540549834	dust
0.7539342055	long range dependencies
0.7538526355	plate
0.7538181353	pancreatic
0.7536236039	osteoarthritis
0.7535635409	lung nodule detection
0.7535591670	rads
0.7534515049	motion capture
0.7533807666	healthy subjects
0.7533469813	cross view
0.7531968534	multi stage
0.7531625006	acquisition times
0.7530935582	preliminary results
0.7529520566	rate adaptation
0.7529139092	structured low rank
0.7527794827	multi layer
0.7525445500	audio visual speech
0.7523721169	initiative
0.7521535545	autism
0.7521196139	video content
0.7516909030	degenerative
0.7515908536	matting
0.7515032115	edge detector
0.7515020777	cognitive impairment
0.7514934225	quantitative susceptibility
0.7514607575	lifelong
0.7514380843	gps
0.7513640061	iterative phase retrieval
0.7513300875	bank
0.7512180897	free electron
0.7510490793	jaccard
0.7510258943	valuable tool
0.7509980000	shot noise
0.7509564037	interferometer
0.7509564037	earthquake
0.7509564037	pore
0.7509564037	exit
0.7509564037	loose
0.7507764181	relational
0.7507262966	spline
0.7504880964	imaging modality
0.7504633337	fitness
0.7503724907	closed form solution
0.7503684935	video surveillance
0.7503500757	computing resources
0.7502768882	feature map
0.7502303078	pedestrian detection
0.7501717510	brain activity
0.7501629384	packet
0.7501629384	cultural
0.7501305043	knee mri
0.7500752417	dice overlap
0.7499975858	synchrotron
0.7498697537	brain tissues
0.7497632008	require large amounts
0.7494271607	survival rate
0.7494166441	indian
0.7491812547	fastmri
0.7490827267	grey
0.7490625160	perform poorly
0.7490319966	rock
0.7490185987	galaxy
0.7489714249	pre defined
0.7489071459	epilepsy
0.7488004204	prostate segmentation
0.7487486221	high dimensionality
0.7486906172	le
0.7486521259	mpeg
0.7486174470	significant differences
0.7485574426	low latency
0.7484943568	telescope
0.7484919862	carbon
0.7483328576	l2
0.7481594964	vector machine
0.7481478030	pearson
0.7480402261	peak signal to noise ratio
0.7477903640	siamese network
0.7477297206	scale invariant
0.7475167176	objective function
0.7472598012	gaussian process
0.7471066880	major challenges
0.7470505054	exchange
0.7469955487	intra prediction
0.7469045104	data mining
0.7469013531	reinforced
0.7468716300	pci
0.7466063544	visual inertial
0.7465382266	attention based
0.7465312191	noisy labels
0.7462613152	emitting
0.7462492349	neuro
0.7460491286	interpolated
0.7460214103	hip
0.7458950999	significantly reduces
0.7458335106	auto encoding
0.7458184311	laparoscopic
0.7458106068	lookup
0.7457806017	genome
0.7457351283	feature aggregation
0.7457192301	dce mr
0.7456412365	voxel level
0.7456082604	age related macular
0.7455227610	histology images
0.7455089139	spread function
0.7454617619	spectral ct
0.7454084757	carotid
0.7452457503	expression recognition
0.7452192090	graph reasoning
0.7451863366	promising results
0.7451657831	processing units
0.7451604417	significant progress
0.7451465696	gp
0.7451451949	panoptic
0.7450384229	learned video compression
0.7449540829	plane wave
0.7449407060	t1 mapping
0.7449196395	image encryption
0.7448798687	highly accelerated
0.7446662552	brain tissue
0.7446366965	alternating direction method of multipliers
0.7446169624	ego motion estimation
0.7445305006	cyclone
0.7444695255	object tracking
0.7443948177	lidc
0.7442956834	integer
0.7442932764	simulating
0.7442929798	highly correlated
0.7442322060	pls
0.7441283926	cyclic
0.7440247260	bilinear
0.7439714606	radiomics features
0.7438299513	compressed videos
0.7435570913	choroid
0.7435160855	hough
0.7433818689	wgan
0.7433675455	microwave
0.7433398485	adenocarcinoma
0.7432665753	report generation
0.7432505418	stroke lesion segmentation
0.7432086979	graph convolutional network
0.7428790980	macular degeneration
0.7428360348	feature vectors
0.7427310731	deep convolutional
0.7427241457	automotive
0.7427202146	high contrast
0.7425893854	stroke lesion
0.7425008467	uk
0.7424304420	cloud detection
0.7422288393	representation learning
0.7421818029	image pair
0.7421241087	golden
0.7421241087	algebraic
0.7420331364	single photon lidar
0.7419890292	lung diseases
0.7419457469	glioblastoma
0.7419163103	piano
0.7418883424	pascal
0.7418686583	consecutive frames
0.7418261742	visual cues
0.7418142834	mini
0.7417202500	multi resolution
0.7416381707	panoramic
0.7416080048	agriculture
0.7415849736	hole
0.7415849736	blended
0.7415578846	painting
0.7414669322	lower resolution
0.7413323933	transmission map
0.7412853208	imaging systems
0.7411868892	bokeh
0.7411467435	times faster
0.7409191368	image matting
0.7408417383	brain mri scans
0.7407770644	outer
0.7407389679	characteristic curve
0.7406952750	adversarial network
0.7406733438	probability maps
0.7405363211	scene understanding
0.7404478596	standing
0.7402983533	forgery
0.7401054868	computation cost
0.7400938346	fibrosis
0.7399206729	centre
0.7397816041	physical properties
0.7397773854	rib
0.7397483788	iterative algorithms
0.7395352408	glaucoma detection
0.7395024219	poisson
0.7394741693	complementary information
0.7394258769	terrasar x
0.7392233125	adopting
0.7392030398	component analysis
0.7391359251	prenatal
0.7390252866	market
0.7390109217	previously proposed
0.7390036884	parameter sharing
0.7389703280	velocimetry
0.7389512701	mechanics
0.7387076034	noise ratio
0.7386934599	spiking
0.7386783221	transmission electron
0.7386545735	words
0.7385796922	dw
0.7385169936	simultaneous localization and mapping
0.7385018037	architecture search
0.7384754611	gland segmentation
0.7384247856	imu
0.7381813323	shape priors
0.7381433858	retrospective study
0.7381166647	activation function
0.7378916084	lensless imaging
0.7377797868	feature refinement
0.7377372463	vq
0.7376349383	competitive performance
0.7375430551	hemorrhage
0.7374963723	output layer
0.7374566146	tomographic imaging
0.7374540686	liquid
0.7374109729	pyramid pooling
0.7373811839	multimodal fusion
0.7373679270	spatial information
0.7372631382	pi
0.7372508272	bubble
0.7369477139	image stitching
0.7369119285	markov
0.7369095654	residual learning
0.7367014840	fourth
0.7366883378	image deblurring
0.7365749302	recently published
0.7365668778	nonnegative
0.7363575268	level set
0.7361030827	chemical shift
0.7360692213	fluorescein
0.7357675342	sliding
0.7357319699	gpr
0.7356660343	multitask
0.7354680182	delta
0.7354196496	local binary
0.7351770593	gpu memory
0.7348813604	covariance
0.7348495916	intra observer variability
0.7347784383	parkinson
0.7347394763	abnormality detection
0.7347220522	dna
0.7346773529	plasticity
0.7344729490	invasive surgery
0.7343211413	significantly reduce
0.7343073069	domain gap
0.7341413802	data acquisition
0.7340745019	sparse view
0.7340479967	training strategy
0.7340371508	nuclei segmentation
0.7337982701	cortex
0.7336532235	task specific
0.7334606770	comprehensive survey
0.7334272261	sea
0.7334231314	gamma
0.7333146209	voc
0.7332938699	vision sensor
0.7332903390	labeled data
0.7332320604	roc curve
0.7332134765	combinatorial
0.7331536594	oral
0.7331387370	spectral resolution
0.7330993052	spatially adaptive
0.7329331392	diffraction limited
0.7328565001	spect
0.7327914425	compressive imaging
0.7326290077	light weight
0.7326043373	diode
0.7325797120	count pet
0.7325480441	angular resolution
0.7324813015	bird
0.7323006281	context encoding
0.7322116402	independent test set
0.7321631072	model based iterative reconstruction
0.7321582174	significant improvements
0.7320702011	ablation study
0.7320186634	cone beam computed
0.7319370921	low quality
0.7318126271	fully convolutional neural networks
0.7318099996	max
0.7317219043	contrastive
0.7316572628	signal to noise ratio
0.7315657635	previous studies
0.7315336533	blood vessel segmentation
0.7314307425	r2
0.7310792959	parkinson's
0.7309389049	communications
0.7309389049	epithelial
0.7309141714	gadolinium enhanced
0.7306016573	acceleration factor
0.7305924787	projective
0.7304193974	vfa
0.7302134338	sensed
0.7302128322	penetrating
0.7301914641	hausdorff
0.7300902299	hadamard
0.7300770132	wasserstein
0.7299770794	gan generated
0.7299221790	sigmoid
0.7299100444	artificial neural
0.7298834579	trial
0.7298099868	depth maps
0.7297811746	encoder decoder architecture
0.7297371396	intracranial
0.7297186096	pooling layer
0.7296158443	reference frame
0.7295724341	intensive care
0.7294508520	land cover classification
0.7292844248	dehazing
0.7292666432	unsupervised anomaly
0.7290515490	evolutionary
0.7289467911	persistent
0.7289110884	computerized
0.7288835445	integrity
0.7287821306	statistical shape
0.7287693974	bcd
0.7287120159	isic
0.7284944743	multilayer
0.7283659560	pre training
0.7283420349	multi organ segmentation
0.7283213552	endoscopic images
0.7281443370	semi supervised learning
0.7281260403	clip
0.7279814057	stereoscopic
0.7278137883	monocular camera
0.7277675993	low rank matrix
0.7276220712	spectral sensitivity
0.7275836148	source camera
0.7273376658	nr
0.7270713160	image completion
0.7270693046	test sets
0.7270273487	zoom
0.7270097547	probability map
0.7269918322	sars cov 2
0.7269768410	multi frame
0.7268856221	molecule localization
0.7267134267	ganglion
0.7262749603	gaussian filter
0.7260832303	tuberculosis
0.7259130048	neighbor
0.7258673829	odometry
0.7258672601	motion vector
0.7258658479	breast ultrasound
0.7258652716	triplet
0.7257896009	high level
0.7257817141	high density
0.7255173915	engine
0.7255047237	spatial frequency domain
0.7254846961	cochlear
0.7253936019	sars
0.7253603299	syndrome
0.7253066099	laplacian
0.7251771159	high frequency components
0.7251164941	kalman
0.7251044773	spatial location
0.7250790812	cs mri
0.7250720766	fish
0.7250704533	kappa
0.7249773627	fuzzy
0.7249451782	momentum net
0.7248678453	optical imagery
0.7248634292	image stacks
0.7247914480	china
0.7247242969	density estimation
0.7246982338	university
0.7245217305	circuits
0.7244534422	observer variability
0.7244046696	apple
0.7243755971	necrosis
0.7243755971	stratified
0.7243708345	stitching
0.7243255341	mri sequences
0.7242417461	thyroid
0.7242038893	cam
0.7240990775	low dimensional manifold
0.7240614580	principal components
0.7239222096	watermarking
0.7238363513	esophagus
0.7238363513	glomerular
0.7238363513	soil
0.7238363513	synchronization
0.7237447785	vector machines
0.7236310808	fetal mri
0.7235698548	binocular
0.7234907688	widely applied
0.7234331835	multi spectral
0.7231168137	python
0.7230720236	vgg
0.7230467933	mean square error
0.7228544521	l_
0.7228426402	preterm
0.7227806066	mixture model
0.7227626276	multiplexing
0.7227544617	graphical
0.7227129051	partial volume
0.7226013224	lung segmentation
0.7224634265	newton
0.7224185333	image watermarking
0.7222043909	cycle consistent adversarial
0.7221122314	point cloud compression
0.7221065453	human action
0.7219406301	human experts
0.7217623394	inertial
0.7217193966	emotion
0.7216843487	reversible
0.7216587679	point wise
0.7216339336	lattice
0.7215915537	existing works
0.7215718156	canonical
0.7215657564	dual domain
0.7215073804	walk
0.7215073804	app
0.7214396018	equilibrium
0.7213815598	mechanical properties
0.7213799899	bd
0.7213544098	breast tumor
0.7212688424	snow
0.7211706018	low level
0.7211043547	l2 loss
0.7208417310	photonic
0.7207939694	parallel mri
0.7207552290	surveillance videos
0.7207535430	similarly
0.7207072837	single pixel imaging
0.7206510700	desirable properties
0.7206085552	cov
0.7205843224	discussion
0.7205629004	generating realistic
0.7205457237	persistence
0.7205194692	activation mapping
0.7205169197	performance drop
0.7204686774	real world scenarios
0.7202862776	exploring
0.7202813493	routing
0.7202749683	sparse view ct
0.7202684248	acdc
0.7200804165	agnostic
0.7199537888	epi
0.7199326047	multi domain
0.7199315059	stereo matching
0.7198750424	car
0.7197241564	euclidean
0.7196381574	idri
0.7196138151	vein
0.7195739506	monocular depth
0.7195165451	mr imaging
0.7195089000	single modality
0.7194536141	melanoma
0.7194252140	tube
0.7194083878	digital image
0.7193478329	accelerated mri
0.7192405302	prnu based
0.7192379134	fr
0.7191202247	diffractive imaging
0.7191037820	increasingly popular
0.7190921390	low snr
0.7190166383	transformer
0.7189842157	unpaired training
0.7187158538	road surface
0.7186736583	recursive
0.7184468341	human pose
0.7182634030	pixel size
0.7181646723	training data
0.7181328695	statistical model
0.7181058300	rankness
0.7179603969	multiple scales
0.7177013435	head motion
0.7175933609	alarm
0.7175398237	multi planar
0.7175204583	doppler
0.7175039939	liver segmentation
0.7174797234	multi sensor
0.7173724157	coco
0.7172940222	deep learning techniques
0.7172425182	arm
0.7171314090	lobe
0.7169809196	climate
0.7169048160	mean squared error
0.7167935499	endoscopic
0.7167396933	colorization
0.7167325414	omnidirectional
0.7166965918	multi organ
0.7166865712	spatial attention
0.7166442741	experimental evaluations
0.7166331637	lymph
0.7166192159	ldr
0.7164210728	highly flexible
0.7164209872	image editing
0.7163577667	rate distortion performance
0.7162609330	mris
0.7162196787	squeeze and excitation
0.7161805169	profilometry
0.7160366063	diabetes
0.7159914721	lip
0.7159142064	diffusion weighted magnetic
0.7158197635	shear
0.7158148721	palm
0.7158128002	brats
0.7157135608	digital cameras
0.7156621852	attention mechanisms
0.7155942835	gaze
0.7153825414	quantum
0.7153538000	versatile
0.7153395728	inversion recovery
0.7152189850	cervical
0.7151694102	web based
0.7150850630	shearlet
0.7150791794	beginning
0.7150617496	reverse
0.7148941993	rcnn
0.7148691161	cosine
0.7147718877	airborne
0.7146997161	coronavirus disease 2019
0.7146013949	cardiac magnetic resonance imaging
0.7145622277	single image
0.7144112699	momentum
0.7143066902	electromagnetic
0.7142944962	gpr data
0.7139951269	hyperspectral image classification
0.7139268128	practical applications
0.7138458518	degrees of freedom
0.7138084679	pixel level annotations
0.7136520048	multi stream
0.7136370000	aggregation network
0.7136274317	salt and pepper
0.7135689014	human connectome
0.7134822879	animation
0.7134126061	camera calibration
0.7134125065	power lines
0.7133530772	spinal
0.7133469465	spatial context
0.7132796045	spot
0.7132160441	modular
0.7132102098	color space
0.7130535767	pixel values
0.7129949311	vision based
0.7129793485	pedestrian
0.7129068539	great potential
0.7128547885	ovarian
0.7127691329	l1
0.7126837888	smear
0.7126484903	polyp segmentation
0.7122946825	cell tracking
0.7122743621	wavelet domain
0.7122232569	paper presents
0.7122104154	air
0.7121724573	convergence rate
0.7121315924	imaging biomarkers
0.7120841018	bidirectional
0.7118585746	chest computed
0.7118446579	sphere
0.7118011209	cranial
0.7113355893	sustainable
0.7112982525	specially
0.7112463064	biobank
0.7111909512	beta
0.7111345290	explainable
0.7110910670	mnist
0.7107688988	femur
0.7107688988	compromising
0.7107533774	domain generalization
0.7106749012	flow field
0.7104206318	seismic data
0.7103636086	biological tissues
0.7103314583	multispectral images
0.7103146228	learning based
0.7102906683	hospital
0.7102901992	multi echo
0.7102531117	muscular
0.7102035069	t_1
0.7101533576	greedy
0.7101186336	earth
0.7100661427	thresholding algorithm
0.7095565690	fidelity term
0.7095118473	fleet
0.7094941821	accordance
0.7094818227	hyperspectral data
0.7094456207	experimental evaluation
0.7094098663	orbit
0.7094098663	silver
0.7093289993	trainable parameters
0.7093266123	dynamic mr
0.7093012523	proton
0.7090925999	impressive performance
0.7089685409	artifacts removal
0.7089412073	metric learning
0.7088572630	attribution
0.7087753266	wireless
0.7087237845	attention maps
0.7087139006	discriminant
0.7084708232	low frequency
0.7084393524	fpga
0.7084362168	user generated
0.7084326871	omnidirectional images
0.7082305051	ensembles
0.7082035069	cohen's
0.7082011659	dermoscopic
0.7081793488	tomography angiography
0.7080283507	mr scans
0.7079432827	lge
0.7079372137	apps
0.7079372137	crystalline
0.7078930776	sparse representations
0.7078571897	topography
0.7078505047	lge mri
0.7077104000	tissue types
0.7074887469	bi
0.7073002233	elastography
0.7072559663	diffusion weighted magnetic resonance
0.7072508870	public datasets
0.7071825457	fully unsupervised
0.7070538156	roll
0.7069583338	rho
0.7069544488	b1
0.7068178987	ophthalmology
0.7067339782	neural nets
0.7066534213	classification tasks
0.7065935819	hand crafted features
0.7064785314	manually segmented
0.7064486939	t2
0.7063707777	prnu
0.7063053872	target tracking
0.7061874633	grad
0.7061508755	organ segmentation
0.7060141181	extensive experiments demonstrate
0.7060106490	iterative optimization
0.7060028250	diagrams
0.7059208473	recurrent neural
0.7058611364	gate
0.7058023859	disjoint
0.7057927352	solar
0.7057371943	mri scan
0.7056948841	jpeg 2000
0.7056748646	siamese
0.7056706584	bag
0.7056111383	optical properties
0.7053766619	magnetic resonance images
0.7053714482	roc
0.7052430189	l_2
0.7052226833	irradiance
0.7051977575	stroke patients
0.7051961575	acquisition scheme
0.7051569233	brain imaging data
0.7050019035	ptychographic
0.7048737578	suite
0.7048034705	united
0.7045949693	valve
0.7045871691	deep convolutional neural
0.7045746073	clinical utility
0.7045418498	jointly trained
0.7043835662	sign
0.7043064903	generative modeling
0.7042937597	activity detection
0.7042611563	c arm
0.7042405884	intensity values
0.7042202890	universal
0.7041993888	sigma
0.7041929330	high frequency details
0.7041086842	additive white gaussian
0.7040557899	ir
0.7040142128	deepfake
0.7039513359	compressed video
0.7039264039	slam
0.7039030969	federated
0.7037611746	driver
0.7036905302	double
0.7036762464	hypertension
0.7036762464	games
0.7035845829	grand
0.7035824603	answering
0.7034684628	smartphone
0.7034636834	bearing
0.7033667321	motor
0.7033479273	multi center
0.7032682204	pan
0.7031318863	clinical translation
0.7031131215	da
0.7029640507	alpha
0.7029251197	glass
0.7028732610	autoencoders
0.7028617567	nodule detection
0.7028578963	speckle reduction
0.7028213024	multi object tracking
0.7026530543	ego
0.7025431685	intelligent
0.7025390879	research topic
0.7025335817	quantitative metrics
0.7025219999	psf
0.7024960880	attributed
0.7024189549	printing
0.7023196803	previously reported
0.7022216137	ci
0.7022156140	processing pipeline
0.7022103121	cord
0.7021502392	traumatic
0.7019390199	compression rates
0.7019058008	chromatic
0.7018256323	spine
0.7017114234	gastrointestinal
0.7016311141	polymerase
0.7015989979	compaction
0.7015173631	relevance
0.7015150667	imagenet
0.7014564742	hardware implementation
0.7014235323	emphasis
0.7013642586	puck
0.7013278124	cbct
0.7012787914	jpeg
0.7012591154	multi parametric
0.7012568370	depth range
0.7011428420	vulnerable to adversarial attacks
0.7010056734	isic 2017
0.7009536521	multiple instance
0.7008786197	transform coding
0.7007053606	internet
0.7006007040	fluid attenuated
0.7005856615	valuable information
0.7005399218	image quality metrics
0.7004399116	patient level
0.7002204494	perceptron
0.7001400741	testing set
0.7001163443	impressive results
0.7000746640	adjacency
0.7000746640	pigment
0.7000069865	eventually
0.6999913998	dynamic contrast enhanced magnetic
0.6999779592	eeg
0.6999546185	challenged
0.6999546185	ion
0.6999219927	crystal
0.6998115750	texture details
0.6997656813	retinopathy
0.6996714266	hematoxylin and eosin
0.6996412756	b spline
0.6995941292	bladder
0.6995941292	systolic
0.6995542151	performance gain
0.6994946026	edge aware
0.6994493242	kitti
0.6994222773	intake
0.6993184692	iron
0.6991948502	check
0.6991824802	harmonic
0.6991705079	histopathological
0.6991682070	face detection
0.6991262025	dot
0.6988011914	filtered
0.6987812507	graph based
0.6986720202	echet inception
0.6985466687	taking into account
0.6984896212	gesture
0.6984127640	satisfaction
0.6984127640	bounded
0.6984127640	permanent
0.6984127640	cumulative
0.6984114278	presentation
0.6982993527	cmr
0.6982736836	pre processing step
0.6982324387	inception
0.6982315331	topology
0.6981202252	pet reconstruction
0.6980918690	energy efficient
0.6980709901	deformable
0.6980261222	lv
0.6979441257	forecasting
0.6979395625	spatial relationship
0.6979192546	prediction error
0.6977796199	diffusion weighted mri
0.6977755647	forests
0.6977446221	reverse transcription polymerase chain
0.6977357716	gestational
0.6975476508	spherical
0.6975211309	grappa
0.6975211309	usa
0.6975044807	multiplication
0.6975030416	interface
0.6974886399	ice
0.6974378140	assistant
0.6974100547	recently introduced
0.6972844367	f1
0.6972276713	alzheimer's
0.6972070136	lf
0.6971969214	disentangled
0.6970904026	impulse
0.6970826032	quantifying
0.6970311141	accounting
0.6967883079	computational photography
0.6967694033	t1
0.6967145787	monocular
0.6966629642	dw mri
0.6964554590	inter prediction
0.6964511035	streak
0.6963809871	annotated dataset
0.6962862380	fisheye
0.6962831418	extensive experimental results
0.6962106741	widely studied
0.6962088656	equalization
0.6961745640	wearable
0.6959444044	distillation
0.6958846741	bacterial
0.6958135043	radiograph
0.6957262867	ntire 2020 challenge
0.6956779006	tandem x
0.6956617081	red
0.6954680894	tz
0.6954680894	cac
0.6954680894	nc
0.6954680894	cbv
0.6954680894	acs
0.6954680894	cn
0.6954680894	tpm
0.6954680894	gru
0.6954680894	rsa
0.6954680894	lbp
0.6952896382	multi instance
0.6952700844	express
0.6951650159	impedance
0.6949650401	image retrieval
0.6949486915	octa
0.6949204546	unmanned
0.6949139613	fps
0.6948824324	human action recognition
0.6948820537	assessing
0.6947860485	deep residual
0.6945716205	digital image processing
0.6945403374	progressive
0.6944087070	relation
0.6943510050	interval
0.6942592947	dce
0.6942444368	suitability
0.6942099589	acute
0.6941407890	ground truth labels
0.6941304661	outstanding performance
0.6940836951	performance improvement
0.6939669985	data augmentation techniques
0.6939275024	bipolar
0.6938586831	kitti dataset
0.6938182177	histogram
0.6938149886	cifar
0.6937537241	small size
0.6936794034	sne
0.6936794034	aa
0.6936794034	nl
0.6935463456	cascade
0.6935343451	functional brain
0.6934969858	spectral clustering
0.6933392826	slide images
0.6932674935	ptychographic microscopy
0.6932544273	congenital
0.6932189361	dermoscopic images
0.6931934759	nonnegative matrix
0.6931707905	cardiac image segmentation
0.6931211503	coupled
0.6930886073	existing methods
0.6930001271	affine
0.6928537441	multi exposure
0.6928462759	image colorization
0.6928296408	lidar data
0.6926409142	voice
0.6926276728	qista
0.6926204900	smart
0.6925715522	inter subject
0.6925164180	infrared
0.6923336788	fdk
0.6923336788	idh
0.6923006906	leveraging
0.6922763893	comparable performance
0.6922158190	multivariate
0.6922158190	analytics
0.6921101678	nets
0.6920368194	aorta
0.6920142776	collaborative
0.6919608192	film
0.6918587220	highly realistic
0.6917642341	excellent performance
0.6917459996	lightweight
0.6915719771	shown great potential
0.6915466522	recently emerged
0.6915357710	endoscopy
0.6915255934	radiologist level
0.6914452484	tendon
0.6914452484	electronics
0.6914362875	marine
0.6914362875	ecosystem
0.6914362875	immune
0.6913659755	edema
0.6912984714	theoretical analysis
0.6912745090	augmentation techniques
0.6912417532	experimental results demonstrate
0.6912218617	hevc
0.6910868199	completion
0.6910780465	regression model
0.6910356320	cross validated
0.6910280581	rt
0.6909531593	graphical user
0.6909455670	class specific
0.6906802514	coronavirus
0.6906496730	streaming
0.6905603728	performance evaluation
0.6905383871	sram
0.6905383871	caipi
0.6904177007	head pose
0.6903728312	pass
0.6903667187	pm
0.6903148001	hyper
0.6901685016	peer
0.6900878623	holography
0.6899473491	importantly
0.6898229764	predictive models
0.6897973027	single cell
0.6897518084	significant improvement
0.6895786179	anatomically
0.6895343323	case studies
0.6895235570	stem
0.6895051636	season
0.6895051636	conservation
0.6895051636	humanitarian
0.6895051636	squamous
0.6894295567	vae
0.6893775685	character
0.6892823216	underwater images
0.6892392179	snr
0.6892389706	csd
0.6892389706	spl
0.6892389706	mir
0.6891630344	temporal correlation
0.6891035383	root mean squared
0.6889709500	mms
0.6889709500	msfa
0.6888816643	aif
0.6888816643	eels
0.6888816643	cfd
0.6888280566	manifold learning
0.6887982812	high risk
0.6886452406	cell carcinoma
0.6885407328	reconstruction quality
0.6885057373	gait
0.6884532496	trends
0.6884437586	infected patients
0.6883881489	segmentation mask
0.6883781551	image sensor
0.6883663732	search algorithm
0.6883517490	cuda
0.6881959067	degeneration
0.6881356546	rigid
0.6881336962	feature representations
0.6880976396	symmetry
0.6878538292	depthwise
0.6875372400	classification accuracy
0.6875063223	twin
0.6874760927	vision tasks
0.6874502846	nfl
0.6874402266	fourier
0.6873712211	mind
0.6872998500	brain volume
0.6870780089	low light conditions
0.6870747864	pulmonary
0.6870157960	ad
0.6869112867	cytometry
0.6866580828	medial
0.6865673742	history
0.6865648766	similar patches
0.6865224984	employing
0.6863831593	light intensity
0.6863793020	smartphone based
0.6863712624	ldr images
0.6862691775	iqa
0.6861998333	radiological
0.6860721869	multi temporal
0.6860670174	spatial alignment
0.6859578620	lr
0.6859336713	experimentally demonstrate
0.6859284307	event based
0.6859136177	cascaded
0.6859073378	family
0.6858413400	neuroimaging
0.6858177049	landsat 8
0.6858129097	brca
0.6858129097	vad
0.6858129097	simd
0.6858129097	sgd
0.6858129097	mocha
0.6858129097	ssm
0.6858129097	ncct
0.6858129097	isles
0.6858129097	cle
0.6858129097	mf
0.6858129097	ivim
0.6858129097	hmm
0.6856931975	v3
0.6856661254	mma
0.6856661254	pni
0.6855899645	great success
0.6855673899	cad
0.6853552329	stomach
0.6853552329	assembled
0.6853552329	stabilization
0.6853523085	harmonics
0.6853464863	mmd
0.6853464863	pso
0.6853309276	geographic
0.6853156460	early detection
0.6852349910	sim
0.6852039473	multiplier
0.6851566971	environmental
0.6849787292	sampling patterns
0.6848000313	raster
0.6847393303	feature pyramid network
0.6846520492	discovery
0.6846371069	linear model
0.6845768397	qa
0.6845768397	pv
0.6845768397	dcis
0.6845768397	rna
0.6844878764	theoretic
0.6843361163	capsule
0.6842936794	lg
0.6842936794	dcf
0.6842936794	esrgan
0.6842936794	srs
0.6842936794	wl
0.6842936794	hdri
0.6842567695	retinal disease
0.6842434541	pyramid
0.6842282290	url
0.6841872921	holistic
0.6841384723	fast iterative
0.6840796776	downstream tasks
0.6839221587	student
0.6838626115	quantitative evaluation
0.6838548462	confocal
0.6838182855	automation
0.6837307133	challenging conditions
0.6836553680	matched filter
0.6835557017	programming
0.6835520833	perceptual similarity
0.6834953438	aircraft
0.6834193564	encrypted images
0.6833871693	decompose
0.6833829651	csi
0.6832450293	oar
0.6832160250	significantly higher
0.6831106651	image deraining
0.6829942628	pcr
0.6829037865	temporal dynamics
0.6828942982	animal
0.6828578256	unified
0.6828533981	significance
0.6827207828	stochastic
0.6826966606	cancer diagnosis
0.6826414891	attention map
0.6826209321	intestine
0.6825864977	mild
0.6825394696	small scale
0.6825394177	diabetic
0.6825302082	deep networks
0.6824961940	hybrid approach
0.6824403845	conceptual
0.6823895563	content adaptive
0.6823124724	belief
0.6823000313	transportation
0.6822768199	loraks
0.6822157647	light sources
0.6821876650	multiple levels
0.6820619249	compressive
0.6820433872	cxr
0.6818397045	pet
0.6815973929	spa
0.6815774535	brain tumor patients
0.6815246404	extensive experimental
0.6813902968	mutations
0.6813797720	despeckling
0.6813358044	mr
0.6812622436	image manipulation
0.6812450293	dft
0.6811499544	decision making process
0.6810816135	ddsm
0.6809291190	sar images
0.6806758255	led
0.6805720415	cerebral
0.6805597821	mlaa
0.6805597821	tdlu
0.6805293565	ultra
0.6804655841	prior works
0.6803955241	injuries
0.6801829395	motion fields
0.6799478311	planar
0.6799338141	hexagonal
0.6799156844	high efficiency
0.6798258585	grayscale images
0.6798228211	signal to noise ratios
0.6797655063	introduction
0.6797535883	mean absolute error
0.6797454105	em
0.6797135722	client
0.6795892360	quality of experience
0.6794508056	colorectal
0.6793986217	low bit
0.6793472409	temporal information
0.6793142752	facial images
0.6792985779	rgb camera
0.6792788323	previous approaches
0.6792593545	cell types
0.6791022583	histology
0.6790563336	infinite
0.6790561499	loupe
0.6790364524	muse
0.6790082470	gan based
0.6789755467	resolution enhancement
0.6789318011	emergency
0.6788712546	multispectral
0.6788209321	trauma
0.6788209321	stopping
0.6787591061	densely
0.6787573386	horizontal
0.6787132745	scope
0.6787069351	definite
0.6786846967	dense block
0.6786258726	realization
0.6785991334	human head
0.6785837909	spp
0.6785837909	amp
0.6785837909	tfm
0.6785837909	sdd
0.6785837909	sap
0.6785831598	hf
0.6784346304	underwater
0.6784017292	least squares
0.6783395897	odt
0.6783102465	dilated
0.6782791378	ductal
0.6782303755	nerves
0.6781073118	horizontal and vertical
0.6779366456	recent advancements
0.6779303085	pollution
0.6779044792	hdr
0.6778857242	otb
0.6778487569	counting
0.6778417028	learning strategy
0.6778193872	segmentation masks
0.6776960399	textile
0.6775225862	risk factors
0.6774453406	transcription
0.6774223796	pretrained
0.6774159451	novelty
0.6773295181	co occurrence
0.6772598478	heads
0.6772598478	erosion
0.6772381327	adas
0.6772300997	instrument
0.6771494446	split
0.6771394150	deep reinforcement learning
0.6770730130	challenging problem
0.6770682669	yellow
0.6770682669	mount
0.6770682669	surge
0.6770682669	carrier
0.6770682669	talking
0.6770682669	drives
0.6770682669	viewer
0.6770682669	systemic
0.6770593583	informed
0.6770145364	jdsr
0.6769684338	mvs
0.6769170013	carlo
0.6769170013	monte
0.6769142707	prime
0.6768859222	metabolic
0.6768673890	dynamical
0.6768626732	rfi
0.6768097666	integrating
0.6767258503	shore
0.6766587389	balance
0.6766565635	roi
0.6766538463	doe
0.6766157483	entropy model
0.6765935175	research area
0.6765789270	cifar 100
0.6765490601	assisted
0.6764006559	retina
0.6763324868	augmenting
0.6762876812	single view
0.6761919447	gpu
0.6760422678	comparable results
0.6760340856	unlike
0.6759894304	parameter maps
0.6757777936	wce
0.6757777936	nrmse
0.6757777936	erp
0.6757777936	har
0.6757777936	ip
0.6757668480	autocorrelation
0.6756109211	panoramic images
0.6755605815	biomedical image
0.6754308762	dcn
0.6754308762	vtm
0.6754308762	stl
0.6754308762	npc
0.6754308762	fda
0.6754170387	nuclear
0.6754139959	directed
0.6753847980	hsi
0.6753678277	road segmentation
0.6753470259	machine learning based
0.6751709479	meta
0.6751501479	pepper
0.6751059577	solid
0.6750324962	child
0.6750051675	important role
0.6749998931	vgg 16
0.6749116693	picture
0.6747926089	elastic
0.6747279527	patient cohort
0.6747178916	mmse
0.6747178916	gif
0.6746515461	erel
0.6746515461	kpca
0.6745959791	differentiable
0.6745695827	histopathology
0.6745689461	dense depth
0.6745539127	stationary
0.6744738440	qis
0.6744515339	electric
0.6741455564	scar
0.6741021810	anisotropy
0.6741021810	fovea
0.6739399150	generalized gaussian
0.6739186376	proliferation
0.6738670793	sdr
0.6738670793	gs
0.6738313854	de raining
0.6738199153	resonance
0.6737571982	pneumonia detection
0.6737298871	interferometric
0.6737251254	cardiomyopathy
0.6737251254	grating
0.6737251254	falls
0.6737251254	logic
0.6737251254	permittivity
0.6734972217	lus
0.6734972217	cu
0.6734972217	gsr
0.6734050251	comparative
0.6734045995	accurately estimate
0.6731604997	circular
0.6730829335	research directions
0.6730795623	retinal layer
0.6730235320	takes into account
0.6729416435	rgb
0.6728649916	sample sizes
0.6726570893	multiple modalities
0.6726396453	data fusion
0.6726112348	encryption
0.6726031506	glaucoma
0.6724254876	evolution
0.6724126984	clinical setting
0.6723735423	metastases
0.6720216130	hcp
0.6719514562	high level semantic
0.6719056538	ga
0.6718509872	fluid
0.6718073411	input output
0.6717558252	passing
0.6717032183	mlp
0.6717032183	ivf
0.6716422878	mds
0.6715866612	extreme
0.6715343422	sar
0.6714174669	log
0.6713987915	auto
0.6713693617	breast cancer diagnosis
0.6712903687	hidden layers
0.6710423695	unique challenges
0.6709701965	plug and play
0.6709677518	oil
0.6709677518	providers
0.6708681950	resnet
0.6708588014	auc
0.6707741789	gaussian
0.6706768992	electrical
0.6706444867	atmospheric
0.6705155070	zero shot
0.6704636226	factorization
0.6704395407	synthesizing
0.6703764945	df
0.6703764945	cr
0.6703557600	scalable
0.6703299322	right ventricle
0.6702871314	svr
0.6702871314	cc
0.6702871314	hsr
0.6702871314	dbn
0.6702871314	oam
0.6702871314	xai
0.6702019887	ia
0.6702019887	recist
0.6702019887	hsv
0.6702019887	mb
0.6701691604	limited memory
0.6701314215	focal
0.6700673143	slr
0.6700673143	sm
0.6700649359	male
0.6699384594	acquisition protocols
0.6699086468	contrast to noise ratio
0.6698288415	arithmetic
0.6698000610	ocular
0.6697688547	significantly outperform
0.6697130000	mi
0.6696690534	simplified
0.6695673809	diffractive
0.6694936726	dark
0.6694902971	pre processed
0.6694748075	ssim
0.6694021517	prototyping
0.6692209949	reasoning
0.6689307015	hyperspectral images
0.6689185757	genetic
0.6686913195	signs
0.6686732374	multimode
0.6685469615	higher level
0.6685265020	crowd
0.6684751231	photoacoustic
0.6684618518	human visual system
0.6683764171	tc
0.6683764171	cfa
0.6683216230	brain lesions
0.6681807364	embedding space
0.6681134730	computer aided diagnosis
0.6680586775	cycle
0.6680330470	facial recognition
0.6680269609	macular
0.6680131258	derivative
0.6680084346	neuroimaging data
0.6679929100	replacement
0.6679406649	ptychography
0.6678446601	incremental
0.6677706728	unfolding
0.6677706728	abdomen
0.6677492751	neuroimaging initiative
0.6677482115	isic 2018
0.6677373466	medical image fusion
0.6677274044	polyp
0.6675953645	application specific
0.6675403232	dice coefficients
0.6673601373	mammography
0.6673593567	sirt
0.6672857543	diagnostic accuracy
0.6672331104	vr
0.6671771219	flair
0.6671339315	music
0.6670070720	model agnostic
0.6670006541	radial
0.6668815290	coherent imaging
0.6668126583	theorem
0.6668060779	unsupervised manner
0.6667671644	breast mri
0.6666998123	tb
0.6666593066	results confirm
0.6666270367	temporal bone
0.6665147763	ic
0.6665049453	image fusion
0.6664244199	ensemble learning
0.6663762232	rest
0.6663739099	interests
0.6663046432	deep learning approaches
0.6661892359	pinhole
0.6661662879	tissue sections
0.6660522872	rule
0.6660015928	hat
0.6659974202	document
0.6658684264	increasingly important
0.6657798924	lumbar
0.6657798924	migration
0.6657588240	fista
0.6657588240	ed
0.6657460800	waste
0.6657422206	comfort
0.6657394276	fractal
0.6656603934	nn
0.6656484746	uhd
0.6656334342	ieee
0.6655684190	sentinel
0.6655666746	cs
0.6655363040	image to image translation
0.6654643642	gopro
0.6653901798	competitive results
0.6653719698	cmos
0.6653644489	adjust
0.6653043840	avalanche
0.6653043840	ventilation
0.6652984744	pc
0.6652540448	typically require
0.6652368030	expert radiologists
0.6652213761	forward problem
0.6651876697	consensus
0.6651257628	retrospective
0.6650931350	visibility
0.6650848873	labeled training data
0.6650390068	discrimination
0.6650225487	lcz
0.6650225487	nst
0.6650225487	qp
0.6650218659	cifar 10
0.6649950330	al
0.6649726574	total number
0.6648317665	cryo
0.6647924074	stare
0.6647839452	cis
0.6647088929	division
0.6645532320	wild
0.6644458766	increasing attention
0.6644418605	hu
0.6644235041	tight
0.6644155105	hr
0.6643488942	dect
0.6643302778	experimental results showed
0.6642548143	diffraction pattern
0.6642513274	isp
0.6641178404	slice wise
0.6640680256	aortic
0.6640563971	dnn
0.6640334103	spd
0.6640333407	editing
0.6639392744	ffdm
0.6638931077	severity
0.6638403244	organization
0.6637615305	interactive
0.6637008249	categorical
0.6636878696	diabetic macular
0.6635284491	root
0.6635038875	tbi
0.6634702589	content aware
0.6633910266	dl based
0.6633547601	svd
0.6633104460	debris
0.6632889093	cine
0.6632592180	md
0.6632592180	fpm
0.6632177021	speed of sound
0.6631631213	pdac
0.6631200826	residual attention
0.6630701250	amd
0.6630409197	nih
0.6630155733	data regime
0.6629970644	oct
0.6629381540	mec
0.6629381540	cvd
0.6629381540	drr
0.6628178122	large size
0.6625676311	linked
0.6625318786	global pandemic
0.6625057771	experiments confirm
0.6624693497	floating
0.6624613373	saliency
0.6623731000	cw
0.6623731000	sl
0.6623731000	pp
0.6623225425	autoencoder
0.6622921969	dc
0.6622771274	lesion size
0.6622256555	spatial angular
0.6622090519	multi branch
0.6621793553	spad
0.6621763419	sclerosis
0.6620779040	grd
0.6620616950	sr
0.6618772968	pa
0.6617861401	domain translation
0.6617176488	image priors
0.6617020285	kl
0.6616606595	lensless
0.6616542063	statistical properties
0.6616130311	neural image compression
0.6615993218	motion tracking
0.6615656439	supervised training
0.6615600756	ept
0.6615508077	pam
0.6615212544	rgb d
0.6615028257	ki
0.6615028257	cox
0.6614733594	hd
0.6613331489	convolutional dictionary
0.6613073826	object interaction
0.6612320029	inference speed
0.6611701961	proposed method
0.6611439511	skeletal
0.6611030420	brain magnetic resonance
0.6610640980	dem
0.6609497514	cd
0.6609252091	asd
0.6608998583	existence
0.6608752759	ba
0.6607879935	flat
0.6606966029	ar
0.6606832176	ace
0.6606832176	bold
0.6605413878	psnr
0.6605248943	ai
0.6604703294	re id
0.6604437539	discriminative features
0.6603926132	gold
0.6602832637	oriented
0.6601661095	file
0.6601026217	modulator
0.6600424740	vision systems
0.6599768134	center
0.6599597150	aggregation
0.6599254424	cbir
0.6599246105	dicom
0.6599246105	pat
0.6598373771	iss
0.6597345491	deep learning frameworks
0.6596842602	experiments demonstrate
0.6595972452	parallel mr
0.6595899608	installed
0.6595899608	corneal
0.6595899608	explosion
0.6595899608	kinetic
0.6595899608	companies
0.6595899608	preventive
0.6595025649	clinical decision making
0.6594198804	graphics
0.6594000565	rmse
0.6593665840	remote sensing images
0.6593332833	divide and conquer
0.6593325318	variational
0.6593282739	sas
0.6592874870	cmb
0.6592499882	csc
0.6592446510	copd
0.6592383480	processing steps
0.6591205140	gnn
0.6589983673	mprage
0.6589912991	nerve head
0.6589851185	ff
0.6589851185	dslr
0.6589379659	basal
0.6589223059	mental
0.6589028794	combat
0.6588719031	api
0.6588065561	vdsr
0.6587847717	yolo
0.6587078377	supported
0.6586272153	scd
0.6586272153	wmh
0.6586272153	biqa
0.6586151436	discrepancy
0.6585935679	result shows
0.6585892220	sect
0.6585892220	cin
0.6585892220	ffr
0.6585206042	orders of magnitude
0.6584461673	multi focus
0.6583926038	average pooling
0.6583778354	lidar
0.6582972270	edof
0.6582972270	psp
0.6582304789	hybrid
0.6582082239	qct
0.6581726568	mbir
0.6581685856	mri
0.6581631213	sd
0.6581631213	qc
0.6581404119	gi
0.6581404119	dmd
0.6581309224	acquisition protocol
0.6581145631	preliminary
0.6580811577	u nets
0.6580518815	minimally
0.6580492941	hs
0.6579756584	retinal image
0.6579600982	ista
0.6579150939	fpp
0.6579150939	rpca
0.6579000565	pd
0.6578651994	compressed images
0.6578360827	low level vision
0.6578304229	high computational cost
0.6578242421	pre treatment
0.6578008223	mar
0.6577572050	fluorescence
0.6577548036	radiology
0.6577334794	image super resolution
0.6577326971	significant margin
0.6577165519	microscopic
0.6577120650	extensive
0.6576692454	gd
0.6575863806	nmf
0.6575597581	sciences
0.6575366660	guided
0.6575253895	radiographs
0.6574103156	dls
0.6574103156	ecg
0.6573349987	shapley
0.6573251759	successfully applied
0.6573124901	fixed size
0.6572945223	unrolled
0.6572374625	extension
0.6572168521	elm
0.6571457914	ccta
0.6571105023	distances
0.6570825218	angiography
0.6570691041	susceptibility mapping
0.6570164279	disease detection
0.6569899235	med
0.6569167804	asl
0.6569059748	dms
0.6568653826	ute
0.6568498905	ns
0.6567811689	building block
0.6566509220	soft
0.6566373768	rl
0.6566373768	ais
0.6566074857	ucf
0.6565925513	dbt
0.6565925513	vsr
0.6564408890	spectral spatial
0.6564176972	rcc
0.6563684805	satellite image
0.6563298032	gbm
0.6563137328	judge
0.6563137328	farming
0.6563137328	message
0.6562908712	ssd
0.6562427235	clinical application
0.6562401667	sp
0.6562314402	piv
0.6562262510	lfs
0.6562262510	april
0.6562262510	googlenet
0.6562262510	tucker
0.6561636681	ratlesnetv2
0.6561636681	squeezenet
0.6561636681	concretely
0.6561636681	assemblynet
0.6561636681	pegasus
0.6561636681	webp
0.6561636681	android
0.6561636681	openstreetmap
0.6561636681	siemens
0.6561616824	near lossless
0.6561381746	ss
0.6561252759	ap
0.6560854139	separable
0.6560127516	blind
0.6559120230	dwi
0.6558895073	vqa
0.6558731196	deep generative
0.6557736334	deraining
0.6557291470	spi
0.6557115319	registration error
0.6556781387	type classification
0.6556708117	street
0.6556408625	msi
0.6555676068	mpi
0.6555668733	dti
0.6555640950	point of care
0.6555460188	practical application
0.6555146048	ae
0.6554973319	fsl
0.6554973319	ssdu
0.6554708289	sift
0.6554597207	directional
0.6554460625	dynamic mri
0.6554029837	tm
0.6553405374	mc
0.6553405374	emd
0.6553360147	conditional
0.6553013068	noise level
0.6552286715	fcm
0.6552245066	mers
0.6551261966	shoulder
0.6550199877	ugc
0.6548667404	fingerprinting
0.6547763085	sparsely
0.6547306785	augmented
0.6547217792	conducting
0.6545943933	fp
0.6545813619	shadow
0.6545020476	black
0.6544175663	sps
0.6543796666	fpn
0.6542742507	dp
0.6541800441	supervised manner
0.6541230836	midi
0.6541222082	bpg
0.6540922839	correlated
0.6539682614	january
0.6538454589	significantly lower
0.6538237160	dt
0.6538237160	simba
0.6537909640	dvc
0.6537665572	srgan
0.6537094059	removal
0.6537064702	robotic
0.6536326275	nir
0.6536170128	gop
0.6535478419	viral
0.6535461391	gastric
0.6535070493	ivoct
0.6534549084	mef
0.6534444063	paper proposes
0.6534091661	ctc
0.6533655003	vvc
0.6533387701	generalization performance
0.6533103839	seg
0.6532822356	sickle
0.6532822356	resultant
0.6532822356	compete
0.6532822356	devoted
0.6532822356	annealing
0.6532501199	pcc
0.6532064085	calls
0.6532064085	differs
0.6531763529	head and neck
0.6531395073	uav
0.6530779837	vc
0.6530776967	dice
0.6530649581	wm
0.6530640980	fc
0.6530299818	fbp
0.6530211902	structured illumination
0.6529674363	dcgan
0.6529169072	mtf
0.6528939680	admm
0.6528684210	depending
0.6528142267	spectroscopy
0.6527853156	eit
0.6527559984	quality enhancement
0.6527358248	ultra low
0.6527332543	competing methods
0.6527291470	gcn
0.6527059275	erct
0.6526884542	oxygen
0.6526884542	modulus
0.6526542338	empirical
0.6525984020	mtl
0.6525978344	expressions
0.6525601600	sae
0.6524358351	human eye
0.6523617639	purpose
0.6523390282	letter
0.6521583859	peripheral
0.6521187689	slim
0.6520807230	cbf
0.6520584536	vertebrae
0.6520306621	adni
0.6520114209	td
0.6519151350	dl
0.6519026146	mci
0.6518692808	atlas
0.6518682844	unlike existing
0.6518395964	ds
0.6517117658	labeled samples
0.6516626643	estimator
0.6516478226	conduct extensive
0.6515811689	conduct experiments
0.6514878125	stereo
0.6514614833	asr
0.6514441249	bundle
0.6514416060	mu
0.6514380751	distance map
0.6513820060	artery disease
0.6513651944	thermal
0.6513597892	imaging protocols
0.6512855965	excellent results
0.6512501561	boltzmann
0.6512293742	axial resolution
0.6511643593	forest
0.6511457296	magic
0.6511453971	idc
0.6511350308	sci
0.6510984587	highly efficient
0.6510827459	laser
0.6510755739	cutting
0.6510594668	cg
0.6510306621	cv
0.6510287546	chest ct images
0.6510237236	wt
0.6510230003	wsi
0.6509876259	crf
0.6509120230	sa
0.6508670429	ce
0.6508504200	oa
0.6508504200	ldct
0.6507551894	subsets
0.6507282979	mining
0.6506195639	ot
0.6505947800	dir
0.6505593800	receiver
0.6505317381	manual labeling
0.6504443971	af
0.6504125733	compression rate
0.6504045326	ct scanners
0.6504005816	accurately classify
0.6503820435	finite
0.6503745704	quantitative measures
0.6502805642	fd
0.6502805642	bv
0.6502805642	isbi
0.6502702714	chest x ray images
0.6502195289	extremely challenging
0.6501950039	subset
0.6501170449	tv
0.6501098965	recurrent
0.6500983431	fracture
0.6500703909	accelerated
0.6500480284	knee
0.6499825102	nas
0.6499669695	detection and recognition
0.6499081972	ms
0.6498558247	cellular
0.6498393376	tof
0.6497842694	owing
0.6497341030	dme
0.6497032716	pde
0.6497023107	xcat
0.6496881990	mae
0.6496881990	rv
0.6496838926	hypothesis
0.6496458727	unmixing
0.6495849089	auroc
0.6493112844	union
0.6492767942	ood
0.6491947504	subjective scores
0.6491282052	gmm
0.6491282052	qpi
0.6490770946	existing approaches
0.6490729199	capsnet
0.6489700562	pg
0.6489700562	mra
0.6489161013	project
0.6488565361	rpe
0.6488449706	atrial
0.6488082239	bm
0.6488020097	tms
0.6487530100	compensation
0.6487432981	verification
0.6487183739	lfi
0.6486850508	pe
0.6486737517	au
0.6486526308	high quality reconstructions
0.6486317038	nlos
0.6484985889	manual segmentations
0.6484581803	network pruning
0.6484381881	obstructive
0.6484286664	miccai
0.6484045248	dvs
0.6483442621	mathematical models
0.6483386214	dn
0.6483386214	hfr
0.6482798093	iris
0.6481122878	cnn
0.6480961529	t_2
0.6480961529	india
0.6480961529	laguerre
0.6480961529	ade20k
0.6480961529	lombard
0.6480961529	rao
0.6480729298	ui
0.6479606215	csf
0.6479606215	pve
0.6479528561	k nearest
0.6479265801	hoi
0.6478885218	cars
0.6478872556	friendly
0.6478752367	vulnerability
0.6478058246	research community
0.6477928395	dcnn
0.6477245139	medical applications
0.6476786659	cpu
0.6476452002	qsm
0.6476393649	sem
0.6476089890	uncertainty measures
0.6475681664	bayesian
0.6475328823	membrane
0.6474286769	qualitative evaluations
0.6474219818	gui
0.6474161901	aerial
0.6473393668	medical experts
0.6473299825	aided
0.6473152287	higher spatial resolution
0.6473082036	ivus
0.6472938779	fa
0.6472693971	tl
0.6472622672	fractional
0.6472570576	ssl
0.6471547331	photo
0.6471385945	itm
0.6471227133	caps
0.6470653273	clinical applications
0.6470589260	simultaneous
0.6470577370	sentinel 2
0.6469917492	convergence speed
0.6469896193	psi
0.6469161694	regularization by denoising
0.6469069313	convolutional network
0.6468986929	conditional adversarial
0.6468909529	point spread
0.6468741181	raw images
0.6468396467	chase
0.6467870387	upper
0.6467661430	exploiting
0.6466861019	gan
0.6466168398	hvs
0.6466089177	creation
0.6465226289	comprehensive experiments
0.6465138898	laboratory
0.6464847615	salient
0.6464571366	disease severity
0.6463957487	stimulation
0.6463476030	das
0.6463336634	vehicles
0.6462994073	quantitatively and qualitatively
0.6462642367	ich
0.6462151718	nucleus
0.6462066532	corruption
0.6462015541	pt
0.6461944946	metal
0.6461783234	least square
0.6460018611	ica
0.6458657540	rr
0.6458432288	self driving cars
0.6458372736	tie
0.6458251210	depth sensing
0.6457751194	tcga
0.6456405885	expansion
0.6455464700	awareness
0.6454421963	sampling strategy
0.6454310211	glands
0.6454095781	anti
0.6453560469	nlp
0.6453060139	emg
0.6453060139	pgd
0.6452369471	routine clinical
0.6452175263	feature descriptors
0.6451891556	unet
0.6451768736	os
0.6451756322	gtv
0.6451572710	concrete
0.6451572710	quasi
0.6451322759	cdi
0.6451322759	cta
0.6450908137	oct images
0.6449915944	single step
0.6448615694	lc
0.6448615694	ca
0.6448615694	av
0.6448496613	guided attention
0.6447390428	motion vectors
0.6447202113	nns
0.6447052580	main challenge
0.6446427064	conducted experiments
0.6445862216	tpr
0.6445493622	er
0.6445395370	application scenarios
0.6445351812	cnr
0.6444645269	exponential
0.6444609226	auxiliary
0.6444506731	temporal context
0.6444336751	rgb image
0.6444238781	fcnn
0.6443444526	adverse
0.6443444526	interferometry
0.6443123601	sms
0.6442689774	hm
0.6442689774	ls
0.6441675361	fgsm
0.6441600396	multispectral image
0.6441596069	neurodegenerative
0.6441576976	class labels
0.6439887498	rop
0.6439887498	ctp
0.6439188655	rnn
0.6439061750	forensics
0.6437177195	relied
0.6436939548	clahe
0.6436939548	cca
0.6436803469	bridge
0.6436649213	lots
0.6436649213	act
0.6436209879	crack
0.6436153503	vhr
0.6435964296	pet images
0.6435739715	segmentation tasks
0.6435007234	sota
0.6434463190	ct
0.6434418453	shape prior
0.6434382683	roar
0.6434236553	hc
0.6434025689	unit
0.6433668398	fid
0.6433596221	entropy
0.6433572698	sat
0.6433000168	rf
0.6432959251	grain
0.6432948445	recognition tasks
0.6432937095	stain
0.6432407280	forward model
0.6431640720	reproducing
0.6431493139	oc
0.6431157869	enhanced
0.6430928041	probabilistic
0.6430544585	active
0.6430470580	differential
0.6429718950	optimizing
0.6429477991	satellite data
0.6429031916	drl
0.6428706876	peak
0.6428147989	instance level
0.6427892972	near infrared
0.6427361598	imagenet dataset
0.6427311732	brats 2019
0.6427115573	rms
0.6427080172	parametric
0.6426858534	no reference image quality assessment
0.6426665032	lrp
0.6426665032	pwls
0.6426665032	atr
0.6426650994	vmaf
0.6426429080	gprinvnet
0.6426217958	dae
0.6426138149	statistical analysis
0.6425859557	comparing
0.6425388523	singular value
0.6425270457	mip
0.6425234691	numerical simulation
0.6425215002	unpaired
0.6424134031	sparsifying
0.6424049210	digital images
0.6423608612	ventricle
0.6423407015	service
0.6423281747	porous
0.6423080590	displacement field
0.6422692807	law
0.6421969733	coherent illumination
0.6421701985	overview
0.6421677862	significantly reduced
0.6421437744	ann
0.6420945379	snns
0.6420333384	eosin
0.6420241822	list
0.6420229322	sentinel 1
0.6420204337	performance improvements
0.6420163005	dwt
0.6420163005	cap
0.6419224060	left
0.6419117371	annotation free
0.6418975440	intelligence
0.6417637683	vote
0.6417398648	point sets
0.6417250588	chroma
0.6416883655	wavelet
0.6416878272	medical image synthesis
0.6416660284	osm
0.6416660284	mil
0.6416660284	fft
0.6415623311	benign and malignant
0.6415260004	studying
0.6414563113	adversarial samples
0.6414406768	analyzing
0.6414388396	carcinoma
0.6413947637	propagation
0.6413504398	functional mri
0.6413158751	training strategies
0.6412371680	diagnostic quality
0.6411452002	lstm
0.6411245505	cavity
0.6411102532	muscles
0.6410629495	limited data
0.6410604207	threat
0.6410278829	user study
0.6409351516	chaos
0.6409232503	atlas based
0.6408039615	convex
0.6407600558	crc
0.6406986971	important factor
0.6406846408	refined
0.6406815079	target recognition
0.6405435549	unlabeled target
0.6404512473	smoothing
0.6404038032	relu
0.6404038032	kinect
0.6404038032	bayes
0.6404038032	growcut
0.6403968816	tissue properties
0.6403308935	site
0.6403116646	satellite
0.6402958099	dct
0.6402595369	neuroscience
0.6402216447	edge information
0.6402055385	retinal diseases
0.6401734390	deblurring
0.6401214239	jpeg2000
0.6400863679	matlab
0.6400584908	comprehensive
0.6400456643	cadx
0.6400048825	foundation
0.6399190044	living
0.6398848611	promising performance
0.6398737520	loop
0.6398328038	od
0.6398204592	abnormality
0.6398051660	mos
0.6397726178	atom
0.6397520858	gm
0.6397520858	fmcw
0.6396121094	traffic
0.6395746637	hog
0.6395626278	clstm
0.6394716808	glcm
0.6394381450	ultrasound image
0.6393693179	sperm
0.6393667476	sight
0.6393557400	biomedical research
0.6393345778	uda
0.6392028929	virtual
0.6391577865	highly desired
0.6391205327	efficientnet
0.6390567013	achieves competitive
0.6389839621	awgn
0.6389303485	tpu
0.6389298753	query
0.6389248474	optical tomography
0.6389085316	automatic segmentation
0.6389036021	recently gained
0.6388799802	avs
0.6388522813	thoracic
0.6387910052	standard convolution
0.6387769795	bloch
0.6387536175	incorporating
0.6386898418	compression artifacts
0.6386421941	microscopy images
0.6386384938	fly
0.6385585381	main idea
0.6385537213	onh
0.6384762121	es
0.6384537573	qualitatively and quantitatively
0.6384311514	table
0.6384257760	gel
0.6382635902	amenable
0.6381916836	wireless capsule
0.6381658533	sampling method
0.6381480472	visual attention
0.6381451360	magnetic
0.6381205045	event
0.6380718563	renal
0.6380662428	ava
0.6380171552	atrophy
0.6380157507	human observers
0.6379578343	youtube
0.6378768945	aneurysm
0.6378592688	iot
0.6378088414	inspired
0.6377561158	rad
0.6377064447	dip
0.6376597105	dnn based
0.6376211322	fundus image
0.6375917013	noisy data
0.6375813009	polsar
0.6375424949	expression
0.6375265056	energy ct
0.6375097479	ps
0.6374626239	abdominal
0.6374586542	label noise
0.6374456450	pruning
0.6374395154	thirdly
0.6374156953	curve
0.6373950166	track
0.6373668189	stabilize
0.6373245409	privacy
0.6372955746	orthogonal
0.6372635342	negatives
0.6372559229	dual
0.6372267741	vcfs
0.6372237042	frequency components
0.6372081666	cl
0.6371398042	svm
0.6370973627	aff
0.6370605445	low field
0.6370578345	stroke
0.6369833798	north
0.6369833798	belongs
0.6369783117	rain
0.6367201895	di
0.6366143630	breast ct
0.6365529941	fusion
0.6365203123	super
0.6364761973	qsmnet
0.6363756820	separation
0.6363486978	spatial domain
0.6362080108	slice by slice
0.6361645574	jpeg images
0.6361543895	bragg
0.6361543895	cifar10
0.6361415478	breast tumors
0.6360279564	residual
0.6360003818	se
0.6359420565	mrf
0.6359375986	wmn
0.6359219988	uncertainty estimates
0.6359189878	results showed
0.6358179865	player
0.6357371703	imaging through scattering media
0.6357166382	deep learning enabled
0.6356581548	alternating
0.6355591590	mse
0.6354919381	age related
0.6353809912	st
0.6353103314	activation
0.6352383252	bnns
0.6351744352	newly proposed
0.6351278874	covid
0.6351245203	principled
0.6351220668	hair
0.6350934532	fpgas
0.6350409220	blood volume
0.6350400548	significant reduction
0.6350202439	teacher
0.6349536310	denoted
0.6349365536	higher accuracy
0.6349025399	search
0.6346950667	radiomics
0.6346557211	diagnosing
0.6346359629	retinal images
0.6346068122	modality specific
0.6345779794	snn
0.6345511730	imposed
0.6345178763	image patches
0.6344908633	city
0.6344701377	neck
0.6344349952	back propagation
0.6343984735	seismic
0.6343180552	anchor
0.6342043778	altered
0.6341578902	mitotic
0.6341578902	marginal
0.6341578902	deficiency
0.6341231235	weak labels
0.6341076854	av1
0.6340108217	fast inference
0.6338958717	injury
0.6338924046	texture analysis
0.6338359527	deeplab
0.6337998062	confined
0.6337321875	covidx
0.6337114893	neutron
0.6336905355	reliability
0.6336537012	deep image compression
0.6336483896	micro
0.6336066186	rois
0.6336013825	accurately detect
0.6335545124	optics
0.6335144936	vertebral
0.6334822784	tr
0.6334106405	cortical
0.6333916265	linear inverse problem
0.6332334287	systematic
0.6330190971	physics
0.6330128437	partial
0.6329981536	trap
0.6329975218	fmri data
0.6329495754	logistic
0.6329403475	cnn architectures
0.6328493991	tradeoff
0.6328172367	cosine transform
0.6327985900	ultrasound
0.6327806824	decide
0.6326709668	experimental setup
0.6326073446	xception
0.6326073446	bayer
0.6325164785	cnn's
0.6325164785	covidnet
0.6325164785	rayleigh
0.6325164785	kaggle
0.6325164785	shannon
0.6325164785	vp9
0.6325077512	deep learning methods
0.6324578743	kidney
0.6323946560	crossover
0.6323698882	b0
0.6323346650	psnr and ms ssim
0.6323342050	computational power
0.6322545023	relative error
0.6322296604	spectral reconstruction
0.6321936748	assistance
0.6320996067	uavs
0.6320975464	preserving
0.6320851574	chronic
0.6319877615	enhancing
0.6319825473	numerical examples
0.6319664811	mt
0.6318717550	dsc
0.6317984597	kodak
0.6317684063	mixture
0.6317414907	source codes
0.6316737266	sampling density
0.6316466787	encoder decoder structure
0.6316375985	blurred image
0.6316213343	manipulation
0.6315878466	computation complexity
0.6315387051	minkowski
0.6315387051	jetson
0.6314743669	psychiatric
0.6314439138	match
0.6314372595	fer
0.6314192005	annotated data
0.6313729908	human subjects
0.6313610485	gland
0.6313453364	enforcing
0.6312189553	std
0.6312158543	attacker
0.6312158543	commercially
0.6312158543	irregularly
0.6312152699	proof of principle
0.6312044104	hrnet
0.6311942860	mobilenetv2
0.6311336316	stack
0.6310633167	reference standard
0.6309387120	pca
0.6309381735	gradient based
0.6308647151	proof of concept
0.6308352548	chestx
0.6307862433	x ray
0.6307571721	natural image
0.6307543610	medicine
0.6307343435	brain regions
0.6307322472	dwis
0.6307322472	kits19
0.6306488410	target detection
0.6306477027	ac
0.6306432714	dominated
0.6305165227	deep residual network
0.6302885860	histological
0.6302845155	ref
0.6302261088	off axis
0.6301663604	gf
0.6301246200	myocardial
0.6301212419	real world applications
0.6301113124	image recovery
0.6300734302	la
0.6300666448	lab
0.6299566397	predictive
0.6299295942	economic
0.6299171211	cellular structures
0.6297510950	color distortion
0.6297056947	artificial
0.6296855977	challenging task
0.6296746567	thalamic
0.6296617066	taking
0.6296036800	wall
0.6295821362	bpp
0.6295761654	noise2noise
0.6295761654	resnext
0.6294974157	dems
0.6294973654	gcns
0.6294834310	gpus
0.6294211577	facial
0.6293497199	visual recognition
0.6293489987	middle
0.6292420236	extensively evaluated
0.6292161795	lasso
0.6289956039	fusion network
0.6289815720	echo
0.6288421298	personalized
0.6288394812	generate high quality
0.6288040968	mp
0.6287359022	convolution neural
0.6286879980	fov
0.6286533986	retinex
0.6286263997	gleason
0.6286242110	nms
0.6285993633	disorder
0.6285840648	dncnn
0.6285823421	psfs
0.6285732729	hierarchical
0.6285112679	biomedical images
0.6284993321	performance gains
0.6284745443	segnet
0.6284326071	unlike conventional
0.6283837648	autonomous
0.6283511823	objective lens
0.6282326273	considerable attention
0.6282315900	cpus
0.6281759228	backbone network
0.6280924585	blockchain
0.6280924585	dopamine
0.6280510093	image prior
0.6279695821	man
0.6279249412	data analysis
0.6279074784	corona
0.6279074784	neuroimage
0.6279074784	pathologic
0.6279074784	hetero
0.6279058319	ensemble
0.6278654766	unlike previous
0.6278589409	learnable
0.6278158914	labelled data
0.6277156242	nuclei
0.6276852441	pdes
0.6276685727	graph
0.6276258562	hsi classification
0.6276137876	easy to implement
0.6275719589	visual features
0.6275645822	avenues
0.6275477785	bottom up
0.6274794374	single source
0.6274091011	conference
0.6274043172	sample size
0.6273981240	electron
0.6273942003	vine
0.6273776914	uncertainty aware
0.6273769087	intersection
0.6273449187	high dynamic range imaging
0.6272064628	interior
0.6271700377	pr
0.6271543912	noise2void
0.6271358309	computer aided
0.6268875218	compact
0.6268319940	dcnns
0.6268314269	block based
0.6266680327	agent
0.6266252449	rgb images
0.6265656311	artifact
0.6265485955	plant
0.6265313241	achieves superior
0.6265246894	discrete
0.6265091865	extractors
0.6263850582	rnns
0.6263694884	operational
0.6261791424	exploration
0.6261723130	generate realistic
0.6261419837	quantitative comparison
0.6261344023	retinanet
0.6261307270	compression efficiency
0.6261262169	translational
0.6260947012	iou
0.6260668207	circle
0.6260502433	insar
0.6258866166	sharpening
0.6258866166	arrangement
0.6258653808	fcn
0.6258652531	remarkable performance
0.6258555529	special
0.6258235491	prostate
0.6258177256	latent code
0.6257406975	automated diagnosis
0.6257214895	remote
0.6256729682	microscopy
0.6256422121	object classification
0.6256396483	lake
0.6256396483	hourglass
0.6255902915	generation
0.6255432430	decomposition
0.6255352816	adam
0.6254462120	pairing
0.6253937810	laplacian of gaussian
0.6253239983	periodic
0.6252804341	machine learning algorithms
0.6252394403	additive
0.6252083086	delivery
0.6251326755	landmark
0.6250894523	retraining
0.6250303501	fake images
0.6249986452	spoofing
0.6249613437	sar data
0.6249389092	recovering
0.6249315924	intermediate features
0.6249114274	generalized
0.6248841107	aes
0.6248750097	pars
0.6248601134	thesis
0.6248601134	ionizing
0.6248517254	portion
0.6248439964	stress
0.6248382139	human effort
0.6247551237	kinetics
0.6247039275	language
0.6246754240	earth's
0.6246619065	pistachios
0.6246619065	prioritization
0.6246183350	anns
0.6246101010	body mri
0.6245741803	epithelium
0.6245725824	bulk
0.6245680719	adjustment
0.6245410107	_1
0.6245273907	measuring
0.6245269399	holographic
0.6245038007	subjective evaluation
0.6244993905	enhancement
0.6244883506	head ct
0.6244878652	critic
0.6244878652	synthesizer
0.6244878652	cubic
0.6244621496	multipliers
0.6244153126	zone
0.6243598561	crucial role
0.6243448137	quality estimator
0.6242896638	starts
0.6242896638	modulate
0.6242825723	pm2.5
0.6242595982	back projection
0.6242516147	effectively reduce
0.6242015326	masked
0.6241972734	injection
0.6241891937	plenty
0.6241891937	derivation
0.6241671574	myocardium
0.6241432130	art
0.6241407073	nutrient
0.6241407073	concerned
0.6241203518	t2w
0.6241081818	transferability
0.6240504528	vgg19
0.6240119529	integration
0.6240112852	sar image
0.6240045381	densenet121
0.6240045381	freesurfer
0.6240045381	zernike
0.6239718096	perception
0.6239088249	denoising algorithms
0.6238822476	brain mr
0.6238392566	fcns
0.6237778246	evaluating
0.6237658200	coded
0.6237520536	visual information
0.6237443276	translation
0.6237184565	selection strategy
0.6236233618	guiding
0.6234470417	l0
0.6234470417	crucially
0.6233997099	sos
0.6233797626	spatial relations
0.6233638382	iterative algorithm
0.6232988506	image processing techniques
0.6232160892	interferometric synthetic
0.6231509036	particle
0.6231388463	coarse to fine
0.6229631403	line of sight
0.6229417992	quantitative and qualitative evaluations
0.6229238193	cognitive
0.6228442811	data imbalance
0.6228439964	curvature
0.6228296766	human eyes
0.6228269195	semi
0.6228158968	sisr
0.6226179934	ranging
0.6225837639	t1w
0.6224428828	topological
0.6224276064	feature spaces
0.6224239883	mass
0.6224068696	achieved impressive
0.6223919871	results demonstrate
0.6222829672	tau
0.6222528031	cardiovascular
0.6222444887	explanation
0.6222307184	mutual
0.6222253082	rethinking
0.6222103269	angular
0.6221552449	unsupervised
0.6221334580	memory limitations
0.6221176090	end to end
0.6220743353	image representation
0.6220376542	source domains
0.6219995652	brain structures
0.6219642515	birth
0.6219642515	interact
0.6219642515	served
0.6218519954	key components
0.6218194513	improved performance
0.6217671531	analog
0.6217650641	query image
0.6217300498	partial differential
0.6216733711	restricted
0.6216439911	combining
0.6216262069	cardiac segmentation
0.6215952860	transparent
0.6215601080	manufacturing
0.6214631810	glue
0.6214428880	na
0.6214411605	disc
0.6213949023	dialectical
0.6213723509	born
0.6213612936	ground truth annotations
0.6213548623	ultimate
0.6213548623	echet
0.6213548623	posedness
0.6213499775	depth information
0.6213286181	gap
0.6212792168	geoscience
0.6212792168	multicenter
0.6212792168	paying
0.6212792168	gradual
0.6212316115	oars
0.6211925300	mobile
0.6211852509	pediatric
0.6211673125	edge
0.6211300647	representation ability
0.6211234696	foveation
0.6210693196	main challenges
0.6210078759	k means
0.6209080897	extensive evaluation
0.6208996084	vector
0.6208891853	computers
0.6208237983	unity
0.6207844628	synthetic ct
0.6207550263	explanations
0.6206981528	convnets
0.6206883516	performed manually
0.6206602281	ordinary
0.6206472116	data compression
0.6206213560	consistently outperforms
0.6205941649	lidar sensors
0.6205619921	leave one out
0.6205124647	numerous
0.6204109578	wsis
0.6202881172	encouraging results
0.6202738855	adding
0.6202471070	removing
0.6202205175	compressed
0.6201978401	traditional machine learning
0.6201611224	knn
0.6201087857	cnns
0.6201029362	voxelmorph
0.6200994882	pain
0.6200391816	mis
0.6200386895	perfusion
0.6200104652	white gaussian noise
0.6200036637	perceptual
0.6198696202	interestingly
0.6198686513	modulation
0.6198666363	ao
0.6197278053	interpolation
0.6196987141	dr
0.6195918064	alexnet
0.6195547674	celeba
0.6195424675	ambient
0.6194915943	mri reconstruction
0.6194523440	unwrapping
0.6193948172	deep learning architectures
0.6192402355	colon
0.6192222392	hsis
0.6191838101	color channels
0.6191275524	science
0.6191275492	image resolution
0.6190813860	pad
0.6190363413	iterative
0.6189883470	unlabelled data
0.6188617968	sampling rates
0.6188183506	reproduction
0.6188183506	folds
0.6188183506	prevention
0.6188183506	column
0.6188183506	secret
0.6187839820	vaes
0.6187453478	cts
0.6187418244	spirit
0.6187383321	research purposes
0.6187062405	image sequences
0.6186890983	lymphocytes
0.6186890983	tubular
0.6186890983	attacking
0.6186890983	dorsal
0.6186890983	distilling
0.6186890983	cephalometric
0.6186890983	constancy
0.6186890983	comparatively
0.6186890983	decoupled
0.6186570587	stylegan
0.6186488920	image transformation
0.6185931521	longitudinal data
0.6185427708	her2
0.6185167274	positive cases
0.6185027828	rule based
0.6184836560	qoe
0.6183943298	rodent
0.6183943298	midline
0.6183943298	reshaping
0.6183943298	fascicle
0.6183943298	rationale
0.6183943298	relaxometry
0.6183943298	avoidance
0.6183943298	capsules
0.6183943298	multichannel
0.6183943298	voxelwise
0.6183943298	periocular
0.6183943298	correspondingly
0.6183918946	gabor
0.6183871260	preprocessing step
0.6183231879	tree
0.6182981254	lits
0.6182622138	multi objective
0.6182149836	data generation
0.6181979699	kernel size
0.6181611998	media
0.6180966173	spectral imaging
0.6180277078	tensor
0.6180046206	yolov3
0.6179542712	breast cancer detection
0.6179367266	actor
0.6179099514	current
0.6178795006	recently proposed
0.6177858304	weather
0.6177855091	field of view
0.6177800414	brain extraction
0.6176845656	pro
0.6176757042	public dataset
0.6176540814	fusing
0.6176499967	image guided
0.6176058627	ict
0.6175466458	fan
0.6175233003	game
0.6174577643	disease classification
0.6174506227	drrs
0.6174389412	l spect
0.6174358532	atrium
0.6172734927	invariant
0.6172663024	shows promising results
0.6172454699	functionals
0.6172454699	expectation
0.6171915238	quanta
0.6171672861	level annotations
0.6171069509	assembly
0.6170994880	multimodal
0.6170803838	retrieval
0.6170335672	training examples
0.6169758424	dipole
0.6169758424	person's
0.6169758424	benefiting
0.6169227455	inceptionv3
0.6168965071	chexpert
0.6168811447	thresholding
0.6168708064	joint
0.6168438330	longitudinal
0.6167773236	redundant information
0.6167495224	cdc
0.6167290531	coherence tomography angiography
0.6166646897	fibers
0.6166133534	biology
0.6165857306	mobilenet
0.6165857306	cityscapes
0.6165781100	keywords
0.6165368937	mr image
0.6164984200	plug
0.6164767455	thz
0.6164590594	quantification
0.6163739177	powerful tool
0.6162292210	minimal
0.6162121969	faster
0.6160937983	cxrs
0.6160737713	homology
0.6160737713	cite
0.6160155746	image database
0.6159607893	propagate
0.6159399695	significantly outperformed
0.6158715051	few shot
0.6158021284	prediction accuracy
0.6157915000	feature learning
0.6157827805	primary
0.6156391852	multiple sources
0.6156284055	pressure
0.6156101646	automatic
0.6156063006	deep learning approach
0.6156045733	dispersion
0.6155822221	panel
0.6155592820	deeplabv3
0.6155317423	surveillance
0.6154675895	descriptors
0.6154352095	net
0.6153670999	disorders
0.6152604422	codec
0.6152073593	absolute
0.6152048008	bm3d
0.6151766924	te
0.6150672580	pupil
0.6150590465	therapy
0.6150289187	tensorflow
0.6149528019	structure aware
0.6149482186	pneumonia
0.6149236359	respiratory
0.6148460806	reflection
0.6147020638	mismatch
0.6146870037	vis
0.6146861448	human activity
0.6145792504	intra
0.6145776018	convnet
0.6145403917	fusion strategy
0.6144760967	digital
0.6144543619	vgg16
0.6144254888	simple yet effective
0.6143686192	logo
0.6143593807	structural details
0.6143524079	long short term
0.6143326326	cohort
0.6143112946	u net
0.6142576071	partially
0.6141967993	graph neural network
0.6141818131	permeability
0.6141818131	cable
0.6140863974	manuscript
0.6140863974	primal
0.6140652792	flux
0.6140652792	corpus
0.6140642515	institutional
0.6140276418	small datasets
0.6139721184	residual network
0.6139528410	tomographic
0.6139315265	transform
0.6139279167	simulated data
0.6139144467	nodule
0.6139125405	ct imaging
0.6139080026	cancer patients
0.6137998586	defect
0.6137655219	brats 2018
0.6137319459	read
0.6137224484	generative
0.6136728801	shallow
0.6136528171	hyperspectral
0.6135596152	low resource
0.6135552611	tversky
0.6135331387	experimented
0.6135077063	introducing
0.6134880576	survival
0.6134844868	descriptive
0.6134483321	modulated
0.6133744166	high level features
0.6133614133	prior information
0.6133288816	converge
0.6133099943	oncology
0.6132984894	joint optimization
0.6132922452	pnp
0.6132824822	resnet18
0.6132824822	lipschitz
0.6132731836	retinal
0.6132597051	scanning electron
0.6132315476	interfaces
0.6132152386	adaptation
0.6131905130	automating
0.6131632304	effectively capture
0.6131165160	impacts
0.6130873735	bin
0.6130463989	rs
0.6129480026	simply
0.6128664258	protection
0.6128634756	small dataset
0.6128481241	cure
0.6128423510	index
0.6128387606	parameter space
0.6127684572	pointnet
0.6126047447	transition
0.6125672261	pool
0.6125657092	automated
0.6124783123	convolutional blocks
0.6124758868	malaria
0.6124582755	deep autoencoder
0.6124334499	necessity
0.6124334499	default
0.6122348439	color images
0.6121883198	single slice
0.6121223322	phase imaging
0.6121135048	determining
0.6120973050	surprisingly
0.6120240116	biases
0.6119829954	parametric maps
0.6119686308	data sources
0.6118670549	sequential
0.6118405449	categorized
0.6117765753	alternatively
0.6117742324	society
0.6116893400	mv
0.6114882536	image transmission
0.6114041433	dataset comprising
0.6113566763	contour
0.6113145590	recent research
0.6112771407	poly
0.6112692846	regulation
0.6112659639	drug
0.6112234622	coil
0.6111451209	biopsies
0.6111273896	compatibility
0.6110903375	feedback
0.6110895669	autofocus
0.6110895669	microaneurysms
0.6110194599	molecular
0.6109619104	central
0.6109051877	locally
0.6108066576	mouse
0.6108006460	ct slices
0.6107788709	tomography
0.6107647870	clinical applicability
0.6107143182	connectome
0.6106233777	nonetheless
0.6106210213	flash
0.6106198849	supervise
0.6105748174	conv
0.6105422931	trackers
0.6105381528	flops
0.6105117538	ml
0.6105092344	class conditional
0.6104604456	node
0.6104546516	replica
0.6104195790	experimental
0.6103658710	fiber
0.6103487043	research efforts
0.6102948850	iv
0.6102385388	personal
0.6101491471	five fold cross validation
0.6101370614	object segmentation
0.6101287060	referable
0.6100744716	global scale
0.6100235340	octave
0.6099830696	segmentation network
0.6099322811	breast
0.6099263665	page
0.6099148616	fundus
0.6099026653	numerical
0.6098861398	meets
0.6098861398	attentional
0.6098797712	description
0.6098753160	echocardiography
0.6098753160	cooperative
0.6098554494	emerging
0.6098506671	qualitative analysis
0.6098207356	typical
0.6097862540	recognition accuracy
0.6096712559	recently
0.6096523329	object pose
0.6096473356	display
0.6096267856	fully connected neural network
0.6095263990	white
0.6095130360	en
0.6095001926	fields of view
0.6094913277	deconvolution
0.6094781185	proposal
0.6094533037	computer assisted
0.6094510222	deblur
0.6094278890	convolutional
0.6093164268	optical flow estimation
0.6092842386	t1 and t2
0.6091539355	mas
0.6091512029	deterministic
0.6090391731	order of magnitude
0.6090344610	defending
0.6089829434	lambda
0.6088914259	notably
0.6088078209	hydrocephalus
0.6087898321	end to end trainable
0.6087792353	target modality
0.6087625191	deep features
0.6087592886	multi frequency
0.6086987397	radiography
0.6086741006	hashing
0.6086605541	lastly
0.6085985665	maximization
0.6085620846	traditionally
0.6085586379	thermal images
0.6085558745	greatly improved
0.6085422362	implications
0.6085411237	feature engineering
0.6084742965	identity
0.6084537930	norm
0.6084479686	thermography
0.6084263602	undersampled data
0.6083946447	collapse
0.6083697615	positive and negative
0.6083665903	gans
0.6083354172	convlstm
0.6083015223	progression
0.6082431662	coronary
0.6082414830	prerequisite
0.6082397360	deepfakes
0.6082389906	attention network
0.6082293404	qualitative and quantitative
0.6081589959	significant challenges
0.6080531183	generative networks
0.6080296300	optimal solution
0.6079773885	attached
0.6079773885	accompanied
0.6079620657	permutation
0.6079620657	pansharpening
0.6079069915	raw data
0.6078806938	methane
0.6078806938	emergent
0.6078806938	maritime
0.6078806938	zonal
0.6078806938	miniature
0.6078806938	inline
0.6078806938	univariate
0.6078806938	cooperation
0.6078806938	notice
0.6078806938	cerebrovascular
0.6078250822	rendering
0.6078078564	centric
0.6077700044	suppression
0.6076676711	backward
0.6076608573	current approaches
0.6076247588	patch level
0.6076074184	gross
0.6075753794	foreground
0.6075396543	multiple views
0.6074587083	multiview
0.6074310007	normalization
0.6074117336	artery
0.6074100239	cup
0.6073870171	initial results
0.6073437092	protein
0.6072792636	inspection
0.6072772853	adversarial
0.6072763665	attenuated
0.6072713475	lung disease
0.6071946864	pair
0.6070446969	main contribution
0.6070203731	rotational
0.6069791160	stacks
0.6069676067	acquisition speed
0.6068486100	diverging
0.6068486100	rectal
0.6068486100	spacecraft
0.6068486100	photoreceptor
0.6068486100	fetoscopic
0.6068486100	broadband
0.6068486100	sorted
0.6068486100	cuts
0.6068486100	neighbours
0.6068486100	macula
0.6068486100	foot
0.6068486100	repeat
0.6068486100	tabular
0.6068486100	simplex
0.6068359756	color image
0.6068355209	model based
0.6067882975	whole slide
0.6066902633	non destructive
0.6066509483	nearest
0.6066408367	missing data
0.6066295915	representation capability
0.6066181653	electromyography
0.6065853759	quantitative imaging
0.6065134314	refinement
0.6065097369	resnet 50
0.6064938637	training sets
0.6064564809	ideally
0.6064365760	qualitative results
0.6063340361	parameter free
0.6063167414	focused
0.6062664649	liver
0.6062172192	acceleration
0.6060183841	waves
0.6059731995	schizophrenia
0.6059731995	differently
0.6059613669	softmax
0.6058679454	gray
0.6058618775	scientific
0.6058481840	replacing
0.6058358040	manual labels
0.6058353879	knowing
0.6058353879	flood
0.6058153931	wave
0.6057340760	attention block
0.6057135264	macro
0.6056554368	inpainting
0.6055695075	myopia
0.6055454004	atrous
0.6054186077	compressed sensing mri
0.6053542611	modulators
0.6053378958	lateral resolution
0.6053047952	insight
0.6052750229	encrypted
0.6052538814	fluoroscopy
0.6051900817	grayscale
0.6051743322	v2
0.6051444282	stenosis
0.6051259165	sacrificing
0.6051259165	acts
0.6051232891	unsuitable
0.6051062651	pneumothorax
0.6051054885	ct reconstruction
0.6050790700	intervention
0.6050506014	archive
0.6050402700	relevant information
0.6050029216	composition
0.6049731050	deep
0.6048707462	liver tumor
0.6047794849	decision
0.6047173332	image signal processing
0.6046233646	chip
0.6046091751	parallel
0.6045884907	portable
0.6045603542	res
0.6045006946	topological features
0.6044778056	decoding
0.6044607212	user's
0.6044442867	moire
0.6044400895	attack
0.6044219445	manual segmentation
0.6043304003	tiny
0.6043147913	accelerating
0.6042865523	contiguous
0.6042671400	restoration
0.6042509128	sonar
0.6041885489	aperture
0.6041595101	existing solutions
0.6041593109	super resolution microscopy
0.6041258932	code
0.6041187772	life
0.6041162971	adversarially
0.6041162971	backprojection
0.6041074339	response
0.6040820097	iterative process
0.6040747618	road
0.6039137615	lung
0.6039042827	whole heart
0.6038785915	ultrafast
0.6038569292	interpretability
0.6038225138	procedural
0.6037937792	conditioned
0.6037900156	image recognition
0.6037712896	canny
0.6037589797	robust
0.6037127748	unsupervised fashion
0.6036939933	ct dataset
0.6036850986	patch
0.6036377176	randomized
0.6036338086	region segmentation
0.6036183790	inavs
0.6035880546	big
0.6035748482	clinical ct
0.6035487990	drive
0.6034960071	codes
0.6034622256	achieved remarkable
0.6034425407	recently developed
0.6034264662	ill posedness
0.6034072057	spatial temporal
0.6033622725	paramount
0.6033610965	vital role
0.6032227293	feature level
0.6032061777	guidance
0.6031728115	multiply
0.6031498110	shows superior
0.6030927671	tongue
0.6030720945	resnet50
0.6030609849	vibration
0.6029850085	open source tool
0.6029083235	connect
0.6028888972	satisfactory results
0.6028707719	cardiac
0.6028599027	pct
0.6028553978	scoliosis
0.6028553978	examining
0.6028553978	program
0.6028250674	steerable
0.6028122436	5 fold cross validation
0.6027463376	review
0.6027240540	multitude
0.6027158204	neutrosophic
0.6027158204	ear
0.6027158204	locality
0.6027158204	imitation
0.6027158204	buffer
0.6027158204	blending
0.6026912203	disease specific
0.6026835844	neuromorphic
0.6026203921	shrinkage
0.6025972289	polarimetric
0.6025291687	cnn architecture
0.6025286468	international
0.6025129209	synthesis
0.6024926207	creating
0.6024902784	mounted
0.6024464812	visual question
0.6024267924	layered
0.6024267924	accelerator
0.6024112966	proxy
0.6023667932	instant
0.6023317714	records
0.6023242333	reconstructing
0.6023030368	junctions
0.6022224325	diffusion
0.6022060261	controllable
0.6022029593	deep learning algorithms
0.6021572215	image augmentation
0.6021481219	reconstruction network
0.6021413285	statistic
0.6021368672	gadolinium
0.6021145826	colocalization
0.6020857122	atypical
0.6020463805	noninvasive
0.6019643285	red blood
0.6019206529	ai models
0.6019054323	raw
0.6018468787	resource
0.6018401220	action
0.6018084756	biological tissue
0.6017427755	transform domain
0.6017170442	safe
0.6017033232	median
0.6016028106	healthcare
0.6015499586	low grade
0.6015371505	integral
0.6014905206	curriculum
0.6014655286	head
0.6014555684	customized
0.6014400928	aware
0.6014102014	additive noise
0.6013947465	spectroscopic
0.6013711537	interaction
0.6013576951	pancreas
0.6013485413	banks
0.6012973710	skeleton
0.6012614964	mixed
0.6012590346	extended
0.6012154130	multiclass
0.6010760047	osteosarcoma
0.6010336700	plenoptic
0.6010110433	imaging technique
0.6009829824	projected
0.6009211280	ghost
0.6008659269	banding
0.6008519534	chapter
0.6008519534	invasively
0.6008519534	mitral
0.6008507075	searching
0.6007774732	depth of field
0.6007565632	horizon
0.6007565632	silicon
0.6007565632	forcing
0.6007499938	calcium
0.6007499938	explaining
0.6007499938	electroencephalography
0.6007499938	viewport
0.6007499938	beamformer
0.6007135973	transforms
0.6006539439	fact
0.6006487875	pytorch
0.6006261277	semantics
0.6005372170	inverse
0.6005263337	reid
0.6004808622	organ
0.6004373803	gated
0.6004373795	circuit
0.6003800031	conventionally
0.6003116936	polyps
0.6002981274	radar
0.6001887724	imagery
0.6001633862	pretrained models
0.6001604276	cube
0.6001514336	ill posed
0.6001372815	localization
0.6001199503	level labels
0.6000345657	cnn model
0.6000292392	coefficient
0.5999795033	grid
0.5999671621	agents
0.5999525975	normalizing
0.5999304725	generic
0.5999160326	recognizing
0.5998793309	surgery
0.5997128036	unpaired image to image translation
0.5996886951	step by step
0.5996642995	unet architecture
0.5996508822	hyperparameter
0.5996248345	accurately segment
0.5996178864	principal
0.5995292401	nowadays
0.5995037427	time lapse
0.5994729661	information contained
0.5994701531	intravascular
0.5994321944	objective
0.5994176802	arising
0.5994143658	mixup
0.5993820286	likelihood
0.5993378261	detecting
0.5993318961	joint learning
0.5992688845	regularization parameter
0.5992659269	digit
0.5991795995	semantic
0.5990923870	context
0.5988976547	displacement
0.5988719041	rise
0.5988464894	undersampled k space data
0.5988410393	weak
0.5988304319	musculoskeletal
0.5988304319	multiresolution
0.5987910745	motivated
0.5987622500	resonance images
0.5987427453	decoupling
0.5986433090	fully convolutional neural network
0.5986257351	fitting
0.5986236117	programmable
0.5986061878	subspace
0.5985954472	foreground and background
0.5985398889	pix2pix
0.5984790195	ground
0.5984764433	consisted
0.5984764433	steady
0.5984158820	thigh
0.5983492984	bilateral
0.5983309379	contact
0.5982909213	psnr and ssim
0.5982617137	precisely
0.5982338063	follow up
0.5982173024	distance
0.5981487044	nano
0.5981112461	dynamic
0.5980911579	image sensors
0.5980676014	urban
0.5980351929	wide field of view
0.5980044057	potentials
0.5979026427	industry
0.5978949430	crisis
0.5978444192	things
0.5978358271	pulse
0.5977703551	cloud based
0.5977536926	tip
0.5977295111	connected
0.5976666402	mammographic
0.5975745316	muscle
0.5975156132	assessment
0.5974413878	fringe
0.5974199891	volumetric data
0.5974181268	interpreting
0.5974061106	asynchronous
0.5974033364	photon
0.5973964388	keeping
0.5973654987	cross
0.5973284785	achieved excellent
0.5973262524	vision applications
0.5973230645	distancing
0.5973230645	tens
0.5972955749	structure similarity
0.5972367953	densenet
0.5971874719	approximate
0.5971459776	indistinguishable
0.5971456216	subspace learning
0.5971159914	scaling
0.5970601377	gradient
0.5970575907	original input
0.5970517770	variety
0.5970469367	tracing
0.5970469367	piece
0.5969802011	lighting
0.5969705503	augmentation
0.5969370556	brain mr images
0.5969236588	hampered
0.5968960980	velocity
0.5966109670	photography
0.5965530275	disparity
0.5965285657	covid19
0.5965235162	covid 19 infection
0.5963914277	perspective
0.5963774911	shown remarkable
0.5963722022	pooling
0.5963169454	joint reconstruction
0.5962885661	hidden objects
0.5962205590	poor performance
0.5961793405	tracking
0.5961679583	eye
0.5961567279	redundancy
0.5961406356	diagonal
0.5960491950	building
0.5959673525	absorption
0.5959410552	angular information
0.5959154715	saturation
0.5958870840	distance metric
0.5957922578	_
0.5957410715	learning techniques
0.5956977074	quick
0.5956803681	clinic
0.5956364274	run
0.5955908106	attentive
0.5955392918	meeting
0.5955392918	relighting
0.5955392918	continual
0.5955392918	thalamus
0.5955392918	rectification
0.5955392918	binarized
0.5955330936	warping
0.5954952472	wavelets
0.5954658145	merging
0.5954608389	neural architecture
0.5954107925	elevation
0.5953495652	growth
0.5953178042	hyperspectral super resolution
0.5952903823	contributes
0.5952862412	driven
0.5951900006	fetal
0.5951880077	wide angle
0.5951853748	cxr images
0.5951623649	tailored
0.5951367610	oblique
0.5951329781	long acquisition
0.5950673186	belong
0.5950673186	phones
0.5949940485	segmentation challenge
0.5949655486	high probability
0.5949296591	compression methods
0.5949273379	inspire
0.5949222124	prevalence
0.5948948042	molecule
0.5948948042	reviews
0.5948671909	compositional
0.5948671909	chaotic
0.5948585961	spread
0.5948175657	observer
0.5947801183	deformation
0.5947384228	military
0.5947107321	whilst
0.5947107321	diffeomorphic
0.5946529968	dense
0.5946423825	simulation
0.5946404002	fake
0.5946153166	image content
0.5945077832	render
0.5944890288	sky
0.5944646711	captioning
0.5944646711	fabric
0.5944406709	today
0.5944134667	highly undersampled
0.5943596074	denoise
0.5942348467	fair
0.5941737971	large datasets
0.5941549622	inversion
0.5941414982	human intervention
0.5940957253	synergistic
0.5940957253	steganalysis
0.5940347184	dnns
0.5939569633	predicting
0.5939378493	mission
0.5938459226	noise free
0.5937839361	image space
0.5936537520	imbalanced
0.5936359303	landslide
0.5936223079	validation dataset
0.5935444179	pursuit
0.5934798279	person
0.5934670965	arterial
0.5934620676	cardiac ct
0.5934171251	template
0.5933914156	slice
0.5933309859	mimic
0.5932720640	scene classification
0.5932558843	camera model
0.5932182050	interpretable
0.5931801874	temporal consistency
0.5930967058	expand
0.5930170849	multiple scattering
0.5930126468	opportunities
0.5930075552	deviation
0.5929714943	impedance tomography
0.5929588742	video data
0.5929394676	quantitative
0.5929386238	understanding
0.5929262006	informative features
0.5928972862	wound
0.5928972862	residue
0.5928972862	posteroanterior
0.5928960781	registration
0.5928959776	advancement
0.5928455031	intuitively
0.5928127997	high resolution images
0.5927894182	enhancement technique
0.5927067246	pre train
0.5926284419	infants
0.5925844978	fully sampled data
0.5925509232	statistical
0.5925289540	adaptive
0.5924993840	labeled source
0.5924464386	proximal
0.5924451961	harmonization
0.5924293504	manage
0.5923869443	normalization layers
0.5923075030	propagation based
0.5922789901	coding
0.5922605882	aliasing
0.5922403099	footprint
0.5922361628	shifting
0.5921612331	expert level
0.5921045681	vehicle
0.5920459818	minimizing
0.5919448900	frame level
0.5919340015	global local
0.5918749580	shown promising results
0.5918619547	comprehensive evaluation
0.5917704884	calculation
0.5917655927	top hat
0.5917328808	circumvent
0.5916605004	silico
0.5916605004	influenced
0.5915490477	security
0.5915360037	multi scale features
0.5915215717	glioma
0.5913387227	brain volumes
0.5912795082	context information
0.5911429785	effectively improve
0.5911229447	aim
0.5911130704	coherence
0.5910926489	x rays
0.5910819401	spatially
0.5910601276	scalar
0.5910477299	anonymization
0.5910404615	object's
0.5910347464	spatio
0.5910265625	inpainting network
0.5910133551	specifically
0.5909370849	visualization
0.5909172578	hindered
0.5907743266	selection
0.5907660413	detailed analysis
0.5907518550	hyperspectral image analysis
0.5907087418	early
0.5906573385	mechanical
0.5905618774	generating
0.5905178325	interested
0.5905122720	claustrum
0.5905122720	atherosclerosis
0.5905122720	conceptually
0.5905122720	shutter
0.5905122720	electro
0.5905122720	displaced
0.5905122720	penalties
0.5905122720	realm
0.5905122720	audiovisual
0.5905122720	multiplex
0.5905122720	partly
0.5905122720	foundations
0.5905122720	plants
0.5905122720	geolocation
0.5905122720	inducing
0.5905122720	toolkit
0.5905122720	panorama
0.5904437995	latent
0.5904430542	vanishing
0.5903880678	imbalance problem
0.5903201645	reconstruction methods
0.5902988224	feasibility
0.5902949803	multiparametric
0.5902940358	benchmarking
0.5902930382	unregistered
0.5902746401	viewed
0.5902322112	parsing
0.5902322112	draw
0.5901472037	intend
0.5901370459	moving
0.5901302964	photorealistic
0.5901072369	femoral
0.5900843461	dynamics
0.5900363677	projection data
0.5900347767	uniform
0.5899746102	instance
0.5899628764	secure
0.5899628764	note
0.5899519742	object localization
0.5899098064	usual
0.5899089064	conjugate
0.5898129172	vascular
0.5897366277	temperature
0.5896476406	cardiac structures
0.5896240207	survey
0.5896143204	hemoglobin
0.5895698619	medical data
0.5895532589	array
0.5895408969	descent algorithm
0.5894557648	clustering
0.5894344130	matter
0.5893972467	invasive
0.5893626272	past few years
0.5893491347	ct image
0.5893053125	reaction
0.5893032844	mapping
0.5892408732	balanced
0.5891733123	delineation
0.5891554625	optimization method
0.5891162390	implementing
0.5890942318	endmember
0.5890930169	variance
0.5890857322	learning
0.5889836109	processing unit
0.5889005334	recent
0.5888645467	monitor
0.5888476929	low count
0.5887778781	lossy
0.5887766512	hierarchical feature
0.5887750162	retrieved
0.5887655059	sensitivity and specificity
0.5887144593	stuff
0.5887056200	numerous applications
0.5886391728	based trackers
0.5885862721	indicator
0.5884683625	certified
0.5884068899	width
0.5884056282	automated methods
0.5883523164	online
0.5883519583	screen
0.5883447873	skin
0.5882106932	spectral
0.5882004514	optimization techniques
0.5881155373	corrupted
0.5880845456	adipose
0.5880271940	equation
0.5879728134	attain
0.5879036044	compressing
0.5879036044	gliomas
0.5878316506	identification
0.5877692608	susceptible
0.5877692608	notion
0.5877507636	website
0.5877326005	video
0.5876286891	vision
0.5875243095	significant difference
0.5875074001	heart
0.5875008021	weighted
0.5874416342	complementary
0.5873518578	imaging problems
0.5873234901	imu data
0.5873075643	failure
0.5872885485	modeling
0.5872110777	voxel
0.5871703787	t2 *
0.5871095681	speckle
0.5871028330	pathology
0.5870686200	dependency
0.5870532338	frequency
0.5869824145	constrained
0.5868757636	simplify
0.5868757636	demonstration
0.5868757636	associations
0.5868204522	manifold
0.5867729090	brain imaging
0.5866856173	precise
0.5866816876	route
0.5866816876	maintenance
0.5864969990	electronic
0.5864528402	disaster
0.5864290421	multi shot
0.5863927771	segmentation
0.5863710011	generated images
0.5863424306	ct scan images
0.5863324907	cgan
0.5863312592	hippocampus
0.5863312592	spike
0.5863279397	sheet
0.5863217004	data fidelity
0.5863207212	scratch
0.5863115862	deep generative model
0.5863033571	multi target
0.5862968361	machines
0.5862692608	deals
0.5862674886	ct image reconstruction
0.5862660740	reconstructed image
0.5862563092	skip
0.5862492680	initial
0.5862338851	intervals
0.5862113152	benchmark dataset
0.5861788240	divide
0.5861706629	objectives
0.5861468107	gan generated images
0.5861400075	validity
0.5861131232	optimization problems
0.5861123166	examination
0.5860984345	comprised
0.5860758851	sense
0.5860593461	volumetric
0.5860458609	recordings
0.5860236477	fast
0.5859676517	image features
0.5859321552	rating
0.5858723638	embryo
0.5858200404	concatenation
0.5857183625	destructive
0.5856657313	incorporation
0.5856626357	group
0.5856062006	sensor fusion
0.5855800135	factor
0.5855608766	probability model
0.5854735376	learning based methods
0.5853520518	species
0.5852218889	catheters
0.5852218889	onboard
0.5852218889	groupwise
0.5852218889	homography
0.5852218889	compressively
0.5852218889	maximal
0.5852218889	inconsistencies
0.5852218889	resilient
0.5852218889	chemotherapy
0.5852079629	aiming
0.5851655963	deep network
0.5851587952	cylindrical
0.5851587952	approaching
0.5851587952	workshop
0.5851587952	pooled
0.5851587952	assembling
0.5851116708	inferred
0.5851061820	proportion
0.5850549874	methods fail
0.5850538679	aberration
0.5850144898	video super resolution
0.5849888255	anatomy
0.5849764363	image preprocessing
0.5848617327	contextual
0.5848253747	decode
0.5847002887	domain invariant
0.5845573649	resource limited
0.5845446639	cloud
0.5845398130	segmenting
0.5845114978	performance degradation
0.5844892547	trade off
0.5844155348	estimating
0.5843324468	equal
0.5843155525	segmentation networks
0.5843007255	learned features
0.5842781142	extensively
0.5842544030	attribution methods
0.5842369368	cell detection
0.5841657313	accounts
0.5841525019	paid
0.5841305283	heart disease
0.5840955345	video generation
0.5840192608	shortage
0.5840192608	cerebrospinal
0.5839884615	data driven approaches
0.5839540695	printed
0.5838734013	lung ct
0.5838188337	span
0.5838127442	batch
0.5837612776	box
0.5837136592	flow
0.5835137515	anatomical regions
0.5834435616	pleasing
0.5834430127	coupling
0.5833137277	running
0.5832739139	merits
0.5832353392	cytology
0.5831501461	single scale
0.5830562746	radiomic
0.5830525842	optic
0.5830215717	quantized
0.5829863316	top down
0.5828782963	seek
0.5827318678	sampled k space data
0.5827136374	insights
0.5826058234	high temporal resolution
0.5825465007	generated samples
0.5824927096	recognition
0.5824654344	cribriform
0.5824602101	dependence
0.5824459549	integrated
0.5824205134	detection
0.5824055817	robot
0.5824038461	valid
0.5823890913	coherent
0.5822911393	speech
0.5822267464	night
0.5822256518	skeleton based action
0.5821884967	prediction
0.5821608358	weighted loss
0.5820454553	embedded
0.5820241487	estimation
0.5819030153	r2 *
0.5817936669	correlation
0.5817540227	gene
0.5817540227	room
0.5817476166	demoireing
0.5817476166	foveated
0.5817476166	cephalograms
0.5817476166	hemodynamic
0.5817476166	daytime
0.5817476166	navigators
0.5817476166	discovering
0.5817476166	imagers
0.5817476166	embryonic
0.5817476166	jump
0.5817476166	asymptotic
0.5817476166	emotional
0.5817476166	convergent
0.5817476166	lasers
0.5817476166	resilience
0.5816606512	airway
0.5816353392	inductive
0.5816353392	contemporary
0.5816353392	watershed
0.5815125092	naive
0.5813506750	selective
0.5813252130	improving
0.5813108879	network architectures
0.5812355741	health
0.5811386418	delay
0.5811341902	probe
0.5811079950	acoustic
0.5810665281	w net
0.5810332888	extensions
0.5809624485	dimension
0.5809423172	extraction
0.5809329793	automatically detecting
0.5809304627	active research
0.5809284917	images captured
0.5808964937	breakthroughs
0.5808432788	sketch
0.5808057165	maximum
0.5807895058	weights and activations
0.5807672734	behavior
0.5807175644	achieves higher
0.5805853781	update
0.5801125754	label maps
0.5800062820	crucial step
0.5800044951	tandem
0.5799400162	overall survival
0.5798732886	disentanglement
0.5798247457	penalty
0.5798145303	meet
0.5797870506	seeks
0.5797576252	anomalies
0.5796812681	iteration
0.5795362207	ship
0.5795362207	curved
0.5795362207	warning
0.5795362207	handheld
0.5795362207	valence
0.5795362207	briefly
0.5794064330	modifying
0.5793855025	embeddings
0.5793555403	ensure
0.5793411759	detection rate
0.5792871044	residual networks
0.5792367184	pilot
0.5792071809	encoding and decoding
0.5791869871	camera motion
0.5791774042	element
0.5791123125	recurrent convolutional
0.5790765455	consolidation
0.5790765455	multitemporal
0.5790632045	learning framework
0.5790564347	neural
0.5790109963	summary
0.5789000424	direction method of multipliers
0.5788764420	video dataset
0.5788405962	squared
0.5788375046	computing
0.5787680669	error
0.5787566395	social
0.5787213896	self supervised
0.5787042271	merge
0.5787042271	zooming
0.5786977814	identifying
0.5786785276	uni
0.5786192845	terrain
0.5785847750	artefacts
0.5784575272	lenses
0.5784219046	difficult task
0.5783138803	volumetric imaging
0.5783096742	controlled
0.5782679657	suffering
0.5781855450	barcodes
0.5781416366	era
0.5781203468	sports
0.5781203468	neonatal
0.5781203468	fault
0.5781203468	repetitive
0.5781203468	overcomplete
0.5781203468	khz
0.5781203468	supplementary
0.5781081656	applications of deep learning
0.5780653591	compression
0.5780650087	autoregressive
0.5780317957	reality
0.5780258199	encoder network
0.5779926957	ischemic
0.5779853529	global
0.5778814668	policy
0.5778744401	window
0.5778656440	weighting
0.5777799837	post processing step
0.5777049225	smoothness
0.5776133064	starting
0.5776125092	infant
0.5775912749	kits
0.5775747148	face
0.5775416613	trials
0.5775042818	multidimensional
0.5774363120	qualitatively
0.5773548800	characterization
0.5773320059	atomic
0.5773006331	assign
0.5773006331	satisfy
0.5772758167	dimensionality
0.5772625203	encoder decoder network
0.5769623927	reading
0.5768558769	par
0.5768242366	id
0.5768112878	utilizing
0.5767765065	lossless
0.5767763126	prominent
0.5767732368	recall
0.5766838685	denoising
0.5765803817	conquer
0.5765792898	position and orientation
0.5765371621	reduction
0.5764802463	imaging device
0.5764619047	comparison
0.5763715283	positives
0.5763571991	distorted
0.5762957131	emphasize
0.5762020301	osteoporosis
0.5762020301	cast
0.5762020301	delayed
0.5762020301	scatterer
0.5762020301	lipreading
0.5761906895	changing
0.5761784483	fully exploit
0.5761782581	humans
0.5761605520	sensing
0.5760783887	custom
0.5760021206	count
0.5759671519	based methods
0.5759232061	moment
0.5759232061	invertible
0.5758721019	camera sensors
0.5758704190	unstructured
0.5758703054	final classification
0.5758010248	significantly increase
0.5757712265	switching
0.5757712265	portrait
0.5757574372	post training
0.5757043437	proper
0.5756495972	group based
0.5756313622	remarkably
0.5755786506	previous methods
0.5755780765	analytic
0.5754754915	ablation
0.5754349254	burden
0.5754102053	absolute error
0.5754014977	bounds
0.5754003306	nonlinear
0.5753962385	path
0.5752812752	stained
0.5752756284	explicit
0.5752434337	object categories
0.5752372216	band
0.5751928084	adversarial images
0.5751524138	develops
0.5751259886	bottleneck
0.5750786593	discriminative
0.5750755146	inability
0.5750661939	difference
0.5750459707	localizing
0.5750459707	authentication
0.5750338971	radio
0.5749925978	accomplished
0.5749626884	ii
0.5749481861	layout
0.5748682833	short
0.5748143772	pixel space
0.5747971442	thin film
0.5746976661	image dataset
0.5746753622	noisy images
0.5746486745	neuron
0.5744884878	\ url https
0.5744570703	biometrics
0.5744570703	pyramids
0.5744420369	interventional
0.5743001192	conductivity
0.5743001192	ventricles
0.5742982887	input data
0.5742894178	iterative method
0.5742492518	model predictions
0.5742342487	extracting
0.5742042271	metasurface
0.5741964440	enabled
0.5741919558	probabilities
0.5741552423	veins
0.5741495781	constrained optimization
0.5740552504	investigating
0.5740265114	spiral
0.5739054954	reproducibility
0.5738805617	motion artifact
0.5738785358	cell imaging
0.5738606949	biomedical
0.5738337933	deeply
0.5738337933	pointwise
0.5738337933	interleaved
0.5738144816	unseen test
0.5738109538	children
0.5737994955	live
0.5736116534	safety
0.5736069897	drone
0.5735645667	proof
0.5734734759	hierarchical structure
0.5733856829	principle
0.5733843861	relations
0.5733421760	boosting
0.5732827693	post
0.5732516152	task driven
0.5732091876	information flow
0.5731942955	km
0.5731243464	multiple domains
0.5730850806	bit
0.5729770723	blur
0.5729705169	scarcity
0.5729564831	selecting
0.5729453907	bright
0.5729021816	reference frames
0.5728097150	generalizability
0.5727942887	posterior
0.5727288719	colonoscopy
0.5727223212	materials
0.5726385088	uncertainty analysis
0.5726106216	nm
0.5725896870	demosaicking
0.5725896870	unrolling
0.5725376965	grading
0.5724436218	embedding
0.5724358228	regressor
0.5724358228	nested
0.5724358228	spectrometer
0.5724358228	drawing
0.5723828517	remotely
0.5723628458	multi
0.5723506307	optimization algorithms
0.5723485409	green
0.5723101926	snapshot
0.5723096876	fusion module
0.5723032601	matching
0.5722968050	bone
0.5721729659	neural network based
0.5721669186	clone
0.5721669186	sugarcane
0.5721669186	wrinkles
0.5721669186	articulatory
0.5721669186	clock
0.5721669186	simplification
0.5721669186	decryption
0.5721669186	gloss
0.5721669186	ischaemia
0.5721608668	subsampling
0.5721014594	roof
0.5721014594	corner
0.5720889982	exploitation
0.5720599291	targeted
0.5719853617	pavement
0.5719853617	egocentric
0.5719853617	correcting
0.5719853617	deploying
0.5719853617	bio
0.5719666295	concept
0.5719139476	iodine
0.5718713641	aerial vehicle
0.5718437694	execution
0.5717217809	fingerprint
0.5715774335	rapid
0.5715335867	hiding
0.5715335867	protect
0.5715162456	cloudy
0.5715123785	biomarkers
0.5714966241	synthetically
0.5714841836	point of view
0.5714839355	turn
0.5714039690	achieve comparable
0.5713842103	detailed
0.5712551294	landscape
0.5710899033	attention
0.5710598243	polarization
0.5710207912	observing
0.5710055632	product
0.5709878284	responsible
0.5709864665	notch
0.5709804862	spaces
0.5709270744	regularization
0.5709087837	shot
0.5708312089	rank
0.5708254176	efficient
0.5708216508	attenuation
0.5708199773	spatial resolutions
0.5708189046	automated detection
0.5707359283	achieves superior performance
0.5706527047	ultimately
0.5706086762	modify
0.5705530549	implicit
0.5704919384	placement
0.5704551777	corresponds
0.5703676948	timely
0.5702497530	anomaly
0.5701740263	posteriori
0.5701593937	occlusion
0.5701452750	lr image
0.5701313406	minimization
0.5701074890	eyes
0.5700687815	automatic detection
0.5700015913	structured
0.5699626935	classification
0.5699360918	ntire 2020
0.5698618409	sensor data
0.5698254387	image acquisition
0.5698216705	quaternion
0.5698206816	uniformity
0.5697795118	tract
0.5697711880	flow based
0.5697655059	generator and discriminator
0.5696631701	trainable
0.5696603631	simulations
0.5696523251	challenge
0.5696134454	significant attention
0.5695811708	convenient
0.5695811708	delineate
0.5695302780	entire network
0.5694252962	volumetric medical
0.5693710113	similarity
0.5693585511	invariance
0.5693183725	unique
0.5693116883	challenge dataset
0.5693067501	generator
0.5692601526	peak signal to noise
0.5692555767	instruments
0.5692328386	real data
0.5692043942	optimization
0.5690843472	mathematical
0.5690582285	rotation
0.5689709438	wider
0.5689202198	f score
0.5688610137	body
0.5688571094	refer
0.5688306856	belonging
0.5687802187	lesion
0.5687550935	encouraging
0.5686818743	initially
0.5686700714	unsupervised deep learning
0.5686602275	force
0.5686527659	passive
0.5686527659	superresolution
0.5686376384	conclusions
0.5686264371	fertilization
0.5686264371	thread
0.5686264371	characterisation
0.5686264371	deforestation
0.5686264371	crowded
0.5686264371	echocardiographic
0.5686264371	assistive
0.5686264371	sinusoidal
0.5686264371	splines
0.5686264371	heuristics
0.5686264371	walls
0.5686264371	canopy
0.5686264371	sentences
0.5686264371	mixtures
0.5686264371	ordered
0.5686264371	concordance
0.5686264371	pushing
0.5686264371	advancing
0.5686264371	compartment
0.5685931181	results
0.5685570855	graph convolutional
0.5685561919	abundant
0.5684832866	projection
0.5684713967	cycle consistent generative
0.5684319680	wavelet based
0.5683979634	regression
0.5683657803	consumer
0.5683525605	large variations
0.5683497399	tissue segmentation
0.5683282659	class label
0.5683104887	encoder
0.5682915980	flexible
0.5682620898	interpreted
0.5682337551	computed
0.5681373784	captions
0.5680351255	threatening
0.5680351255	losing
0.5679984615	machine
0.5679704149	outlier
0.5679587324	steganography
0.5679030417	rater
0.5678952489	format
0.5678443755	spectrum
0.5677891750	calibration
0.5677833395	doctors
0.5676458060	visible
0.5675954764	final
0.5674445185	motion information
0.5674402347	focusing
0.5674232937	approx
0.5673168615	arteries
0.5672891805	crop
0.5671342359	labeling
0.5668611461	accommodate
0.5668431037	total
0.5668313930	struggle
0.5668171832	networks
0.5667285798	superior results
0.5667015554	infarction
0.5666564701	aggregate
0.5666204781	calculating
0.5665145553	transferred
0.5664702987	tumor
0.5664644179	decomposed
0.5663774217	handwritten
0.5663238652	reconstruction
0.5662735187	fpga based
0.5662306856	squeeze
0.5661422669	whole slide images
0.5661110514	matched
0.5660727024	uncertainty
0.5660508404	ct data
0.5660214034	overlapping
0.5659426241	highly effective
0.5658631877	axial
0.5657929470	scoring
0.5657159174	transfer
0.5656812309	inter and intra
0.5656800833	biopsy
0.5656426141	style
0.5655868329	speech enhancement
0.5655686206	source
0.5655196060	connections
0.5655176897	imager
0.5654981020	extending
0.5654768341	covid 19
0.5654600964	powered
0.5654600964	catheter
0.5654600964	tackling
0.5654600964	separating
0.5654011081	refractive
0.5653847914	inherent
0.5653506225	utility
0.5652737892	cross resolution
0.5652381433	b1 +
0.5651343016	temporal
0.5650985201	p 0.05
0.5649907571	diffraction
0.5649529447	board
0.5648750136	difficult problem
0.5648336273	defense
0.5648163855	core
0.5648142056	pathology segmentation
0.5647084589	deep cnns
0.5647073596	positron
0.5646958669	ranges
0.5646938154	grasp
0.5646130351	low signal to noise ratio
0.5645713200	status
0.5645098085	proposing
0.5644834828	target domains
0.5644729251	clinically
0.5644472853	decoder
0.5644453963	image matching
0.5644316334	deep reinforcement
0.5644257617	diversity
0.5644168149	goals
0.5644114558	sharing
0.5643597462	fat
0.5643355163	continues
0.5642856684	damage
0.5642804358	fibre
0.5642622484	probabilistic model
0.5642016676	fusion method
0.5641784012	alignment
0.5641545506	efficiency video coding
0.5641188275	cornea
0.5641188275	aleatoric
0.5641188275	silhouette
0.5641188275	aneurysms
0.5641188275	prototypical
0.5641188275	accumulate
0.5641188275	magnetization
0.5641188275	closure
0.5641188275	bootstrap
0.5641188275	collectively
0.5641188275	autonomously
0.5641188275	differing
0.5641188275	drowsiness
0.5641188275	posture
0.5641188275	endoscope
0.5640882829	cancer risk
0.5640870877	clean images
0.5640828991	pig
0.5639658417	recovery
0.5639594017	balancing
0.5639535134	view
0.5639389421	line
0.5638937062	pairwise
0.5638812152	graph attention
0.5637831934	handcrafted
0.5637479591	specular
0.5637479591	inferior
0.5637165194	decide whether
0.5636943319	voting
0.5636038023	class classification
0.5635168677	lane
0.5634825497	geometric features
0.5634797028	simulation study
0.5634674705	optimization algorithm
0.5634658407	distributed
0.5634626331	visualizing
0.5634621777	divergence
0.5634621777	perceptually
0.5634304212	void
0.5633773960	crossing
0.5633313568	ground truth images
0.5632870736	replaced
0.5632862831	subsequently
0.5632328551	leave
0.5630887924	pure
0.5630674392	cardiac motion
0.5629903780	transformed
0.5629559104	symbolic
0.5629559104	rectified
0.5629559104	naturalistic
0.5629086032	guided deep
0.5628974956	morphological
0.5628194468	ray
0.5628158695	fused
0.5627977992	corrupted images
0.5627867119	resolution limit
0.5627698798	jet
0.5627578825	risk
0.5625063298	realism
0.5624946094	vitro
0.5624582990	significant role
0.5624011081	consequence
0.5623622211	compress
0.5623428700	backbone
0.5623397621	discretized
0.5623195033	sparse
0.5623184558	construction
0.5623176635	optical imaging
0.5623149330	retargeting
0.5623088430	comparisons
0.5623043333	energy
0.5622986866	speckled
0.5622986866	genomic
0.5622986866	octree
0.5622760139	hidden
0.5622679981	infrared images
0.5621926842	symmetric
0.5621816787	phantom
0.5621671873	medical image classification
0.5621233397	singular
0.5621217085	availability
0.5621200359	ink
0.5621200359	linking
0.5621200359	morphologic
0.5621200359	relaxed
0.5621200359	mark
0.5621200359	complexes
0.5620751482	retaining
0.5620751482	answer
0.5618150633	diffusion tensor
0.5617552206	data collected
0.5617158423	collection
0.5615162050	network
0.5614761083	nonrigid
0.5614761083	validations
0.5614761083	reenactment
0.5614761083	calcification
0.5614761083	conservative
0.5614761083	existent
0.5614761083	teeth
0.5614761083	clothes
0.5614761083	metasurfaces
0.5614761083	stabilizing
0.5614761083	digitization
0.5614761083	assays
0.5614761083	walking
0.5614761083	realtime
0.5614761083	hazards
0.5614761083	artists
0.5614761083	die
0.5614761083	biologists
0.5614761083	mammalian
0.5614761083	coastal
0.5614761083	scleral
0.5614761083	shortcuts
0.5614761083	fatigue
0.5614761083	normals
0.5614761083	reusing
0.5614761083	motivations
0.5614761083	inventory
0.5614761083	rolling
0.5614761083	morphologies
0.5614761083	ophthalmic
0.5614761083	participant
0.5614761083	uptake
0.5614761083	tear
0.5614761083	triple
0.5614761083	emphasizing
0.5614761083	broken
0.5614761083	elaborate
0.5614761083	playing
0.5614761083	utilising
0.5614761083	ophthalmologist
0.5614761083	analogous
0.5614761083	subjectively
0.5614761083	glasses
0.5614761083	spots
0.5614761083	settlements
0.5614761083	tolerance
0.5614761083	hour
0.5614604697	deep learning framework
0.5614309383	based adaptive
0.5612916561	texture features
0.5612832123	learner
0.5612832123	microvascular
0.5612832123	manipulating
0.5612832123	terahertz
0.5612832123	contouring
0.5612832123	facies
0.5612832123	repetition
0.5612832123	plaque
0.5612832123	today's
0.5612832123	regularizing
0.5612460979	perturbations
0.5612460979	reports
0.5611775985	shelf
0.5611170155	fast algorithm
0.5610802404	regularization parameters
0.5610583811	discover
0.5610083420	blurred
0.5609925903	emergence
0.5609639819	toolbox
0.5608504772	latency
0.5607042626	multi phase
0.5606401321	data consistency
0.5606119723	times faster than
0.5606002490	mosaic
0.5605818812	communication
0.5605010137	interpretation
0.5604232721	axis
0.5604187122	cues
0.5603273223	lens
0.5603250326	downstream
0.5602912815	complement
0.5602781460	cyclegan
0.5602273767	rare
0.5602179917	robust segmentation
0.5601986268	working
0.5600587893	aggregating
0.5600163775	reconstruction algorithms
0.5600045476	imputation
0.5600028770	services
0.5599589030	downscaling
0.5599336188	opinion
0.5598637996	arbitrary
0.5598472216	cell
0.5598403146	linear
0.5598286917	connectivity
0.5597821675	evolved
0.5597821675	primate
0.5597821675	smoother
0.5597746207	hand
0.5597684270	interactions
0.5596873081	benchmark
0.5596560508	generalizable
0.5596540413	inter
0.5593523958	image noise
0.5592276976	subtraction
0.5591475576	training labels
0.5591327102	regarded
0.5590072539	classifying
0.5588865022	ground truth data
0.5588354782	lie
0.5588266309	vectors
0.5588142836	paper introduces
0.5587902585	cancer
0.5587055972	specificity
0.5586874679	accelerators
0.5586836169	shape analysis
0.5586149146	sequence to sequence
0.5585434641	reporting
0.5585380631	noise sources
0.5585147924	growing
0.5584784802	computational methods
0.5584556028	association
0.5584027772	keypoint
0.5584004691	cmr images
0.5583575012	non uniform
0.5583535706	type
0.5583307317	categorization
0.5583307317	ultrasonic
0.5583307317	exhaustive
0.5583247832	asymmetric
0.5582307627	context based
0.5581566150	relationships
0.5581553792	half
0.5581043741	conclusion
0.5580270406	obtaining
0.5579901268	waveform
0.5579901268	serial
0.5579885071	respiration
0.5579885071	multilevel
0.5579885071	augmentations
0.5579885071	rejection
0.5579885071	digitally
0.5579535488	amplitude and phase
0.5579319089	visual
0.5578511046	commonly
0.5578269610	b mode
0.5577903442	p 0.001
0.5576790791	fashion
0.5576329728	keypoints
0.5575929093	evaluation
0.5574902335	random noise
0.5574889251	deep convolutional networks
0.5574802302	cell classification
0.5574734481	ultrasound data
0.5574625404	unconstrained
0.5574563311	lateral
0.5574496911	priors
0.5574458325	restore
0.5573921553	image compression framework
0.5573513223	traditional methods
0.5572331656	face images
0.5571737202	direct
0.5571725046	illumination microscopy
0.5571615813	earlier
0.5571353933	morphology
0.5570327458	sampling
0.5570287638	achieves comparable
0.5569496666	priori
0.5569314058	ease
0.5569079889	screening
0.5568308972	pretraining
0.5568308972	baggage
0.5568308972	sorting
0.5568308972	penalized
0.5568308972	exposures
0.5568147990	excitation
0.5568124173	tuning
0.5567882381	select
0.5567734202	variable
0.5567291242	combined
0.5566424840	enhancement network
0.5566251892	encoded
0.5566236258	global features
0.5566210437	formation model
0.5566137174	processor
0.5565772199	breathing
0.5565143740	lead
0.5564783439	relationship
0.5564142834	deployment
0.5563777505	image restoration tasks
0.5562868354	extracted features
0.5562610159	approximation
0.5562591904	date
0.5562077186	transport
0.5561655009	competition
0.5561322521	equipped
0.5560971130	coming
0.5559999529	surgical
0.5559761224	conjunction
0.5559274654	align
0.5558848932	infrastructure
0.5558562424	vendor
0.5558562424	burst
0.5558479045	scatter
0.5557911296	drawback
0.5556629741	firstly
0.5556478356	learning approaches
0.5555751608	image based
0.5555660864	guarantees
0.5555606678	encode
0.5555533784	texture information
0.5555312336	indirect
0.5555214572	multi band
0.5554718446	palpation
0.5554590080	hematoxylin
0.5554510511	necessarily
0.5554484258	phase recovery
0.5554218888	orders
0.5553956703	mammogram
0.5553334815	store
0.5553148350	quantify
0.5553054138	morphological features
0.5552600438	encoder and decoder
0.5552405084	monitoring
0.5552330098	indoor
0.5552318764	hoc
0.5552292423	engineering
0.5551403143	oct scans
0.5551142724	dataset includes
0.5551036459	deliver
0.5550889592	real world settings
0.5550808919	qualitative
0.5550254468	quantitative features
0.5550138806	overlap
0.5549735131	leaf
0.5549301464	parameterization
0.5549301464	cut
0.5548950498	modification
0.5548746734	nonlocal
0.5548523885	correlations
0.5548117372	adversary
0.5547447494	exact
0.5547361106	distinguishing
0.5547350092	spatial
0.5547333009	supervised
0.5547124151	fetal motion
0.5546420472	improved
0.5546143807	neighbors
0.5546141354	node features
0.5546134858	fourier ptychographic
0.5546109676	representational
0.5546109676	grasping
0.5545163619	mortality
0.5544545210	depth
0.5544252689	confidence
0.5544185297	cancer related
0.5543553062	care
0.5543377728	question
0.5543089493	border
0.5542911985	feature based
0.5542554154	model uncertainty
0.5542494164	modality
0.5541998553	self supervision
0.5541501121	interference
0.5541215907	satisfactory
0.5540799701	computational
0.5540772941	extra
0.5540634069	anatomical information
0.5540331866	mix
0.5539950498	percentage
0.5538759048	cnn models
0.5538356599	unlabelled
0.5537374301	artefact
0.5537251873	age
0.5537189005	coarse
0.5536736256	boost
0.5534865604	single
0.5534653409	clinical diagnosis
0.5534531453	gating
0.5534392197	segmentation methods
0.5534375150	constraint
0.5533786445	modern
0.5533141765	automatically detect
0.5532831334	w
0.5532810567	fully
0.5531617445	image and video
0.5531607934	anisotropic
0.5531593573	application areas
0.5531551634	characteristic
0.5531482646	dynamic vision
0.5531275433	annotated training data
0.5531196291	semantic features
0.5530707635	vertebra
0.5530250478	chain
0.5529526409	consistent
0.5529435863	consistency
0.5527832745	stereo images
0.5527729013	performance metrics
0.5526871454	baseline model
0.5526346132	application
0.5525728540	f
0.5524466045	benign
0.5523114570	non rigid
0.5522289198	add
0.5521801900	memory
0.5521722787	transformations
0.5520389690	tumors
0.5519597112	modal
0.5519338284	acquiring
0.5518507814	arbitrary style
0.5518321317	ideal
0.5518204512	operates
0.5517963018	structural
0.5517775393	undersampled
0.5517466599	simulation and experimental results
0.5515713614	statistically
0.5514910448	tensor based
0.5514617942	processors
0.5514617942	delamination
0.5513326816	cancer cells
0.5513308972	morphing
0.5512872289	shape information
0.5512483246	weakly supervised learning
0.5512464970	optimized
0.5510980163	video prediction
0.5510714039	square error
0.5510289271	evaluations
0.5509961524	re identification
0.5509763334	staging
0.5509763334	dental
0.5509763334	ring
0.5509763334	bitstream
0.5509763334	bringing
0.5509763334	albeit
0.5509763334	rotated
0.5509763334	drawings
0.5509763334	optoacoustic
0.5509466921	annotate
0.5507780014	regime
0.5507186130	cell segmentation
0.5506791985	flows
0.5506339011	sectional
0.5506246045	video segmentation
0.5506027527	superpixel
0.5505462845	illuminated
0.5504919567	correspond
0.5504833017	frameworks
0.5504222253	synthetic
0.5504056990	utilization
0.5503967510	states
0.5503963960	image interpolation
0.5503188578	dmri data
0.5502595453	image level
0.5502175889	hyperprior
0.5501413521	mild cognitive
0.5500656784	structural mri
0.5500128664	impairment
0.5499660208	image set
0.5498856743	projection algorithm
0.5498374527	open
0.5498153654	correction
0.5497884220	energy based
0.5497746213	true
0.5497345533	vessel
0.5496604045	cover
0.5496437840	hold
0.5495824670	turbulence
0.5495824670	tracer
0.5495824670	tunable
0.5495824670	resistant
0.5495824670	figure
0.5495824670	evolving
0.5495746866	grained
0.5494505036	feature
0.5494247954	extractor
0.5493417634	tone
0.5492856599	bitrates
0.5492807650	grade
0.5492771283	computer vision
0.5492339011	consist
0.5492273147	situ
0.5492013164	diagnosis
0.5491105016	domain transfer
0.5490812706	converted
0.5490418154	pattern
0.5490284649	mask
0.5489245689	region
0.5488749347	pose
0.5488673906	granularity
0.5488673906	scars
0.5488673906	extrinsic
0.5488673906	extrapolation
0.5488673906	incorrectly
0.5488673906	subsampled
0.5488673906	foveal
0.5488673906	spontaneous
0.5488673906	manifolds
0.5488673906	vertex
0.5488673906	parking
0.5488673906	stylized
0.5488673906	sensitivities
0.5487979618	inclusion
0.5487596123	binary
0.5487319646	spatiotemporal
0.5486938994	360 degree
0.5486613649	implants
0.5485956720	registration method
0.5485444048	anatomical structure
0.5485029105	annotating
0.5485029105	parcellation
0.5485029105	neighborhood
0.5484312933	aesthetic
0.5484134807	malignant
0.5483951275	tile
0.5483906282	important features
0.5483284137	anatomical
0.5483077481	intraoperative
0.5483077481	controlling
0.5482935680	divided
0.5482454574	video enhancement
0.5482276222	random
0.5481775031	supervision
0.5481532313	non convex
0.5480935624	v
0.5480896134	pathologists
0.5480855743	usefulness
0.5479650723	deep learning based methods
0.5479531632	optical
0.5479465077	orbits
0.5479445784	functionality
0.5479244426	possibilities
0.5478844338	real and fake
0.5478839450	quantization
0.5478697582	place
0.5478460892	diagnosis and treatment
0.5477577352	robustness
0.5477402446	guaranteed
0.5476620897	modified
0.5476484921	connection
0.5475223237	training procedure
0.5475111603	until now
0.5474705130	experiments
0.5474505653	poorly
0.5473985858	method named
0.5473439040	evaluations demonstrate
0.5473130240	determination
0.5472682767	fnav
0.5472641020	implementation
0.5472563072	prospective
0.5472563072	multiplexed
0.5472487927	clean
0.5472487621	orientation
0.5472162483	architecture called
0.5472003112	geometry
0.5471893951	histology image
0.5471072507	advanced
0.5470988223	movement
0.5470533582	transmitted
0.5470121698	fingerprints
0.5470059519	gan training
0.5469790567	framelet
0.5469790567	logarithmic
0.5469021587	vertical
0.5467578294	analysis
0.5467559872	segmentor
0.5467559872	histopathologic
0.5467559872	overestimation
0.5467559872	parasites
0.5467559872	copyright
0.5467559872	routines
0.5467559872	wire
0.5467559872	attachment
0.5467559872	decentralized
0.5467559872	invariants
0.5467559872	touching
0.5467559872	summarization
0.5467559872	healing
0.5467559872	master
0.5467559872	inject
0.5467559872	compositions
0.5467559872	ageing
0.5467559872	microvasculature
0.5467559872	intersections
0.5467559872	untrimmed
0.5467559872	imaginary
0.5467559872	sclera
0.5467559872	paintings
0.5467559872	subpixel
0.5467559872	surgeries
0.5467559872	families
0.5467559872	trabecular
0.5467559872	breath
0.5467559872	microlens
0.5467559872	geostatistical
0.5467559872	hotspot
0.5467559872	unimodal
0.5467559872	fluctuation
0.5467559872	underdetermined
0.5466425559	machine learning models
0.5465597888	semantically
0.5465417607	support
0.5465059601	basis
0.5463701728	annotated images
0.5463649382	devised
0.5463599115	innovative
0.5463090916	additionally
0.5462936438	nodules
0.5462496226	cylinder
0.5461927542	r2 =
0.5461925654	water
0.5460434134	transient
0.5460204220	strength
0.5460109659	quantitative assessment
0.5459948910	continuous
0.5459925062	quantitatively
0.5457569535	practitioners
0.5457347288	cultivar
0.5457347288	torso
0.5457273568	paired
0.5456955788	viewpoint
0.5456706446	promise
0.5456702412	mammography images
0.5456579662	background
0.5456531049	b mode ultrasound
0.5456019478	applying
0.5455671293	cope
0.5455412451	test cases
0.5455333392	fine
0.5455085594	block
0.5454396804	network design
0.5453651841	cross dataset
0.5453548093	stochastic gradient
0.5453410678	audio
0.5453144877	alternative
0.5452958883	operator
0.5452865497	spatial correlation
0.5452156863	advance
0.5452119954	hands
0.5451826520	infection
0.5451677633	reliable
0.5451221306	windows
0.5451077413	significant potential
0.5451008687	descriptor
0.5449681596	continue
0.5449641097	sparse sampling
0.5449244134	deep neural network architectures
0.5449170282	clips
0.5448595603	units
0.5447833904	similarity metrics
0.5447715152	integrate
0.5446777965	heat
0.5446499045	fast fourier
0.5446162960	imaging scenarios
0.5444893415	shared
0.5444455482	scale
0.5444253072	frontal
0.5444076744	kinds
0.5444063838	y
0.5443444455	camera and lidar
0.5442691213	channel
0.5442436731	plane
0.5442384939	dose ct
0.5442246171	learning based image compression
0.5440974085	rate
0.5440598600	abundance
0.5440586627	unified framework
0.5440476880	ellipse
0.5440344489	microscope
0.5439939652	quantity
0.5439113455	image degradation
0.5438247243	imaging
0.5437728638	length
0.5436257854	recognition systems
0.5436253851	rigid registration
0.5436127780	marker
0.5435279236	platform
0.5435045761	version
0.5434681596	tomosynthesis
0.5434392728	salt
0.5434390821	shift
0.5434352262	degraded images
0.5433734703	^ *
0.5431559127	noticeable
0.5431320872	overhead
0.5431059800	aided diagnosis
0.5430623049	cone
0.5430458795	brain
0.5430346030	vasculature
0.5430323823	transform learning
0.5430288645	nerve
0.5430047756	cancer detection
0.5429503442	performance comparison
0.5428995924	change
0.5428899219	map
0.5428868851	nonconvex
0.5428868851	standardized
0.5428379388	chest
0.5427712830	house
0.5427044487	convolution
0.5425591417	analyse
0.5425530380	allocation
0.5425346030	transferring
0.5425312629	magnification
0.5425077206	ex vivo
0.5423946149	beat
0.5423308038	text
0.5422826491	triage
0.5422826491	successive
0.5422149894	regularization methods
0.5421899762	contributing
0.5421746658	video based
0.5421495552	solving
0.5421010599	mgre
0.5420505164	driving
0.5419668457	unknowns
0.5419668457	cow
0.5419668457	poles
0.5419668457	mm2
0.5418825563	image processing tasks
0.5418367720	generalization
0.5417734918	vulnerable
0.5417390045	builds
0.5417252866	variational auto
0.5417060761	moderate
0.5416633443	multiscale
0.5416442491	aforementioned
0.5416282149	imaging studies
0.5415149019	effective
0.5414616310	fractures
0.5414613649	private
0.5414407762	neural network architecture
0.5413696535	freedom
0.5413374765	assuming
0.5413374765	characterizing
0.5413319424	signatures
0.5411949681	tests
0.5411538165	infectious
0.5411538165	investigations
0.5411538165	projector
0.5411538165	fluoroscopic
0.5411538165	clutter
0.5411538165	places
0.5411538165	apertures
0.5411538165	mitigation
0.5410856485	h
0.5410469569	attribute
0.5410393531	land
0.5410032630	diffuse
0.5408610650	local features
0.5408326304	pixel
0.5408164468	super resolution network
0.5408134979	proposed method achieves
0.5407294530	kidney and tumor
0.5407045439	technologies
0.5406986926	quantitative and qualitative
0.5406782901	images acquired
0.5406743728	db
0.5406495494	web
0.5406124265	detectors
0.5405434326	accurate
0.5405072820	likelihood estimation
0.5404811859	weight
0.5404120869	dynamic objects
0.5403541113	aperture imaging
0.5403461573	versa
0.5403012438	category
0.5402932350	cluster
0.5402720412	hue
0.5402676387	interpolation network
0.5400441136	co registered
0.5400079382	stacked
0.5400007346	learning methods
0.5399311824	unlabeled
0.5398360663	information loss
0.5398241139	image domain
0.5398134994	save
0.5398033984	margin
0.5397602394	scans
0.5397595647	noisy image
0.5397084573	activity
0.5396799938	vital
0.5395693285	deep learning model
0.5395650249	opportunity
0.5395297356	pre trained models
0.5395275015	decomposing
0.5394731031	frame
0.5394718591	cartilage
0.5394484636	investigation
0.5394288204	dropout
0.5393826250	accurate predictions
0.5393461144	mutation
0.5393461144	cluttered
0.5393461144	motivation
0.5393461144	bodies
0.5392863669	local
0.5392563680	low resolution images
0.5392382032	decorrelation
0.5391308609	parts
0.5390480920	push
0.5390024463	convolutions
0.5389837943	wide
0.5389511798	fidelity
0.5389473207	substantial
0.5388834169	subjective
0.5387668563	brain images
0.5387537632	device
0.5387203733	gigapixel
0.5387203733	composite
0.5387203733	bases
0.5386660153	intensive
0.5386308262	refinement network
0.5385638973	subjective and objective
0.5385607303	malignancy
0.5384819446	valued
0.5384607825	baseline method
0.5384398111	maximizing
0.5384174620	addressing
0.5383187555	next
0.5382993960	image data
0.5382671681	expense
0.5382509487	phase step
0.5381410942	clean image
0.5380991219	pneumonia cases
0.5380978516	hr images
0.5380948552	stable
0.5378457320	vision models
0.5377915334	sign detection
0.5377254584	previous
0.5376844769	space
0.5376659518	fraction
0.5376488991	observation
0.5376396094	image
0.5376020815	efforts
0.5375946093	probability
0.5375612251	cbct images
0.5375547441	ratio
0.5375209636	background noise
0.5374833473	laborious
0.5374830992	region based
0.5374566555	promoting
0.5373610330	tactile
0.5373217083	averaging
0.5373093125	mesh
0.5372319723	sensor
0.5371700430	noise models
0.5371521888	failures
0.5371266000	fmri datasets
0.5370987767	deploy
0.5370422378	translate
0.5370218650	increasingly
0.5369184823	mid
0.5369139177	matrix
0.5368850735	normalized
0.5368484246	inference
0.5368344224	texture classification
0.5367614160	point
0.5367542940	brief
0.5367392013	preservation
0.5366999280	quantitative analysis
0.5366987963	transformation
0.5366456169	down sampled
0.5366101988	ultrasound image segmentation
0.5365842327	non invasive
0.5365794434	long
0.5365569062	backpropagation
0.5363613046	amplitude
0.5363461144	rotating
0.5363461144	exemplar
0.5363303598	visual localization
0.5363183930	medical image reconstruction
0.5363005377	target
0.5362366167	man made
0.5362340259	low light imaging
0.5362108922	statistics
0.5361516448	training and testing
0.5361492066	hundreds
0.5360585315	closed
0.5360521234	mri data
0.5360482530	t1 weighted mri
0.5360262812	recommendations
0.5360262812	corners
0.5359855972	image domains
0.5359746349	open dataset
0.5358963095	image alignment
0.5358492370	emission
0.5357693582	free
0.5357666466	method outperforms
0.5357438835	formulation
0.5356354229	medical
0.5355978894	excellent
0.5355348373	persons
0.5353995777	visual analysis
0.5353547911	thorough
0.5353365148	examples
0.5353289967	height
0.5352906302	ventricular
0.5352395535	deep models
0.5352007071	paired data
0.5351708228	human motion
0.5351277569	learning approach
0.5350240419	human brain
0.5349990976	filter
0.5349583145	piecewise
0.5349306504	though
0.5348242687	sophisticated
0.5347312922	g
0.5345741693	structure
0.5345407096	aesthetics
0.5345407096	augments
0.5345407096	worn
0.5345407096	tubes
0.5345407096	micrographs
0.5345204653	object
0.5344634065	achieve superior
0.5344571229	library
0.5343650294	forensic
0.5343507391	level features
0.5342813654	inference accuracy
0.5340921112	lr images
0.5340857626	efficient solution
0.5340214831	p value
0.5340162095	long short
0.5339899931	retain
0.5339180226	angle
0.5339100536	gender
0.5338828111	partitioning
0.5338828111	causal
0.5338828111	imperfect
0.5338828111	demosaicing
0.5338732553	biometric
0.5338611643	accomplish
0.5338471376	consistency loss
0.5337845119	prototype
0.5336938129	fed
0.5336610894	dimensional
0.5336120117	smoothed
0.5334970378	attention networks
0.5334962132	typically
0.5334777747	diagnosis and prognosis
0.5334519008	brain segmentation
0.5333995814	imaging through scattering
0.5333827211	stage
0.5333761716	reconstruction error
0.5333655870	equations
0.5333173644	method achieves
0.5333173175	magnetic resonance image
0.5333061088	needle
0.5332925299	low and high
0.5332886815	coordinate
0.5332460749	isotropic
0.5331765827	average
0.5331463884	hybrid loss
0.5331223731	volume
0.5330953774	spatial pyramid
0.5330559593	millions
0.5329829673	dependent
0.5329454227	score
0.5329319039	sub aperture
0.5328875769	significantly faster
0.5328408982	distortion
0.5327878703	movies
0.5327800780	hard
0.5327325637	experiment
0.5326850243	automated segmentation
0.5326528006	susceptibility
0.5326258746	octa images
0.5325457275	correct
0.5325148437	m
0.5324926619	context adaptive
0.5324660740	dataset
0.5324660426	feasible
0.5324132542	absence
0.5323904467	stability
0.5323539933	bias
0.5323171847	condition
0.5322748257	finally
0.5321674434	simplicity
0.5320527478	bounding
0.5320208370	three dimensional
0.5319973913	light
0.5319625745	trust
0.5319625745	ventral
0.5319625745	transferable
0.5319625745	nighttime
0.5319427256	explainability
0.5319427256	tractography
0.5319427256	mixing
0.5318195394	validation
0.5318145055	positive
0.5317579118	radiation
0.5317533629	prevalent
0.5317488016	audio and video
0.5317295964	angiograms
0.5317295964	norms
0.5317295964	seed
0.5316325503	shortcomings
0.5316168587	structural and functional
0.5315957610	features extracted
0.5315949494	management
0.5315302871	reference
0.5314971643	deep architectures
0.5314962415	human machine
0.5314568444	lost
0.5314536878	minimum
0.5313342134	l
0.5313183114	fast and accurate
0.5312624677	noisy
0.5311085365	coordinates
0.5310352378	forward
0.5308601100	updating
0.5308601100	sharpness
0.5308410980	extremely low
0.5307670953	favorably
0.5306405783	microtubule
0.5306405783	discomfort
0.5305488596	spin
0.5305478241	choose
0.5305159742	histological images
0.5304683174	methods
0.5304135463	retrieve
0.5304083665	prior
0.5304048520	intermediate
0.5302922438	regularize
0.5302767733	detection method
0.5302361056	traditional
0.5301953896	localization and mapping
0.5301255415	annotated datasets
0.5300887611	competing
0.5300614297	realistic
0.5300564033	microscopy data
0.5300532548	map estimation
0.5299321298	prior distribution
0.5299286293	exclusive
0.5299286293	sec
0.5297666525	lot
0.5297245339	trees
0.5296997440	imaging data
0.5296716183	self similarity
0.5296126526	rd
0.5295435711	picking
0.5295435711	deconvolutional
0.5295284444	target images
0.5294966109	state
0.5294820341	covid 19 pneumonia
0.5294641959	temporally
0.5294410985	explain
0.5293315811	clinical settings
0.5292861789	brain structure
0.5292836738	implant
0.5292433125	rapid development
0.5292408932	label
0.5291625979	disease
0.5291394969	food
0.5291348965	light microscopy
0.5291299376	high grade
0.5290918475	common
0.5289518222	hybrid deep
0.5288969952	patient data
0.5288954104	widefield
0.5288954104	heatmap
0.5288954104	serving
0.5288954104	flipping
0.5288954104	biomechanical
0.5288954104	counter
0.5288954104	resampling
0.5288954104	fog
0.5288954104	pedestrians
0.5288954104	incoming
0.5288954104	turning
0.5288954104	realizing
0.5288954104	sounds
0.5288954104	hazard
0.5288954104	fluence
0.5288954104	translating
0.5287023554	single energy
0.5286802144	breast tissue
0.5286516448	spatial and temporal
0.5285343805	modes
0.5284708686	fragmented
0.5284548079	data sharing
0.5283936079	bitrate
0.5283706520	y net
0.5283646419	sex
0.5283646419	factorized
0.5283646419	distal
0.5283646419	marked
0.5283646419	deriving
0.5283646419	microstructural
0.5283646419	radiance
0.5283646419	elasticity
0.5283646419	rural
0.5283646419	uniqueness
0.5283646419	angiographic
0.5283646419	pruned
0.5283433556	random sampling
0.5282735074	ranking
0.5281771540	benchmark datasets demonstrate
0.5281530506	bootleg
0.5281530506	triplets
0.5281530506	confusion
0.5281530506	airways
0.5281530506	compound
0.5281530506	collision
0.5281530506	printer
0.5281530506	contrasted
0.5281530506	separability
0.5281530506	parcel
0.5281530506	manifestations
0.5281530506	unannotated
0.5281530506	edit
0.5281530506	country
0.5281530506	morphometry
0.5281530506	misleading
0.5281530506	cartoon
0.5281530506	clients
0.5281530506	sentence
0.5281530506	resizing
0.5281530506	diffracted
0.5281530506	detrimental
0.5281530506	concave
0.5281530506	curvilinear
0.5281530506	isolate
0.5281530506	grounded
0.5281530506	probing
0.5281530506	panchromatic
0.5281530506	probes
0.5281530506	truths
0.5281530506	skill
0.5281530506	uneven
0.5281530506	associate
0.5281530506	inverted
0.5281530506	travel
0.5281530506	reservoir
0.5280977942	clear
0.5280507330	developing
0.5280157078	sparsity
0.5280099733	simple
0.5279427014	shape and texture
0.5278840153	synthesized
0.5278695114	database
0.5278613200	abilities
0.5278566546	no reference
0.5278449466	similarities
0.5277627554	t
0.5276870291	development
0.5275661719	fails
0.5275371977	small objects
0.5275183651	potential applications
0.5274908036	phase retrieval algorithm
0.5274606961	spleen
0.5274079385	mpmri
0.5273763527	embed
0.5273736195	share
0.5272907373	heterogeneity
0.5271869888	expert's
0.5271869888	neutral
0.5271824524	high and low
0.5271708333	manual
0.5271219011	differentiation
0.5271219011	trend
0.5271219011	arise
0.5270881548	265 hevc
0.5270496417	acquisition
0.5270013527	encountered
0.5269838758	multispectral filter
0.5269525575	sensor noise
0.5269062566	et
0.5268663806	8 bit
0.5268483445	shown promising
0.5268324128	predictive model
0.5268198383	slide level
0.5268101637	et al
0.5268035262	fusion techniques
0.5267922309	population
0.5267582220	monotonic
0.5267582220	decimation
0.5267582220	thorax
0.5266822937	pyramid network
0.5266488605	importance
0.5266101708	mr reconstruction
0.5265292086	wrapped
0.5265292086	subsidiary
0.5265292086	shooting
0.5265292086	autocalibration
0.5265292086	bins
0.5265292086	resize
0.5265292086	antennas
0.5265292086	necrotic
0.5265292086	spectrogram
0.5264940913	functional magnetic resonance
0.5264839213	kernel
0.5264249717	virus
0.5264146154	sensitive
0.5264143462	improved reconstruction
0.5263799919	aid
0.5263789175	local and global
0.5263732944	pandemic
0.5263130351	super resolution imaging
0.5263024352	predicted
0.5262988019	transfer learning approach
0.5262799986	reproduce
0.5262707036	behaviour
0.5262228643	results highlight
0.5261681061	globe
0.5261681061	6dof
0.5261681061	financial
0.5261681061	staff
0.5261681061	contamination
0.5261681061	organizations
0.5261681061	intriguing
0.5261681061	symbols
0.5261681061	literatures
0.5261681061	conducts
0.5261681061	cytopathological
0.5261681061	autonomy
0.5261681061	instabilities
0.5261681061	lighter
0.5261681061	flooding
0.5261681061	chamber
0.5261681061	interdependencies
0.5261681061	x265
0.5261681061	scored
0.5261681061	cardiologists
0.5261681061	underrepresented
0.5261681061	latents
0.5261681061	misclassify
0.5261681061	farmers
0.5261681061	astronomy
0.5261681061	ranged
0.5261681061	adjustable
0.5261681061	checking
0.5261681061	smears
0.5261681061	ghosting
0.5261681061	overfit
0.5261681061	nuisance
0.5261681061	fascicles
0.5261681061	resort
0.5261681061	viruses
0.5261681061	biomolecules
0.5261681061	scripts
0.5261681061	harness
0.5261681061	keys
0.5261681061	clipping
0.5261681061	chances
0.5261681061	threefold
0.5261681061	packages
0.5261681061	upload
0.5261681061	notoriously
0.5261681061	penalizes
0.5261681061	detectability
0.5261681061	permit
0.5261681061	compliance
0.5261681061	summation
0.5261681061	impacted
0.5261681061	progressed
0.5261681061	realizations
0.5261681061	downscaled
0.5261681061	approximates
0.5261681061	bigger
0.5261681061	smallest
0.5261681061	adaption
0.5261681061	flowing
0.5261681061	needing
0.5261681061	concentrated
0.5261681061	depicting
0.5261681061	older
0.5261681061	governing
0.5261681061	emitted
0.5261681061	nanostructures
0.5261681061	resembles
0.5261681061	expands
0.5261681061	innovation
0.5261681061	discussing
0.5261681061	nanometer
0.5261681061	alleviated
0.5261681061	pushes
0.5261681061	weakness
0.5261681061	burn
0.5261681061	blurriness
0.5261681061	retest
0.5261681061	apparatus
0.5261681061	stems
0.5261681061	accidents
0.5261681061	adjusts
0.5261681061	openly
0.5261681061	altitude
0.5261681061	ringing
0.5261681061	minima
0.5261681061	endogenous
0.5261681061	relax
0.5261681061	indirectly
0.5261681061	ups
0.5261681061	marginally
0.5261681061	demodulation
0.5261681061	dissimilar
0.5261681061	completeness
0.5261681061	discriminates
0.5261681061	portability
0.5261681061	fatal
0.5261681061	round
0.5261681061	electrode
0.5261681061	dry
0.5261681061	photoplethysmography
0.5261681061	century
0.5261681061	undergone
0.5261681061	receiving
0.5261681061	3x
0.5261681061	accounted
0.5261681061	asked
0.5261681061	hampers
0.5261552620	geometric
0.5261054893	ill posed inverse problem
0.5260804185	machine learning approaches
0.5259728545	functional
0.5259462234	calibration method
0.5259340220	metric
0.5259304600	register
0.5259262251	labeled images
0.5259118309	non invasively
0.5258644487	polarized
0.5258474364	detection accuracy
0.5258405682	kidneys
0.5258405682	insertion
0.5258405682	plans
0.5258405682	naturalness
0.5258405682	bacteria
0.5258405682	compensated
0.5258405682	abstraction
0.5258405682	visualisation
0.5258405682	connecting
0.5258405682	assigning
0.5258405682	microstructures
0.5258405682	written
0.5257790798	representation
0.5257507015	incomplete
0.5255870174	proves
0.5255861686	negligible
0.5255134776	data hiding
0.5254738496	labelling
0.5254399457	sound
0.5254191429	attacks
0.5254007310	neurological
0.5253857063	depend
0.5253017995	264 avc
0.5252295494	ultra high
0.5251759391	blood
0.5250844357	computer aided detection
0.5250460176	convergence
0.5248789023	z
0.5248291318	tool
0.5247909033	positive rate
0.5245315634	applying deep learning
0.5244869828	hybrid method
0.5244349833	previously
0.5244334651	hyperspectral image super resolution
0.5242602864	processing algorithms
0.5242165039	internal
0.5241132354	reconstruction techniques
0.5240545985	loss
0.5240141901	venous
0.5240140914	surface reconstruction
0.5240125739	processing speed
0.5239488351	ppm
0.5239344022	inpainting based
0.5238203125	reconstruction technique
0.5237918638	detector
0.5237719511	theory
0.5236516448	spatial and spectral
0.5236147279	deep learning based approaches
0.5236093681	theory and methods
0.5235305425	bring
0.5235234891	planning
0.5234814720	variants
0.5234788926	r
0.5234724650	correspondence
0.5234720956	area
0.5234408959	rate reduction
0.5234194900	attempts
0.5234178938	high acceleration
0.5233817705	encoding
0.5233157979	labeled datasets
0.5233005988	real
0.5232326744	video processing
0.5231713601	generator network
0.5230588639	phase
0.5230442256	image search
0.5230035995	phone
0.5229422082	advantage
0.5229195142	slow
0.5229177667	classical
0.5228300075	strengths
0.5228282598	position
0.5228184977	scan
0.5227979870	squares
0.5227968470	pelvic
0.5227968470	validating
0.5227968470	biophysical
0.5227935641	weighted imaging
0.5227045585	test data
0.5226448432	95 ci
0.5226338232	medical imaging applications
0.5226066139	regard
0.5225879405	learned
0.5225056948	knowledge
0.5224968551	sr methods
0.5224863576	aspects
0.5224353811	temporal features
0.5223924407	masking
0.5223760558	reconstructed
0.5223365023	gan models
0.5223215904	detection methods
0.5222354091	late
0.5222267639	regression based
0.5221675544	set
0.5221540746	compensate
0.5220873520	heuristic
0.5220873520	optimisation
0.5220178180	mapped
0.5220110333	plain
0.5219812432	drones
0.5219812432	researches
0.5219400597	metadata
0.5219400597	gradually
0.5219056103	training
0.5218480790	verified
0.5217860620	flow estimation
0.5217622268	compatible
0.5217151158	labor
0.5216385114	tumour segmentation
0.5216375549	motion
0.5215653930	measure
0.5215653030	progressively
0.5215653030	prognostic
0.5215076284	coefficients
0.5214864887	open challenge
0.5214374815	speed
0.5214015375	regularized
0.5213897528	surface
0.5213255221	dedicated
0.5212376663	supervised and unsupervised
0.5211805882	greater
0.5211629616	period
0.5211454926	limited training data
0.5210949421	functional magnetic
0.5210009118	investigates
0.5209989374	undersampling
0.5209927139	low resolution image
0.5209613829	appearance
0.5208684903	optimal
0.5208493663	massive
0.5208409295	neuronal
0.5207777131	simple and efficient
0.5207384247	segment
0.5207349399	clouds
0.5207194397	sequence
0.5206371362	exposure
0.5206323115	test
0.5205774116	motion prediction
0.5205417906	semg
0.5205417906	personnel
0.5205417906	10,000
0.5204569422	outdoor
0.5203839020	millimeter
0.5203633311	masses
0.5203232080	relative
0.5202799546	segmentation algorithm
0.5202771317	observers
0.5201641671	lesion regions
0.5201602938	bound
0.5201126078	landmarks
0.5201097934	anchors
0.5200868721	pelvis
0.5200868721	autofocusing
0.5200126001	key idea
0.5200021208	multiple images
0.5199893492	numerical results
0.5199521201	technology
0.5199359587	defects
0.5199134959	color
0.5197456151	detection model
0.5196484994	modelling
0.5196403047	synthetic images
0.5196369556	machine learning methods
0.5195765625	impractical
0.5195536861	achieve competitive
0.5195239507	non uniformity
0.5195216044	location
0.5194898778	signal detection
0.5194658572	correspondences
0.5194626375	specifically designed
0.5194569927	serves
0.5193230497	leading
0.5193218997	simulator
0.5192993893	approach yields
0.5192149841	interesting
0.5191712435	down sampling
0.5191299162	spatial transformation
0.5190603551	centers
0.5190568371	pixel based
0.5190311773	phase information
0.5190216558	domain
0.5190066445	formats
0.5189274951	developments
0.5189087656	disease related
0.5189072360	epistemic
0.5189063274	locating
0.5189063274	ensembling
0.5189063274	geological
0.5189063274	abstract
0.5189063274	inferring
0.5187636240	human
0.5187371093	discriminator
0.5187349781	training and validation
0.5186969882	usable
0.5186950664	critical
0.5186637390	based
0.5186533629	existing
0.5186340794	preprocessing
0.5185907979	markers
0.5185778294	image transformations
0.5184142847	filtering
0.5183672660	effect
0.5182392449	generating high quality
0.5181256782	inner
0.5181230952	medium
0.5181188877	diagnostics
0.5180840939	learning scheme
0.5180837327	convolution based
0.5180248147	negative
0.5180036488	simulated and real
0.5179589592	helps
0.5179564099	arts
0.5179517833	scanning
0.5178824740	texture
0.5178342150	repeatability
0.5178076629	detection and tracking
0.5178023568	n
0.5177214393	pet data
0.5176781202	architecture
0.5176374934	stored
0.5175470403	truth
0.5175306259	operative
0.5175233555	advantages
0.5174925451	covid 19 cases
0.5174243041	occurrence
0.5173053929	contrast
0.5173051775	beam
0.5172964631	encoders
0.5172785944	spectral analysis
0.5172750031	results illustrate
0.5172547214	smoke
0.5172547214	phoneme
0.5172430919	robotics
0.5171913653	fit
0.5171910152	generated data
0.5171199080	detect and classify
0.5171033903	pipeline
0.5169918053	data driven approach
0.5169654685	suas
0.5169592826	simulation results
0.5168209173	annotation
0.5168065922	train and test
0.5168053410	u
0.5167419198	incoherent
0.5166378385	resolved
0.5166193694	navigation
0.5166064962	semantic information
0.5164503322	images and videos
0.5164191585	object based
0.5162878460	degradations
0.5162794457	iii
0.5161899198	branch
0.5161666108	flight
0.5161142200	co
0.5160990210	boundary
0.5160660345	difficult to obtain
0.5160619759	reducing
0.5160209301	small
0.5159146463	graphs
0.5159112997	apart
0.5157702084	illumination
0.5156738099	fight
0.5156738099	glaucomatous
0.5156738099	enriched
0.5156738099	histologic
0.5156738099	centerline
0.5156738099	placing
0.5156738099	revisit
0.5156738099	affinity
0.5156738099	metastasis
0.5156738099	acting
0.5156738099	artistic
0.5156738099	photographic
0.5156127685	function
0.5155093623	fold
0.5154974008	classifiers
0.5154492638	detection and segmentation
0.5154441180	experimentally
0.5154429420	fire
0.5154084645	blindness
0.5153883005	1,000
0.5153200874	organs
0.5153048434	skull
0.5151021060	operating
0.5150381753	dealing
0.5149996031	generating synthetic
0.5148380570	methodologies
0.5148351285	combinations
0.5147764309	plausible
0.5147667124	image to image
0.5147224331	dictionary
0.5145975702	quality evaluation
0.5145080714	impact
0.5144579495	reinforcement
0.5143817632	dmri
0.5143802283	numbers
0.5143696579	hdr images
0.5143318546	aligned
0.5141808732	mode
0.5141426433	theoretical
0.5141380258	training dataset
0.5141224996	stream
0.5140228569	global and local
0.5139563788	analytical
0.5139517406	formation
0.5139281104	row
0.5138403708	guide
0.5138204299	fixed
0.5137742999	localized
0.5137376650	essential
0.5137151139	link
0.5137103860	hot
0.5136091242	non line of sight
0.5135049859	fast and robust
0.5134264972	noise robust
0.5133978978	purposes
0.5133765341	accessible
0.5133026105	death
0.5132302820	goal
0.5132224423	approach outperforms
0.5131191760	sensitivity
0.5129896540	minute
0.5129848017	unconditional
0.5129848017	mutually
0.5129848017	shrinking
0.5129848017	localisation
0.5129848017	formulating
0.5129848017	objectively
0.5129848017	bucket
0.5129564313	measurement
0.5129156104	testing
0.5129132347	fundamental
0.5128330334	time series
0.5127698332	viable
0.5127662508	quality
0.5127184559	mask based
0.5125282629	registration network
0.5124798067	human expert
0.5123706123	deep transfer learning
0.5123657977	automatically segment
0.5123540017	predefined
0.5123188560	digital breast
0.5123077629	outbreak
0.5122750615	optical systems
0.5122381767	cancerous
0.5121939661	experts
0.5120018392	camera parameters
0.5119667240	transforming
0.5119503551	360 \ deg
0.5119379005	conventional
0.5119207633	mri images
0.5119019929	segmentation results
0.5118469008	videos
0.5117405733	data synthesis
0.5116773866	unpaired image to image
0.5116463670	distorted images
0.5115585165	defective
0.5115493121	compares
0.5115141098	scattering
0.5114806813	presence
0.5114612834	basic
0.5113334629	source and target
0.5112094257	redundant
0.5110881634	groundtruth
0.5110699906	periods
0.5110051387	tumor detection
0.5109778722	differentiate
0.5109778722	lies
0.5109421459	aspect
0.5109242085	conversion
0.5108439111	solution
0.5108158470	test dataset
0.5105950900	cameras
0.5105633881	potential
0.5105304464	extremely
0.5104571565	clinical research
0.5104407235	movements
0.5103897840	imaging speed
0.5103799702	resulted
0.5103112029	brain networks
0.5102153697	multi shell
0.5102125635	severe
0.5102018026	histopathology image
0.5101526510	confounding
0.5100578661	findings
0.5100312172	concise
0.5100312172	dead
0.5100312172	visits
0.5100312172	diameters
0.5100312172	demographic
0.5100312172	preclinical
0.5100312172	primitive
0.5100312172	junction
0.5100312172	widths
0.5100312172	enlarged
0.5100312172	elimination
0.5100312172	pointing
0.5100312172	ocean
0.5100312172	postprocessing
0.5100312172	glomeruli
0.5100312172	independence
0.5100312172	defenses
0.5100312172	landslides
0.5100312172	untrained
0.5100312172	optimizations
0.5100312172	bending
0.5100312172	misclassification
0.5100312172	diffusivity
0.5100312172	prevailing
0.5100312172	finetuning
0.5100312172	young
0.5100312172	tail
0.5100312172	occupancy
0.5100312172	exudates
0.5100312172	fragments
0.5100312172	standalone
0.5100312172	randomness
0.5100312172	encouraged
0.5100312172	flying
0.5100312172	storing
0.5100312172	origin
0.5099811974	output images
0.5098203829	maps
0.5097992810	sparse signal
0.5096764440	accurate classification
0.5096607321	technical
0.5096258476	becoming increasingly
0.5096243774	simulated
0.5096083130	volunteers
0.5095315891	axes
0.5095315891	slope
0.5095315891	contraction
0.5095315891	concentrations
0.5095315891	lights
0.5095315891	tutorial
0.5095138289	tumour
0.5094826656	intensity based
0.5094515441	arrays
0.5092008551	volumes
0.5091078907	paradigm
0.5089508655	micrometer
0.5089421634	network structure
0.5089225687	similar performance
0.5089206153	informative
0.5088975099	relying
0.5088719662	regularisation
0.5088719662	imperceptible
0.5088480227	diagnostic imaging
0.5088370168	bayesian deep learning
0.5088326067	fields
0.5088302926	linearly
0.5088230271	cloud shadow
0.5088091731	sr network
0.5087992017	refining
0.5087992017	finger
0.5087992017	zones
0.5087973086	images
0.5087859534	classical methods
0.5087670646	ct and mri
0.5087542057	situation
0.5087173667	biologically
0.5087173667	blue
0.5087173667	secondary
0.5087173667	templates
0.5087129977	study
0.5087067268	controls
0.5086973231	frequently
0.5086970680	temporal and spatial
0.5086182299	second
0.5085954192	k
0.5085490254	spiking neural
0.5085049859	trained and validated
0.5085018312	radiologist
0.5084821751	orientation distribution
0.5084492638	segmentation and tracking
0.5083815016	carry
0.5083521122	real images
0.5081450399	broad
0.5081289938	power
0.5080873013	shape
0.5079951736	trajectory
0.5078964648	precision
0.5078526017	local structure
0.5077896398	approach achieves
0.5077831776	training and inference
0.5077801410	fragment
0.5077587984	local information
0.5077517411	producing
0.5076895330	representations
0.5075995446	residuals
0.5075754496	success
0.5075673148	tedious and time consuming
0.5075617836	low light images
0.5075242448	\ mathbf x _1
0.5074838473	natural
0.5073727437	image formation model
0.5073330493	scheme
0.5073259024	order
0.5073171467	speed and accuracy
0.5072322649	autoencoder based
0.5071380616	materials and methods
0.5070753286	discriminate
0.5070123342	unsupervised deep
0.5070086792	information processing
0.5069600214	hardware
0.5069531124	signal
0.5069006973	tumor regions
0.5068789247	existing techniques
0.5068708717	last
0.5068656302	formed
0.5068164030	prone
0.5068035322	software
0.5067922236	access
0.5067833817	diagnostic performance
0.5067810304	reflectance
0.5067606444	d
0.5065756993	speaker
0.5065302487	am
0.5065123820	camera
0.5064890694	real space
0.5064416676	chemical
0.5063276092	classifier
0.5062467482	p
0.5061088946	patients
0.5060705221	hierarchy
0.5060705221	resolving
0.5060705221	invisible
0.5060705221	solver
0.5060180028	optimization framework
0.5059620425	homogeneity
0.5059249786	physically
0.5059249786	theoretically
0.5058464341	resources
0.5057318958	e
0.5056459790	intuition
0.5056459790	multiplications
0.5056459790	occurred
0.5056459790	paucity
0.5056459790	writing
0.5056459790	assesses
0.5056459790	helped
0.5056459790	logs
0.5056459790	session
0.5056459790	detectable
0.5056459790	doctor
0.5056459790	harmful
0.5056459790	smoothly
0.5056459790	workers
0.5056459790	replicate
0.5056459790	centroids
0.5056459790	proving
0.5056459790	raters
0.5056459790	decouple
0.5056459790	disadvantage
0.5056459790	shallower
0.5056459790	nonlinearity
0.5056459790	claims
0.5056459790	asymmetry
0.5056459790	enhancements
0.5056459790	absent
0.5056459790	arms
0.5056459790	chose
0.5056459790	carries
0.5056459790	corrects
0.5056459790	connects
0.5056459790	micron
0.5056459790	distribute
0.5056459790	raised
0.5056459790	attains
0.5056459790	communicate
0.5056459790	illuminating
0.5056459790	reformulate
0.5056459790	penetration
0.5056459790	tilted
0.5056459790	mature
0.5056459790	electrodes
0.5056459790	calculates
0.5056459790	shorten
0.5056459790	undergo
0.5056459790	utilised
0.5056459790	explains
0.5056459790	covariates
0.5056459790	price
0.5056459790	inserted
0.5056459790	practicality
0.5056459790	symptom
0.5056459790	photometric
0.5056459790	tion
0.5056459790	hindering
0.5056459790	evolve
0.5056459790	unrelated
0.5056459790	referring
0.5056459790	spent
0.5056459790	fetuses
0.5056459790	uncorrelated
0.5056459790	fractions
0.5056459790	decomposes
0.5056459790	mitigated
0.5056459790	sides
0.5056459790	frozen
0.5056459790	disciplines
0.5056459790	oversampling
0.5056459790	pieces
0.5056459790	weaker
0.5056459790	aligns
0.5056459790	unacceptable
0.5056459790	deteriorates
0.5056459790	recommend
0.5056459790	options
0.5056459790	billion
0.5056459790	stride
0.5056459790	illuminations
0.5056459790	streamlines
0.5056459790	everyday
0.5056459790	transducers
0.5056459790	inaccessible
0.5056459790	worst
0.5056459790	distinguishable
0.5056459790	phenotypic
0.5056459790	misdiagnosis
0.5056459790	adaptations
0.5056459790	enjoys
0.5056459790	phonemes
0.5056434178	established
0.5055923761	myelin
0.5055923761	metastatic
0.5055923761	servers
0.5055923761	thresholds
0.5055923761	intestinal
0.5055923761	randomization
0.5055382330	cgans
0.5054070814	high efficiency video
0.5053892256	k space
0.5053055420	neural network training
0.5052182344	gained
0.5051475778	rgb + d
0.5050906262	labeled dataset
0.5049975184	trained end to end
0.5049637803	model based reconstruction
0.5049243308	distribution
0.5048672422	segmentation algorithms
0.5048660833	joint spatial
0.5048617572	main
0.5048245855	kinematic
0.5048159317	thousands
0.5047860008	number of iterations
0.5047200379	captured images
0.5047018898	photographs
0.5045173069	deeper
0.5044613144	segmentation accuracy
0.5044573801	architectures
0.5044067889	independent test
0.5042427804	self attention
0.5041074095	degree
0.5040731321	c
0.5040396386	signal reconstruction
0.5040280059	baseline models
0.5040196874	objects
0.5039862221	base
0.5039654987	density
0.5039523057	trade
0.5038655451	researchers
0.5038614473	ill posed inverse
0.5037358029	pathological
0.5037271545	resolution
0.5037151372	mr image segmentation
0.5037020484	globally
0.5036753151	industrial
0.5036716801	full reference
0.5036699742	develop and evaluate
0.5036677774	image coding
0.5036366678	false
0.5036240809	high frequency information
0.5035810856	spatial relationships
0.5035792288	original
0.5034691218	dimensional light
0.5033998978	b
0.5033966968	low
0.5033339338	splitting
0.5032502617	classification network
0.5031135125	lidar based
0.5030918462	segmentations
0.5030289336	design
0.5030121187	bones
0.5030016588	spectral information
0.5029652434	phantoms
0.5029260435	estimation method
0.5028962379	data processing
0.5028793663	testing phase
0.5028508986	weakly
0.5028269250	reproducible
0.5027744041	equivalent
0.5027595748	once
0.5027196424	taking advantage of
0.5027122508	accurate and robust
0.5027110024	highlight
0.5026978116	signals
0.5025921309	c + +
0.5025795366	few shot learning
0.5025288581	scene
0.5024098004	leveraged
0.5024043430	visually
0.5023992659	single shell
0.5023209920	feature points
0.5021339827	video denoising
0.5020601379	fold cross
0.5020001296	trained and evaluated
0.5019492901	outstanding
0.5018176206	style image
0.5018114143	transmission
0.5018055778	codecs
0.5018017905	current methods
0.5017207178	compute
0.5015290390	noise
0.5014749485	optimization based
0.5014742898	respect
0.5014333476	based approaches
0.5012706924	synthetic and real
0.5012445110	patch based methods
0.5012227164	research
0.5011763249	treated
0.5011450544	control
0.5011261980	effectiveness and efficiency
0.5010648343	quality prediction
0.5010292291	independent
0.5010176947	tune
0.5009953664	sinogram
0.5009438837	5 fold cross
0.5009130294	practical
0.5008810247	image decomposition
0.5008253322	training and test
0.5007665603	past
0.5007315814	data points
0.5006892874	located
0.5006476675	literature
0.5006086144	evidence
0.5005942647	recent approaches
0.5005854573	complicated
0.5004998638	parallelism
0.5004716099	contrary
0.5004658741	3x3
0.5004658741	receivers
0.5004658741	membership
0.5004622508	accuracy and robustness
0.5004137491	video action
0.5003453073	clinical information
0.5003251987	segmentation task
0.5003205097	segmentation maps
0.5003091478	irregularity
0.5003091478	bleeding
0.5003091478	columns
0.5003091478	uploaded
0.5003091478	supply
0.5003091478	10x
0.5002886151	optical coherence tomography images
0.5002791694	research field
0.5001749213	deep feature
0.5001158727	record
0.5001027146	proposed method outperforms
0.5000792430	lines
0.5000764119	intention
0.5000764119	truncated
0.5000764119	methodological
0.5000764119	symmetries
0.5000764119	hierarchically
0.4999436711	key
0.4999176117	cells
0.4998941502	size
0.4998617689	concatenated
0.4997941224	studies
0.4997233042	public
0.4996534852	enforce
0.4996409255	segmentation framework
0.4995792777	designing
0.4995332536	class
0.4994956680	unseen datasets
0.4994734314	biopsy images
0.4994492307	gadolinium enhancement
0.4994382287	modal retrieval
0.4994044091	iterative methods
0.4993978914	depth prediction
0.4993700374	pay
0.4993700374	cones
0.4993700374	item
0.4993700374	folding
0.4993700374	adaptable
0.4993700374	pixelwise
0.4993700374	pick
0.4993700374	checkerboard
0.4993700374	predominant
0.4993700374	bundles
0.4993700374	arousal
0.4993700374	fix
0.4993700374	optimality
0.4993700374	seamless
0.4993700374	steganographic
0.4993700374	geometrically
0.4993700374	sided
0.4993700374	undergoing
0.4993700374	engines
0.4993700374	formulas
0.4993700374	tracts
0.4993700374	collaboration
0.4993700374	tilt
0.4993700374	dramatic
0.4992853601	dose
0.4992841573	generators
0.4992561524	input images
0.4992098945	approach
0.4991811313	experiments conducted
0.4991538943	latent features
0.4990679924	open problem
0.4990242706	depth images
0.4989877700	pre
0.4989629778	setup
0.4988585295	goodness
0.4988391848	dl models
0.4987828051	trivial
0.4987772597	scale estimation
0.4987461628	detect
0.4987216451	randomly
0.4986706995	drusen
0.4986000406	emulate
0.4986000406	thousand
0.4986000406	thicknesses
0.4986000406	selectivity
0.4986000406	retained
0.4986000406	image's
0.4986000406	characterise
0.4986000406	protected
0.4986000406	raising
0.4986000406	fetus
0.4986000406	graded
0.4986000406	gauge
0.4986000406	fulfill
0.4986000406	1st
0.4986000406	ordinal
0.4986000406	sectioning
0.4986000406	won
0.4986000406	opened
0.4986000406	monitored
0.4986000406	prostatectomy
0.4986000406	diversified
0.4986000406	programs
0.4986000406	compiled
0.4986000406	restriction
0.4986000406	distributional
0.4986000406	pave
0.4986000406	constrains
0.4986000406	negatively
0.4986000406	moved
0.4986000406	leak
0.4986000406	1.5t
0.4986000406	unifies
0.4986000406	famous
0.4986000406	unrealistic
0.4986000406	demographics
0.4986000406	ing
0.4986000406	restricts
0.4986000406	concentrate
0.4986000406	appearing
0.4986000406	laws
0.4986000406	inform
0.4986000406	distinguishes
0.4986000406	developers
0.4986000406	synergy
0.4986000406	functionalities
0.4986000406	brand
0.4986000406	regress
0.4986000406	harder
0.4986000406	lesser
0.4986000406	alternate
0.4986000406	impairments
0.4986000406	acquires
0.4986000406	superficial
0.4986000406	compactness
0.4986000406	intense
0.4986000406	handles
0.4986000406	corroborate
0.4986000406	collections
0.4986000406	strokes
0.4986000406	justification
0.4986000406	advocate
0.4986000406	reflecting
0.4986000406	preference
0.4986000406	cheaper
0.4986000406	delivering
0.4986000406	biggest
0.4986000406	paving
0.4986000406	respond
0.4986000406	barriers
0.4986000406	proteins
0.4986000406	vastly
0.4986000406	radiometric
0.4986000406	contrasting
0.4986000406	unpredictable
0.4986000406	2nd
0.4986000406	successively
0.4986000406	accessibility
0.4986000406	metrology
0.4986000406	inevitable
0.4986000406	satisfies
0.4986000406	occurring
0.4986000406	speaking
0.4985976079	gradients
0.4985360149	hardware based
0.4984759607	input image
0.4984443798	spectral and spatial
0.4984359897	decrease
0.4984040656	variation
0.4983384835	distinct
0.4983255264	detection and classification
0.4982872813	image level labels
0.4982805560	increasing demand
0.4981501138	improvements
0.4981443698	^ \ circ
0.4979824495	self attention mechanism
0.4978307600	denoised
0.4978059155	features
0.4977735981	real time
0.4977601577	key features
0.4977599084	challenges
0.4976941581	s
0.4976436945	image details
0.4974880638	great
0.4974715307	signature
0.4974463757	commercial
0.4974309421	variables
0.4974205799	data
0.4973821260	unsupervised domain
0.4973813969	branches
0.4973594935	grayscale image
0.4972977651	unseen data
0.4971716525	acquisition and reconstruction
0.4971142526	systems
0.4970320971	general
0.4969152190	daily
0.4968969601	mechanism
0.4968017175	capabilities
0.4968014122	train
0.4967479651	detection and localization
0.4967468549	displays
0.4967094449	input
0.4966895235	input and output
0.4966273711	unknown
0.4965947874	high resolution image
0.4965049859	efficient and effective
0.4961982536	unbiased
0.4959368612	kind
0.4958801137	runtime
0.4958769773	shown great
0.4957567721	reflect
0.4957247391	distributions
0.4957233150	diverse
0.4956904056	remarkable
0.4956735367	define
0.4956161540	learning based approaches
0.4955918015	terms
0.4955620157	field
0.4955235066	square
0.4954200949	case
0.4953941460	essential role
0.4953835170	allowing
0.4953299586	results reveal
0.4952192716	segmentation and classification
0.4952138745	material
0.4951845913	radiographic
0.4951413172	practice
0.4951251914	workflow
0.4949001058	targeting
0.4949001058	subsurface
0.4949001058	photons
0.4948761980	simple and effective
0.4948341615	scenes
0.4947308017	single pixel detector
0.4946662290	limited
0.4944763868	patient
0.4944486391	shell
0.4944071574	image normalization
0.4943667280	advancements
0.4943433999	avoiding
0.4943199096	video analysis
0.4942490470	average dice
0.4942474304	leaderboard
0.4941636928	model outperforms
0.4941542926	synthetic and real data
0.4941085902	advances
0.4941051968	limit
0.4939384967	ratios
0.4939103760	classification task
0.4938945419	low level features
0.4938379048	frame based
0.4938322584	word
0.4937588649	emotions
0.4937243580	underwater image
0.4937086613	versions
0.4936369141	properties
0.4935996261	strategies
0.4935006667	parameter
0.4934763926	high
0.4934326817	comprising
0.4934326817	difficulties
0.4933882673	relevant
0.4933866102	cache
0.4933838437	imaging applications
0.4933596779	registration accuracy
0.4933238356	scales
0.4933113096	wise
0.4932190042	forces
0.4932190042	aging
0.4932190042	agricultural
0.4932190042	critically
0.4932000042	multimedia
0.4932000042	experimentation
0.4932000042	restoring
0.4931994843	cloth
0.4931038975	physical model
0.4930917003	microstructure
0.4930917003	biomarker
0.4929740532	step
0.4929643663	contours
0.4929610672	content
0.4929036539	3 d
0.4928355620	supervised methods
0.4926765353	interventions
0.4926765353	robots
0.4926765353	inaccurate
0.4926528184	technique
0.4922893454	target dataset
0.4922687114	guarantee
0.4922043579	experiments performed
0.4922006294	low dose computed
0.4921533166	phenomenon
0.4921008353	regularization techniques
0.4920976115	imaged
0.4920733164	sampling scheme
0.4920641174	global information
0.4919208977	network's
0.4918840295	labels
0.4918822509	slide
0.4918650028	impossible
0.4917707095	algorithm
0.4917471698	normal
0.4917421912	conventional methods
0.4916782158	receptive
0.4916239214	complete
0.4915941883	model size
0.4915900272	strain
0.4915825548	colored
0.4915825548	instantaneous
0.4915825548	multiplicative
0.4915825548	drivers
0.4915825548	dementia
0.4915422551	definition
0.4915177571	participants
0.4914757974	restoration tasks
0.4914398269	code and trained
0.4914205477	8x
0.4914205477	penumbra
0.4913819541	performance
0.4913735536	fall
0.4912897096	bssfp
0.4912266286	denoiser
0.4912114190	pathologist
0.4911813698	anomalous
0.4911813698	calibrated
0.4911667167	layer
0.4911401986	focuses
0.4911097959	sets
0.4910370182	means
0.4910026528	diagnosed
0.4909124504	principles
0.4909093574	multiple datasets
0.4908390054	sequences
0.4907785304	unet + +
0.4907764533	automate
0.4907705373	recent methods
0.4907418984	according
0.4905834745	explores
0.4905747772	consisting
0.4905247299	suffers
0.4904750353	similarity based
0.4904206620	experienced
0.4904080838	directions
0.4904051657	matrices
0.4903936869	partition
0.4903914832	realistic images
0.4903127643	quantities
0.4902962342	rays
0.4901868593	inverse tone
0.4901582268	expected
0.4900411863	spatial and channel
0.4900376046	instead
0.4899741198	real world datasets
0.4899546932	induced
0.4899519166	sr models
0.4899318749	medical image datasets
0.4899155024	resection
0.4899155024	dominant
0.4899155024	joints
0.4899049232	degrees
0.4898488885	radiologists
0.4898479674	x
0.4897838598	subspaces
0.4897838598	positional
0.4897838598	signed
0.4897838598	instability
0.4897838598	opening
0.4897838598	differentiating
0.4897838598	defocus
0.4897838598	team
0.4897838598	treating
0.4897838598	anatomic
0.4897611804	staining
0.4897496095	workflows
0.4896344967	models trained
0.4896018506	channels
0.4895772626	computation
0.4895636625	moir \
0.4895520780	streaks
0.4894632384	fabrication
0.4894632384	choroidal
0.4894632384	assignment
0.4894632384	queries
0.4894632384	sourced
0.4893805051	performing
0.4893407000	method shows
0.4892366224	straightforward
0.4892266286	tracker
0.4892117488	form
0.4892040136	produced
0.4891432006	capacity
0.4891420592	achieving
0.4889940412	amounts
0.4889021171	differences
0.4888686516	ct volume
0.4888382849	considerable
0.4888323548	seconds
0.4887738175	gathering
0.4887738175	maturity
0.4887738175	ensembled
0.4887738175	films
0.4887738175	fruits
0.4887738175	postoperative
0.4887738175	students
0.4887738175	subtype
0.4887738175	undesired
0.4887738175	skeletons
0.4887738175	actors
0.4887738175	deforming
0.4887738175	textured
0.4887738175	analytically
0.4887738175	layouts
0.4887738175	analysing
0.4887738175	uniquely
0.4887738175	atmosphere
0.4887738175	opposite
0.4887738175	shading
0.4887738175	geodesic
0.4887738175	insert
0.4887738175	seeking
0.4887738175	distant
0.4887738175	threats
0.4887738175	granular
0.4887712151	suppress
0.4887401986	deal
0.4887387909	applications
0.4887122508	accurate and efficient
0.4886896035	reconstruction algorithm
0.4885912630	datasets demonstrate
0.4885432852	future
0.4883514975	progress
0.4883303820	consideration
0.4883134037	allowed
0.4882947104	gestures
0.4882141690	drop
0.4881901508	sure
0.4881165372	plan
0.4880354836	diseases
0.4880345320	implementations
0.4879219721	models
0.4878764497	encourage
0.4878317919	missing
0.4878209627	method performs
0.4878155181	countries
0.4877642715	morphed
0.4877642715	retrained
0.4877239694	closely
0.4875828524	related
0.4874690781	imaging techniques
0.4874214867	imaging technology
0.4873842150	standardization
0.4873842150	luminance
0.4873627893	pseudo
0.4873568022	multiple
0.4873468010	skeleton based
0.4873128490	widespread
0.4873121747	ways
0.4872492157	denoisers
0.4872274858	training scheme
0.4872144153	classification and segmentation
0.4871132391	processing
0.4869916517	color information
0.4869798337	hierarchical features
0.4869336846	connected layers
0.4869094942	brats 2020
0.4868988564	aerial image
0.4868570524	subnet
0.4867927765	$ \ ell_ \ infty
0.4867925748	affected
0.4867758180	high field
0.4867405433	algorithmic
0.4867254902	cases
0.4867081570	original image
0.4866206355	neural network architectures
0.4865939658	recover
0.4865544084	dilation
0.4865453575	sample
0.4865205799	report
0.4864886746	promote
0.4863734488	reasonable
0.4863179061	handling
0.4863016961	individual
0.4862647014	discriminators
0.4862647014	ambiguous
0.4862647014	eliminating
0.4862563988	fundamentally
0.4862563988	parameterized
0.4862350652	lesions
0.4862278842	routine
0.4862246581	mappings
0.4862120808	adoption
0.4862077071	fuse
0.4861497611	profiles
0.4861139725	performances
0.4860690462	undersampled k space
0.4860547282	trained and tested
0.4859656302	level
0.4859378771	recent success
0.4859295419	real world data
0.4858386043	dimensional space
0.4858350180	interpret
0.4857923391	slightly
0.4857566539	neighboring
0.4857478259	coherence tomography images
0.4857457740	degraded
0.4857408814	baseline
0.4856427302	consistently
0.4856285921	residual u net
0.4856153615	fewer
0.4855866643	combination
0.4855613101	similar
0.4854605841	time resolved
0.4854456043	hours
0.4853392074	test images
0.4852890155	sensors
0.4852707250	high noise
0.4851862611	accuracy and efficiency
0.4850789328	generalizes
0.4850584160	infected
0.4849845020	convolutional neural network based
0.4849343819	experimental design
0.4848531839	mainstream
0.4848531839	preserved
0.4848401239	abnormal
0.4848144422	sum
0.4847629363	carefully
0.4847154174	unsupervised methods
0.4846176143	reason
0.4846103199	large
0.4845371325	subject
0.4845277190	highly challenging
0.4845248907	iterations
0.4844963338	he
0.4844596694	storage
0.4843694171	area under
0.4843583065	medical imaging data
0.4843527161	jpeg image
0.4843215351	land use
0.4842998422	helpful
0.4842560320	annotations
0.4842059912	proposals
0.4841976919	pictures
0.4841976919	positioning
0.4841695474	contrast enhanced magnetic resonance imaging
0.4841092650	released
0.4841020102	huge
0.4840172374	mechanisms
0.4840095685	image size
0.4839713022	labeled
0.4839520062	network structures
0.4839310336	partitions
0.4839310336	averages
0.4839243279	physical
0.4839232261	remove
0.4837966745	characterize
0.4837368223	resnet based
0.4836859970	important step
0.4836782500	meshes
0.4836455280	external
0.4836455280	contributions
0.4836377880	global spatial
0.4836280583	symptoms
0.4836280583	learnt
0.4836267504	unseen
0.4835256911	solely
0.4834299532	detailed information
0.4833229520	image series
0.4832656104	users
0.4832611572	ideas
0.4832209112	h & e
0.4832105703	detection performance
0.4831178886	segmentation predictions
0.4830883332	operate
0.4830824681	assess
0.4829954141	requirements
0.4829595166	abundances
0.4828906178	heavily
0.4828354284	pulmonary disease
0.4828322203	reconstruction loss
0.4827518746	costs
0.4827440954	conventional method
0.4826293398	labelled
0.4826159312	eliminate
0.4825899867	covid 19 patients
0.4825795999	tend
0.4825513354	types
0.4824530624	gain
0.4824444445	corrected
0.4824443355	spread functions
0.4823780583	standards
0.4823615879	fr \
0.4821070930	modules
0.4820585795	generate
0.4818672158	streams
0.4818611770	usage
0.4818574611	processed
0.4818454976	hi
0.4815094556	paper addresses
0.4814927416	maintaining
0.4814670142	simulate
0.4813462946	prediction model
0.4812911863	efficient and accurate
0.4812763121	decade
0.4811965165	mammograms
0.4811802487	pairs
0.4810495479	strong
0.4810117996	highly
0.4809869229	learning algorithms
0.4809237824	leading causes
0.4809220321	tools
0.4808217527	augment
0.4808053021	spectrum disorder
0.4807883576	patient's
0.4807262290	model's
0.4807181802	variability
0.4807168074	empirical results
0.4805439282	limitations
0.4805428647	robust and accurate
0.4805428647	code and models
0.4804632055	drawn
0.4804353828	cancer screening
0.4804285028	method called
0.4804263605	close
0.4803764147	module
0.4803135936	5g
0.4803135936	2x
0.4803135936	milliseconds
0.4803135936	weeks
0.4803135936	stiffness
0.4802932913	perceived
0.4802505179	confirmed
0.4802024062	production
0.4801621227	baseline methods
0.4801385131	protocols
0.4801267205	clinical
0.4801168342	reconstructed images
0.4800597772	functions
0.4798635661	examine
0.4797674939	large number
0.4796817895	non contact
0.4796122953	assumptions
0.4795087789	p =
0.4794611628	66
0.4793862598	holes
0.4793449079	experience
0.4793232585	contribution
0.4793207227	scenario
0.4793139135	effective and efficient
0.4792759317	termed
0.4792492000	generated
0.4792270467	applicable
0.4792267896	information
0.4792243232	non trivial
0.4791679377	jointly
0.4791651188	pcle
0.4790746974	reconstruction process
0.4790276812	reuse
0.4790200879	trajectories
0.4789616142	interferogram
0.4789616142	predominantly
0.4789616142	mandible
0.4789616142	theories
0.4789616142	mistakes
0.4789616142	repositories
0.4789616142	industries
0.4789616142	activated
0.4789616142	categorize
0.4789616142	suppresses
0.4789616142	immense
0.4789616142	favor
0.4789616142	enlarge
0.4789616142	footage
0.4789616142	entries
0.4789616142	replaces
0.4789616142	revolutionized
0.4789616142	fabricated
0.4789616142	prepare
0.4789616142	discarded
0.4789616142	rising
0.4789616142	possesses
0.4789616142	opaque
0.4789616142	utilise
0.4789616142	policies
0.4789616142	roles
0.4789616142	maximizes
0.4789616142	guess
0.4789616142	altering
0.4789616142	replay
0.4789616142	blurs
0.4789616142	comparably
0.4789616142	damages
0.4789616142	broader
0.4789616142	delivered
0.4789616142	injected
0.4789616142	synergistically
0.4789616142	imply
0.4789616142	dividing
0.4789616142	dielectric
0.4789616142	hungry
0.4789616142	transmitting
0.4789616142	movie
0.4789616142	mimics
0.4789616142	genes
0.4789616142	blob
0.4789616142	stacking
0.4789616142	sensory
0.4789616142	discarding
0.4789616142	regularizations
0.4789616142	treats
0.4789616142	gave
0.4789616142	accompanying
0.4789616142	intrinsically
0.4789616142	compresses
0.4789616142	surprising
0.4789616142	unsolved
0.4789616142	alter
0.4789616142	mitigates
0.4789616142	retrain
0.4789616142	attempted
0.4789616142	recalibrate
0.4789616142	elderly
0.4789616142	resected
0.4789616142	exceeding
0.4789616142	confirming
0.4789616142	overlaps
0.4789616142	straight
0.4789616142	uncover
0.4789616142	consumes
0.4789616142	restrict
0.4789616142	forecast
0.4789616142	modulating
0.4789616142	mirror
0.4789616142	definitions
0.4789298437	model selection
0.4788968994	gains
0.4788648106	fmri
0.4788284710	series
0.4787159903	spectra
0.4787148092	concentration
0.4786950352	play
0.4786797639	serve
0.4786424062	decades
0.4786222005	crafted
0.4785690810	moving object
0.4785396776	observe
0.4785116130	exploited
0.4784674572	focus
0.4782853185	heterogeneous
0.4781718032	consecutive
0.4781586086	`
0.4781067998	self supervised learning
0.4780136567	achieved promising
0.4779180728	fits
0.4777717087	refocusing
0.4777717087	curated
0.4777717087	practically
0.4777717087	expanding
0.4777717087	drift
0.4777717087	professional
0.4776958361	techniques
0.4776342906	variant
0.4775940122	freely available
0.4775535039	built upon
0.4775387662	data acquired
0.4774948477	protocol
0.4774458429	calculate
0.4774396322	patterns
0.4774021475	registration methods
0.4773972863	lives
0.4773939868	descent
0.4773871874	radiotherapy
0.4773772505	real noise
0.4773636770	negative rate
0.4773213927	this
0.4772817477	neural net
0.4772507033	estimate
0.4770569035	achieved great
0.4770181458	model
0.4770013484	overlapped
0.4768652094	blurring
0.4768423180	healthy
0.4768302570	limited availability
0.4767902867	pristine
0.4767405143	mri acquisition
0.4767301595	neurons
0.4767072520	ai based
0.4766733200	conditioning
0.4765991845	views
0.4765662890	expensive and time consuming
0.4765389272	salient object
0.4765318761	colour
0.4764362879	us
0.4764031182	freely
0.4763727809	trained models
0.4762941985	nodes
0.4761343969	offer
0.4760947594	scenarios
0.4760901185	formulate
0.4760831288	locate
0.4758930219	method
0.4758597229	j
0.4758266246	feed
0.4757791763	visualize
0.4757577226	image similarity
0.4757031385	experiment results
0.4756108829	clinical studies
0.4755791871	requiring
0.4755742589	extremely high
0.4755701708	infer
0.4755569640	higher
0.4755428647	accuracy and speed
0.4755378030	constraints
0.4755289481	tissue
0.4754974742	brightness
0.4754702336	self
0.4754537296	convert
0.4754500327	exist
0.4754235214	overcoming
0.4754235214	organized
0.4754235214	contaminated
0.4753990769	sections
0.4753568547	predictor
0.4753458001	synthetic and real world
0.4753412920	capturing
0.4752866258	yield
0.4752445986	computer
0.4752051746	deformations
0.4751605243	intensity
0.4751455445	outcome
0.4750045309	large volume
0.4749694263	clinical data
0.4749685643	offline
0.4749479331	measurement noise
0.4749300962	depends
0.4748949022	task
0.4747339988	whole body
0.4746932917	degradation
0.4746693893	scanners
0.4746630188	phantom data
0.4746442970	maintain
0.4746425221	inputs
0.4745488936	embedding based
0.4745460351	content based
0.4744689901	network weights
0.4743890133	finding
0.4743504937	feature detection
0.4743410655	forward operator
0.4742814565	n =
0.4742765772	reference data
0.4742725256	simultaneously
0.4741867780	de
0.4741118146	magnitude
0.4740721403	fused images
0.4739498879	improve
0.4738825868	network parameters
0.4738461652	readily
0.4736101958	footprints
0.4736101958	stego
0.4736101958	beats
0.4735370349	outperforms existing
0.4734865571	enhance
0.4734755910	realize
0.4734685823	activations
0.4734554960	un
0.4733562452	cost
0.4733444814	prognosis
0.4733254049	influence
0.4733066799	require large
0.4732733340	algorithms
0.4732194564	number
0.4731182075	recent progress
0.4730834869	posed
0.4730638980	imaging devices
0.4730069544	increasing
0.4729052538	learning models
0.4727833601	emerged
0.4727833070	fusion methods
0.4727644748	assumption
0.4727606161	takes advantage
0.4727042097	raw image
0.4726518888	versus
0.4725683622	noise model
0.4725540257	sct
0.4725173164	visemes
0.4724972333	derive
0.4724884942	decreasing
0.4723296433	testing data
0.4723236659	classification performance
0.4723004138	stained images
0.4722652415	effort
0.4722596146	paper describes
0.4721983612	reward
0.4721983612	certainty
0.4721983612	inhomogeneous
0.4721983612	relating
0.4721983612	repair
0.4721983612	geographical
0.4721983612	filling
0.4721983612	polynomial
0.4721983612	decompositions
0.4721983612	impaired
0.4721983612	innovations
0.4721983612	propagating
0.4721983612	truncation
0.4721983612	modelled
0.4721696418	smaller
0.4720943658	referred
0.4720371576	me
0.4720245537	continuously
0.4720111989	invariant feature
0.4719530933	reconstruction accuracy
0.4719239137	satellites
0.4718911916	superiority
0.4718315497	phase contrast imaging
0.4718233747	area of research
0.4718133464	training of deep
0.4717825930	tracking performance
0.4717206710	enhancement methods
0.4717056449	assumed
0.4716901498	compression algorithms
0.4716809800	obtained
0.4715814012	subtle
0.4715582150	based classifier
0.4714956280	$ \ ell_2
0.4714182769	costly
0.4713175280	prevent
0.4713113389	important
0.4711728699	regularizer
0.4711702121	camera based
0.4711619352	approach shows
0.4711182487	generally
0.4710834051	one shot
0.4710388203	classification models
0.4709237579	accuracy loss
0.4709123037	vanilla
0.4709080343	iteratively
0.4709080343	regional
0.4708437121	lungs
0.4708315016	contained
0.4708158020	achieving high
0.4707401815	collect
0.4706521305	occlusions
0.4705510441	end
0.4705271932	detection and diagnosis
0.4704749583	photos
0.4703866383	composed
0.4703048269	segmentation performance
0.4703016455	synthetic datasets
0.4702416487	discontinuities
0.4702304815	empirically
0.4701426053	deep neural network based
0.4701409191	property
0.4700773035	modeled
0.4700707280	parameters
0.4700704771	efficacy
0.4700625998	frames
0.4699842456	desirable
0.4699624213	majority
0.4699624037	establish
0.4698917901	cadaveric
0.4698917901	seeds
0.4698917901	chet
0.4698917901	subproblem
0.4698917901	100,000
0.4698892047	framework
0.4697994066	produce high quality
0.4697843978	data distributions
0.4696565881	component
0.4696258675	separate
0.4696228616	segmentation models
0.4695126349	timepoint
0.4695126349	motility
0.4695126349	chips
0.4693414362	decompression
0.4693386679	recognize
0.4692839793	verify
0.4692125889	computations
0.4691703963	replace
0.4691217605	multi task network
0.4690956114	greatly
0.4690888566	environment
0.4690202177	base model
0.4689376518	accuracies
0.4689204858	multi object
0.4689145349	handle
0.4689080728	proposed approach
0.4688968934	dependencies
0.4688834735	localize
0.4688775987	powerful
0.4688555145	nature
0.4688332306	classification problem
0.4688194964	irregular
0.4688139389	dnn models
0.4686770712	thereafter
0.4686395536	f measure
0.4686375848	acquired
0.4685179702	upsampling
0.4685179702	collecting
0.4685047559	learn
0.4684717217	section
0.4684114525	model learns
0.4683973067	prove
0.4683221270	reveal
0.4682953681	regression models
0.4682910875	gan model
0.4682688026	immersive
0.4682688026	practices
0.4682688026	centered
0.4682688026	visualizations
0.4682482676	medical ultrasound
0.4682253275	segmented
0.4681755986	clustering algorithms
0.4680144748	illustrate
0.4680066601	synthetic dataset
0.4678110007	levels
0.4678021769	boxes
0.4677836292	masks
0.4677523881	manipulations
0.4677523881	sessions
0.4677523881	delineations
0.4677523881	reweighted
0.4677523881	twofold
0.4677523881	subregions
0.4677523881	calibrate
0.4677523881	onset
0.4677523881	rectangular
0.4677523881	adjustments
0.4677523881	oxygenation
0.4677523881	prototypes
0.4677523881	initialized
0.4677523881	carrying
0.4677523881	alleviating
0.4677523881	decay
0.4677523881	immediately
0.4677523881	authentic
0.4677523881	viability
0.4677451133	applied
0.4677171205	unpaired data
0.4676863051	profile
0.4675793831	combining multiple
0.4673412513	registered
0.4673350683	biological
0.4672632960	formulated
0.4672237916	raise
0.4672003628	optimize
0.4669773245	dimensions
0.4669767125	perturbation
0.4669459347	standard
0.4668125889	classic
0.4667065008	facilitate
0.4666863051	thickness
0.4666228394	calculated
0.4666114127	high end
0.4665755989	hence
0.4665699623	pixels
0.4665162148	achieve higher
0.4664862647	improvement
0.4664809698	criterion
0.4664600939	layers
0.4664541158	reduce
0.4664092024	established methods
0.4663852126	implement
0.4662772359	graph neural
0.4662696725	vessels
0.4662606949	test datasets
0.4662576648	methods require
0.4662146282	visual assessment
0.4661260525	great importance
0.4660532067	dense network
0.4660409986	selected
0.4659228682	model driven
0.4658893510	showing
0.4658723115	assigned
0.4658631585	entire
0.4658157911	spatial features
0.4658078026	sinograms
0.4657819783	segmentation labels
0.4657733604	relevant features
0.4657237852	hdr image
0.4656330272	important information
0.4655668286	reconstruction method
0.4655240512	critical role
0.4654608078	publicly available
0.4654476700	time consuming
0.4654353995	maximize
0.4653953865	designed
0.4652820551	promising
0.4652730781	effectiveness
0.4652609055	interferograms
0.4652590024	published
0.4652350005	capability
0.4650647544	requirement
0.4650329653	ambiguity
0.4649503628	benefits
0.4649083995	weights
0.4649059699	resolutions
0.4648843533	retrieval process
0.4648707250	publicly
0.4648424718	$ \ ell_1
0.4648235067	added
0.4647769542	model parameters
0.4647763027	whole brain
0.4647530891	isolated
0.4647530891	optimally
0.4647203313	sufficient
0.4647100802	mitigate
0.4646602770	easy
0.4646384676	operators
0.4646121286	generates
0.4646002570	occluded
0.4645851724	conditions
0.4645023689	deep encoder decoder
0.4644708789	expert
0.4644579790	automatically
0.4644282053	prediction models
0.4643920900	included
0.4643849680	separated
0.4643849680	scalability
0.4643393898	classified
0.4643339092	effects
0.4643090114	overcome
0.4641878122	viewing
0.4641782142	tries
0.4641313721	bands
0.4641264479	term
0.4641180020	visual speech
0.4641033530	assist
0.4640990189	heavy
0.4640787778	distinguish
0.4640208600	complex
0.4640100331	suffer
0.4639942542	predictive value
0.4639732840	denoising methods
0.4639620670	addresses
0.4639545887	closely related
0.4639374880	denoising performance
0.4639345764	learned image
0.4637891574	possibility
0.4637547321	interpolation methods
0.4637236561	segmentation result
0.4637008484	benefit
0.4636968210	cm
0.4636311392	ai systems
0.4635707038	specific features
0.4635698834	determine
0.4635272919	cropped
0.4635272919	parallax
0.4635272919	generalizing
0.4634054907	computationally
0.4633724665	generalizes well
0.4633711566	high spatial
0.4633436211	algorithm called
0.4633211213	physicians
0.4632857769	first
0.4632847730	reach
0.4632837202	covering
0.4632291592	sketches
0.4632272578	blocks
0.4632189277	diagnostic
0.4631443746	products
0.4631357212	phenotypes
0.4630384880	even though
0.4630299276	predict
0.4630205126	few view
0.4629732601	describes
0.4629684160	wavefront
0.4629286344	accurate diagnosis
0.4629233409	incorporate
0.4629126822	determined
0.4628866985	although
0.4628631894	assessed
0.4627161429	demand
0.4627006870	accuracy
0.4626378128	realistic looking
0.4626268083	two dimensional
0.4625824360	proposed architecture
0.4625786845	validation accuracy
0.4625574480	explored
0.4624867120	relies
0.4624400771	spreading
0.4623774413	testing dataset
0.4623311095	similar accuracy
0.4623211213	criteria
0.4623211213	wavelength
0.4623014421	aimed
0.4622578797	aims
0.4622101121	generated image
0.4621601864	metrics
0.4621204461	training stage
0.4620697556	output
0.4620304756	enhanced mri
0.4619591252	devices
0.4619331230	suitable
0.4619272975	volumetric video
0.4618838041	article
0.4618532148	tackle
0.4618054739	trained from scratch
0.4617657650	desired
0.4617079502	performed
0.4616613066	held
0.4616163836	specialized
0.4615977087	treatment
0.4615811188	framework achieves
0.4615342991	flexibility
0.4615260667	world
0.4614962791	backbones
0.4614898741	geometries
0.4613338995	load
0.4613281425	https
0.4612748590	human vision
0.4612367308	reference image quality assessment
0.4611530456	orientations
0.4611327856	extent
0.4610824131	related features
0.4610783756	strategy
0.4610676410	forms
0.4610390688	quantisation
0.4609504067	predictions
0.4608843430	clustering methods
0.4608760753	sampled
0.4608075308	model achieves
0.4607183315	front end
0.4606010162	preserve
0.4605753396	scanner
0.4605750045	downsampling
0.4604571226	tedious
0.4604556796	im
0.4604268557	watermark
0.4604171913	drawbacks
0.4604170339	closely related to
0.4604077525	direction
0.4602131119	valuable
0.4601528111	competitive
0.4601407055	detection algorithm
0.4601285840	processing methods
0.4600551584	o
0.4600407076	suited
0.4599366408	training process
0.4599289569	tissues
0.4598965066	results demonstrated
0.4598734794	lack
0.4598262615	compared
0.4598213237	patches
0.4598193329	\ mu m
0.4597557781	rppg
0.4597374139	characterized
0.4596622492	10 fold cross validation
0.4595292716	deep model
0.4593885159	approximately
0.4592453524	\ emph
0.4591926274	equivariant
0.4591926274	suboptimal
0.4591926274	tables
0.4591926274	converting
0.4591926274	repeated
0.4591926274	roughly
0.4591926274	estimators
0.4591064798	deep network based
0.4590308732	choice
0.4590105948	minimize
0.4589632967	overall
0.4589072863	popularity
0.4588228367	traumatic brain
0.4588222327	shadows
0.4588147486	superior
0.4587910283	subsequent
0.4587122352	coils
0.4586992974	image pixels
0.4586977809	well established
0.4586674445	moments
0.4586432760	method generates
0.4586319993	doing so
0.4586295176	identify
0.4586116858	constructed
0.4585313824	non local
0.4585199485	world health
0.4585055349	study demonstrates
0.4584960715	method produces
0.4584890029	look
0.4584538052	automated algorithm
0.4584343524	sources
0.4584309362	deep learning technique
0.4584184025	fluorescent
0.4584005454	fully convolutional neural
0.4583882947	reported
0.4583878297	convolutional neural network architecture
0.4581999451	clinical decision
0.4581360828	tested
0.4581259658	involved
0.4581178460	\ cite
0.4578752153	accurately
0.4578277417	avoid
0.4578231135	create
0.4577860144	method of multipliers
0.4577731259	throughput
0.4577294707	years
0.4576804433	these
0.4576682126	large field of view
0.4576449678	refine
0.4574875462	compression framework
0.4574188249	synthesize
0.4573419593	continuity
0.4573419593	confident
0.4573419593	nanoscale
0.4573419593	sagittal
0.4573419593	reflective
0.4573419593	amplification
0.4573419593	nanoparticles
0.4573419593	paradigms
0.4573419593	monochromatic
0.4573419593	technological
0.4573419593	antenna
0.4573419593	incrementally
0.4573419593	quantizer
0.4573419593	inspiration
0.4573419593	grouping
0.4573419593	unwanted
0.4573419593	strictly
0.4573248988	measurements
0.4572475755	represent
0.4572361204	generating adversarial
0.4571496459	require manual
0.4571226457	problems in imaging
0.4570992526	most
0.4570137261	^ 2
0.4569583928	challenging datasets
0.4569106781	explicitly
0.4567843213	hyperparameters
0.4566819165	domains
0.4566342187	something
0.4566290961	times
0.4566099629	exams
0.4566048049	deep supervision
0.4565037109	addition
0.4564697880	dose ct denoising
0.4564685950	impressive
0.4564336030	adopted
0.4563926885	additional
0.4563878858	paper
0.4563591587	discussed
0.4562569190	gan architecture
0.4561973683	applicability
0.4561762160	regions
0.4561694513	epochs
0.4561694513	minority
0.4561694513	entails
0.4561694513	converts
0.4561694513	facilities
0.4561694513	centres
0.4561694513	aggregates
0.4561694513	hash
0.4561694513	receives
0.4561694513	enrich
0.4561694513	morbidity
0.4561694513	correctness
0.4561694513	disasters
0.4561694513	relieve
0.4561694513	normalize
0.4561694513	depict
0.4561694513	convincing
0.4561694513	invaluable
0.4561694513	constructs
0.4561694513	slight
0.4561694513	warped
0.4561694513	comprise
0.4561694513	radius
0.4561694513	fastest
0.4561694513	repeatedly
0.4561694513	inconsistency
0.4561694513	specifications
0.4561694513	passes
0.4561694513	accumulated
0.4561694513	leaving
0.4561694513	neglect
0.4561694513	worth
0.4561694513	operated
0.4561694513	anticipate
0.4561694513	rows
0.4561694513	lengths
0.4561694513	formalism
0.4561694513	submission
0.4561694513	maximally
0.4561694513	stimulus
0.4561694513	turns
0.4561694513	desktop
0.4561694513	illustrates
0.4561694513	screens
0.4561694513	judgment
0.4561694513	viewers
0.4561694513	ignoring
0.4561694513	eliminates
0.4561694513	delineated
0.4561694513	featuring
0.4561694513	regularly
0.4561694513	adequately
0.4561694513	borders
0.4561694513	erroneous
0.4561694513	lose
0.4561694513	slower
0.4561694513	encompasses
0.4561694513	grow
0.4561694513	deterioration
0.4561694513	convexity
0.4561694513	downloaded
0.4561613619	image datasets
0.4561153186	vivo
0.4561103515	required
0.4561016636	conduct
0.4559927512	inverse imaging
0.4559206782	trained
0.4559077773	increased
0.4558866501	detected
0.4558857380	pregnancy
0.4558857380	10k
0.4558857380	subnetwork
0.4558857380	incidence
0.4558857380	therapies
0.4558857380	ranks
0.4558857380	blocking
0.4558857380	intricate
0.4558857380	pitch
0.4558857380	arrival
0.4558857380	brightfield
0.4558857380	generalise
0.4558857380	embeds
0.4558857380	registrations
0.4558857380	quantifies
0.4558857380	download
0.4558857380	intractable
0.4558857380	regimes
0.4558857380	promises
0.4558857380	equivalence
0.4558857380	opacities
0.4558857380	preprocessed
0.4558857380	priority
0.4558857380	ordering
0.4558857380	remedy
0.4558857380	drastic
0.4558857380	manipulate
0.4558857380	summarizes
0.4558857380	ignores
0.4558857380	fringes
0.4558857380	spacing
0.4558857380	functionally
0.4558857380	thought
0.4558857380	hinder
0.4558857380	boosts
0.4558857380	interpolating
0.4558857380	encodings
0.4558857380	searches
0.4558857380	constantly
0.4558857380	localizes
0.4558857380	subcortical
0.4558857380	rated
0.4558857380	researched
0.4558857380	indexes
0.4558857380	relates
0.4558857380	registering
0.4558857380	correlates
0.4558857380	transitions
0.4558857380	eliminated
0.4558719055	significant
0.4558453365	accelerate
0.4557684441	diagnoses
0.4557594498	require additional
0.4556371830	reconstruction problems
0.4556263251	clustering algorithm
0.4555691581	repository
0.4555691581	manipulated
0.4555691581	averaged
0.4555691581	equipment
0.4555691581	upscaling
0.4555638078	regular
0.4555168915	classify
0.4555065023	complexity
0.4554826978	evaluated
0.4554678840	spectral images
0.4554201536	rely
0.4553192394	solved
0.4552466007	prediction performance
0.4552299932	disease prediction
0.4552098332	outperformed
0.4551912468	acquisition parameters
0.4551575645	experimental data
0.4551448234	proposed
0.4551233398	needed
0.4551123606	qualitative and quantitative results
0.4550233156	http
0.4548562120	areas
0.4548317215	significantly
0.4547932924	reconstruct
0.4546945628	estimation error
0.4546128680	built
0.4545789753	model based iterative
0.4545692185	deep learning based medical image
0.4544332071	brain scans
0.4543786632	remote sensing image
0.4542927125	proposed methodology
0.4542702588	artifacts
0.4542650910	adjusted
0.4542650910	assessments
0.4542650910	rules
0.4542650910	regularizers
0.4542649140	problems
0.4542647186	physician
0.4541795449	reader
0.4541795449	defining
0.4541795449	mimicking
0.4541795449	indicators
0.4541795449	digitized
0.4540858249	resolve
0.4540520131	uncertainties
0.4540520131	behaviors
0.4540520131	brains
0.4540520131	intuitive
0.4540409019	beamforming
0.4539771751	method combines
0.4539639049	manually
0.4539337115	deployed
0.4538962351	widely
0.4538844682	training images
0.4538127364	caused
0.4536667345	extract
0.4536609440	idea
0.4536402945	malicious
0.4536402945	spikes
0.4536402945	door
0.4536023305	frequent
0.4535943241	rough
0.4535943241	macroscopic
0.4535943241	disparities
0.4535122341	language processing
0.4534865965	\ pm
0.4533533210	annotated
0.4533518459	reconstruction pipeline
0.4533426340	solutions
0.4533416514	modified u net
0.4533384021	non parametric
0.4531328416	specific information
0.4531158887	optical diffraction
0.4530341147	public benchmark
0.4530272789	under sampled
0.4530085314	require
0.4530057678	alternative methods
0.4529399386	follow
0.4528597086	attributes
0.4528362062	adapting
0.4527684740	newly
0.4527565016	infections
0.4527565016	tracks
0.4527565016	detections
0.4527430499	object level
0.4526955069	system's
0.4526955069	hazy
0.4526955069	dissimilarity
0.4526801828	tensors
0.4526755616	decoder network
0.4526547658	slices
0.4526425082	proved
0.4526343586	model complexity
0.4525711421	facing
0.4525711421	vegetation
0.4525711421	apparent
0.4525012086	alleviate
0.4524719378	female
0.4524609953	endmembers
0.4524522049	capable
0.4524386634	problem
0.4524256251	institutions
0.4524256251	minor
0.4524256251	scatterers
0.4524256251	optically
0.4524256251	benchmarked
0.4524256251	topics
0.4524256251	calculations
0.4524256251	adjusting
0.4524256251	ready
0.4524110467	based approach
0.4523603935	acquire
0.4523375433	high cost
0.4523220880	approach produces
0.4523038828	sharp
0.4523038828	insufficient
0.4521621619	events
0.4521420430	result
0.4521099435	utilized
0.4520333789	recorded
0.4519822199	points
0.4519412678	difficulty
0.4518722031	achieve
0.4518515557	source images
0.4517599363	medical imaging tasks
0.4517081186	takes advantage of
0.4516950869	framework called
0.4516082142	lower
0.4515603935	understand
0.4514906941	return
0.4514906941	metallic
0.4514906941	retrieving
0.4514906941	excessive
0.4514906941	shots
0.4514906941	compartments
0.4514906941	documentation
0.4514906941	transducer
0.4514906941	formula
0.4514906941	forming
0.4514906941	influences
0.4514906941	suppressing
0.4514906941	recurrence
0.4514797023	holograms
0.4513566130	reconstruction problem
0.4513516528	iqa methods
0.4513022429	varying
0.4512873903	considering
0.4512015547	learning process
0.4511538828	candidate
0.4511538828	papers
0.4511526419	constructing
0.4511526419	reaching
0.4511278693	publicly available datasets
0.4510510497	agreement
0.4510421312	semantic label
0.4510416720	usability
0.4510416720	blindly
0.4510416720	clustered
0.4510416720	suspicious
0.4510416720	opacity
0.4510416720	therapeutic
0.4510416720	exposed
0.4510416720	feeding
0.4510416720	nearby
0.4510416720	grouped
0.4510416720	geophysical
0.4510416720	backgrounds
0.4510128314	community
0.4509752483	thus
0.4509174351	clothing
0.4509174351	unexpected
0.4509174351	speckles
0.4509174351	surroundings
0.4509174351	discretization
0.4509174351	optimizer
0.4509174351	links
0.4509174351	alongside
0.4509174351	skills
0.4509151122	properly
0.4509138507	derived
0.4508786971	efficiency
0.4507735930	budget
0.4507735930	bicubic
0.4507602673	scattered
0.4507140705	dictionaries
0.4506782627	2 d
0.4506623843	none
0.4506187366	instances
0.4505592818	transfer learning based
0.4504923258	large number of parameters
0.4504757353	structure information
0.4504678136	created
0.4504360362	technique called
0.4503910825	paper reviews
0.4502474793	bad
0.4502474793	redundancies
0.4502474793	animals
0.4501538241	model based methods
0.4501192096	trying
0.4501056748	statistical models
0.4500729711	range
0.4500674543	v net
0.4499847769	challenging
0.4499670575	consumption
0.4499568462	improved image quality
0.4499028746	registration algorithms
0.4498714698	works
0.4498225097	tissue classes
0.4498144061	image regions
0.4498054456	intrinsic
0.4496634480	see
0.4496627099	proposed framework
0.4496607648	categories
0.4496391116	tasks
0.4496285764	$ \ beta
0.4494986712	b scans
0.4494479418	providing
0.4494264461	\ textbf
0.4493922900	physiological
0.4493787868	discrepancies
0.4493787868	catastrophic
0.4493787868	broadly
0.4493787868	prospectively
0.4493787868	transparency
0.4493787868	digits
0.4493787868	home
0.4493787868	bypass
0.4493787868	stop
0.4493787868	mathematically
0.4493787868	vertices
0.4493787868	imposing
0.4493787868	manufacturers
0.4493787868	aggressive
0.4493787868	nanoscopy
0.4493787868	explained
0.4493787868	stand
0.4493787868	alterations
0.4493217257	priori knowledge
0.4492844702	address
0.4492678318	shapes
0.4492580545	incorporated
0.4491571319	kernels
0.4491504385	outperforms
0.4491383021	beneficial
0.4491007016	afterwards
0.4490140255	data privacy
0.4489883190	addressed
0.4488947361	consists
0.4488286259	methodology
0.4487402908	yet
0.4487281268	variations
0.4486744779	extracted
0.4486167769	target model
0.4486159033	37
0.4485188726	proposes
0.4485179271	uniformly
0.4485179271	unnecessary
0.4485179271	unexplored
0.4485179271	spectrally
0.4485179271	barrier
0.4485179271	propagated
0.4485179271	risks
0.4484602540	identified
0.4484503390	surgeon
0.4484503390	articles
0.4484503390	saturated
0.4484503390	waveforms
0.4484503390	played
0.4484503390	compromised
0.4484503390	vendors
0.4484503390	4k
0.4484503390	achievements
0.4484503390	splits
0.4484503390	insensitive
0.4484503390	items
0.4484503390	contributed
0.4484503390	surpass
0.4484503390	exhibited
0.4484503390	perturbed
0.4484503390	shifted
0.4484503390	acceptance
0.4484503390	submissions
0.4484503390	magnitudes
0.4484503390	managing
0.4484503390	relate
0.4484503390	binarization
0.4484503390	envelope
0.4484503390	adaptability
0.4484503390	analysed
0.4484503390	simplifies
0.4484503390	publications
0.4484503390	constraining
0.4484503390	strict
0.4484503390	alleviates
0.4484503390	photograph
0.4484503390	promotes
0.4484503390	grows
0.4484476074	features learned
0.4484271312	data fitting
0.4483513871	retrieval problem
0.4481944606	recovered
0.4481759840	obtain
0.4480613296	image contrast
0.4480150252	role
0.4479396051	improves performance
0.4479278977	eg
0.4478716784	trace
0.4478614551	average accuracy
0.4478584965	capable of producing
0.4478549968	topic
0.4478170103	solve
0.4477800402	low noise
0.4477434101	training datasets
0.4476447493	datasets
0.4476119495	poor
0.4474823584	environments
0.4474757590	discuss
0.4473770661	severely
0.4472215317	achieves
0.4470828253	motion patterns
0.4470455538	subjects
0.4470129550	q
0.4469340776	increase
0.4469234780	detection and ranging
0.4468874664	filters
0.4468510248	perform
0.4468231660	top
0.4467134977	consuming
0.4466995359	slides
0.4466969075	making
0.4466247285	build
0.4466160761	mri based
0.4466124963	meters
0.4465174491	defined
0.4465051133	captured
0.4464917413	meter
0.4464917413	exam
0.4464917413	coronal
0.4464032878	major
0.4463810289	imaging tasks
0.4463030674	shed
0.4462012640	naturally
0.4461473799	peaks
0.4461473799	orthogonality
0.4461473799	plots
0.4460613415	method improves
0.4458921651	imaging sensors
0.4457599115	original data
0.4457067530	include
0.4456752750	target object
0.4456472419	ex
0.4455514109	crucial
0.4454386462	experiments validate
0.4454123865	quality reconstructions
0.4453562825	supervised deep
0.4452608488	vulnerable to adversarial
0.4452164543	approaches
0.4452059019	generation network
0.4451652100	deformed
0.4451652100	offset
0.4451433191	traditional approaches
0.4451114827	additional information
0.4450942090	towards
0.4450692776	network learns
0.4449995054	second order
0.4449813969	motions
0.4449435182	mm
0.4449014941	then
0.4448679140	forgetting
0.4448467292	improves
0.4448165035	tuned
0.4447901601	data distribution
0.4447817845	efficiently
0.4447495596	geometric information
0.4447468358	level fusion
0.4446956281	limiting
0.4445759362	because
0.4445497629	limitation
0.4445096167	per pixel
0.4444564071	mouth
0.4444461948	comparable
0.4443670407	concepts
0.4443558192	specific
0.4443512604	wearing
0.4442977018	hypotheses
0.4441107565	supervised models
0.4440796155	account
0.4440710308	women
0.4440668835	method achieved
0.4440649723	min
0.4440358613	static
0.4439507425	actual
0.4439286791	diagnose
0.4439264461	\ deg
0.4438718185	leads
0.4438400829	completed
0.4438400829	establishing
0.4438400829	receive
0.4438400829	inconsistent
0.4438400829	expanded
0.4438400829	historical
0.4438400829	inhomogeneity
0.4438400829	solves
0.4438400829	unreliable
0.4438400829	counts
0.4438400829	pulses
0.4438319647	light conditions
0.4436428212	high energy
0.4436309488	super resolution methods
0.4436273711	introduces
0.4436039718	textual
0.4436039718	readout
0.4435357077	investigated
0.4435127853	generalize
0.4435083529	you
0.4434888377	imbalance
0.4434333572	attention u net
0.4432837206	extend
0.4432437370	achieved
0.4431796898	process
0.4431727388	testing accuracy
0.4431649814	factors
0.4431211784	constant
0.4431169513	wave imaging
0.4430609841	translation tasks
0.4430150692	estimates
0.4430058889	based metrics
0.4429938223	ensemble model
0.4429903418	reduced
0.4429891146	large scale video
0.4429376948	leaves
0.4429092661	biased
0.4428871331	mitigating
0.4428871331	remained
0.4428871331	shaping
0.4428871331	generalisation
0.4428871331	realistically
0.4428871331	establishes
0.4428871331	involvement
0.4428871331	feedforward
0.4428871331	grown
0.4428871331	clinics
0.4428871331	raises
0.4428871331	transposed
0.4428871331	anatomies
0.4428871331	analyzes
0.4428871331	suppressed
0.4428871331	selects
0.4428871331	delays
0.4428871331	subproblems
0.4428871331	versatility
0.4428871331	centroid
0.4428871331	faced
0.4428871331	figures
0.4428871331	satisfying
0.4428871331	attentions
0.4428871331	loading
0.4428871331	overlooked
0.4428871331	chance
0.4428871331	men
0.4428871331	degrading
0.4428871331	infers
0.4428871331	possess
0.4428871331	attained
0.4428871331	complexities
0.4428871331	proportional
0.4428871331	exciting
0.4428871331	defines
0.4428871331	restrictions
0.4428871331	claim
0.4428871331	accelerates
0.4428871331	consequences
0.4428871331	circumstances
0.4428871331	files
0.4428871331	failed
0.4428094692	modalities
0.4427875382	noises
0.4427305340	datasets including
0.4426813114	do
0.4425339745	surfaces
0.4424409160	nodule classification
0.4422859924	sometimes
0.4421987047	discriminator network
0.4421914105	textures
0.4421884693	correctly
0.4420677649	bits
0.4420425074	so far
0.4419957179	reconstructions
0.4419714893	head models
0.4419540910	twenty
0.4419378402	shown
0.4419019821	filtered back
0.4418928606	unbalanced
0.4418928606	translations
0.4418928606	lacking
0.4418928606	choosing
0.4418928606	textural
0.4418928606	quadratic
0.4418928606	crops
0.4418928606	speeds
0.4418928606	obstacle
0.4418928606	embryos
0.4417256334	initialization
0.4416377642	after
0.4415588652	faces
0.4415499116	eeg data
0.4415384096	characters
0.4415214060	cancer tissue
0.4414480160	recording
0.4414030599	shaped
0.4412884879	outliers
0.4412796575	individuals
0.4412094755	simulated and experimental
0.4412029488	existing algorithms
0.4411987964	currently
0.4411869345	classes
0.4411361101	ability
0.4411146827	dynamically
0.4410412514	settings
0.4410105631	reconstruction performance
0.4410033262	method yields
0.4409492202	multi camera
0.4408491408	represented
0.4408177848	estimated
0.4407911560	stages
0.4407837206	yields
0.4407407099	~
0.4407190953	auc =
0.4406891836	alternating direction method
0.4406787040	tissue contrast
0.4406782723	noise patterns
0.4406595597	projections
0.4406221081	simulation and experimental
0.4405712199	introduce
0.4405341475	3t
0.4405239342	pre trained model
0.4402869160	essential step
0.4402358236	achieves high
0.4402351578	analyses
0.4401795449	low light image
0.4401407634	specimens
0.4400751904	until
0.4400512926	present
0.4400411220	smooth
0.4397983689	volume segmentation
0.4397638670	directly
0.4396890977	plays
0.4395091820	edges
0.4394495814	propose
0.4392929904	construct
0.4392811375	adapt
0.4392502232	including
0.4391402196	determine whether
0.4391363932	aberrations
0.4391250064	dataset consisting
0.4390278442	miou
0.4390128257	gaussian model
0.4388564210	exploit
0.4388130377	method learns
0.4387590323	random fields
0.4387368725	$ t_1
0.4386164084	includes
0.4385324882	targets
0.4385132289	preserves
0.4384188203	employ
0.4382988574	abnormalities
0.4382377897	classification results
0.4381910651	measures
0.4381641061	every year
0.4381035392	$ l_2
0.4380843577	significant improvements over
0.4380456522	zero
0.4379634381	large annotated
0.4379542509	$ l_
0.4378054172	seeing
0.4377574884	proven
0.4376006080	estimations
0.4376006080	misalignment
0.4376006080	incident
0.4372745815	ir images
0.4372632289	molecules
0.4371509682	fail
0.4371157254	medical image processing
0.4370334888	suggest
0.4369955904	based metric
0.4369577750	issue
0.4367446478	sharper
0.4367446478	maintains
0.4367446478	viseme
0.4367446478	experiences
0.4367446478	ongoing
0.4367446478	rainy
0.4367446478	induces
0.4367446478	exhibiting
0.4367446478	imposes
0.4367446478	margins
0.4367446478	imperative
0.4367446478	reflectivity
0.4367446478	exceed
0.4367446478	sought
0.4367446478	translates
0.4367446478	clinician
0.4367446478	filled
0.4367446478	participating
0.4367446478	executed
0.4367446478	pathway
0.4367446478	appropriately
0.4367446478	rigorously
0.4367446478	qualities
0.4367446478	handled
0.4367388776	validated
0.4364835162	proposed model
0.4364200517	values
0.4362818349	adequate
0.4362818349	particles
0.4362735097	normal brain
0.4362615985	enables
0.4361871913	least
0.4361343868	analysis shows
0.4360808691	user
0.4359345748	level information
0.4358892497	non rigid registration
0.4358240142	characteristics
0.4358086960	herein
0.4357663002	higher performance
0.4356724454	quality scores
0.4356324571	collected data
0.4355949884	affect
0.4355772652	projects
0.4355772652	ambiguities
0.4355772652	specialists
0.4355772652	rigorous
0.4355772652	favorable
0.4355148223	\ textit
0.4354946686	demonstrate
0.4354941949	camera pose
0.4353291776	except
0.4353152717	number of training samples
0.4352353183	large margin
0.4351793590	effectively
0.4351752254	deep denoising
0.4349091999	takes
0.4349067362	combines
0.4348351547	strongly
0.4348138874	larger
0.4347733884	difficult
0.4346302292	angles
0.4345731223	edge features
0.4344112513	mean
0.4339955471	goes
0.4339579559	super resolution reconstruction
0.4337602653	speed up
0.4337543592	presented
0.4336716006	pathology images
0.4336544770	paper explores
0.4336312027	great significance
0.4335590253	superpixels
0.4334434500	sub band
0.4334231799	structures
0.4332762137	denoising algorithm
0.4332679917	presents
0.4332242013	here
0.4332241586	attack success
0.4331800094	linear combination
0.4331628452	called
0.4331328781	not necessarily
0.4331099954	thin
0.4330927121	ophthalmologists
0.4330855020	domain adversarial
0.4330147103	reconstruction times
0.4329424982	makes
0.4328180461	sizes
0.4327587810	outperform
0.4327525704	processing step
0.4326042648	introduced
0.4325732496	conducted
0.4324800520	implemented
0.4323978303	cities
0.4323978303	leakage
0.4323978303	approximations
0.4323579837	course
0.4323327898	large scale datasets
0.4321744107	last years
0.4321195937	studied
0.4319907180	data driven methods
0.4319344888	ensemble method
0.4318782225	blurry
0.4318782225	gaps
0.4318782225	fool
0.4318782225	beams
0.4318782225	treatments
0.4318782225	artificially
0.4318782225	careful
0.4318629564	reconstructing images
0.4318467163	produce
0.4318186979	localization accuracy
0.4318128847	taxonomy
0.4318128847	facilitating
0.4318128847	displayed
0.4318128847	surgeons
0.4317886119	i
0.4317789170	domain adaptation methods
0.4316913105	threshold
0.4315522011	employed
0.4314891232	context model
0.4314796952	rank tensor
0.4314593365	tiles
0.4314257306	x ray images
0.4314234549	algorithm outperforms
0.4313657368	said
0.4313657368	don't
0.4313264044	acquisitions
0.4312630489	limits
0.4310759372	release
0.4310759372	paths
0.4310759372	vast
0.4310725430	amounts of labeled
0.4309905638	grades
0.4309905638	controller
0.4309905638	cubes
0.4309905638	inferences
0.4309905638	weaknesses
0.4309787516	while
0.4309636509	local context
0.4307656037	adapted
0.4307227456	minutes
0.4306301435	fast reconstruction
0.4306003256	reconstruction from undersampled
0.4304012309	analysis tasks
0.4303344508	clinicians
0.4303173958	classification and object
0.4302748281	components
0.4302192561	take into account
0.4299947113	rates
0.4299689421	actions
0.4299543099	regarding
0.4298007976	enable
0.4296191620	$ \ ell_
0.4296099701	representing
0.4291651694	retrieval methods
0.4291221553	back
0.4290617672	deep prior
0.4290328743	registration algorithm
0.4289865408	scores
0.4288772482	questions
0.4288772482	days
0.4288745879	demonstrates
0.4287534340	setting
0.4287444115	real clinical
0.4287118770	phase microscopy
0.4285676774	subtypes
0.4284193774	extraction and classification
0.4283853249	accordingly
0.4283367449	convolutional sparse
0.4283324694	state of art
0.4280384365	labeled training
0.4279797423	worldwide
0.4279680797	sites
0.4278590061	reference image
0.4276797553	high dimensional data
0.4276517903	adds
0.4276517903	compromise
0.4276517903	understood
0.4276517903	adults
0.4276517903	evaluates
0.4276517903	drops
0.4276517903	compelling
0.4276517903	subjectivity
0.4276517903	synthesizes
0.4276517903	formulations
0.4276517903	maintained
0.4276517903	isolation
0.4276517903	actively
0.4276517903	exceeds
0.4276517903	virtually
0.4276517903	readers
0.4276517903	permits
0.4276517903	faithfully
0.4276517903	rotations
0.4276517903	undesirable
0.4276517903	method's
0.4276517903	constitute
0.4276517903	spurious
0.4275985213	lumen
0.4274619707	typically rely
0.4274382217	optical images
0.4274159917	magnetic particle
0.4274038082	single image super
0.4273563506	resemble
0.4273563506	refines
0.4273563506	break
0.4273563506	essence
0.4273563506	tackles
0.4273563506	submitted
0.4273563506	constitutes
0.4273563506	reductions
0.4273563506	predictors
0.4273563506	searched
0.4273563506	approved
0.4273563506	distinguished
0.4273563506	libraries
0.4273563506	disadvantages
0.4273563506	lobes
0.4273563506	interpolate
0.4273563506	gathered
0.4273563506	scientists
0.4273563506	communities
0.4273563506	publication
0.4273563506	stylization
0.4273563506	motivates
0.4273563506	strengthen
0.4273563506	uncertain
0.4273563506	7t
0.4273563506	synchronized
0.4273563506	ages
0.4273563506	necessitates
0.4273563506	unsatisfactory
0.4273563506	pathways
0.4273563506	attracting
0.4273563506	fitted
0.4272879184	existing studies
0.4272865611	due
0.4272823857	widely used
0.4272496089	attempt
0.4272485404	samples
0.4272337906	evaluate
0.4271848807	reconstruction module
0.4271022998	architectural
0.4271022998	identical
0.4271022998	perspectives
0.4271022998	describing
0.4271022998	setups
0.4271022998	equally
0.4271022998	sequentially
0.4271022998	microscopes
0.4270598041	reconstruct high quality
0.4270196868	subcellular
0.4270196868	volunteer
0.4270196868	correlate
0.4270196868	tumours
0.4270196868	aligning
0.4270196868	bottlenecks
0.4270196868	helping
0.4270196868	cropping
0.4270196868	developmental
0.4270196868	adversely
0.4270196868	converges
0.4270196868	reflects
0.4270196868	expressed
0.4270196868	grids
0.4270196868	wrong
0.4270196868	accumulation
0.4270196868	prohibitively
0.4270196868	ratings
0.4270196868	pivotal
0.4270196868	cheap
0.4270196868	competitors
0.4270196868	infeasible
0.4270196868	histograms
0.4270196868	preparation
0.4270196868	arbitrarily
0.4270196868	started
0.4270196868	renders
0.4270196868	hinders
0.4270196868	proximity
0.4270196868	shorter
0.4270196868	surpassing
0.4269247046	institution
0.4269247046	cores
0.4269247046	outlines
0.4268524399	develop
0.4267994288	paper demonstrates
0.4267983737	$ \ mu
0.4267173013	real datasets
0.4266902519	wide range
0.4266817790	combine
0.4266649652	as
0.4264986184	in
0.4263976362	classifies
0.4262885955	enabling
0.4262813721	reference images
0.4261918760	commonly used
0.4261510546	ai applications
0.4260185335	supervised machine
0.4259310947	remains
0.4259002367	localization algorithms
0.4258205003	output image
0.4257976362	witnessed
0.4257976362	tremendous
0.4257976362	start
0.4257976362	stimuli
0.4257922529	space sampling
0.4257260132	sub sampled
0.4256826783	collected
0.4255788605	resulting
0.4255166373	36
0.4254864679	flip
0.4252762252	considered
0.4252300018	sparse data
0.4251666968	depth image
0.4251631956	utilize
0.4250657662	cracks
0.4250555195	without losing
0.4249517712	flow imaging
0.4248772482	decoders
0.4248673200	learns
0.4247544349	multi tissue
0.4245862761	named
0.4244678811	confirm
0.4243905044	image characteristics
0.4243640091	tasks including
0.4243298145	segmentation quality
0.4243159809	additional computational
0.4243118725	\ infty
0.4243039618	image translation tasks
0.4243006169	popular
0.4242832671	supervised machine learning
0.4242684472	if
0.4242241942	cardiac magnetic
0.4241689052	highlighting
0.4241689052	reflected
0.4240800334	indeed
0.4240593621	augmentation methods
0.4240065759	_2
0.4240011266	real image
0.4238868046	boundaries
0.4238739548	image plane
0.4238470411	numerically
0.4238470411	homogeneous
0.4238431701	requires
0.4235607478	capture
0.4235373427	classifications
0.4235031298	data augmentation method
0.4234293256	improved accuracy
0.4234250190	pathologies
0.4234050766	native
0.4233309802	looking
0.4232191472	last decade
0.4231145851	accurate prediction
0.4231025065	unfortunately
0.4231015581	stains
0.4231015581	miss
0.4231015581	cue
0.4231015581	cycles
0.4231015581	specialist
0.4230869517	measured data
0.4230864679	epidemic
0.4230864679	shortcoming
0.4230864679	passed
0.4230864679	ineffective
0.4230864679	appearances
0.4230864679	engineered
0.4230864679	appears
0.4230864679	adapts
0.4230864679	references
0.4230864679	downsampled
0.4230864679	distinctive
0.4230864679	dermatologists
0.4230864679	tractable
0.4230864679	perceive
0.4230864679	adult
0.4230864679	stronger
0.4230864679	minimizes
0.4230864679	fluctuations
0.4230864679	meaning
0.4230864679	hypothesize
0.4230864679	optimised
0.4230864679	academic
0.4230864679	optimum
0.4230184372	expensive
0.4229971967	human level
0.4229797052	increasing number
0.4229652349	cancers
0.4228913293	so
0.4228832172	preoperative
0.4228832172	outline
0.4228832172	essentially
0.4228832172	prepared
0.4228832172	approximated
0.4228832172	entities
0.4228621634	conducted extensive
0.4228574576	transmit
0.4228330901	does
0.4227708159	leverage
0.4227478656	video recognition
0.4227398428	prediction task
0.4226539120	deep learning based approach
0.4226223726	given
0.4226107041	damaged
0.4226107041	concerns
0.4226107041	package
0.4226028116	varies
0.4224886026	server
0.4224886026	populations
0.4224886026	phenomena
0.4224886026	aggregated
0.4224814320	spatio temporal data
0.4223638068	supporting
0.4223496163	scanned
0.4223480422	generation tasks
0.4223397198	rather than
0.4222415964	encourages
0.4222415964	minimized
0.4222415964	fairly
0.4222415964	host
0.4222415964	assumes
0.4222415964	offered
0.4222415964	implies
0.4222415964	successes
0.4222415964	annotators
0.4222415964	behavioral
0.4222415964	inevitably
0.4222415964	guides
0.4222415964	inexpensive
0.4222415964	perfectly
0.4222415964	discriminating
0.4222415964	obvious
0.4222415964	w.r.t
0.4222415964	speakers
0.4221638476	based framework
0.4221118203	compression scheme
0.4220631583	buildings
0.4220351363	enhances
0.4220351363	suggested
0.4219491748	computed tomography images
0.4219265465	did
0.4218647350	driven approach
0.4218331571	developed
0.4216415580	visual representation
0.4215036066	secondly
0.4214084881	contribute
0.4213290888	bandwidth
0.4211190486	hospitals
0.4210660662	steps
0.4210640718	reduces
0.4210270878	successful
0.4210131036	pipelines
0.4209416978	demonstrated
0.4208855173	field programmable
0.4208112165	next generation
0.4207449638	measured
0.4206285377	hologram
0.4206020565	point operations
0.4205093290	learning rate
0.4205049860	based method
0.4204524641	gan based methods
0.4204358232	activities
0.4203294471	generative network
0.4203070268	haze
0.4203070268	considerations
0.4203043258	outputs
0.4202638552	frames per second
0.4202350646	provided
0.4202053137	updated
0.4202053137	descriptions
0.4202053137	guidelines
0.4202053137	documents
0.4202053137	curves
0.4201719217	^ p
0.4200650728	field of research
0.4199349031	data preprocessing
0.4199040015	roads
0.4199040015	complications
0.4199040015	corrections
0.4199040015	revealing
0.4199040015	incorrect
0.4199040015	authors
0.4199005763	nevertheless
0.4198877591	argue
0.4198877591	simpler
0.4198877591	brings
0.4198877591	exhibits
0.4198206855	going
0.4197330339	styles
0.4196142591	systematically
0.4194712552	image generator
0.4194269040	optimization approach
0.4193913033	overfitting
0.4193702152	frequencies
0.4192975324	procedure
0.4192964717	provide
0.4192381855	baselines
0.4190901446	applications of deep
0.4189566555	shows
0.4188657844	implicitly
0.4188087197	commercially available
0.4186450069	gslider
0.4185757289	reconstruction results
0.4183976084	image volumes
0.4183079152	design space
0.4182051747	denoising problem
0.4180801741	right
0.4180463082	indices
0.4180368819	inherently
0.4180368819	counterpart
0.4180368819	supports
0.4180314592	autoencoder network
0.4179386435	whole slide imaging
0.4179293364	advantageous
0.4179293364	unchanged
0.4179293364	projecting
0.4179293364	accepted
0.4179293364	holds
0.4179293364	problematic
0.4179293364	originally
0.4179293364	choices
0.4179293364	diffuser
0.4179293364	changed
0.4179293364	showcase
0.4179293364	confirms
0.4179293364	expressive
0.4179293364	displacements
0.4179293364	arises
0.4179293364	atlases
0.4179293364	enforces
0.4179293364	wavelengths
0.4179293364	covered
0.4179293364	preventing
0.4179293364	spanning
0.4177718995	moreover
0.4176940409	multi scale feature
0.4176319558	classification model
0.4175981893	classification loss
0.4175805090	meaningful
0.4173562385	$ l_1
0.4173433740	processes
0.4173197177	attracted
0.4173197177	scarce
0.4173197177	situations
0.4173197177	affecting
0.4170588956	modifications
0.4170588956	conclude
0.4170588956	robustly
0.4170576152	voxels
0.4169923119	experimental results show
0.4169240694	aware network
0.4169226178	outperforming
0.4168268932	explore
0.4168227127	especially
0.4168089300	produces
0.4167420263	classification problems
0.4165540881	health problem
0.4163784437	a comprehensive review
0.4163297038	surrounding
0.4160159518	test samples
0.4159627356	current clinical
0.4158562385	\ mathbf
0.4158542905	net outperforms
0.4158467308	configuration
0.4157853226	optimal performance
0.4157852679	imaging quality
0.4157531809	revealed
0.4157531809	applies
0.4157531809	encodes
0.4157531809	affects
0.4157522848	narrow
0.4156588956	million
0.4156050159	10 fold cross
0.4155910812	regardless
0.4155776797	teams
0.4152456004	$ \ mathcal
0.4150712751	convolutional encoder
0.4150165260	information content
0.4147555993	high quality reconstruction
0.4147367229	very high resolution
0.4147320122	compare
0.4146845410	segmentation map
0.4146646011	dataset collected
0.4146418025	reliably
0.4146418025	devise
0.4145382322	speedup
0.4144547571	proposed scheme
0.4144376358	opens
0.4144376358	sufficiently
0.4144376358	adopts
0.4144376358	obtains
0.4144376358	extends
0.4144261473	reconstruct high resolution
0.4144235079	spectral features
0.4143034396	accurate detection
0.4142858318	apply
0.4142657923	showed
0.4141598529	surrogate
0.4141465644	removed
0.4141465644	reached
0.4141248047	adjacent
0.4141248047	detects
0.4141248047	latest
0.4140520708	positive reduction
0.4139560821	investigate
0.4138904867	hr image
0.4138562471	retrospectively
0.4138544117	details
0.4138273581	colors
0.4137379212	contrasts
0.4135637136	training phase
0.4134788200	months
0.4133651180	high correlation
0.4131857624	solvers
0.4131704312	single images
0.4131583970	procedures
0.4131081184	image sets
0.4130706777	adaptively
0.4130457044	rate estimation
0.4128661966	non cartesian
0.4127656139	segmentation method
0.4126358924	simultaneous localization and
0.4125755879	image sequence
0.4124463642	routinely
0.4124463642	urgent
0.4124463642	linearity
0.4124463642	assisting
0.4124463642	viewpoints
0.4124463642	translated
0.4124463642	flexibly
0.4124463642	stratification
0.4124463642	suspected
0.4124463642	underwent
0.4124463642	determines
0.4124463642	intact
0.4124463642	disentangle
0.4124463642	differ
0.4122996900	far
0.4122599621	network depth
0.4122237028	4x
0.4121893602	spatial light
0.4120772412	synthesized images
0.4120408132	percent
0.4120188050	dl model
0.4118867452	latter
0.4118579023	meanwhile
0.4117925333	extraction method
0.4117692561	unprecedented
0.4116431514	validate
0.4113750206	x ray phase contrast
0.4111810208	contexts
0.4111404125	indicating
0.4111404125	received
0.4111259060	optimization process
0.4109370902	image modalities
0.4108957549	completely
0.4107735306	divided into
0.4107183165	image patch
0.4106959985	far field
0.4103876972	later
0.4103087264	specimen
0.4103087264	identifies
0.4102125869	average dice score
0.4102043360	improved results
0.4101404125	remain
0.4101404125	responses
0.4100570362	atoms
0.4099901508	analyze
0.4098713498	diameter
0.4097602453	issues
0.4097317508	data samples
0.4096627075	invariant features
0.4095685865	notable
0.4095685865	obstacles
0.4095685865	richer
0.4095685865	restored
0.4095685865	transverse
0.4095685865	densities
0.4095685865	closest
0.4095685865	derivatives
0.4095685865	missed
0.4095685865	generality
0.4095685865	highlighted
0.4095685865	selectively
0.4095685865	ubiquitous
0.4095685865	removes
0.4095685865	exclusively
0.4095685865	deviations
0.4095685865	approximating
0.4095685865	unstable
0.4094945132	designs
0.4094692048	complex object
0.4094455605	super resolution techniques
0.4093957549	coverage
0.4088957549	predicts
0.4088548539	aim 2020
0.4088523344	study shows
0.4086750430	among
0.4086611636	did not
0.4085923373	comprehensive review
0.4085713498	diseased
0.4085524716	point cloud data
0.4085146565	performs
0.4083313769	compression techniques
0.4082773197	learned compression
0.4082381462	captures
0.4082179723	besides
0.4079835691	outcomes
0.4079064460	$ \ sim
0.4078925775	considerably
0.4078925775	exists
0.4077184543	cloud compression
0.4075935968	specific task
0.4075351895	specific tasks
0.4074093170	fusion approach
0.4073534000	examined
0.4073534000	facilitates
0.4073534000	expertise
0.4072631627	part
0.4071883918	265
0.4070906056	compressed data
0.4070692561	perfect
0.4070692561	reasons
0.4070692561	acceptable
0.4070692561	hope
0.4070692561	decreases
0.4069751773	observed
0.4069577292	regularization method
0.4066281980	tracking algorithm
0.4066098143	detection task
0.4065873743	comprehensively
0.4065873743	recommended
0.4065873743	delivers
0.4065873743	surveys
0.4065873743	cumbersome
0.4065279011	furthermore
0.4064829083	single camera
0.4064221433	remaining
0.4064221433	dramatically
0.4064199990	learning based registration
0.4063924913	trained networks
0.4058197170	requires large
0.4057750139	images of covid 19
0.4056922148	distortions
0.4056737256	largest
0.4056357929	counterparts
0.4056119380	based iterative reconstruction
0.4056049713	highest
0.4055405548	chosen
0.4055153438	projection images
0.4054919803	inside
0.4054662489	obtain high
0.4054031604	$ \ ell_0
0.4051949510	such
0.4051609963	detection results
0.4051427775	lesion classification
0.4050988311	consequently
0.4050081117	vary
0.4049835691	platforms
0.4048949833	proposed algorithm
0.4048513766	extracts
0.4048350481	conventional approaches
0.4048313313	analyzed
0.4047583413	m ^
0.4047394719	yielded
0.4046877209	imaging resolution
0.4046081117	yielding
0.4045833751	medical datasets
0.4045634751	reconstructs
0.4045517059	respective
0.4045517059	reaches
0.4044374052	left and right
0.4044290379	comprises
0.4044290379	trains
0.4044290379	degrade
0.4044290379	geometrical
0.4044290379	cohorts
0.4042904216	bottom
0.4042805933	manner
0.4041023177	image classifiers
0.4040224812	photo realistic images
0.4039546902	groups
0.4039266472	non linear
0.4039230164	achieve similar
0.4038927315	intensities
0.4038927315	considers
0.4036901220	hybrid deep learning
0.4036162383	generalize well
0.4035693582	objective quality
0.4034297230	decisions
0.4034162763	lf image
0.4033804897	heatmaps
0.4033804897	depths
0.4033804897	deaths
0.4032853771	go
0.4032745921	full
0.4030740208	involve
0.4030740208	assume
0.4028917872	highlights
0.4028917872	creates
0.4028917872	ignore
0.4028623713	shifts
0.4028623713	demands
0.4028623713	drastically
0.4028482554	high computational
0.4027394719	clusters
0.4026305827	decoded
0.4026305827	brought
0.4026305827	suggesting
0.4026305827	causing
0.4026305827	runs
0.4026305827	individually
0.4026305827	illustrated
0.4024240926	super resolved images
0.4023077835	phases
0.4022391976	results obtained
0.4021680433	quickly
0.4021680433	suggests
0.4020836124	deep learning systems
0.4020711488	professionals
0.4020711488	tackled
0.4020711488	impose
0.4020711488	affordable
0.4020711488	constrain
0.4020711488	concern
0.4020711488	transfers
0.4020711488	scaled
0.4020711488	faithful
0.4020711488	achievable
0.4020529476	observations
0.4020528952	oct image
0.4020074885	reveals
0.4020074885	primarily
0.4020066449	relaxation
0.4019404510	conventional algorithms
0.4018187308	together
0.4016741552	contents
0.4016741552	easier
0.4015866365	fed into
0.4015353952	accurate results
0.4014996003	candidates
0.4014996003	planes
0.4014408827	demonstrate superior
0.4013497204	per second
0.4011737256	exhibit
0.4010650604	particularly
0.4010275485	surpasses
0.4010275485	paves
0.4010275485	duration
0.4010275485	mentioned
0.4010275485	computes
0.4010275485	overcomes
0.4010275485	examinations
0.4010275485	reviewed
0.4010275485	enormous
0.4009820611	\ approx
0.4009671849	integrates
0.4008857114	closer
0.4008857114	sized
0.4008857114	varied
0.4007611516	smartphones
0.4007611516	fuses
0.4007611516	matches
0.4007611516	offering
0.4007611516	presenting
0.4007611516	occur
0.4007611516	worse
0.4006979541	represents
0.4006712861	conditional random
0.4005792121	configurations
0.4002735626	recognition performance
0.4002384244	savings
0.4002384244	traces
0.4002104678	retinal blood
0.4001332899	independently
0.4000702588	recognized
0.4000702588	longer
0.3999233409	thanks
0.3998788932	computational ghost
0.3997857480	peak signal to
0.3997067138	\ mathcal
0.3994719474	achieved significant
0.3994448223	t1 weighted mr
0.3994434817	his
0.3992861817	segments
0.3992614928	acquisition process
0.3992517501	discovered
0.3992517501	demanding
0.3992517501	avoids
0.3992517501	irrelevant
0.3992517501	realized
0.3992517501	rarely
0.3992517501	alternatives
0.3992517501	recovers
0.3992517501	quantified
0.3992517501	ensures
0.3992517501	possibly
0.3992517501	saving
0.3992241773	deep learning based segmentation
0.3990772514	model produces
0.3990540626	lacks
0.3990540626	inadequate
0.3990540626	ensuring
0.3990540626	expect
0.3990540626	option
0.3990540626	summarized
0.3990540626	intended
0.3990540626	unavailable
0.3990540626	prevents
0.3990540626	inefficient
0.3990540626	giving
0.3990540626	lowest
0.3990540626	prohibitive
0.3990041058	spatial structure
0.3988881460	quantitative results
0.3988150281	compression performance
0.3987333697	resulting model
0.3987206936	model performance
0.3986868861	an end to end fashion
0.3986803123	databases
0.3985147291	non contrast ct
0.3981373380	losses
0.3979354842	real world images
0.3979076036	ground based
0.3979061544	successfully
0.3978582046	operations
0.3977859473	prior knowledge about
0.3977173380	largely
0.3974842336	estimation algorithm
0.3973865398	employs
0.3973865398	substantially
0.3972817052	this paper proposes
0.3970992298	covid 19 pandemic
0.3970766134	covid 19 diagnosis
0.3969154669	image structure
0.3968960322	learning based approach
0.3968519707	dimensional feature
0.3968404328	preferred
0.3968404328	appealing
0.3968404328	visualized
0.3968404328	dubbed
0.3968404328	updates
0.3968404328	seamlessly
0.3968103614	framework outperforms
0.3967810578	architecture outperforms
0.3967138437	near
0.3966724408	classification algorithms
0.3965113088	using
0.3964937657	264
0.3964801247	timing
0.3964288023	summarize
0.3964288023	workload
0.3964288023	tracked
0.3964288023	optimizes
0.3964288023	decreased
0.3964288023	treat
0.3964288023	implements
0.3964115918	non euclidean
0.3963194523	out of distribution
0.3960337602	$ \ mathbf
0.3959295543	obtained results
0.3958140764	mass segmentation
0.3957598529	perceptual image
0.3955467809	ct denoising
0.3955411291	based post processing
0.3953547914	important task
0.3952555984	model achieved
0.3951804732	generated content
0.3948759467	u net architecture
0.3948595515	third
0.3945168364	poses
0.3944422542	degrades
0.3944422542	finds
0.3944422542	attractive
0.3944422542	reflections
0.3944422542	covers
0.3944422542	ranked
0.3944422542	indispensable
0.3944125241	c means
0.3943639368	variation regularization
0.3943326936	adopt
0.3942845932	image reconstruction method
0.3941725826	non
0.3941568816	proposed approach outperforms
0.3941530986	original images
0.3940217808	fill
0.3938882492	incorporates
0.3938700157	well known
0.3938223965	unlabeled images
0.3937422542	occurs
0.3937312701	reduce artifacts
0.3936885070	distance based
0.3936403069	during
0.3936237109	down
0.3936091890	mean square
0.3933183600	merged
0.3933183600	unclear
0.3933183600	discusses
0.3933183600	rendered
0.3933183600	finer
0.3933183600	gaining
0.3932698403	clinical dataset
0.3932575536	processing techniques
0.3932111754	computer graphics
0.3931742464	existing datasets
0.3931486082	above
0.3928315472	captured data
0.3925951560	conventional approach
0.3923335957	rather
0.3922145749	pixel detector
0.3918199855	however
0.3917136924	3d inavs
0.3915271676	segmentation model
0.3915262819	involving
0.3914581926	significant performance
0.3914264334	doing
0.3914213987	test accuracy
0.3914041848	maps generated
0.3912192731	this paper presents
0.3911252670	vision task
0.3909962860	purely
0.3903575586	more importantly
0.3903202817	pixel wise loss
0.3902985730	now
0.3900183894	high quality images
0.3896656339	major challenge
0.3895603830	registration performance
0.3893869598	time
0.3893334913	image interpretation
0.3893187384	benchmarks
0.3892511469	potentially
0.3890590654	network training
0.3887329110	elements
0.3886754258	re
0.3886629809	rgb d images
0.3886156986	based action recognition
0.3883190324	ill posed problem
0.3883187384	increases
0.3883116887	one
0.3881886915	locations
0.3879833132	in vitro
0.3878608762	while maintaining
0.3878395212	toward
0.3878013756	aims to develop
0.3874262441	trained network
0.3872593393	methods rely
0.3868091401	schemes
0.3867459428	involves
0.3866505289	proposed network
0.3866150377	followed
0.3866114465	hold out
0.3863191119	real dataset
0.3863146108	accurate reconstruction
0.3863016176	keep
0.3862591563	learned video
0.3862216148	to
0.3861255366	utilizes
0.3860673989	separately
0.3860338997	computational framework
0.3860043703	the
0.3858440804	deep learning networks
0.3858257179	optimization methods
0.3857459428	exploits
0.3856265949	world scenarios
0.3856126646	despite
0.3855980103	acquired pneumonia
0.3855236040	generate high resolution
0.3854843875	2000
0.3853810127	multi spectral images
0.3851773554	positions
0.3849662748	without sacrificing
0.3849403373	operation
0.3849115058	further
0.3847583381	residual convolutional
0.3847077491	detection network
0.3845001192	0.001
0.3841903872	offers
0.3841033932	measurement data
0.3840957204	dataset size
0.3840538580	much
0.3833931231	large scale dataset
0.3832187907	leverages
0.3831697731	sub
0.3831060361	side
0.3829547481	challenging tasks
0.3825906435	super resolution task
0.3824981559	traditional machine
0.3824001827	demonstrating
0.3824001827	representative
0.3822434395	ability to learn
0.3820304472	proposed methods
0.3820264418	proposed technique
0.3820037769	dense u net
0.3819314327	carried
0.3818790502	tomographic image
0.3817997851	rich
0.3814411861	even
0.3814001827	rapidly
0.3813951467	two stream
0.3813747311	approach improves
0.3812830375	signal to noise
0.3811253105	therefore
0.3809095976	person image
0.3808907466	a
0.3803536601	computer vision tasks
0.3801860924	cause of death
0.3801066002	provide additional
0.3796541811	former
0.3795386033	data volumes
0.3795283240	trade off between
0.3793138647	machine learning model
0.3792478351	ill
0.3790574974	system
0.3789839364	super resolution problem
0.3789779210	source model
0.3788251796	th
0.3787765753	number of parameters
0.3785361056	high inter
0.3784815028	leading cause of
0.3784381219	readily available
0.3782423217	medical image data
0.3781253998	data augmentation methods
0.3777735930	small subset
0.3777657703	key step
0.3777308025	an open source
0.3777262658	four
0.3776932893	also
0.3776503834	low spatial
0.3774462230	based optimization
0.3773983742	image reconstructions
0.3772444940	diagnose covid 19
0.3770757048	who
0.3769866664	\ ell_0
0.3767516253	errors
0.3765965551	taken
0.3762730804	significant improvement over
0.3760257438	few
0.3760118348	connected network
0.3759304911	following
0.3757040785	proposed model outperforms
0.3756342281	\ kappa_
0.3756082924	let
0.3753464475	medical domain
0.3750062448	means clustering
0.3749540209	high frame
0.3747533760	e.g
0.3747062903	ray ct
0.3746317069	publicly available at https
0.3745761522	important problem
0.3745671309	i.e
0.3742822296	all
0.3740292314	two
0.3739434133	graph signal
0.3739280636	underlying
0.3739260062	area under receiver
0.3739254629	need
0.3738685823	diagnosis systems
0.3737733800	more
0.3734978227	$ ^ 2
0.3733923670	little
0.3733624366	machine learning algorithm
0.3731693354	we
0.3731619445	0.05
0.3730383597	critical step
0.3730320221	dynamic contrast
0.3726916865	again
0.3726442705	z net
0.3725057517	r cnn
0.3724445757	test results
0.3723120264	method outperformed
0.3721646308	high resolution imaging
0.3721180428	clinical datasets
0.3720667994	github.com
0.3719309723	large amounts of
0.3719037115	outside
0.3718889416	image velocimetry
0.3715563522	roi detection
0.3715494621	since
0.3714704692	validation experiments
0.3709386699	region of interest
0.3707952821	by
0.3707368286	evaluation results
0.3703892922	critical applications
0.3703752270	ability to detect
0.3703136676	some
0.3702506052	old
0.3697898393	existing deep learning methods
0.3696627757	an
0.3694668740	test image
0.3692963221	trained cnn
0.3687401804	favorably against
0.3686886565	value
0.3686305876	small sample
0.3685771105	deep transfer
0.3681287336	our
0.3680193085	regarded as
0.3680080929	human visual
0.3679926441	three
0.3678335246	microscope images
0.3678269901	same
0.3677504081	generate synthetic
0.3675655045	at
0.3673464188	easily
0.3672670882	retrieval algorithms
0.3672207282	art video
0.3671872624	public data
0.3671200489	image distortion
0.3670468391	simulation data
0.3666273263	under
0.3664514332	each
0.3662529435	diffraction imaging
0.3658417659	improve image quality
0.3656285899	many
0.3654102245	think
0.3653750664	traditional image
0.3653585185	every
0.3652052082	shows promising
0.3651409831	neural network models
0.3649062112	up
0.3647564205	upon
0.3647542845	deep learning technology
0.3644962071	amount
0.3642879204	$ \ pm
0.3642575641	extract features
0.3640906893	+ +
0.3640671811	done
0.3639250270	several
0.3637349497	an end to end manner
0.3636914605	through
0.3634350057	simulated images
0.3631950502	non stationary
0.3629375838	propose to add
0.3628821228	fully connected neural
0.3627876577	top performing
0.3627654044	others
0.3625029270	learning paradigm
0.3623461028	traditional single
0.3623450247	proposed solution
0.3621942588	needs
0.3621369325	deep learning method
0.3618002118	novel
0.3616689850	modified version of
0.3615375263	sub optimal
0.3611026570	does not
0.3610726597	new
0.3609367253	caused by
0.3607162152	for
0.3606128816	visual data
0.3597354373	while keeping
0.3597016906	off
0.3596172358	what
0.3594565031	covid 19 ct
0.3589454281	compared to conventional
0.3589024525	field imaging
0.3587999269	rank matrix
0.3587326235	recent advances in
0.3587126093	on
0.3585569767	mean squared
0.3583799263	deep architecture
0.3583127186	outperforms current
0.3582753369	wise attention
0.3579696409	brain magnetic
0.3576339632	but
0.3575381920	relatively small
0.3571635832	angiography images
0.3570786422	significant challenge
0.3570355433	multimodal image
0.3569937947	fused image
0.3565991683	it's
0.3563144993	possible
0.3559017834	it
0.3553456645	a large margin
0.3546400620	whole
0.3546064640	two stage
0.3545796725	\ mu
0.3545066456	very
0.3544805630	covid 19 infected
0.3543788209	self consistent
0.3541903316	t net
0.3540970176	real applications
0.3540788552	model compression
0.3538606185	certain
0.3537515161	fire detection
0.3537198873	good
0.3535366884	0.69
0.3535366884	0.62
0.3535366884	46
0.3533458004	compression method
0.3532485344	chest x ray image
0.3532277627	real time video
0.3531435458	surface based
0.3530692515	\
0.3529437056	those
0.3528475810	integrated into
0.3527332860	1200
0.3526244458	0.55
0.3526244458	125
0.3525614281	network for single image
0.3523224673	faster than
0.3522479839	achieve better performance
0.3521158507	learning ability
0.3520549009	vision community
0.3513236073	both synthetic and real world
0.3513113206	random field
0.3511776477	existing models
0.3511444102	otherwise
0.3511078804	both
0.3509312039	tumor segmentation challenge
0.3506077757	\ ell_2
0.3505906430	whereas
0.3503857653	real time processing
0.3503829208	slide imaging
0.3502625017	level feature
0.3501247430	video compression methods
0.3499668803	95
0.3498982076	lossy image
0.3496956101	ever
0.3496407131	way
0.3496387601	mri segmentation
0.3495400501	automatic diagnosis
0.3494581460	directly applied
0.3493176108	hampered by
0.3492151333	high degree
0.3490563415	reconstruction networks
0.3488611324	processing tasks
0.3488522327	pre trained network
0.3488084508	greater than
0.3487761801	front
0.3485039300	high signal to noise ratio
0.3482205213	recent deep learning based
0.3477348721	capable of generating
0.3476525099	\ ell_1
0.3476068877	trained model
0.3472022567	learning problem
0.3471721549	example
0.3470618524	low computational
0.3469535294	appropriate
0.3468830855	denoising results
0.3468477323	resulting images
0.3466468648	multi modal data
0.3464813225	much fewer
0.3463614402	dose ct image
0.3458581330	85
0.3458527642	input feature
0.3457962839	with
0.3457181060	low quality images
0.3456569802	deep convolution
0.3456128778	experimental results indicate
0.3454020453	get
0.3453549302	2017
0.3452926682	68
0.3452926682	3.5
0.3452926682	1.7
0.3452926682	0.68
0.3452926682	0.12
0.3452926682	800
0.3452926682	62
0.3452771126	$ \ sigma
0.3452419529	feature information
0.3452361062	cnn based methods
0.3450168512	known
0.3448764232	segmentation plays
0.3448688691	produces high
0.3448674068	automatic methods
0.3447893779	different
0.3447555438	there
0.3447435780	best performing
0.3446916554	computer generated
0.3446623748	serious
0.3446468633	3d
0.3445856967	segmentation problem
0.3442610855	outperforms previous
0.3441478122	without compromising
0.3439736332	state of
0.3439651600	near field
0.3439373528	used
0.3439294981	based fusion
0.3437139282	gap between
0.3436986149	image classification tasks
0.3436719627	across
0.3436693474	based algorithms
0.3435243463	accurate segmentation of
0.3434083900	2020
0.3433946798	76
0.3433946798	0.4
0.3433702038	out of focus
0.3432577888	changes
0.3430789539	no
0.3430105384	trained on imagenet
0.3428621790	cancer imaging
0.3428433816	2
0.3427992667	promising approach
0.3426926605	1d
0.3426174673	classification methods
0.3425808229	self driving
0.3425421071	image sr
0.3423442560	well
0.3422403551	the uk biobank
0.3421611216	non local attention
0.3420761843	achieve high
0.3420574847	work
0.3419839630	beyond
0.3419018293	6.3
0.3415779837	360
0.3415622148	scanning transmission
0.3413595254	into account
0.3413437359	automatic brain
0.3413191348	available
0.3412278751	sub bands
0.3411395698	detection algorithms
0.3411104635	does not require
0.3408866013	$
0.3408784639	recent advances in deep learning
0.3403060912	without
0.3401010863	want
0.3399978269	categorized into
0.3398351251	use
0.3398341403	know
0.3397375157	learning tasks
0.3392130354	an efficient
0.3390569920	appear
0.3389030821	deep learning architecture
0.3388325969	before
0.3386740855	do not
0.3385821970	study proposes
0.3383410209	residual image
0.3383234752	ever increasing
0.3382123723	diagnosis of skin
0.3380864991	relationship between
0.3379238083	usually
0.3379152062	from
0.3377341656	corresponding
0.3376601898	five
0.3376231561	detection models
0.3376105741	covid 19 screening
0.3375016658	reliance on
0.3374314181	supervised deep learning
0.3373467450	ten
0.3373031820	shall
0.3371484489	vs
0.3370119635	histopathological image
0.3368430327	almost
0.3367614545	diagnosis of covid 19
0.3367429942	over
0.3366841156	low signal to noise
0.3366688073	learning based method
0.3366432663	success of deep learning
0.3366385624	annotated training
0.3365948692	12
0.3365325847	the art methods
0.3364033561	comes
0.3361345249	give
0.3360535882	time of flight
0.3358950795	detection approaches
0.3355076214	0.15
0.3355076214	0.9
0.3355076214	2.0
0.3354754353	2d
0.3354307647	a fixed number
0.3352469452	than
0.3351900074	concerning
0.3348957768	causes
0.3348023228	2d or 3d
0.3346337254	applying deep
0.3343864207	the existing state
0.3343397391	adversarial example
0.3341353957	name
0.3341044514	42
0.3341044514	0.03
0.3338586882	quite
0.3337913977	interest
0.3336251348	versatile video
0.3335335904	sampled k space
0.3334838537	whole tumor
0.3334575554	enhancement method
0.3334088473	3d point cloud
0.3332573592	various
0.3331805382	particular
0.3330939057	this paper reviews
0.3329763599	try
0.3329349862	2019
0.3327111423	described
0.3327049065	much larger
0.3323778757	nodule segmentation
0.3323058490	alternative approach
0.3320641781	robustness against
0.3320261543	estimation network
0.3320252012	image segmentation tasks
0.3319845513	50
0.3319399115	16
0.3319204377	non circular
0.3318522039	becomes
0.3317625990	$ ^ 3
0.3316342354	built up
0.3315480618	3
0.3315367513	becoming
0.3314808834	\ circ
0.3312821273	high level feature
0.3312593361	reconstruction framework
0.3311588190	enough
0.3306457175	better
0.3305781524	always
0.3304865977	\ theta
0.3304862124	show
0.3302792314	time varying
0.3302641527	44
0.3301840917	relatively
0.3300800263	&
0.3300293303	smaller than
0.3299858898	run time
0.3298214208	84
0.3298150805	x ray computed tomography
0.3297566376	art methods
0.3297512247	deep cnn
0.3297509691	about
0.3297205767	600
0.3297205767	became
0.3297205767	soon
0.3297205767	1.6
0.3297205767	0.52
0.3297205767	3.8
0.3297205767	tried
0.3296141831	residual neural
0.3295659496	learning based medical
0.3294865581	x ray and ct
0.3294798395	19
0.3291230067	1
0.3291202067	robust to noise
0.3290738345	prediction network
0.3289616622	of
0.3288738596	via
0.3288352183	novel coronavirus
0.3288239432	light field image
0.3286640878	2018
0.3286517027	per
0.3284570068	segmentation techniques
0.3282597532	image compression methods
0.3282179309	prior based
0.3282107307	improve performance
0.3280930727	*
0.3278346079	between
0.3276969588	another
0.3276127771	medical segmentation
0.3275110704	few seconds
0.3274507561	year
0.3274037537	without requiring
0.3270414605	cause
0.3268515606	covid 19 detection
0.3267527256	using deep learning
0.3266240248	dose computed tomography
0.3265958913	sub pixel
0.3263686274	in vivo human
0.3263455997	supervised learning approach
0.3262763541	existing gan
0.3261449971	image super resolution via
0.3261057458	nine
0.3261024676	serve as
0.3260229234	community acquired
0.3259390069	an essential step
0.3254861621	useful
0.3253896793	dimensional data
0.3253750521	image analysis tasks
0.3253253771	out of plane
0.3252214259	seen
0.3251878442	^
0.3251045847	4
0.3250208031	presence of noise
0.3249375294	normal data
0.3247880825	top 1 accuracy
0.3242162845	shed light on
0.3241506824	|
0.3240192313	large dataset
0.3239190385	improve accuracy
0.3236516922	co attention
0.3236144979	source dataset
0.3235057440	encoder decoder based
0.3234893168	noise distribution
0.3234229974	@
0.3233610762	added value
0.3232957371	able
0.3232903179	deep neural network architecture
0.3232516739	17
0.3232452690	not
0.3232277496	73
0.3232277496	89
0.3232277496	88
0.3232277496	1.8
0.3232277496	truly
0.3232277496	51
0.3232277496	eleven
0.3232277496	1.2
0.3232277496	105
0.3232277496	83
0.3230215191	a simple but effective
0.3230087648	unsupervised image to image
0.3228216735	indicate
0.3227882509	57
0.3222630396	super resolution method
0.3219851237	7
0.3219438616	large volumes of
0.3218441548	when
0.3215569292	outperforms state of
0.3214763186	source data
0.3214185874	full field
0.3214180709	rely on
0.3211357743	driven approaches
0.3210925708	proposed method shows
0.3208976987	recent deep
0.3208028170	imaging datasets
0.3207092023	an average dice
0.3207042407	model training
0.3203191916	weighted magnetic resonance imaging
0.3201776308	and
0.3201634293	an ablation study
0.3201543231	less
0.3201103042	available at https
0.3200282628	found
0.3197613833	large number of
0.3197137412	100
0.3195943311	only
0.3194889726	end to end training
0.3193513243	any
0.3193395895	associated
0.3192492332	3d point clouds
0.3192062409	or
0.3191526798	0.02
0.3191463098	other
0.3189389773	thereby
0.3186486192	a unified framework
0.3184510314	depending on
0.3184495903	48
0.3184495903	0.70
0.3184495903	looks
0.3183168281	higher accuracy than
0.3182331066	facial image
0.3180512993	against
0.3179952742	suffer from
0.3179849132	differences between
0.3177592268	model architecture
0.3175658436	without relying
0.3173353127	no reference image quality
0.3173058839	real ct
0.3172954816	focuses on
0.3170745284	whereby
0.3170745284	hardly
0.3170070177	influenced by
0.3169534333	learning method
0.3167837983	they
0.3166272081	into
0.3165976881	this paper develops
0.3164810622	data structure
0.3163906617	insight into
0.3162183158	proposed method performs
0.3161272881	proposed approach achieves
0.3160512001	first order
0.3159317204	4d
0.3156952249	exposure image
0.3156439314	vision algorithms
0.3156258083	like
0.3156063430	having
0.3154775164	face image
0.3151491101	necessary
0.3150765758	learning enabled
0.3150370295	learning algorithm
0.3149753790	87
0.3148746251	8
0.3142879692	classification algorithm
0.3140690767	along
0.3140006909	take
0.3139984944	robustness to noise
0.3137544926	in situ
0.3137435451	growing interest
0.3136093767	aimed at
0.3134533474	method for estimating
0.3132711229	trained deep neural
0.3132680361	likely
0.3131100080	small data
0.3129305593	an upper bound
0.3129105771	deep learning applications
0.3128227386	within
0.3127518013	k space data
0.3126602948	level semantics
0.3123220338	just
0.3122720345	throughout
0.3120348974	inspired by
0.3118672128	learning model
0.3118384337	81
0.3117118534	$ \ times
0.3116835786	co occurrence matrix
0.3116513970	extensive experiments on
0.3116277808	this letter
0.3115177060	network based
0.3113694217	visual object
0.3111869343	networks trained
0.3111807673	=
0.3111019130	\ sigma
0.3109802279	learn features
0.3109175695	$ _
0.3105900151	entire image
0.3105283721	synthetic image
0.3105057837	images of different
0.3103595320	etc
0.3102009873	detection systems
0.3101903622	52
0.3101903622	0.80
0.3101903622	0.66
0.3101903622	say
0.3101903622	121
0.3101557465	mr data
0.3101069155	content image
0.3099666166	segmentation based
0.3097710970	whole brain segmentation
0.3096512167	\ times
0.3095516838	allow
0.3094607184	make
0.3090903988	large amounts of data
0.3089823685	an important tool
0.3087412951	achieves better performance
0.3087273535	39
0.3086389979	acquired images
0.3086042544	high false
0.3085493850	well suited
0.3085278698	echo time
0.3085057837	datasets with different
0.3084607299	volumetric images
0.3084140224	deep learning based image
0.3083488275	actually
0.3082685620	$ \ approx
0.3081473570	a single pixel detector
0.3080624549	wide range of
0.3078270483	out
0.3076670678	in recent years
0.3075548925	4d flow
0.3074865198	help
0.3074675527	eight
0.3073885129	0.67
0.3072786392	high compression
0.3072184286	aware loss
0.3070456781	video datasets
0.3069799616	of great importance
0.3069235238	compared with traditional
0.3068998704	allows
0.3068971918	0.2
0.3068797045	sampled data
0.3068780927	mine
0.3068780927	twice
0.3067525955	made
0.3064328465	an overview
0.3062385304	regions of interest
0.3061975804	suffers from
0.3061707422	a deep learning approach
0.3060129372	image information
0.3059951207	multimodal brain
0.3053723049	how
0.3052749992	recent advancements in
0.3052715387	experiments conducted on
0.3052300175	relying on
0.3052098643	best
0.3050649721	non negative
0.3049765392	end to end fashion
0.3049398750	denoising network
0.3048628740	based model
0.3046973609	often
0.3045814584	brain network
0.3045190319	adaptive histogram
0.3044753200	10
0.3044313239	an in depth
0.3043464315	depend on
0.3042474723	challenge 2020
0.3041105313	image texture
0.3040889708	a comprehensive survey
0.3038231792	+
0.3037533150	65
0.3037164728	in silico
0.3037155612	deep learning based framework
0.3031864840	one or more
0.3031144471	relies on
0.3027768926	effective approach
0.3026318868	plus
0.3026272683	immediate
0.3023456044	describe
0.3023208526	102
0.3022700700	spatial distribution
0.3022671365	this paper describes
0.3022499225	why
0.3020248169	20
0.3019922049	contain
0.3018386944	advanced deep
0.3018265099	retrieval method
0.3016922176	model called
0.3016633157	sensing imagery
0.3015846309	one to one
0.3015732747	2.2
0.3014543598	unpaired image
0.3014502625	33
0.3014502625	29
0.3012171246	2014
0.3012135741	task based
0.3011803081	covid 19 positive
0.3011229597	intersection over
0.3011209995	models achieve
0.3009972429	among others
0.3009161859	real world image
0.3008638710	still
0.3006944655	thick
0.3005836865	mr segmentation
0.3005244171	frequently used
0.3005008173	a deep learning framework
0.3004873044	deals with
0.3004206219	amongst
0.3001180411	6d
0.3001180411	reasonably
0.3001180411	27
0.3001180411	seems
0.3000221083	an effective tool
0.2998317972	chest x ray dataset
0.2996513744	0.04
0.2995099319	real time applications
0.2993402450	execution time
0.2992497339	must
0.2992234525	vision problems
0.2991187880	iterative phase
0.2989687735	increasing number of
0.2989683943	global feature
0.2988566629	seven
0.2988031454	outperforms other methods
0.2985926088	a major challenge
0.2985338626	reconstruction approaches
0.2983623349	uses
0.2982259929	the art
0.2981919008	2011
0.2979674775	step towards
0.2976720293	recognition models
0.2973721155	aims at
0.2973702483	neither
0.2972905268	an important step
0.2971934468	detail
0.2971328198	1024
0.2968053549	2d and 3d
0.2967545034	leads to
0.2967437880	promising technique
0.2967064715	even if
0.2966808751	recent deep learning
0.2966548437	re sampling
0.2965379077	53
0.2965379077	69
0.2965379077	hundred
0.2965379077	kept
0.2965379077	took
0.2965379077	0.7
0.2965379077	180
0.2964760371	referred to as
0.2964340273	this study proposes
0.2962134189	followed by
0.2960487622	\ lambda
0.2960221909	21
0.2959699395	5
0.2958808431	x ray ct
0.2956853380	containing
0.2955728732	seem
0.2955728732	regards
0.2955719124	the shelf
0.2954198489	art techniques
0.2952457706	significant impact
0.2952060572	a case study
0.2949404135	being
0.2948793238	2013
0.2948650320	become
0.2947882756	exactly
0.2947882756	wherein
0.2947112625	achieves state of
0.2945855522	target image
0.2945453369	extensive experiments show
0.2944677017	camera images
0.2943926766	incorporated into
0.2943216616	people
0.2942644287	bayesian deep
0.2942097907	its
0.2941608733	consider
0.2940890915	91
0.2938284912	already
0.2936751996	whether
0.2936050025	of covid 19 from
0.2936046824	gets
0.2936046824	26
0.2936046824	merely
0.2936046824	31
0.2936046824	4.5
0.2935148751	provides
0.2932875862	an innovative
0.2930351046	dozens of
0.2929399378	2016
0.2928654073	0.72
0.2928654073	1.3
0.2927313458	contains
0.2926745531	dealing with
0.2926499320	this paper
0.2925089326	last few years
0.2923305146	clearly
0.2921353028	this chapter
0.2920518293	method consists
0.2920466022	based super resolution
0.2920177911	1.5
0.2918834786	learning based super
0.2916558184	relationships between
0.2916054776	a deep convolutional neural network
0.2915848243	38
0.2915848243	55
0.2915288670	spectral image
0.2915028759	un trained
0.2914752411	supervised approach
0.2914523653	x _1
0.2912364895	from scratch
0.2912292078	optical image
0.2911564255	ones
0.2911273660	many to one
0.2909541582	image super resolution using
0.2908666189	trained to predict
0.2908596644	using convolutional neural networks
0.2908024632	as opposed
0.2906058810	semantic segmentation network
0.2904424249	alone
0.2903924502	computer tomography
0.2902980138	much faster
0.2902722134	suffering from
0.2902190242	connected layer
0.2900410402	estimation methods
0.2899810634	^ 3
0.2899436308	0.71
0.2899436308	0.8
0.2896183342	supervised segmentation
0.2893082847	unavailability of
0.2892714283	0.78
0.2892714283	67
0.2892714283	93
0.2892714283	0.3
0.2892639486	find
0.2892276815	0.96
0.2892098476	higher than
0.2890936636	covid 19 disease
0.2888757900	compressed image
0.2888014674	training approach
0.2887104728	realistic image
0.2886642226	particle image
0.2886503962	resulting image
0.2886326302	without retraining
0.2885181133	opposed to
0.2879149784	in vivo
0.2877912625	current state of
0.2877114050	learning based algorithms
0.2875335792	synthesis methods
0.2873743155	depends on
0.2872960369	previous work
0.2872059111	performs better than
0.2869870576	whole slide image
0.2869256511	the proposed method
0.2868791057	low signal
0.2866902244	0
0.2866836306	frequency information
0.2865194640	network outperforms
0.2865074563	compared to
0.2864725643	0.88
0.2864725643	away
0.2864713049	based on deep learning
0.2864389841	as few as
0.2864169228	plethora of
0.2863429988	learning based segmentation
0.2860234482	getting
0.2857682095	24
0.2857307788	fundamental problem
0.2856694257	94
0.2853024141	imaging based
0.2852887395	image artifacts
0.2851554941	mri methods
0.2851127703	refers to
0.2849130462	learning based framework
0.2848381639	state of art methods
0.2847360700	encoder side
0.2846978368	sub cellular
0.2846257393	performance analysis
0.2845756733	0.76
0.2845756733	0.6
0.2845756733	82
0.2845398481	follows
0.2845398481	nor
0.2844974494	0.93
0.2841870046	tracking methods
0.2840685476	medical field
0.2839830413	23
0.2838756041	architecture design
0.2838404605	small subset of
0.2837209107	good generalization
0.2833184296	mainly
0.2832762076	500
0.2831069873	at least
0.2830873246	results indicate
0.2830632488	0.94
0.2829982712	six
0.2828277951	relationships among
0.2826219341	70
0.2826219341	18
0.2826130750	average dice score of
0.2826046928	0.79
0.2825599868	current deep learning
0.2825444018	take advantage of
0.2823479242	128
0.2823005240	information about
0.2820647040	0.97
0.2820242095	1.0
0.2819935965	proposed method achieved
0.2819685554	image style
0.2818915518	tend to
0.2818493414	86
0.2818217788	up sampling
0.2817635590	two fold
0.2817329167	learning networks
0.2816136988	$ norm
0.2816123231	0.90
0.2816123231	0.5
0.2813641598	single model
0.2812512256	insights about
0.2809618594	augmentation method
0.2805890281	nearly
0.2804929586	existing deep learning based
0.2801445239	modern deep
0.2801312069	0.98
0.2800999029	proposed approaches
0.2800846687	supervised learning based
0.2799797190	move
0.2799741324	faster and more
0.2798174844	through scattering media
0.2795162120	0.92
0.2794466517	end to end learning
0.2794422631	cnn training
0.2793558247	200
0.2792707813	35
0.2792707813	ignored
0.2791685358	14
0.2791147176	9
0.2790931600	namely
0.2790071060	0.84
0.2789819955	0.87
0.2788401692	x ray ghost
0.2787896594	96
0.2787858004	+ t
0.2787808477	image representations
0.2787551525	mri datasets
0.2785553975	pre trained cnn
0.2785438764	mismatch between
0.2784252115	28
0.2783808978	important tool
0.2783761618	previous method
0.2781255807	three dimensions
0.2780656453	increasing demand for
0.2780039329	learning based algorithm
0.2777830960	less than
0.2777199168	on pascal voc
0.2776435616	method requires
0.2776054751	90
0.2774308159	behind
0.2773349123	40
0.2771941867	serves as
0.2771359203	multiple models
0.2768741174	specified
0.2767690909	0.73
0.2767111382	has
0.2766288587	25
0.2765268888	\ mathbf x
0.2765145573	of such models
0.2763189667	of great significance
0.2760192589	0.95
0.2759052346	put
0.2758735081	spatial feature
0.2758116944	can
0.2757662419	0.77
0.2755855308	13
0.2755767757	0.01
0.2754854883	99
0.2754466765	image adaptive
0.2754299479	shown to perform
0.2754091695	0.85
0.2751884321	2015
0.2751884321	22
0.2750663261	tracking method
0.2750167324	techniques provide
0.2748508064	insights into
0.2745958647	1000
0.2745448117	owing to
0.2745297896	too
0.2744809197	15
0.2744734276	80
0.2743190095	day
0.2742696941	based on
0.2741792860	dynamic range imaging
0.2741736862	segmentation of retinal
0.2741315599	0.75
0.2740792589	92
0.2740332083	11
0.2740189743	placed
0.2738116944	that
0.2737300897	accurate quantification
0.2737111382	have
0.2737111382	been
0.2737111382	which
0.2737111382	be
0.2737099898	based systems
0.2736606594	this article
0.2736267777	net architecture
0.2736077135	their
0.2735104810	come
0.2733512202	motivated by
0.2733190095	0.89
0.2729764301	near optimal
0.2728116944	are
0.2728116944	is
0.2726268380	more accurate
0.2725544410	per frame
0.2724743581	susceptible to
0.2722720395	mask r
0.2717889538	itself
0.2717786187	0.74
0.2717786187	0.99
0.2717052164	98
0.2716947737	normally
0.2716306805	believe
0.2715115583	400
0.2715115583	150
0.2715115583	themselves
0.2712742450	was
0.2711362182	accounting for
0.2711052164	2.5d
0.2708405233	using deep neural networks
0.2708361472	512
0.2707158205	ct based
0.2707028543	trained deep
0.2707018839	75
0.2706318169	60
0.2706313729	segmentation process
0.2704481526	normal images
0.2703051328	2.5
0.2703051328	2012
0.2703051328	97
0.2703004472	120
0.2701058588	reconstruction approach
0.2699972374	entirely
0.2699606141	0.91
0.2699606141	0.86
0.2694721807	32
0.2693271252	additional data
0.2692840567	gives
0.2691303342	detecting covid 19
0.2687357835	were
0.2686616349	converted into
0.2685904650	compared against
0.2683535947	whose
0.2683529221	training algorithm
0.2682562807	indicates
0.2680916798	approach consists
0.2678242298	below
0.2677754469	101
0.2677429743	may
0.2676480625	art algorithms
0.2675812261	lidar point
0.2674471995	6
0.2673741854	method relies
0.2673706368	own
0.2672634940	similar images
0.2671964891	number of layers
0.2670526806	due to
0.2669533642	advent of
0.2667904621	where
0.2667053558	limited availability of
0.2666303054	256
0.2665867795	the whole network
0.2664496983	using generative adversarial networks
0.2664417897	weighted mr images
0.2660520684	lead to
0.2660224299	0.1
0.2659950259	very few
0.2659535531	64
0.2659252592	around
0.2658690813	structure segmentation
0.2657167839	analysis techniques
0.2656850544	imaging performance
0.2656724852	test time
0.2655371699	t test
0.2650358124	complex data
0.2649710344	number of classes
0.2649687330	guided image
0.2649344548	large images
0.2648033148	before and after
0.2646872889	detection problem
0.2646225529	had
0.2645969783	neural style
0.2644639451	well defined
0.2644194939	34
0.2644052347	large data
0.2643489552	terms of psnr
0.2642800002	encoding network
0.2642615712	single gpu
0.2642341745	segmentation approaches
0.2641968644	respectively
0.2640969781	supervised classification
0.2638989492	0.83
0.2636619677	them
0.2635988235	learning frameworks
0.2635042939	affected by
0.2633800416	never
0.2632671701	while preserving
0.2630665527	0.82
0.2630637878	deep video
0.2630528339	30
0.2629794127	deep image
0.2628964529	wide variety of
0.2626305668	could
0.2626099079	will
0.2625384304	a fully convolutional network
0.2624088013	side information
0.2621078870	on two datasets
0.2618215621	interactions between
0.2617778535	denoted as
0.2617371845	45
0.2616700536	based features
0.2616159809	two photon
0.2615930668	thoroughly
0.2615894299	a priori knowledge
0.2614609723	sr images
0.2610951821	decomposed into
0.2609091502	call
0.2606287519	0.81
0.2603655011	advances in deep learning
0.2602968814	single shot 3d
0.2595603514	might
0.2595540318	a deep neural network
0.2593907239	discriminate between
0.2593445519	data for training
0.2592986523	deep super resolution
0.2592313021	300
0.2592313021	indicated
0.2592255685	based solutions
0.2590794771	mostly
0.2590621056	four dimensional
0.2589806078	based registration
0.2589159070	onto
0.2582514120	novel coronavirus disease
0.2581708500	a weakly supervised
0.2575218193	space time
0.2570537547	into consideration
0.2569409019	morphological changes
0.2569304942	root mean
0.2568012943	full resolution
0.2563513053	high bit
0.2561195128	human computer
0.2558808237	either
0.2556487033	achieves significant
0.2556451757	number of samples
0.2555623884	non overlapping
0.2554062958	limited number
0.2551194345	denoising method
0.2550514749	mri dataset
0.2549812899	spectral data
0.2548769905	tradeoff between
0.2548150432	coding method
0.2539730361	efficient network
0.2539062528	well studied
0.2535093995	improvement over
0.2535036598	based image retrieval
0.2534338032	compared with existing
0.2533045597	existing deep
0.2530938657	more than
0.2529105989	investigate whether
0.2529090494	x ray projection
0.2525772394	this paper introduces
0.2524137212	significantly better than
0.2521461290	not always
0.2521417380	translation model
0.2519661692	convolution network
0.2519096189	phase images
0.2517984498	the proposed approach
0.2517738431	cannot
0.2515813477	experimental results on
0.2515715615	network performance
0.2515033327	computer vision community
0.2514493417	10 ^
0.2514332190	3 dimensional
0.2514032502	compared to standard
0.2511531842	would
0.2509732281	prior information about
0.2508382793	acquired data
0.2507483681	noise ratios
0.2506100727	ranging from
0.2505747494	segmentation pipeline
0.2505583026	mri brain
0.2504828187	successfully applied to
0.2504730750	typically rely on
0.2503686381	should
0.2502150402	sensing images
0.2500251991	imaging process
0.2500191186	wide range of applications
0.2499552141	according to
0.2499473606	non linear mapping
0.2499459303	global image
0.2499424378	segmentation approach
0.2497597290	time dependent
0.2497347532	a convolutional neural network
0.2496440468	and vice versa
0.2495969055	as well as
0.2495478130	commonly known
0.2494775572	and vice
0.2492567667	focus on
0.2490082348	training method
0.2490011098	existing cnn
0.2487676396	trained to perform
0.2487166455	comparison between
0.2486600944	associations between
0.2485006881	easy to use
0.2480424225	elevation models
0.2477855657	instance learning
0.2470681259	the art performance
0.2469160046	learning based reconstruction
0.2463301265	u net based
0.2461719936	try on
0.2460061498	robust image
0.2459565125	based classification
0.2458626292	focus image
0.2455916366	in spite
0.2455765843	segmentation of brain
0.2452631143	two stage framework
0.2449152422	alternating direction method of
0.2449061524	contrast mri
0.2446585550	a broad range
0.2445231090	high degree of
0.2443801124	very close
0.2439873980	roc curve of
0.2439445704	features extracted from
0.2434983668	better than
0.2433332638	shot learning
0.2432618808	become one of
0.2432270846	publicly available dataset
0.2431651499	interaction between
0.2430250811	intensity images
0.2426939936	based models
0.2425568335	the receiver operating characteristic curve
0.2425196619	focused on
0.2423841699	covid 19 lung
0.2415693355	number of false
0.2415639247	clinical images
0.2415165463	attention model
0.2414330581	human object
0.2413435188	results show
0.2412306639	proposed metric
0.2409940406	good agreement
0.2408849419	processing technique
0.2407914623	algorithm based
0.2405012433	automatic classification
0.2403938754	increasing interest
0.2403902697	improved image
0.2399925221	near real time
0.2398390244	better results than
0.2398030270	spatial image
0.2396090799	end to end manner
0.2394421614	focus images
0.2393962449	and tracking of
0.2393438914	the other two
0.2390904118	compared to existing
0.2390211576	deep super
0.2389264263	from highly undersampled
0.2388609027	tomography images
0.2387759121	convolutional long
0.2385342725	based representation
0.2380761018	temporal data
0.2380507649	emerged as
0.2380314704	experiments show
0.2378082864	proposed hybrid
0.2376549577	the art approaches
0.2375912543	so called
0.2375048982	image feature
0.2374834654	efficient video
0.2374781571	based loss
0.2373229621	~ 1
0.2372739137	shortage of
0.2370134550	a deep learning based
0.2369195011	diagnosis of breast
0.2368830023	method to automatically
0.2368314632	as much as possible
0.2367973686	super resolution images
0.2367369127	self adaptive
0.2365823653	automatic segmentation of
0.2360705266	order to reduce
0.2360365470	characterized by
0.2358438914	the time of
0.2355475951	for use in
0.2353693472	machine learning approach
0.2352612133	efficient method
0.2351477373	derived from
0.2349752165	cope with
0.2348659232	of computer vision and
0.2347096286	image distribution
0.2346264512	simulated and real data
0.2345975226	correspond to
0.2341856657	larger than
0.2339917819	number of
0.2339909687	non line of sight imaging
0.2339247863	robust deep
0.2338534024	enhanced images
0.2338252944	method enables
0.2337904753	including image
0.2334714661	these issues
0.2333438362	lower than
0.2332447545	accomplished by
0.2331848881	a fully convolutional neural network
0.2331515448	to date
0.2330858324	this end
0.2330255898	weighted images
0.2328748102	during training
0.2328495557	compared to existing methods
0.2328438914	to work with
0.2326354380	the proposed algorithm outperforms
0.2326308737	automated analysis
0.2326137279	represented by
0.2325021405	and so on
0.2324365877	an open problem
0.2324017474	compared to traditional
0.2322718625	inference time
0.2322359073	quite challenging
0.2318131098	training framework
0.2317637799	capable of
0.2317618808	with or without
0.2315075904	an end to end trainable
0.2311893040	using convolutional neural
0.2311319256	consisting of
0.2309751228	a fully automated
0.2308420955	belonging to
0.2306230051	automated segmentation of
0.2305943535	new opportunities
0.2303142439	detection based
0.2302569565	while retaining
0.2301509503	images obtained
0.2301182564	high dynamic
0.2293187413	existing deep learning
0.2288451831	a wide variety
0.2287686668	of magnitude faster
0.2285290578	inspired by recent
0.2284866590	consist of
0.2284309800	tends to
0.2283520181	great interest
0.2283419548	an input image
0.2280636389	critical role in
0.2280177200	knowledge about
0.2279511454	methods perform
0.2276575616	this paper investigates
0.2276260722	with and without
0.2274698341	the proposed algorithm
0.2273164466	unsupervised approach
0.2272536829	limited number of
0.2272501564	for fast and
0.2272460517	this study
0.2271519137	not only
0.2270465267	more and more
0.2268542870	for low dose ct
0.2267956110	for accurate and
0.2265887330	an alternative
0.2264423780	as long as
0.2260468781	architecture consists
0.2260102669	mean shift
0.2259985339	ct datasets
0.2259761376	an end to end
0.2257437384	five fold
0.2256014901	able to
0.2253807690	based algorithm
0.2253283058	previous state of
0.2252014978	covid 19 chest x ray
0.2251307566	applied to
0.2249301985	f1 score of
0.2242851338	a model to
0.2241248395	does not need
0.2238549391	validation data
0.2236663714	aiming at
0.2235468104	the image to
0.2233364668	a comparative study
0.2232539439	network model
0.2232343673	produced by
0.2231623704	using deep learning techniques
0.2231483838	regardless of
0.2228007701	performs well
0.2226214757	$ \
0.2225618161	joint image
0.2222740632	network layers
0.2220902074	an emerging
0.2220900987	scan time
0.2220677990	computation time
0.2218736293	but also
0.2216749829	unable to
0.2215618077	detection framework
0.2214911139	very challenging
0.2214868172	compared with
0.2214649367	non blind
0.2214585514	images generated
0.2212275013	semantic image
0.2211406573	learning network
0.2211122028	order to provide
0.2211080702	based image
0.2210105581	the movement of
0.2210105581	the identity of
0.2209582987	3d object detection
0.2207636733	network for retinal
0.2203937062	this work
0.2203789717	\ em
0.2202340236	\ rho
0.2201186321	to improve
0.2200105581	the guidance of
0.2200105581	the formation of
0.2200105581	the contrast of
0.2200105581	the phase of
0.2199819860	camera image
0.2197472912	recent work
0.2194719523	sub sampling
0.2193815985	popular deep
0.2190105581	the method of
0.2190105581	the problems of
0.2188329565	to address
0.2188011563	the results of
0.2187015373	balance between
0.2186744966	5 fold
0.2186558078	from different sources
0.2183283058	recent state of
0.2182649678	regularization based
0.2181868652	video image
0.2181283842	single forward
0.2180911526	transformed into
0.2179939129	based techniques
0.2179433829	between real and
0.2177834826	pet image
0.2175394539	an explainable
0.2173256608	based on deep
0.2170537990	learning technique
0.2168868264	additional training
0.2168622817	scale features
0.2168011563	the network to
0.2166979146	early detection of
0.2165084902	sensing applications
0.2164943519	video object
0.2164229270	level classification
0.2163438914	of deep learning in
0.2162069426	based on convolutional neural networks
0.2161584125	imaging methods
0.2160105581	the details of
0.2159249339	arising from
0.2158342239	decoder architecture
0.2158011563	the shape of
0.2158011563	the learning of
0.2157864850	a multi task learning
0.2157721298	kinds of
0.2155991824	with applications in
0.2155524506	for solving inverse
0.2150937909	view image
0.2149255428	formulated as
0.2148011563	the parameters of
0.2148011563	the study of
0.2147810540	a modified version
0.2147629252	order to obtain
0.2147588903	based motion
0.2146149256	two steps
0.2145405738	on chip
0.2143152785	recent advances in deep
0.2143096309	the resolution of
0.2141485587	resolution images
0.2140105581	the encoder and
0.2140105581	the content of
0.2140105581	the assumption of
0.2140105581	the increase of
0.2139555631	imaging features
0.2139420745	a novel
0.2139002165	accounts for
0.2138893692	responsible for
0.2138613339	a generative adversarial network
0.2138075617	analysis algorithms
0.2138011563	the domain of
0.2138011563	the model to
0.2138011563	the end of
0.2137631267	using deep convolutional neural networks
0.2136102252	dataset demonstrate
0.2135142444	lossless image
0.2132695148	accurate quantification of
0.2132305059	adversarial domain
0.2132127968	tumor classification
0.2131289842	widespread use
0.2130105581	the processing of
0.2129407672	at risk
0.2128011563	a measure of
0.2128011563	the loss of
0.2127640856	an interactive
0.2126451331	general framework
0.2126272031	a comprehensive
0.2125105581	the optimization of
0.2125105581	the removal of
0.2124074193	residual u
0.2124046053	based compression
0.2123329583	this issue
0.2122219065	dataset consisting of
0.2120105581	the network on
0.2119871186	a large scale
0.2118011563	the acquisition of
0.2118011563	the objective of
0.2118011563	the fusion of
0.2118011563	the information of
0.2116761858	optic disc and
0.2116462721	benefit from
0.2115105581	the addition of
0.2115105581	the challenges of
0.2115105581	the spatial and
0.2114773816	temporal convolutional
0.2112971533	so as to
0.2112472299	limited training
0.2110002473	an average
0.2108011563	the space of
0.2108011563	a function of
0.2106166595	the proposed model
0.2105869185	a memory efficient
0.2105105581	the predictions of
0.2105105581	the theory of
0.2105105581	the results with
0.2105105581	the uncertainty of
0.2102198133	the past decade
0.2101179337	correspondences between
0.2100400902	prone to
0.2100105581	the aid of
0.2100105581	the user to
0.2098011563	the order of
0.2098011563	the outputs of
0.2098011563	the weights of
0.2095105581	the boundary of
0.2095105581	the similarity of
0.2095105581	the performances of
0.2094216056	one dimensional
0.2091816675	agreement between
0.2090883735	experiments on synthetic
0.2090105581	the measurement of
0.2088773377	shown to improve
0.2085691999	range of applications
0.2085105581	the physics of
0.2085105581	the result of
0.2085105581	the computation of
0.2085105581	the noise in
0.2083938936	application of deep learning
0.2083670909	good performance
0.2080162141	amounts of training
0.2079110892	this paper explores
0.2077392839	end to end deep
0.2077142618	the diagnosis and
0.2075907721	extracted from
0.2075358221	achieve state of
0.2075105581	a method of
0.2075105581	the sparsity of
0.2075105581	the architecture of
0.2074617564	multi exposure image
0.2074283382	such as
0.2073580524	methods in terms
0.2073500751	classification approaches
0.2072157165	captured by
0.2071690792	source image
0.2071624144	synthesis method
0.2070105581	the model on
0.2068011563	the issue of
0.2067229950	experiment results show
0.2066625719	deep learning segmentation
0.2066591827	co segmentation
0.2066074112	field of machine learning
0.2065352708	to solve
0.2065134593	based on convolutional neural
0.2065105581	a class of
0.2065105581	the geometry of
0.2064576782	based on generative adversarial
0.2062732756	model performs
0.2057142178	leave one
0.2055105581	the framework of
0.2054855631	simple method
0.2053184840	perform better
0.2052142618	in relation to
0.2051409692	a unified
0.2050219626	much more
0.2050105581	a database of
0.2048451228	a challenging task
0.2048330201	processing method
0.2048085611	conditional image
0.2047597183	using generative adversarial
0.2046538676	formed by
0.2046168681	net model
0.2044761930	real time performance
0.2044090537	large scale data
0.2042142618	the tasks of
0.2042142618	the challenge of
0.2041075177	this paper addresses
0.2040872690	extensively used
0.2040105581	the key to
0.2038138892	view data
0.2028162884	correlation between
0.2027907032	detection tasks
0.2027765703	much higher
0.2027618877	belong to
0.2026580992	trained on
0.2026344261	each pixel
0.2025105581	the statistics of
0.2023699076	learning features
0.2023456937	data volume
0.2021820857	available at
0.2019834564	diagnosis of lung
0.2018421300	space data
0.2018238200	much smaller
0.2018008659	current deep
0.2017597284	trained to generate
0.2016515116	broad range of
0.2014120581	network trained
0.2012142618	the core of
0.2010144004	available online
0.2009601865	machine learning method
0.2006688072	the code and
0.2005513252	mean absolute
0.2004755111	useful tool
0.2003468134	learning based medical image
0.2003180630	a deep convolutional
0.2002026346	the roc curve
0.1999568457	covid 19 chest
0.1999214795	free image
0.1997310442	numerical experiments show
0.1996004112	act as
0.1995597839	this problem
0.1995534198	deep learning algorithm
0.1992908263	a key role
0.1991712230	the proposed framework
0.1990960825	often fail
0.1987018599	each iteration
0.1986180374	recent progress in
0.1986058765	end to end deep learning
0.1985730920	leading to
0.1984051945	a multi task
0.1981291229	starting from
0.1980964880	detection system
0.1980336224	a simple
0.1979549136	to detect
0.1979268542	close to
0.1977626127	a deep network
0.1973423040	disease 2019
0.1973383664	pre trained on
0.1973197699	and cloud shadow
0.1970605815	difference between
0.1968439899	consists of
0.1968354923	deep learning system
0.1967868652	objects of interest
0.1966677270	automated method
0.1965824706	domain data
0.1965166314	more precisely
0.1965084629	in spite of
0.1964308317	accurate segmentation
0.1963929748	a large scale dataset
0.1961791873	make use of
0.1961358721	reconstruction tasks
0.1960207077	to reduce
0.1958885541	reconstruction model
0.1958356693	very low
0.1957623636	effective method
0.1957131934	as high as
0.1956096098	detection of covid 19
0.1954710290	two step
0.1954252599	to overcome
0.1952364368	quality images
0.1949463474	advantages over
0.1948686041	in addition
0.1948234889	tested on
0.1948060676	an important
0.1948051483	target data
0.1946718896	use case
0.1946503823	segmentation datasets
0.1944493136	linear combination of
0.1943951790	non covid
0.1943188444	automatic detection of
0.1942499081	this thesis
0.1942251886	including data
0.1941299091	method to generate
0.1939172424	become increasingly
0.1938599080	large scale image
0.1938132624	outperforms other state of
0.1937959020	significant impact on
0.1937740236	class segmentation
0.1930274536	art object
0.1929331165	compared to previous
0.1928605633	improved training
0.1928379660	this manuscript
0.1928064639	level accuracy
0.1927575337	some extent
0.1927135162	an encoder decoder
0.1927109582	number of measurements
0.1925791932	the wild
0.1925002537	improved classification
0.1924946635	better performance than
0.1923589892	efficient algorithm
0.1923247723	an unsupervised
0.1922888314	accompanied by
0.1919159865	an encoder decoder architecture
0.1918652892	focusing on
0.1916877280	sub networks
0.1916334000	showed good
0.1915398363	makes use of
0.1914472723	an integral part
0.1914463638	trained on synthetic
0.1913479419	treated as
0.1912685265	in order to
0.1911215419	training time
0.1910670203	model shows
0.1909532642	to generate
0.1906208822	information from multiple
0.1905946138	computer vision applications
0.1903793625	one stage
0.1903080233	similarities between
0.1902458011	proposed pipeline
0.1896663430	important role in
0.1892164376	access to
0.1892076130	time consuming task
0.1891857948	$ \ textit
0.1886198678	to extract
0.1885964138	microscopy image
0.1885134072	real time imaging
0.1883342545	the proposed method achieves
0.1879177524	an important role
0.1875090121	performance compared
0.1874170689	network to learn
0.1873542849	a posteriori
0.1873374090	three classes
0.1869673496	scale feature
0.1869646014	large range of
0.1869009069	determined by
0.1868769468	structured low
0.1867324833	model trained
0.1864113836	in terms of
0.1863342962	trained to learn
0.1861541970	function based
0.1861387252	great potential for
0.1857127509	feature extraction from
0.1854425983	based reconstruction
0.1854223574	challenged by
0.1853086137	conditioned on
0.1852626921	slightly better
0.1851382537	domain adaptation for
0.1850400204	model accuracy
0.1850027668	one class
0.1847663094	a deep learning
0.1847046206	acts as
0.1846686188	detection based on
0.1846439916	neural architecture search for
0.1845069813	discrepancy between
0.1843149191	visible image
0.1841441250	pre trained deep
0.1839191441	real time object
0.1838867222	a single
0.1837814293	b mode images
0.1835171215	end to end deep neural
0.1835059672	a deep learning model
0.1834886080	low dynamic
0.1834837267	a two stage
0.1833305821	to obtain
0.1831916793	one step
0.1830721750	differentiate between
0.1829510077	3d printed
0.1828760830	learning applications
0.1824532642	to learn
0.1824370884	used to train
0.1824262428	x ray image
0.1822885615	information provided
0.1820321605	proposed to solve
0.1820016721	per patient
0.1817286338	very useful
0.1816380293	coding standard
0.1816364692	integral part of
0.1816032677	using deep
0.1814126610	entropy loss
0.1813722543	on par
0.1813682769	proposed techniques
0.1813405701	classification framework
0.1812781951	image signal
0.1812610405	a benchmark dataset
0.1812140271	tracking system
0.1810386866	deal with
0.1808947938	cad system
0.1806198678	to predict
0.1805799771	dominated by
0.1801074312	neural network model
0.1800655949	development of deep learning
0.1799697545	relied on
0.1797110481	detection using
0.1795592354	by introducing
0.1793617598	running time
0.1793444632	both synthetic and real
0.1791066345	limited amount of
0.1790899565	network for image
0.1788042161	$ m
0.1787925151	model to learn
0.1786463687	an edge
0.1785812928	x ray imaging
0.1784070237	images from multiple
0.1780951250	improve upon
0.1780397679	very time consuming
0.1780163894	computer vision algorithms
0.1779824098	composed of
0.1777360630	$ g
0.1777017204	tissue images
0.1776671472	divided into two
0.1775405981	obtained by
0.1775359039	comprehensive review of
0.1775225883	based applications
0.1774490462	covid 19 dataset
0.1773622646	the last layer
0.1772790950	super resolution via
0.1772578897	local attention
0.1771256357	benchmark data
0.1770499269	in most cases
0.1769361324	field of machine
0.1767118226	split into
0.1766534669	mri image
0.1765350417	image as input
0.1764981812	other words
0.1764888027	two public datasets
0.1764097354	to ensure
0.1763863861	powerful tool for
0.1762130980	conventional image
0.1762066657	deep learning network
0.1758814298	three fold
0.1758116295	the other hand
0.1756536285	accurate estimation of
0.1755278087	on demand
0.1754130434	interpreted as
0.1754050044	classified into
0.1753812997	a new
0.1753456250	achieved state of
0.1753120470	benefiting from
0.1753067929	top 1
0.1750542587	a machine learning based
0.1748964462	proposed to detect
0.1748637822	distances between
0.1747768297	generation method
0.1747608402	specifically designed for
0.1746877713	to take advantage
0.1746160924	proposed strategy
0.1744224451	sensing data
0.1743782472	supported by
0.1743463285	existing state of
0.1743407069	visual results
0.1742639514	art performance on
0.1741811797	the art results
0.1741272266	relation between
0.1739722302	with respect to
0.1736810312	an ensemble
0.1736434929	main contribution of
0.1735819710	perform experiments
0.1735246014	3d u net
0.1735102324	resolution features
0.1734908462	at test time
0.1734006912	generative adversarial network for
0.1733725122	an intelligent
0.1731510431	ai system
0.1729980596	very important
0.1729336261	a modified u net
0.1729303110	enables high
0.1727904883	the proposed scheme
0.1727075335	standard methods
0.1726550235	amounts of data
0.1723077746	evaluated on
0.1722017575	small number of
0.1721850080	a key step
0.1721580761	an iterative
0.1720993892	impact on
0.1720490077	respect to
0.1719629514	the proposed method outperforms
0.1716932694	a priori
0.1715482291	using transfer learning
0.1715157463	low data
0.1713735067	essential role in
0.1713578473	rapid development of
0.1712335757	viewed as
0.1711765153	estimation approach
0.1711318322	high resolution 3d
0.1711240020	hundreds of
0.1708958188	3d video quality
0.1708326180	pairs of images
0.1707766036	metric based
0.1707126349	corresponds to
0.1706156175	connection between
0.1705690292	this limitation
0.1705668064	served as
0.1705548006	much less
0.1703379765	task network
0.1703328349	proposed to address
0.1703265150	an essential role in
0.1701626838	second stage
0.1700792587	advantage over
0.1700112306	an initial
0.1699259167	sub regions
0.1698142948	to avoid
0.1696732889	1 d
0.1696266767	methods provide
0.1696259947	freely available at
0.1694346045	a significant challenge
0.1693248428	camera system
0.1693190433	self learning
0.1692779356	this study demonstrates
0.1691888291	weighted mri
0.1691011486	a real world
0.1687132282	over smoothing
0.1686623810	equipped with
0.1686377073	recent developments in
0.1686221938	tumor patients
0.1686059778	results compared
0.1683981019	segmentation using deep learning
0.1683946883	\ url
0.1683870067	u net architectures
0.1683143173	millions of
0.1682515816	a promising technique
0.1682105735	with gradient penalty
0.1681784242	a fundamental problem
0.1681282263	high quality image
0.1680252747	accurate estimation
0.1679500953	a series of
0.1677748062	a survey
0.1676684936	diagnosis system
0.1676514304	for retinal vessel segmentation
0.1676470610	over union
0.1676007377	segmentation of multiple
0.1675450924	analysis methods
0.1674877634	data from multiple
0.1674469875	outperform state of
0.1674300268	robust against
0.1673333231	the proposed network
0.1673211233	propose to learn
0.1671347826	hindered by
0.1670062522	a multi stage
0.1669998542	along with
0.1669521617	sampled images
0.1667080289	existing ones
0.1666820984	\ &
0.1666079466	vision system
0.1665818495	multiple data
0.1664976875	a critical step
0.1664346043	both quantitatively and qualitatively
0.1664162097	the dice similarity coefficient
0.1664067085	based diagnosis
0.1663440124	based image processing
0.1663156888	prediction based
0.1662943938	to retrieve
0.1662831042	led to
0.1662404207	different sizes
0.1660713957	overlap between
0.1660266050	models trained on
0.1658329591	this regard
0.1657961969	based feature
0.1657808807	presented here
0.1651925357	a lightweight
0.1651621007	an order of magnitude
0.1651082896	accurate method
0.1651047693	most importantly
0.1649857889	deep network for
0.1649483490	a synthetic dataset
0.1649095503	to classify
0.1647629197	a semi supervised
0.1646575206	to generate realistic
0.1643359974	based on deep neural networks
0.1642970023	refer to
0.1641268519	early diagnosis of
0.1640169145	an adaptive
0.1640056709	differs from
0.1639546055	based pipeline
0.1638743535	accordance with
0.1637417755	for brain tumor segmentation
0.1636894842	an explicit
0.1634837573	covid 19 from chest
0.1633553645	prior work
0.1633517609	the past few
0.1633309012	a cnn based
0.1631949443	non expert
0.1630485874	very little
0.1628979772	by combining
0.1628954432	learning pipeline
0.1627467311	classification datasets
0.1627253931	3d convolutional neural network
0.1623086021	based technique
0.1622798975	multitude of
0.1622348673	significant role in
0.1621242018	fusion based
0.1618779755	paper shows
0.1618344488	experiments on real
0.1616710315	non contrast
0.1616383288	to enhance
0.1614109992	publicly available at
0.1612811520	extract features from
0.1612187361	architecture based
0.1610687261	image samples
0.1610129198	neural networks trained
0.1609897096	positive rate of
0.1609805545	generated by
0.1608792031	obtained from
0.1607438933	distinguish between
0.1607110747	mainly focus on
0.1606993905	stage approach
0.1605014466	the first stage
0.1604354200	time points
0.1604270367	the same time
0.1602892709	segmentation method based on
0.1602806704	an online
0.1602383844	learning based image
0.1601828375	computer vision techniques
0.1601195372	each year
0.1600770962	three kinds
0.1598780867	on imagenet
0.1598685891	images for training
0.1597585132	acquisition time
0.1596521170	tens of
0.1595466643	methods suffer
0.1594557933	the help of
0.1593055244	identification of covid 19
0.1591351805	emphasis on
0.1591309018	automated detection of
0.1589312367	a novel deep learning based
0.1586258382	contrast imaging
0.1585219712	based sr
0.1585159786	deep learning based method for
0.1584088111	correlations between
0.1583701672	method works
0.1582677297	$ z
0.1582304668	a dual
0.1581514300	based architecture
0.1580763531	unsupervised method
0.1580576800	a generative model
0.1579268279	non invasive imaging
0.1579067566	proposed module
0.1577428837	to identify
0.1577250314	cancer classification
0.1576433199	imaging approach
0.1575882515	over fitting
0.1574636598	applicable to
0.1572899141	compatible with
0.1570914162	imaging method
0.1570240584	segmentation dataset
0.1569457832	conventional 2d
0.1568483362	use cases
0.1568154476	consists of three
0.1567640285	algorithm based on
0.1566535971	deep learning for medical
0.1566520054	art performance
0.1565395754	success in image
0.1565309842	free images
0.1565244017	propose to use
0.1564762698	in house
0.1563973770	a generalized
0.1562771940	relations between
0.1562042388	cardiac image
0.1561006474	generating high
0.1560746245	art networks
0.1559674887	every pixel
0.1559528606	distance between
0.1557959136	the receiver operating characteristic
0.1557014856	retrieval algorithm
0.1556600950	approach based
0.1554295692	based camera
0.1553345581	on top of
0.1552976071	a single gpu
0.1552579904	good agreement with
0.1552089235	proposed models
0.1551009319	made publicly
0.1549361825	great success in
0.1548782287	almost all
0.1548750426	made available
0.1548549047	the same
0.1545912730	a wide range of applications
0.1544008277	the art techniques
0.1543363743	image registration using
0.1542623956	network achieves
0.1541841725	method based on
0.1541836459	end to end framework
0.1539939997	image super
0.1539928837	to reconstruct
0.1539689932	deep learning method for
0.1538552421	in vivo data
0.1538391002	to assist
0.1536045149	the ground truth
0.1535480367	visual system
0.1535250154	feature extraction and
0.1534493957	resolution optical
0.1534364762	data shows
0.1534054302	contribute to
0.1532912971	supervised method
0.1530836741	provided by
0.1529495134	learning architectures
0.1529215512	achieving state of
0.1528909636	the left ventricular
0.1526606341	model for image
0.1526543113	a wide range
0.1524712170	to train
0.1524620001	an important role in
0.1523512025	by minimizing
0.1523328399	need for manual
0.1523043067	small training
0.1522516275	the past few years
0.1518872745	much lower
0.1518422568	network models
0.1516646225	unsuitable for
0.1516462412	to mitigate
0.1516126203	very difficult
0.1515948915	imaging model
0.1515810482	often suffers
0.1515279607	50 \
0.1514750167	apart from
0.1513887469	learning based framework for
0.1513502143	the proposed
0.1513263106	experiments on
0.1512536716	through extensive experiments
0.1512206534	difficult to
0.1510957123	improvements over
0.1510848317	data size
0.1509844424	a general framework
0.1509686919	trained neural
0.1508492965	a multi scale
0.1507911978	a small number
0.1505567016	indistinguishable from
0.1505134601	a systematic
0.1504712170	to achieve
0.1502662437	large scale 3d
0.1501843212	learning solutions
0.1499224205	an active
0.1497702011	by means of
0.1497691155	compete with
0.1496316699	automated deep learning
0.1494437119	attributed to
0.1494340104	comprised of
0.1494330172	a preliminary
0.1494314980	u net model
0.1492087517	method to improve
0.1491109434	optical system
0.1490366041	consists of two
0.1489085538	deep neural network for
0.1486545145	an independent test
0.1485271794	automated approach
0.1484543740	small amount of
0.1484057507	by proposing
0.1480731602	thousands of
0.1480548876	deep learning architecture for
0.1480236569	neural network approach
0.1478787143	model trained on
0.1478737711	proposed multi
0.1475660963	method to extract
0.1470908634	most likely
0.1470005187	amounts of
0.1469610843	a variety of
0.1468306682	this work proposes
0.1467158628	the art algorithms
0.1466085834	layer segmentation
0.1464442757	covid 19 classification
0.1464315460	brain image
0.1462180534	automatic classification of
0.1461719817	multi image
0.1460649828	two main
0.1460526904	conjunction with
0.1459132669	exposure images
0.1458440268	as opposed to
0.1457397438	contrast to noise
0.1457140397	an automatic
0.1456810049	the first time
0.1456049984	a single rgb
0.1455128353	resulted in
0.1454109470	deep learning methods for
0.1453072382	a wide range of
0.1450749897	unsupervised image
0.1449260118	information contained in
0.1449033723	images collected
0.1448753513	in mind
0.1448030830	major challenge for
0.1447964787	using deep convolutional
0.1447329046	help improve
0.1446896384	against adversarial
0.1443772963	plenty of
0.1442028702	method achieves state of
0.1440836249	deep learning framework for
0.1440302643	set of
0.1438213805	information provided by
0.1438076619	made possible
0.1438022963	derivation of
0.1437253088	an internal
0.1436186750	the forward operator
0.1435205951	combined with
0.1434380904	well suited for
0.1431353974	widely available
0.1428702276	for medical image segmentation
0.1426679433	an f1 score
0.1425908650	dependencies between
0.1424690362	contributes to
0.1424637418	while avoiding
0.1423103954	large amount of training
0.1423040269	used to
0.1422027129	dice score of
0.1421701793	significant improvement in
0.1420684422	the original image
0.1420636525	resolved images
0.1420509175	an effective
0.1419975019	compared to other methods
0.1419513761	\ ~
0.1417187343	on par with
0.1417159471	a review
0.1415657480	a deep convolutional neural
0.1415527391	at different scales
0.1413864589	statistical analysis of
0.1413566459	detection method based on
0.1412969965	performance compared to
0.1411807719	to tackle
0.1410677804	very high
0.1410183466	classification method
0.1409567242	to perform
0.1409041204	images using deep learning
0.1408878714	the last few years
0.1408484724	an ill posed problem
0.1408419265	from natural images
0.1407200090	nature of
0.1406828919	by adding
0.1406446295	images acquired by
0.1406286008	accurate detection of
0.1406219668	to automatically segment
0.1405213683	architecture for image
0.1404689763	methods rely on
0.1404571489	a pre trained
0.1403746876	making use of
0.1402760710	approach based on
0.1401491019	extended to other
0.1400888775	deep learning based method
0.1400877497	key role in
0.1400588401	methods based on
0.1400256297	differential diagnosis of
0.1400064015	real time detection
0.1399946307	specific data
0.1399763655	an essential
0.1399456667	network to predict
0.1398948286	time domain
0.1397804804	a fully automatic
0.1397662695	dice scores of
0.1397206415	quantitative analysis of
0.1396109653	in particular
0.1395337299	automatic diagnosis of
0.1394867619	trained end
0.1393961620	model based on
0.1393622158	comparison with state of
0.1393226066	sub network
0.1392700451	much attention
0.1391967806	long time
0.1391250329	a single image
0.1391109653	associated with
0.1390682575	dice coefficient of
0.1389315195	further investigation
0.1387054962	the most common
0.1386668330	the input image
0.1386194640	under sampling
0.1386071010	challenging because
0.1385659211	scale image
0.1383874935	a single shot
0.1383662276	to fully exploit
0.1383136382	two classes
0.1382777665	with high accuracy
0.1382312556	the left ventricle
0.1382277754	to recover
0.1380615885	better understand
0.1380121882	the proposed method performs
0.1379571365	better performance
0.1379362534	adversarial attacks on
0.1377430362	time series data
0.1376655827	the art deep
0.1375866462	framework based on
0.1375818056	$ n
0.1375731716	the key idea
0.1375722592	resolution techniques
0.1373974718	comprehensive evaluation of
0.1373160821	mean intersection
0.1372811135	more robust
0.1372101991	more complex
0.1370581157	deep neural networks for
0.1370361280	by applying
0.1367124802	neural networks for
0.1367020168	segmentation using deep
0.1364537418	more sophisticated
0.1364207096	significantly better
0.1363666022	does not rely on
0.1360407854	$ t
0.1360047224	an adversarial
0.1359559726	to fine tune
0.1357767192	the use of
0.1356734264	dynamic range of
0.1356624148	belongs to
0.1356441178	images generated by
0.1356358846	thus allowing
0.1355810724	to noise ratios
0.1355751833	360 \
0.1355172382	different types of
0.1354135754	different domains
0.1352245035	deformable image
0.1351899107	learning systems
0.1351556715	to further reduce
0.1351335087	trained convolutional
0.1351069577	able to achieve
0.1350260368	a very challenging task
0.1349266226	feature maps from
0.1347772581	the current state
0.1346443257	more likely
0.1346405679	multiple types of
0.1344846328	present paper
0.1343242969	2019 challenge
0.1342452949	deep learning techniques for
0.1342442837	to alleviate
0.1338581149	image reconstruction using
0.1338295983	real time 3d
0.1337608156	to generate high quality
0.1337190107	released at
0.1336628682	automatic analysis
0.1336224600	a lot of
0.1335268991	very deep
0.1334731100	automatic analysis of
0.1331685701	this purpose
0.1331065815	quantitative assessment of
0.1330925295	the art models
0.1328372670	the proposed technique
0.1327818614	test set of
0.1327675248	resonance image
0.1325747357	trained on large
0.1324486371	a high speed
0.1323655848	the latent space
0.1319396018	perform better than
0.1319209597	data demonstrate
0.1319209210	method for automatic
0.1318818319	then processed
0.1317528190	an integrated
0.1317480543	perform well
0.1314736702	based image compression
0.1314609596	a vital role
0.1314586446	a high resolution image
0.1313793108	a low dimensional
0.1312077235	clinical imaging
0.1311544784	with skip connections
0.1311090463	to remove
0.1310844814	prior knowledge of
0.1310660619	an improved
0.1309567242	to estimate
0.1309154088	embedded into
0.1308680253	an image
0.1308343528	classification of covid 19
0.1307776319	instead of
0.1307695396	last few
0.1307689611	little attention
0.1306730290	images captured by
0.1305321232	to create
0.1304540784	fine tuning of
0.1304061747	learning architecture
0.1303536434	intend to
0.1302440010	amount of
0.1301171281	a promising approach
0.1298243404	outperform other
0.1296540869	good quality
0.1295628249	more accurately
0.1294550425	the point spread function
0.1294191817	new loss function
0.1290483055	the proposed approach achieves
0.1289506688	continue to
0.1287585419	adaptation method
0.1286058008	represented as
0.1285156493	coming from
0.1283477818	confined to
0.1283366330	a two stream
0.1283325307	attention network for
0.1282486954	variety of
0.1281359542	an approximate
0.1281098167	art deep learning
0.1280518214	decoder structure
0.1279319270	$ k
0.1279130886	field of computer vision
0.1277885296	a deep neural
0.1277631825	convolutional neural network for
0.1276148099	learning classifiers
0.1274377530	3d medical image segmentation
0.1274327388	an automated
0.1272610725	modified u
0.1268816583	an ill posed
0.1268433345	scan images
0.1268046985	to optimize
0.1267534159	diverse set of
0.1267249286	imposed by
0.1266560462	semantic segmentation of
0.1265074224	inverse problems in
0.1264905620	on mobile devices
0.1264410379	and pre trained models
0.1263040269	used as
0.1261740136	recently deep
0.1261713835	scheme based on
0.1261394485	continues to
0.1261376716	the purpose of
0.1260858215	based x ray
0.1260735015	potential of deep
0.1260027173	a challenging problem
0.1259807784	research topic in
0.1259731862	further boost
0.1258763282	3d convolutional neural networks
0.1258130334	$ ^ \
0.1257583401	looking at
0.1256935123	the proposed model outperforms
0.1256824545	related to
0.1256680229	well designed
0.1256667266	a data driven approach
0.1256303482	replaced by
0.1255837791	based segmentation
0.1255611698	acquired during
0.1254916248	the art method
0.1254476435	standard deviation of
0.1254095345	more specifically
0.1253976995	order to address
0.1253576522	a high resolution
0.1253278301	concerned with
0.1252217093	also known as
0.1252000846	a novel technique
0.1251934625	often require
0.1251375420	= 1
0.1251270746	suitable for
0.1250457649	deep learning models for
0.1249530857	the art accuracy
0.1247844715	all optical
0.1246433687	a brief
0.1244315240	learning framework for
0.1243344001	network trained with
0.1243180938	evaluated against
0.1243019032	a low cost
0.1242968679	vital role in
0.1240595669	specifically designed to
0.1240351053	the entire
0.1240076211	learning based models
0.1239657257	on chest radiographs
0.1239591005	network based methods
0.1239556698	and error prone
0.1238884903	by leveraging
0.1238055448	the proposed methodology
0.1237822421	the diffraction limit
0.1235572382	in contrast to
0.1235502964	each frame
0.1235321232	to handle
0.1234374835	a python
0.1233816605	local network
0.1233669161	more efficient
0.1233597576	the target domain
0.1231261000	an area under
0.1229051969	a conditional generative adversarial network
0.1228011171	complex image
0.1227533787	imaging domain
0.1227072942	image segmentation using
0.1226616699	large volumes
0.1226519580	more reliable
0.1226329591	to super resolve
0.1226199854	devoted to
0.1225884618	generalization ability of
0.1225879367	these methods
0.1225409542	great potential in
0.1224949537	using chest x ray
0.1224652544	works well
0.1224288168	\ beta
0.1223951021	first attempt
0.1223704699	deep learning based model
0.1223605966	different scales
0.1223018079	$ mm
0.1222722532	version of
0.1221309792	many real world
0.1220589622	improvement compared to
0.1220262413	the arts
0.1219433859	the performance of
0.1219194406	refer to as
0.1218966795	to get
0.1218470633	model trained with
0.1218011171	specific image
0.1217860432	made publicly available
0.1215961176	more stable
0.1215684480	to acquire
0.1215315726	by fine tuning
0.1215067398	a novel loss function
0.1213425030	used to generate
0.1213184480	to understand
0.1213121420	the proposed approach outperforms
0.1213044835	inferred from
0.1211916372	connections between
0.1211901293	10 fold
0.1210720667	based architectures
0.1209569676	based on convolutional neural network
0.1207404387	non gaussian
0.1207189396	from chest x ray images
0.1206175994	to enable
0.1205453854	in resource limited
0.1203593138	a fully convolutional neural
0.1203276442	a hybrid
0.1202637012	challenging due to
0.1201195408	a data driven
0.1200713604	aims to
0.1198332038	the original
0.1197512169	notion of
0.1197237718	advantage of
0.1195841498	modeled as
0.1195765377	those obtained
0.1194939758	results obtained by
0.1193201371	over time
0.1193140280	to assess
0.1193023561	accuracy compared
0.1192884710	dataset contains
0.1192794228	multiple image
0.1192025834	more flexible
0.1191644842	by incorporating
0.1190956544	architecture consists of
0.1190588316	field data
0.1189694621	model to predict
0.1188803304	increasingly used
0.1188447267	contrast images
0.1188022198	in many cases
0.1187422941	an advanced
0.1186118211	different resolutions
0.1185267668	the receiver operating
0.1185187292	to diagnose
0.1184971812	a portable
0.1184936471	real ones
0.1184509327	to segment
0.1184433693	a single model
0.1184318267	a recurrent neural network
0.1184257006	contrary to
0.1183564551	outperforms other
0.1181950976	the proposed methods
0.1180755199	more precise
0.1178597080	each class
0.1178396428	2020 challenge
0.1178003700	in conjunction with
0.1176296231	$ p
0.1174038855	simple yet
0.1173273728	while achieving
0.1172419455	to do so
0.1171571582	field images
0.1171119961	and healthy controls
0.1170640866	a light weight
0.1167621555	end to end network
0.1166162710	classified as
0.1165791202	the proposed pipeline
0.1165341966	deep learning approaches for
0.1164898196	perform well on
0.1164348993	interested in
0.1164117192	used for
0.1163952898	full use of
0.1163286586	no additional
0.1162428541	quality assessment of
0.1162419647	a linear combination
0.1162129532	operates on
0.1161387269	although deep learning
0.1161288152	vulnerable to
0.1160682861	to realize
0.1159434689	collected from
0.1158075265	a powerful tool
0.1157110065	interact with
0.1156931736	useful information
0.1155960892	re training
0.1155071732	encoded into
0.1154251381	learning based approach for
0.1154166698	1 mm
0.1154017617	solved by
0.1153584766	non iterative
0.1153106386	an application
0.1152108929	network to perform
0.1151094446	acquired at
0.1150971205	very effective
0.1150741709	the main idea
0.1149668002	technique based on
0.1149442373	cell detection and
0.1148793069	image de
0.1148575145	par with
0.1146002481	performs better
0.1145458040	for hyperspectral image classification
0.1144214670	this paper shows
0.1142701075	attached to
0.1142688234	cause of cancer
0.1142397198	both simulated and real
0.1142227569	significant improvements in
0.1141783366	multiple types
0.1141273613	to facilitate
0.1141242832	two consecutive
0.1141073949	a closed form
0.1140576309	future work
0.1140199694	made great
0.1140179959	an early
0.1139587096	an inverse problem
0.1139539810	an improvement
0.1139111658	at last
0.1138850546	1 2
0.1138505578	re trained
0.1138137135	a proxy
0.1137757955	quantitative evaluation of
0.1137478710	using deep convolutional neural
0.1136512115	the source domain
0.1135697252	a conditional generative
0.1135503700	an auc of
0.1134509327	to produce
0.1134206477	comes at
0.1133134820	induced by
0.1131664458	the last decade
0.1131068620	frames per
0.1131037767	and structural similarity index
0.1129426626	to accurately segment
0.1129142162	two types of
0.1129059907	builds on
0.1127980796	with ground truth
0.1127779046	present experimental
0.1127731571	a low rank
0.1126788476	deep learning model for
0.1125958068	stereo image
0.1125552743	role in
0.1125160086	comparative study of
0.1124782344	images acquired from
0.1124509327	to capture
0.1124377069	using chest
0.1124371622	the proposed solution
0.1124078464	small amount
0.1123617672	based approach for
0.1122130821	a single frame
0.1121874274	the most popular
0.1121814026	level image
0.1119701174	lies in
0.1118917348	phase only
0.1117960414	to automatically detect
0.1116791574	2 3
0.1116539713	linked to
0.1116151001	the proposed architecture
0.1115513501	based method for
0.1114767039	each category
0.1114682389	to guide
0.1114657027	a single camera
0.1113000588	less than 1
0.1112778102	a loss function
0.1112556494	the training process
0.1112046142	covid 19 cases from
0.1111099046	consisted of
0.1110187914	based on deep neural
0.1110051204	by employing
0.1108906073	absence of
0.1108900200	this task
0.1108742772	important part of
0.1105664778	benign or
0.1105537539	on board
0.1104685400	as much as
0.1104464310	terms of accuracy
0.1101987452	avenues for
0.1101273613	to determine
0.1101039633	at different resolutions
0.1100996435	often suffer
0.1100984948	x ray phase
0.1100870017	a low resolution
0.1100765696	3d shapes
0.1100048854	a variational autoencoder
0.1099659445	image diagnosis
0.1098775707	registration based
0.1098405853	deep learning approach for
0.1097942537	images collected from
0.1097768119	a deep learning system
0.1097651515	for lung nodule
0.1096934484	able to generate
0.1096889364	similarity between
0.1096418484	on github
0.1096264187	anomaly detection in
0.1096197849	these problems
0.1095834868	computational time
0.1095525966	analysis based
0.1094851589	in practice
0.1092049512	the experimental results demonstrate
0.1092000440	considered as
0.1089001003	driven methods
0.1088980951	2d slices
0.1088295673	images from low
0.1088069303	vision techniques
0.1087493602	a neural network model
0.1087255751	a single forward
0.1086810602	comparable performance to
0.1086678914	in combination with
0.1086455350	on real data
0.1085318874	learning based methods for
0.1085183503	3d cnns
0.1085101339	a deep learning based method
0.1084771157	best knowledge
0.1084577422	the art sr
0.1083866198	validated on
0.1082431693	diagnosis using
0.1082061904	calls for
0.1081947360	images demonstrate
0.1081933583	a v
0.1081067454	do so
0.1079683573	amenable to
0.1078922748	more compact
0.1077639073	truth data
0.1077226604	while requiring
0.1076713361	three kinds of
0.1075841037	sensing image
0.1075309596	a large
0.1074214089	deep brain
0.1073424662	residual network for
0.1073287338	usually require
0.1071864399	these challenges
0.1071283935	becoming more
0.1070480652	scale datasets
0.1070264826	starts with
0.1070091926	operate on
0.1069907054	the training data
0.1068409622	as possible
0.1068183859	the problem of
0.1068048618	advancements in
0.1067703795	a preprocessing step
0.1067079999	to enforce
0.1065608091	sub tasks
0.1065060523	suited for
0.1064679325	information regarding
0.1064213534	1 3
0.1063977046	a crucial step
0.1063415934	network consists
0.1063318791	a small set of
0.1063123017	networks trained on
0.1062606365	single 2d
0.1062178872	proposed method uses
0.1061416436	approaches based
0.1060654856	by conducting
0.1059449578	thus reducing
0.1059352004	mode images
0.1058471684	to circumvent
0.1056525925	do not require
0.1053995440	standard 3d
0.1050521002	the source code
0.1050065912	a neural network
0.1050010867	together with
0.1049814261	not clear
0.1049745770	bag of
0.1049154867	in medical image analysis
0.1048407027	the proposed strategy
0.1048221536	task learning
0.1048038929	also discussed
0.1047699318	comparable to
0.1047509277	a wide variety of
0.1046909087	visual inspection of
0.1046400224	network to generate
0.1046036880	2d slice
0.1046002919	on cifar 10
0.1044546528	\ sim
0.1042144872	image super resolution with
0.1040954429	performance on
0.1040754059	learning approach to
0.1039561949	based model for
0.1038992166	intensity only
0.1038732137	deep learning models in
0.1038183859	the effectiveness of
0.1037760732	to differentiate
0.1037462119	automated analysis of
0.1036757550	well suited to
0.1034230211	by comparing
0.1033379465	drawn from
0.1033067100	most existing
0.1031969812	ct scans of
0.1031548541	3d semantic segmentation
0.1030894004	aim at
0.1029819023	two decades
0.1028180150	consistency between
0.1028048618	portion of
0.1027782977	more powerful
0.1025403984	tasks like
0.1022887102	the discrete cosine
0.1021082425	a source domain
0.1020933684	in clinical practice
0.1020303611	more complicated
0.1019578467	recent success of
0.1019254289	to maximize
0.1017521724	learning based model
0.1017243188	information from
0.1016759414	a multi
0.1014832562	efficient way
0.1014625544	the potential to improve
0.1014060920	accurate diagnosis of
0.1012789723	any additional
0.1012687604	manual segmentation of
0.1012406484	in turn
0.1012388930	to interpret
0.1011210192	by taking
0.1011176095	based framework for
0.1011064058	for future research
0.1009907906	to further improve
0.1009753654	other tasks
0.1009564171	a small fraction
0.1008488315	method to detect
0.1007834408	order to improve
0.1006832986	model to generate
0.1006790144	to eliminate
0.1006320018	up to 10
0.1006128638	addressed by
0.1005553174	each component
0.1004603057	remarkable performance in
0.1004468238	attempt to
0.1002736481	images using deep
0.1001309019	taking into
0.1001255806	to synthesize
0.1001068622	a single pixel
0.1000843427	to pre train
0.1000595810	based quality
0.1000242382	experimented with
0.0999982525	verified by
0.0999559247	the art performance on
0.0998865734	reconstruction based
0.0997582607	based on u net
0.0997496859	image reconstruction from
0.0997153270	quality metric for
0.0996676543	^ \
0.0996367110	a survey on
0.0996090770	receptive field of
0.0995999115	modeled by
0.0995839739	images from
0.0995156713	a crucial role in
0.0995149553	contrast ct
0.0993861071	proposed method provides
0.0993741995	a human expert
0.0993646499	three main
0.0993535376	many researchers
0.0992112697	more discriminative
0.0991497365	method relies on
0.0990814639	ct scans from
0.0990780742	learn from
0.0990341101	achieve better
0.0987876735	the fly
0.0987729522	large set of
0.0985450725	mainly focus
0.0984665451	each voxel
0.0983055675	a large amount of
0.0982804062	achieve good
0.0982354983	segmentation performance on
0.0982101271	the acdc
0.0980818945	$ net
0.0978396878	by exploiting
0.0977029502	dependence on
0.0976788978	a key role in
0.0976674977	framework consists of
0.0976082854	learning approach for
0.0976007341	classification accuracy of
0.0975941396	performance compared with
0.0974599918	number of images
0.0974399129	method for multi
0.0973627075	models trained with
0.0972743161	potential to improve
0.0972355966	an auxiliary
0.0972095504	various kinds of
0.0971692218	paper focuses on
0.0970795718	very similar
0.0970410314	two orders of magnitude
0.0969130488	learning technologies
0.0968984680	recognition using
0.0968183859	a set of
0.0967767192	a large number of
0.0967704708	assigned to
0.0967647743	while reducing
0.0967619416	compared to state of
0.0966887154	this paper aims
0.0966500466	method consists of
0.0965835949	computational complexity of
0.0965660754	two branches
0.0964459925	an important task
0.0964305321	the training set
0.0962900816	more sensitive
0.0962113078	utilization of
0.0961066633	major challenge in
0.0960800762	particle imaging
0.0960566065	network for 3d
0.0960099605	to evaluate
0.0959916419	quality of images
0.0959800186	trained and tested on
0.0959482558	based denoising
0.0958655928	not feasible
0.0958418229	performance analysis of
0.0957659140	dataset consists of
0.0957352836	contributing to
0.0956941478	used to determine
0.0956861432	applications such as
0.0956612633	no need
0.0956581281	an integral part of
0.0956523590	$ ^
0.0955780572	do not take
0.0955461576	2d cnn
0.0955243317	on three public
0.0954014922	paid to
0.0953826961	a parallel
0.0953104028	single network
0.0952634193	the research community
0.0952328322	different categories
0.0952058988	segmentation based on
0.0951099759	an analysis
0.0950639312	different kinds of
0.0950461474	adapted to
0.0950232798	standard image
0.0948870785	for example
0.0948766638	look at
0.0947574418	single low
0.0946514121	2020 challenge on
0.0946118801	an accuracy of
0.0945454027	few years
0.0945240027	requiring only
0.0944546492	two separate
0.0943713842	spatial distribution of
0.0943587372	the test set
0.0943533373	ground truth for
0.0943387021	an f1 score of
0.0943361474	proven to
0.0943027748	in clinical settings
0.0942801586	not sufficient
0.0941049750	the most widely used
0.0941033357	transfer learning from
0.0939341436	network framework
0.0938843687	fail to
0.0938371888	very promising
0.0937077289	s \
0.0936941950	combination of
0.0936113556	achieves good
0.0935275737	performance of
0.0935041112	from rgb images
0.0934743177	convolutional neural networks for
0.0934714799	the training phase
0.0934613339	crucial for
0.0934485654	by replacing
0.0934276358	to accelerate
0.0933649850	3d cnn
0.0932368274	promising results on
0.0932317100	more effective
0.0931803029	superior performance of
0.0931604092	also discuss
0.0931250823	the state of
0.0930796359	a novel way
0.0930671034	this approach
0.0930248093	change detection in
0.0928981944	the optic disc
0.0928658824	a novel end to end
0.0928199762	proportion of
0.0928033361	of rain streaks
0.0927744989	then apply
0.0927606805	work addresses
0.0927336710	benefits from
0.0926508428	lots of
0.0924994057	replaced with
0.0924446182	up to
0.0923805479	based on convolutional
0.0922555773	the test dataset
0.0922235835	current work
0.0921953729	the gold standard
0.0921117087	an effective way
0.0919064010	promising results in
0.0918773517	well trained
0.0918440797	to minimize
0.0917400198	a significant improvement
0.0917392952	the feature maps
0.0915991420	\ text
0.0915730211	by utilizing
0.0915252783	dataset containing
0.0914682393	accuracy compared to
0.0914620402	evaluation of
0.0914523903	an imaging technique
0.0914318545	an in house
0.0914113952	well annotated
0.0913461658	the expense of
0.0911697372	the task of
0.0911459277	the need for
0.0910787969	the target image
0.0909873270	the art convolutional neural
0.0909787366	chest x
0.0909688712	two stages
0.0909474450	tool for
0.0908932007	classification based on
0.0908774872	deep learning methods in
0.0908696004	effective way
0.0907935598	mean dice
0.0907808616	challenging due
0.0907536147	the validity of
0.0906739645	directly from
0.0905971809	the input images
0.0904950460	effectiveness of
0.0904360382	trying to
0.0904109233	the reconstructed image
0.0902690967	a conditional generative adversarial
0.0902225913	other state of
0.0901793349	extensive experiments on three
0.0901560384	much better
0.0901494087	particularly challenging
0.0901359224	these limitations
0.0901071306	both quantitative and qualitative
0.0899354273	set of images
0.0898914089	to build
0.0898779857	a critical role
0.0898586597	a small fraction of
0.0898195935	two stage deep
0.0898169696	to simulate
0.0897422250	method in terms
0.0897212005	becomes more
0.0897142187	some cases
0.0896714453	neural network architecture for
0.0896678540	learning system
0.0895907791	to infer
0.0895688236	by adopting
0.0894591804	images via
0.0894475118	realization of
0.0893089908	rgb +
0.0892501472	images obtained from
0.0891567653	to converge
0.0891380981	able to reconstruct
0.0891023984	at https
0.0890885758	landmark detection in
0.0890463953	no reference image
0.0890282041	this goal
0.0890123477	to resolve
0.0890073317	and treatment planning
0.0889647189	an end to end deep
0.0889016840	very limited
0.0888983767	further improve
0.0888593342	work proposes
0.0888324789	quality of
0.0887293473	each modality
0.0886894696	automatic method for
0.0886188663	based algorithm for
0.0885586432	cnn architecture for
0.0885061266	implementation of
0.0884954098	stage framework
0.0883207576	various types of
0.0883039611	loss functions for
0.0882862835	foundation for
0.0882503958	from chest x rays
0.0882023435	mean error
0.0881997182	data generated by
0.0881846504	a novel deep
0.0880716333	trained with
0.0880628063	this topic
0.0879900323	most commonly
0.0878930039	different scanners
0.0878026655	compression system
0.0878014745	relatively low
0.0877816857	on two benchmark
0.0876717662	classification system
0.0876557817	better image quality
0.0876125944	the quality of
0.0873125944	the context of
0.0872484532	incorporation of
0.0872140999	images obtained by
0.0871444662	the extracted features
0.0871052799	resolution imaging
0.0870721625	not robust
0.0869788429	takes into
0.0869216592	often requires
0.0868620265	the domain gap
0.0868094964	two ways
0.0867411581	large amount of
0.0867032845	problem in computer
0.0866100885	this phenomenon
0.0865900552	the experimental results
0.0865393290	a small number of
0.0865150349	new insights
0.0865098299	a crucial role
0.0865004362	each other
0.0863734422	this survey
0.0863681017	prerequisite for
0.0863325253	deep learning for
0.0863221391	a point cloud
0.0861827942	by modifying
0.0859797900	breakthroughs in
0.0859484247	to deal with
0.0858527795	p \
0.0857638165	using generative
0.0857111054	source domain to
0.0856288159	segmentation of
0.0856266860	achieving better
0.0855632340	the fused image
0.0855365260	for single image super resolution
0.0855155858	learning model for
0.0854396570	by augmenting
0.0853170358	the art results on
0.0852536153	features from
0.0852473598	2d 3d
0.0852010859	often suffers from
0.0850699399	art results for
0.0849701966	more challenging
0.0849389914	proposed algorithms
0.0849234701	very small
0.0847887645	the second stage
0.0847348800	second step
0.0845904362	final image
0.0845148415	very challenging task
0.0843994129	very large
0.0843946547	a thorough
0.0843560285	yet effective
0.0842736802	to extract features
0.0841215302	fed to
0.0839656937	a reference image
0.0839434098	to protect
0.0838349205	better generalization
0.0838114545	able to produce
0.0837804051	in order to reduce
0.0837599425	able to obtain
0.0837127180	these findings
0.0836532704	constructed by
0.0836435419	an image based
0.0835700082	many works
0.0835511537	compared with state of
0.0835250013	the frequency domain
0.0833224953	the obtained results
0.0833125944	the effect of
0.0833061116	series data
0.0830353233	two kinds of
0.0830123477	to promote
0.0829851506	a model trained
0.0829735796	various fields
0.0829585071	need to
0.0829449771	the medical field
0.0828508009	confirmed by
0.0827912779	applications like
0.0827694213	the domain shift
0.0827626657	cells from
0.0827506385	a total of
0.0826546797	a proof of concept
0.0826525361	different modalities
0.0825920991	representation learning for
0.0825206000	easy to
0.0824136647	3d ct images
0.0823634709	a coarse to fine
0.0823501444	to accurately detect
0.0823269680	the world health
0.0823221481	the most important
0.0823138314	performs well on
0.0822992002	arise from
0.0822923908	the training procedure
0.0822160800	a large dataset
0.0820294437	super resolution with
0.0819944504	performed at
0.0819690866	currently available
0.0819578272	the first work
0.0819502198	2d u net
0.0819140769	a deep learning method
0.0818839269	kind of
0.0817131969	exploitation of
0.0816171509	truth images
0.0815467646	accuracy of
0.0814989139	to fuse
0.0814483334	model consists of
0.0813949657	sensitive to
0.0813222913	an image reconstruction
0.0813186667	results on real
0.0812873160	widely used for
0.0812368633	compared with other
0.0810901391	to provide
0.0810842233	an additional
0.0810574156	pixels into
0.0810275737	analysis of
0.0810111085	based approach to
0.0809805419	learning based method for
0.0809261844	performance in terms of
0.0808043112	to supervise
0.0806686932	or even better
0.0805750479	able to learn
0.0804411340	by simulating
0.0802811968	method for
0.0801878519	without increasing
0.0801769555	learning method for
0.0800664304	and semi supervised learning
0.0800404445	performance of deep
0.0799907106	high spatial and
0.0799749662	corresponding ground
0.0799471901	this work presents
0.0799241383	tensor imaging
0.0799237199	diagnosis from
0.0798912874	high signal
0.0798776365	paper aims to
0.0797767180	latent space of
0.0797412677	a great potential
0.0797126126	deployed on
0.0796801878	an important problem
0.0796015857	an end to end deep learning
0.0795833966	novel algorithm
0.0795822524	to combat
0.0793811037	termed as
0.0793734956	used to assess
0.0792859249	the covid 19 pandemic
0.0792816781	outperforms several
0.0792469364	to detect covid 19
0.0792196412	for few shot
0.0792083220	combinations of
0.0792039899	the low frequency
0.0791843541	a multi modal
0.0791820659	reconstruction using
0.0790729508	possible future
0.0790403374	results compared to
0.0790335295	x ray computed
0.0790098706	estimated by
0.0789991623	to quantify
0.0788972274	two layer
0.0788953772	to develop
0.0787922475	various domains
0.0787761053	compared to other
0.0787677793	3d unet
0.0787124517	inverse problems with
0.0786819130	three popular
0.0786658133	enabled by
0.0786491469	successfully used
0.0786338229	this reason
0.0785994033	a multi layer
0.0784973082	not yet
0.0784970850	method based on deep
0.0784960950	the human brain
0.0784673959	this gap
0.0783840917	a comparative
0.0783645824	a broad range of
0.0783556410	an experienced
0.0782803029	generative model for
0.0781880976	super resolution for
0.0781517975	recognition system
0.0781503297	based on deep convolutional
0.0781291314	converted to
0.0781119023	the noise distribution
0.0779505768	the trained network
0.0778514155	control over
0.0778324667	imaging via
0.0777675799	the white matter
0.0777648567	more difficult
0.0777347001	by fusing
0.0777222550	performed by
0.0776588598	two distinct
0.0775944242	mapping between
0.0774587658	challenging task of
0.0773661049	to refine
0.0773398302	presence of
0.0772339549	the low rank
0.0771952201	the generated images
0.0771115922	on synthetic data
0.0770903706	the generated image
0.0770163145	the main
0.0770115793	network approach
0.0770087696	across different
0.0767910960	a large range
0.0767737110	by enforcing
0.0766571242	significantly more
0.0766081222	suitability of
0.0765609862	the search space
0.0764762853	very fast
0.0764174986	widely used in
0.0763450396	an attention
0.0763272646	data set of
0.0763195158	non covid 19
0.0762964628	3d shape
0.0762394611	majority of
0.0762172603	compensate for
0.0761815666	a recently developed
0.0761119778	bounds on
0.0761102452	relatively high
0.0760735259	$ weighted
0.0760228623	based brain
0.0759926675	lesion segmentation from
0.0759366608	accurate 3d
0.0758591450	comparable or
0.0756843819	the human eye
0.0756838690	network learns to
0.0756632516	a two step
0.0756544738	much as possible
0.0756505815	the trained model
0.0755850279	rise to
0.0755762696	3d volume
0.0755396292	learning architecture for
0.0755368503	an example
0.0754798962	a public dataset
0.0754504187	able to detect
0.0753964969	availability of
0.0753740900	emergence of
0.0753107467	mapping using
0.0752128229	large amount
0.0751955950	an interesting
0.0750999029	more realistic
0.0750895316	during inference
0.0750894242	the deep learning model
0.0750870528	mainly due
0.0749792711	by providing
0.0748783364	knowledge into
0.0748392840	overview of
0.0747994199	by exploring
0.0747918180	a monocular
0.0747893336	used to estimate
0.0747876735	the aforementioned
0.0747622256	in conjunction
0.0747231850	slide image
0.0747141350	three class
0.0745969601	3d volumes
0.0745386437	the art methods in terms
0.0745216372	lack of
0.0744610764	the final
0.0742548916	created by
0.0742140390	image compression with
0.0741940809	the reconstruction error
0.0741851668	extract more
0.0741461588	significant amount of
0.0741261421	the classification performance
0.0740627852	the entire image
0.0740462022	a non convex
0.0740312367	distribution of
0.0740262273	of skin lesions
0.0740207681	measured by
0.0739634749	lot of
0.0738784862	amount of labeled
0.0737781051	the original images
0.0737632033	emerging as
0.0737185855	driven by
0.0737184137	terms of
0.0736940634	a fast
0.0736740512	a person's
0.0736284058	requires only
0.0735460776	sum of
0.0735352653	the forward model
0.0735283587	various scenarios
0.0734868923	this review
0.0734742758	conducted on
0.0733632353	size images
0.0733556435	number of training
0.0733350049	the target object
0.0733281375	helpful for
0.0732046043	adaptation methods
0.0730057142	learn more
0.0729847670	captured using
0.0729805795	to achieve high
0.0729800808	mean average
0.0727563143	often suffer from
0.0724691521	studies show
0.0724466084	approach uses
0.0723948890	u net like
0.0722876735	to augment
0.0722679868	named as
0.0722599435	processing time
0.0722210359	to encourage
0.0721259313	the human body
0.0721223881	value decomposition
0.0720670853	a custom
0.0720488491	able to extract
0.0719585010	high temporal
0.0718191101	supervised training of
0.0717766550	while providing
0.0717501986	the rate distortion
0.0717193807	leads to better
0.0716658039	improvement in
0.0716626735	to compress
0.0716136666	three types of
0.0716051988	score of
0.0715417611	the field of
0.0713400961	resulting in
0.0713299004	a recently proposed
0.0713179384	achieves better
0.0712779515	to make
0.0712440699	a fully convolutional
0.0712394611	superiority of
0.0712141092	each layer
0.0711969359	defined by
0.0711943195	the validation set
0.0711603618	defined as
0.0711384459	on simulated data
0.0711104609	the high frequency
0.0710757258	both local and global
0.0710672595	the acquired data
0.0709632048	to attain
0.0709617283	two domains
0.0709407373	practical use
0.0709202595	scale images
0.0709062487	shown to
0.0709012387	neural network for
0.0707946769	solved using
0.0707865505	identified by
0.0707251805	to image translation
0.0707032869	a post processing
0.0707004131	imaging through
0.0706201102	samples from
0.0705996626	devices such as
0.0705474160	a fully connected
0.0705217743	translation between
0.0704355670	3d facial
0.0704339932	done by
0.0704205714	models based on
0.0703959018	a self supervised
0.0703719882	in order to obtain
0.0703352320	object detection in
0.0702513900	very well
0.0702377590	loss function for
0.0701755017	the field of machine learning
0.0701417476	the input
0.0701417476	the target
0.0701109070	framework for
0.0701041973	compression using
0.0700997935	the last
0.0700738618	two state
0.0700220178	measurements from
0.0700198987	different stages
0.0700153813	the image domain
0.0699291244	estimation using
0.0698829854	converge to
0.0698809852	achieved by
0.0698757885	calculated from
0.0698539015	for detecting covid 19
0.0697541075	the latter
0.0697059170	the art deep learning
0.0696932542	regard to
0.0696872482	scope of
0.0696173716	constrained by
0.0695940593	various levels of
0.0695588115	ease of
0.0695098232	proposed method on
0.0694826577	a large number
0.0694201597	absolute error of
0.0693969961	in comparison to
0.0693497649	parameters than
0.0693391959	lesions from
0.0693155227	an unknown
0.0692871652	x ray data
0.0692334281	still challenging
0.0692274767	to align
0.0692204238	super resolution of
0.0691992974	not limited to
0.0691758148	at once
0.0691524985	the state of art methods
0.0691291314	generalizes to
0.0690927571	reduced by
0.0690886964	a deep
0.0690729340	the past
0.0689525104	good results
0.0689448607	growing interest in
0.0688955932	more efficiently
0.0687661840	solely on
0.0687515373	guided by
0.0687319125	although many
0.0686930789	information across
0.0686725988	also evaluated
0.0686637205	types of
0.0686582217	research work
0.0686255581	stored in
0.0686168809	performance over
0.0685432065	self training
0.0684841133	the ultimate
0.0684348900	time point
0.0684239944	the image quality
0.0684078116	network for
0.0683226488	the output image
0.0683125762	variety of image
0.0683113273	the segmentation accuracy
0.0682906114	approaches do not
0.0681979154	similar to
0.0681309957	to compensate for
0.0680059193	a simple yet
0.0679728945	the brats 2020
0.0679635483	obtained through
0.0679447907	a non linear
0.0679447695	for image classification
0.0679432824	the proposed loss
0.0679126735	to locate
0.0678842997	different classes
0.0677784295	to choose
0.0677321569	the training dataset
0.0677252573	this study aims
0.0677211328	convolutional network for
0.0676714927	also introduce
0.0676544327	a cost function
0.0675603749	most common
0.0675434951	3d scene
0.0675091219	first stage
0.0674821014	an arbitrary
0.0674553226	while simultaneously
0.0674486802	approach does not
0.0674446182	used in
0.0674275892	the usage of
0.0674172801	aided by
0.0674033451	each object
0.0673415805	the fine grained
0.0673310863	the art machine learning
0.0673061017	obtained at
0.0673023403	3d ct
0.0673011637	signal from
0.0672739171	the results obtained
0.0672685961	experiments on three
0.0672525589	to delineate
0.0672507022	purpose of
0.0672501784	enhanced by
0.0672254204	coupled with
0.0672171075	used to detect
0.0671571585	a new paradigm
0.0671468094	to modulate
0.0669963808	challenging task due to
0.0669963757	a wide
0.0669748746	known as
0.0669624862	the spatially varying
0.0669223830	in terms of psnr
0.0669166411	images without
0.0668803461	assessed by
0.0668769794	evaluate several
0.0668437143	neural network with
0.0668253374	imaging system
0.0668225913	a pair of
0.0667983210	any prior
0.0667500721	to judge
0.0667500427	the last few
0.0666708949	union of
0.0665792761	computational cost of
0.0665745672	same patient
0.0665603334	recovered from
0.0665417611	the presence of
0.0665407012	simple but
0.0665281029	a convolutional neural
0.0665122482	abundance of
0.0664347972	a trade off between
0.0664325049	level performance
0.0664143906	the present paper
0.0663981916	corrupted by
0.0663791314	quantity of
0.0663512205	development of
0.0663312973	effective at
0.0663150332	a training dataset
0.0662748766	properties of
0.0662546356	searching for
0.0662520000	extensive experiments on two
0.0662187949	on two public
0.0661650428	a variational
0.0661478212	existing work
0.0660568173	resolution image
0.0660223549	with minimal
0.0659256131	experimental results on two
0.0658915665	an overall accuracy of
0.0658330620	reconstruction time
0.0657995408	as input
0.0657905267	attention mechanism to
0.0657612657	classification using
0.0657500328	limited by
0.0657129374	patients from
0.0656686231	as well
0.0656384469	the receptive field
0.0656256564	introduced by
0.0655140125	performance against
0.0655089830	collected by
0.0654856621	using artificial
0.0654205714	network based on
0.0654048450	method uses
0.0653882028	the data distribution
0.0653523549	possibilities for
0.0653451486	recognition method
0.0652744613	to embed
0.0652132771	image classification with
0.0651994973	become more
0.0651800181	best performance
0.0651790976	sampled from
0.0651390261	segmentation network to
0.0651116109	no need to
0.0650994405	imaging with
0.0650720259	across multiple
0.0650094723	this method
0.0649344442	by integrating
0.0649227456	each patient
0.0648949535	images with
0.0648077141	novel view
0.0647834052	novel self supervised
0.0647568057	to increase
0.0647399629	proposed method compared to
0.0647175219	network with
0.0646369797	each individual
0.0646149776	collected at
0.0646040449	used to create
0.0645966489	an external
0.0645688765	used for training
0.0645603893	imagery using
0.0645597770	learned by
0.0645072504	the measured data
0.0644911049	to recognize
0.0644337898	the art methods in terms of
0.0644311266	application to
0.0644075830	a model based
0.0644009056	two parts
0.0643608694	by analyzing
0.0643599124	four different
0.0643458309	a 3d convolutional neural network
0.0643179299	each block
0.0642653143	a framework
0.0642537391	light detection
0.0642162631	to noise ratio
0.0642121277	data augmentation for
0.0640783482	a novel approach
0.0640602101	3d ultrasound
0.0639564316	a real time
0.0638535537	obtained using
0.0637992462	implemented by
0.0637989390	an autoencoder
0.0637815520	given input
0.0637445575	detection in
0.0636582332	a vital role in
0.0636361920	a convolutional
0.0635787711	image segmentation with
0.0635701469	further research
0.0635572492	hard to
0.0634519296	algorithms based on
0.0634448331	architecture based on
0.0633845966	several challenges
0.0633769794	techniques like
0.0633675483	more general
0.0633609939	likely to
0.0633224998	estimated from
0.0632315938	performance in many
0.0632125034	not only improves
0.0632085910	two major
0.0631509814	of training images
0.0631507618	assumed to
0.0631075986	each sample
0.0631052829	a fully
0.0630977475	work focuses on
0.0630777569	processed by
0.0630407012	obtained via
0.0630189728	deep learning approach to
0.0630172595	a novel deep neural network
0.0630008816	different levels
0.0629944701	methods do not
0.0629120582	to accommodate
0.0628508763	heavily on
0.0628234499	a novel network
0.0627922171	motion during
0.0627511628	the efficacy of
0.0627497410	u net with
0.0627256727	approaches based on
0.0626653337	a lot
0.0626585057	dependent on
0.0626254476	areas such as
0.0626228623	evaluations on
0.0626031970	able to predict
0.0625826847	invariant to
0.0625671458	the current state of
0.0625180245	two modalities
0.0625036625	these metrics
0.0624911049	to collect
0.0624495061	degree of
0.0624449976	approach provides
0.0623309561	the art model
0.0623176472	a case
0.0623172015	problem as
0.0623125740	the first step
0.0622371518	detection from
0.0622341778	range of
0.0621698987	overall accuracy
0.0621616313	acquired from
0.0621315959	various types
0.0621115916	maps from
0.0620880485	or even
0.0620801961	the model performance
0.0620770560	synthesis using
0.0620724998	tested using
0.0620578921	the point spread
0.0620188418	controlled by
0.0619443670	also evaluate
0.0619263418	x ray dataset
0.0618561981	3d pose
0.0618524208	different layers
0.0618124655	all cases
0.0618107281	stacks of
0.0617974402	annotations from
0.0617855015	still limited
0.0617465405	all tested
0.0617306030	the feature level
0.0617104016	proves to
0.0617014337	validated using
0.0616939743	this idea
0.0616841031	each level
0.0616815404	dataset of
0.0616577425	more natural
0.0615981745	each cell
0.0615798695	the imaging process
0.0615785759	fps on
0.0615018869	dataset for
0.0614939982	to mimic
0.0614307618	subsets of
0.0614163264	ct scans with
0.0614126735	to suppress
0.0613856485	seeks to
0.0613751407	validated by
0.0613520425	to meet
0.0613455571	modalities such as
0.0613441787	representations from
0.0613039811	method provides
0.0612729848	proved to
0.0612065305	pairs of
0.0611573571	tasks such as
0.0611181932	classification of
0.0611014943	based machine
0.0610517856	the image space
0.0610172371	these models
0.0609849647	used to improve
0.0609684277	a few
0.0609471939	amount of training data
0.0609219415	a simple yet effective
0.0609021821	an experiment
0.0608834167	the most suitable
0.0608601165	extracted by
0.0608427098	each stage
0.0607812406	the peak signal to noise ratio
0.0607338125	the art methods on
0.0606691364	the main contribution
0.0606673184	to accomplish
0.0606626735	to maintain
0.0606568678	image into
0.0606350944	part of
0.0606264349	approach to
0.0605764349	data from
0.0605478517	family of
0.0605298563	two different
0.0605048260	also provide
0.0604835778	results on
0.0604808061	better understanding
0.0604722923	diagnosis based on
0.0604650460	an object
0.0604588380	demonstrated by
0.0604196745	dimensional images
0.0604130958	non medical
0.0604076637	an end to end learning
0.0603733276	performed using
0.0603233503	to exploit
0.0603179299	several studies
0.0603068504	an embedded
0.0602967994	implications for
0.0602625973	a common
0.0602610503	detection of
0.0602411049	to establish
0.0602395391	arrangement of
0.0602157438	the application of deep learning
0.0601423196	an independent
0.0601373310	without loss
0.0601019926	most relevant
0.0600713871	an open
0.0600148748	vision tasks such as
0.0600086777	the training
0.0599918491	to answer
0.0599421201	the low level
0.0599308565	recovered by
0.0598811113	train models
0.0598624641	first step
0.0598548119	a small set
0.0598446836	to adjust
0.0597985431	also show
0.0597977286	the noise level
0.0597652306	taken at
0.0597482716	with high spatial
0.0597153180	commonly used in
0.0596181932	estimation of
0.0596163362	method for image
0.0595834054	to stabilize
0.0595664840	assumptions on
0.0595594244	methods in terms of
0.0595193281	the one hand
0.0594932600	application of deep
0.0594474979	the perceptual quality
0.0594468941	suited to
0.0594416980	10 \
0.0594194807	patients with
0.0593934499	the medical domain
0.0593394101	essential for
0.0593261879	annotated by
0.0593147798	composed of two
0.0593120793	an array of
0.0593112784	an intermediate
0.0593094059	used to construct
0.0593086449	approach for image
0.0592954958	applied on
0.0592913591	over conventional
0.0592780333	same object
0.0592444541	similar image
0.0592356593	networks for image
0.0591697798	perceptual quality of
0.0591454154	the art networks
0.0591252056	ability to
0.0591182902	assessment of
0.0591156504	designed to
0.0591041870	same class
0.0590843615	image denoising with
0.0590634716	achieved through
0.0590578543	an area
0.0590455729	information within
0.0590454185	datasets show
0.0590362692	impact of
0.0590112029	rate of
0.0589902324	net for
0.0589838125	time consuming and
0.0589801068	for clinical diagnosis
0.0589727315	feature maps of
0.0589316838	light detection and
0.0588841162	a large amount
0.0588010796	development of new
0.0587831214	other hand
0.0587115168	reconstruction methods for
0.0586933436	adoption of
0.0586928718	for model training
0.0586700315	the art video
0.0586677892	this scenario
0.0586133846	taken from
0.0585988574	used to predict
0.0585941146	increased by
0.0585645007	used to perform
0.0585584303	many fields
0.0585120878	take into
0.0585051327	room for
0.0584910263	the segmentation network
0.0584808264	high level of
0.0584711693	an optimized
0.0584698143	information into
0.0584656945	visual quality of
0.0584432302	used to evaluate
0.0584145675	not explicitly
0.0583967573	experiments on two
0.0583915189	efficient than
0.0583702833	report on
0.0583014782	supervised image
0.0582969582	spatial resolution of
0.0582749515	proof of
0.0582740712	manually by
0.0582610475	clinical use
0.0581810884	platform for
0.0581227312	method on
0.0581181932	diagnosis of
0.0581131896	the potential of
0.0580497724	constructed from
0.0580303333	the present work
0.0580058393	a small
0.0579644247	as inputs
0.0579279052	the physical model
0.0578808473	drop in
0.0578756326	different scenarios
0.0578749061	regions of
0.0578339944	different types
0.0577831214	further development
0.0577713037	signals from
0.0577660062	comes from
0.0577602789	reconstructed from
0.0577562157	to denoise
0.0577551310	by up to
0.0577453915	to decode
0.0577402146	segmentation of medical
0.0577344150	account for
0.0577256824	an encoder
0.0577095636	many applications
0.0576691720	generated from
0.0576554304	two key
0.0576117059	various applications
0.0576082102	after training
0.0575744382	to localize
0.0575427797	across datasets
0.0575393883	conditions such as
0.0575298563	these two
0.0574727390	any given
0.0574673887	approach allows
0.0574191322	for real time applications
0.0573801038	by calculating
0.0573309561	the art image
0.0573300514	3d space
0.0573188433	internet of
0.0573062120	deep convolutional neural network for
0.0572825771	the reconstructed images
0.0572706145	knowledge from
0.0572562157	to regularize
0.0571972028	an entire
0.0571939325	more important
0.0571794547	versions of
0.0571723826	more suitable
0.0571459418	by solving
0.0571356359	normal or
0.0571305806	tools for
0.0571157316	for training deep
0.0570358317	created from
0.0570110503	approach for
0.0570012194	run on
0.0569982710	mr images from
0.0569710058	specificity of
0.0569694663	reconstructed using
0.0569584303	three public
0.0569252267	directly on
0.0568915662	\ accuracy
0.0568865437	frame by
0.0568812351	reconstruction from
0.0568668509	a public
0.0567979806	scarcity of
0.0567142936	the proposed models
0.0567025607	contrast between
0.0566760498	implemented using
0.0566144641	further improvement
0.0565869626	acquired by
0.0565797736	the best possible
0.0565792745	the art deep learning based
0.0565275033	a non invasive
0.0565216285	performance than
0.0564888532	various levels
0.0564739129	a multi level
0.0564554575	to assign
0.0564080261	numbers of
0.0563600351	the model trained
0.0563274967	2d ultrasound
0.0563156902	an interpretable
0.0562955047	by extracting
0.0562873319	this project
0.0562453736	result in
0.0562116600	constraint on
0.0561362084	evaluated on three
0.0561318670	both cases
0.0561294630	problems such as
0.0561289517	trained using
0.0561128146	a test set
0.0561070758	dimension of
0.0560527820	source code of
0.0560526952	work demonstrates
0.0560310050	subset of
0.0559958300	the development of deep learning
0.0559719840	two strategies
0.0559359293	the same scene
0.0559257226	a strong
0.0558665680	accurate than
0.0557965963	inability to
0.0557882766	in many fields
0.0557791305	percentage of
0.0557600847	evaluated on two
0.0557294782	models for image
0.0557156622	using machine
0.0557060630	factors such as
0.0556180190	3d lidar
0.0555694297	the pixel level
0.0555671214	the light source
0.0555603808	most current
0.0555438545	provide more
0.0555381170	only limited
0.0555372819	list of
0.0555191668	proliferation of
0.0554732893	these approaches
0.0554554806	semantic segmentation using
0.0554500266	reconstruction method for
0.0554414619	three different
0.0554107966	the number of
0.0554007769	a fixed
0.0553777952	this report
0.0553327080	mapping from
0.0553269602	each point
0.0552929249	an extra
0.0552851642	implemented on
0.0552656006	performed on
0.0552464419	important for
0.0552165901	error of
0.0552159714	problem with
0.0552109554	studies on
0.0552075120	a sequence of
0.0551998528	also provided
0.0551905429	to modify
0.0551424221	used to segment
0.0551125102	the former
0.0550768691	used as input
0.0550765563	equivalent to
0.0550550770	resulting from
0.0550526125	parameters such as
0.0550333508	an inverse
0.0550240338	added to
0.0550206633	less parameters
0.0549572242	a computationally efficient
0.0549521021	the high level
0.0549428010	error between
0.0549242464	reduction of
0.0548644408	models for
0.0548608387	evaluated using
0.0548220051	to analyse
0.0548074992	level of
0.0546689556	robustness to
0.0546071862	to distinguish between
0.0545899708	amount of data
0.0545690872	usefulness of
0.0545675921	signs of
0.0545461508	a pixel wise
0.0545128154	a graph
0.0545115852	model with
0.0545074213	the art segmentation
0.0544929690	no significant
0.0544662825	determination of
0.0544483503	a major
0.0544369141	an individual
0.0544205791	acquired using
0.0543526652	representation of
0.0543503597	full 3d
0.0543439985	diseases such as
0.0543174172	an attempt
0.0542908453	as part of
0.0542879820	all three
0.0542297491	a machine learning
0.0542238229	both qualitatively
0.0541737894	detected by
0.0541613943	variations in
0.0541476203	detection via
0.0541107966	by using
0.0540916069	the choroid
0.0540466232	the trade off between
0.0540190999	scans from
0.0540133207	to automate
0.0539957425	reconstructed by
0.0539753453	2d images
0.0539731761	the current
0.0539729638	cnn trained
0.0539466949	applied to other
0.0539171408	improved by
0.0539159437	able to capture
0.0538943325	acquired with
0.0538863196	to map
0.0538756800	reduction in
0.0538743021	to convert
0.0537612202	ideas from
0.0537528863	by reducing
0.0537360335	the most challenging
0.0537077993	do not perform
0.0536737894	outputs from
0.0536678212	measured using
0.0536560931	employed as
0.0536497582	computer vision tasks such as
0.0535766380	an excellent
0.0535648369	great potential to
0.0535509056	very efficient
0.0535327518	different architectures
0.0534892233	an optical
0.0534817168	an expert
0.0534770991	a 3d
0.0533462140	large dataset of
0.0533242007	also present
0.0533092486	also investigate
0.0532822316	two components
0.0532680827	with negligible
0.0532671142	an extension
0.0532604261	also presented
0.0532084142	the generator
0.0532004560	estimated using
0.0531991710	dedicated to
0.0531782720	techniques for
0.0531731539	generated using
0.0531078880	by changing
0.0530948186	the inverse problem
0.0530917610	while still
0.0530628327	a challenging task due to
0.0529839007	all previous
0.0529828279	the most effective
0.0529667993	to reach
0.0529522382	3d objects
0.0529425318	method to
0.0528982221	restricted to
0.0528368667	five different
0.0528352416	time frequency
0.0528236114	3d localization
0.0528233503	to explore
0.0527777862	properties such as
0.0527771027	not suitable
0.0527612417	learned from
0.0527441299	the first
0.0527411049	to boost
0.0527410466	generate new
0.0527328997	a high quality
0.0527299517	some recent
0.0527015646	convolutional neural network with
0.0526968232	encountered in
0.0526955409	an optimal
0.0526952270	classified by
0.0526810884	allowing for
0.0526740779	an extended
0.0526720673	propose to
0.0526600117	to differentiate between
0.0526257582	influence on
0.0526133148	on two publicly available
0.0525822359	subject to
0.0525587355	performance under
0.0525408453	the need of
0.0525124581	also demonstrated
0.0525117774	often limited
0.0525092017	the field of medical
0.0524928705	robust to
0.0524914340	presence or
0.0524889175	the feature space
0.0524714503	system achieved
0.0524667516	the spatial domain
0.0524335426	utilized as
0.0523935994	uncertainty in
0.0523926298	on various datasets
0.0523830877	performances on
0.0523463690	time required
0.0523308986	none of
0.0522592607	both simulation and
0.0522546451	by simply
0.0522309354	overall performance
0.0522217703	gap by
0.0522195588	methods for
0.0521754496	solution to
0.0521627551	model for
0.0521430274	also tested
0.0521373218	aspects of
0.0521151339	on two publicly
0.0520809741	many clinical
0.0520545913	at hand
0.0520375171	assessed using
0.0520267315	to form
0.0520199388	3d point
0.0519924696	an objective
0.0519392064	different areas
0.0519344021	used to classify
0.0519103682	comparison of
0.0518249867	identification of
0.0517647337	proposed system
0.0516658227	a method based
0.0516622076	best results
0.0516606055	research on
0.0516327342	an extensive
0.0516228336	accuracy than
0.0516168505	techniques such as
0.0516151339	on two challenging
0.0516080261	delineation of
0.0515680466	2d +
0.0515064552	field of
0.0515054436	learns to
0.0514950333	not available
0.0514848598	reconstruction of
0.0514669000	calculated by
0.0514470478	adapt to
0.0514358031	further introduce
0.0514231670	not exist
0.0513916292	the final image
0.0513223119	involved in
0.0513148369	architecture search for
0.0513040768	such systems
0.0512822316	also shows
0.0512772044	challenges such as
0.0512439556	superior to
0.0512430648	the mutual information
0.0512091312	an event
0.0512062544	the art denoising
0.0512038211	more effectively
0.0511896879	the state of art
0.0511860963	evaluation on
0.0511525127	the same class
0.0511262479	amount of time
0.0511153876	in painting
0.0511131896	the robustness of
0.0510854752	several deep learning
0.0510812323	3d bounding
0.0510749516	type of
0.0510720923	3d imaging
0.0510523666	recorded by
0.0510086777	the problem
0.0510039885	characterization of
0.0509930721	used to extract
0.0509897492	to visualize
0.0509839754	different tasks
0.0509801984	make full
0.0509779647	this question
0.0509088634	except for
0.0508951952	a comparison
0.0508789389	performance across
0.0508688799	transferred to
0.0508610982	these artifacts
0.0507856154	feasibility of using
0.0507741141	treatment of
0.0507617496	tries to
0.0507352702	the test data
0.0507037694	top performance
0.0506727434	relative to
0.0506249867	application of
0.0506246122	for covid 19 diagnosis
0.0506225913	the superiority of
0.0505897161	computed from
0.0505389601	a multimode
0.0505277317	the input data
0.0504997658	inclusion of
0.0504848598	structure of
0.0504706206	the pre trained
0.0504353346	approach consists of
0.0504219019	the raw data
0.0503979354	a consequence
0.0503953708	to integrate
0.0503877706	trained to
0.0503596280	an integral
0.0503264443	on three publicly available
0.0503074992	localization of
0.0502344707	most effective
0.0501939456	devised to
0.0501851904	the resultant
0.0501717774	3d geometric
0.0501485246	three key
0.0501463663	this strategy
0.0501424249	assessed on
0.0501384654	comparison with
0.0501378720	an accurate
0.0501232868	these studies
0.0501024425	functionality of
0.0500978601	those obtained by
0.0500609640	while improving
0.0500403292	challenging because of
0.0500359505	position of
0.0500274937	squeeze and
0.0500202524	effective way to
0.0499942786	trained by
0.0499818579	good accuracy
0.0499553974	demonstrated on
0.0499370870	experiments over
0.0499314967	the segmentation model
0.0499284199	both tasks
0.0499242464	extraction of
0.0499160669	existence of
0.0499089501	cohort of
0.0499037465	difficult due to
0.0498979875	obtained with
0.0498925749	opportunity to
0.0498894895	developed for
0.0498825771	the classification task
0.0498461487	a 2d
0.0498387767	the whole image
0.0498325120	the basis of
0.0498225913	the goal of
0.0498181188	conducted using
0.0498040452	segmentation in
0.0497938170	optimized by
0.0497804761	also compare
0.0497670358	a subset of
0.0497512862	the usual
0.0497467534	a 3d convolutional
0.0497373324	by optimizing
0.0497229806	beneficial for
0.0497122037	the natural image
0.0496484800	two public
0.0496433008	this case
0.0496339578	levels of
0.0496231062	introduced as
0.0496139347	needed to
0.0496080261	aspect of
0.0496038676	information from different
0.0495797736	this gap by
0.0495601852	advancement of
0.0495497737	by selecting
0.0495294768	scenarios such as
0.0495131045	these tasks
0.0495093766	only requires
0.0495046568	efforts on
0.0494941285	the output
0.0494707722	consistent with
0.0494288023	problem of
0.0493935994	appearance of
0.0493770644	objects in
0.0493662219	both modalities
0.0493503922	the network parameters
0.0493385399	ensemble of
0.0493233503	to measure
0.0493205575	new approaches
0.0492939023	the retina
0.0492767406	the segmentation results
0.0492374459	aimed to
0.0492315115	modification of
0.0492313587	novel approach
0.0492224625	amplitude of
0.0491334660	to verify
0.0491080261	forms of
0.0490885056	a mean absolute
0.0490880485	by considering
0.0490578005	proposed method over
0.0490575221	segmentation from
0.0490436371	constraints on
0.0490423097	than previous
0.0490192039	the field of computer
0.0490139932	patterns from
0.0490017556	evaluated by
0.0489797649	the well known
0.0489585156	to preserve
0.0489465704	possibility of
0.0489141281	to simplify
0.0488823849	work presents
0.0488756666	to connect
0.0488682728	based method to
0.0488514201	superior performance in
0.0488307735	subjects from
0.0488253496	two sets
0.0487908575	against state of
0.0487380437	a significant
0.0487338125	expected to
0.0487302394	3d convolutional neural
0.0487250507	occurrence of
0.0487205427	sensitivity of
0.0487047491	top of
0.0487008287	various tasks
0.0486901127	helpful to
0.0486688526	existing methods on
0.0486471561	effect on
0.0486237917	organization of
0.0486134567	fraction of
0.0485783186	many medical
0.0485738058	tumors from
0.0485521351	a graph based
0.0485219464	several applications
0.0484930721	used to obtain
0.0484868273	further demonstrate
0.0484796053	behavior of
0.0484729806	developments in
0.0484717742	by creating
0.0484716463	artifacts such as
0.0484714278	from different domains
0.0484558900	this challenge
0.0484440238	this kind of
0.0484419233	generalize to
0.0484156296	to store
0.0484154119	than traditional
0.0483666788	to implement
0.0483604491	similarities in
0.0483305868	generative models for
0.0483122222	system achieves
0.0483037219	different strategies
0.0482778457	definition of
0.0482597545	no prior
0.0482416464	volumes from
0.0482190844	a single network
0.0481673815	and up sampling
0.0481668921	to guarantee
0.0481586129	to fill
0.0481547753	characteristics of
0.0481542461	in chest x rays
0.0481527002	the most significant
0.0481443944	second approach
0.0481435802	two important
0.0481334660	to encode
0.0481183000	used to measure
0.0480951716	the development of
0.0480834404	far from
0.0480657490	a result
0.0480356782	recorded from
0.0479914002	this way
0.0478972763	the reconstruction quality
0.0478805852	an extremely
0.0478749061	prediction of
0.0478007334	the art reconstruction
0.0477950405	bottleneck for
0.0477734495	to combine
0.0477681012	in order to achieve
0.0477667320	a patch based
0.0477635810	a multi view
0.0477551282	of chest x rays
0.0477470616	review of
0.0477229806	tailored for
0.0477213647	an autonomous
0.0477212053	3d reconstruction
0.0477053863	form of
0.0477031232	recovery of
0.0476994797	this area
0.0476702001	then uses
0.0476596153	synthesized from
0.0476309508	also called
0.0476253500	the literature
0.0476171598	with varying
0.0475978277	needed for
0.0475965320	to apply
0.0475766131	a series of experiments
0.0475628723	the art performance in
0.0475440247	an energy
0.0475149585	many computer vision
0.0475041870	two orders
0.0475029219	an input
0.0474893578	a holistic
0.0474678948	available for training
0.0474638922	structure from
0.0474502295	ensembles of
0.0474442612	performance in
0.0474390392	an increased
0.0474205261	variants of
0.0474019430	out of
0.0473912896	these works
0.0473838674	based approaches for
0.0473838185	a time consuming
0.0473645113	captured from
0.0473472671	but not
0.0473250973	a key
0.0472932219	data from different
0.0472839971	architecture for
0.0472838311	allowed to
0.0472737014	a high dimensional
0.0472705766	task of
0.0472681932	technique for
0.0472628404	an image to image
0.0472262107	advances in
0.0472104768	these properties
0.0472056873	in order to address
0.0471890392	by performing
0.0471736063	of interest
0.0471559247	the influence of
0.0471544270	role in many
0.0471500953	use of deep learning
0.0471486624	2d cnns
0.0470507455	expense of
0.0470311561	limited to
0.0470074112	an unseen
0.0469883207	to monitor
0.0469609096	context of
0.0469241786	different levels of
0.0468978231	diagnosed with
0.0468937122	opportunities for
0.0468669512	a pixel level
0.0468484871	these results
0.0468214232	mri scans of
0.0467950378	by modeling
0.0467885130	promising results for
0.0467759940	each task
0.0467613071	correlated with
0.0466455555	between frames
0.0466443574	augmented with
0.0466443574	exist for
0.0466413574	under various
0.0466412714	required by
0.0466294494	method on two
0.0466257582	operating on
0.0466252315	not contain
0.0466230082	explanations for
0.0465892409	dataset with
0.0465825120	the advent of
0.0465668921	a viable
0.0465333146	a plug and play
0.0465197233	a full
0.0465116474	methods such as
0.0465058394	limited due to
0.0464881271	mapped to
0.0464861844	growth of
0.0464581167	prevalent in
0.0464399116	a student
0.0464288115	new approach
0.0464242464	improvement of
0.0464171753	a powerful
0.0463552046	an eye
0.0463465738	metrics such as
0.0463271379	3d object
0.0463168859	discussion of
0.0462886988	novel learning based
0.0462762879	fails to
0.0462441299	a given
0.0462274258	an enhanced
0.0462268551	threat to
0.0462232079	an overall
0.0461835839	us images
0.0461694842	the ground
0.0461613943	increase in
0.0461204463	or not
0.0460621110	contained in
0.0460444323	three publicly
0.0460204815	to construct
0.0460046440	pipeline for
0.0459780535	distribution from
0.0459293444	tumor segmentation in
0.0459157453	a u net architecture
0.0459107966	the accuracy of
0.0458945128	the performance
0.0458367283	the receiver
0.0458344578	beginning of
0.0458225913	the impact of
0.0458203692	images taken
0.0458053641	screening of
0.0457993271	different parts
0.0457395967	designed for
0.0457363568	to save
0.0456740923	an action
0.0456521562	a publicly available dataset
0.0456351824	guaranteed to
0.0455489533	lesion segmentation in
0.0455425228	potential for
0.0455164934	aim to
0.0455053301	also demonstrate
0.0454955976	such cases
0.0454798218	tested with
0.0454749290	also achieves
0.0453896472	degrees of
0.0453886561	a principled
0.0453803142	a novel method
0.0453546003	to analyze
0.0453292925	each sub
0.0453231281	building on
0.0453174710	often rely on
0.0453155159	a multilayer
0.0452894111	the most relevant
0.0452891175	employed for
0.0452815659	to ease
0.0452790134	drawback of
0.0452439402	to search for
0.0451930145	proposed to
0.0451740133	proposed for
0.0451532946	the art convolutional
0.0450831808	place in
0.0450645955	to compute
0.0450613895	not require
0.0450610718	essential to
0.0450571251	a median
0.0450028649	network architecture for
0.0449958990	integrated with
0.0449897492	to calculate
0.0449812059	an experimental
0.0449617207	the evolution
0.0449534994	extraction from
0.0449468898	a deep learning approach for
0.0449450542	response to
0.0449418589	most recent
0.0449343143	visualization of
0.0449335214	relevant to
0.0448869871	to use
0.0448691220	this technique
0.0448418189	to distinguish
0.0448303020	an improvement of
0.0448225913	a combination of
0.0448188598	these measurements
0.0448074992	knowledge of
0.0448046995	to support
0.0448025955	quality than
0.0447675687	demonstrated using
0.0447531543	reconstructions from
0.0447524205	rise of
0.0447422745	to leverage
0.0447409992	to restore
0.0447368534	interpretation of
0.0447029061	3d videos
0.0446961754	automation of
0.0446747750	works on
0.0446712440	simplicity of
0.0446711755	described by
0.0446696506	imaging provides
0.0446571163	performed with
0.0446543788	to adapt
0.0446451298	the ill posed
0.0446304367	equal to
0.0446200873	optimized for
0.0446157453	the so called
0.0446121409	risk of
0.0445973664	this context
0.0445299544	picture of
0.0445235192	also propose
0.0445128154	the latent
0.0444866400	the feature map
0.0444585339	description of
0.0444523169	learning models for
0.0444452202	abilities of
0.0444303037	deep learning model to
0.0444251844	contribution of
0.0444072095	to carry
0.0444070951	drawbacks of
0.0444033634	problem by
0.0443972763	the segmentation performance
0.0443770650	selection of
0.0443659550	a novel adaptive
0.0443628421	period of
0.0443580651	results than
0.0443368667	across various
0.0443191975	to represent
0.0443137137	spatial information of
0.0443073530	an original
0.0442366400	the image sensor
0.0442366397	requirement for
0.0442036228	operate in
0.0441849470	scheme for
0.0441756513	paired with
0.0441361493	by achieving
0.0441298726	this setting
0.0441175076	differences in
0.0441140804	an algorithm
0.0441101624	era of
0.0440225787	to incorporate
0.0440019702	solutions for
0.0439614003	performance with
0.0438949651	a coarse
0.0438864293	1 \
0.0438777170	algorithm for
0.0438359335	the fact
0.0438307908	this research
0.0437797342	well as
0.0437231224	based segmentation of
0.0436786747	various machine
0.0436618869	vulnerability of
0.0436558529	critical for
0.0436275763	potential of
0.0436190227	to select
0.0436183000	used to identify
0.0435708957	deviation of
0.0435698926	discovery of
0.0435616786	the coronavirus disease
0.0435525850	used to reconstruct
0.0435063139	consideration of
0.0434849440	solution for
0.0434631453	a promising
0.0434245042	first introduce
0.0434239610	tissues from
0.0434158453	to account for
0.0434006810	seen as
0.0433997345	diagnosis and treatment of
0.0433977654	based methods for
0.0433709053	same dataset
0.0433268040	to translate
0.0433191252	proposed method with
0.0433154935	little as
0.0433150248	novel end to end
0.0433070938	any other
0.0433028229	goals of
0.0432879031	for 3d medical image
0.0432849336	from undersampled
0.0432831717	to validate
0.0432811904	procedure for
0.0432407662	a compact
0.0432135536	helpful in
0.0431865525	approach on
0.0431804545	by radiologists
0.0431615892	rest of
0.0431504871	than existing
0.0431470616	observed in
0.0431466862	computed by
0.0431437660	an observation
0.0431103788	burden on
0.0431101624	demonstration of
0.0431052302	needs to
0.0430801721	to adversarial attacks
0.0430671458	the amount of
0.0430579106	method against
0.0430535389	to replace
0.0430478570	sequence of
0.0430130419	adapted for
0.0430108458	required to
0.0429990495	a modified
0.0429953589	than conventional
0.0429836713	this kind
0.0429780535	cases from
0.0429252733	an approximation
0.0429060162	a group of
0.0428976515	approaches use
0.0428761130	other approaches
0.0428731124	presented in
0.0428719267	a pre processing
0.0428697899	limitations of
0.0428511391	implemented in
0.0428383644	a 3d u net
0.0428142660	a large set of
0.0428110718	a new approach
0.0427788076	importance of
0.0427689225	goal of
0.0427572112	feasibility of
0.0427554367	tailored to
0.0427372615	three tasks
0.0427286569	challenge due to
0.0427043833	from different modalities
0.0426746618	this assumption
0.0426702001	if not
0.0426513391	new algorithm
0.0426496758	a differentiable
0.0426478300	a fundamental
0.0426472049	proposed framework on
0.0426395050	aiming to
0.0426361563	placement of
0.0426224625	array of
0.0426052689	novel architecture
0.0425949881	to compare
0.0425850376	the generated
0.0425780310	comparison to
0.0425691932	attempts to
0.0425666270	the human visual
0.0425469170	course of
0.0425128154	a reference
0.0425112029	generation of
0.0425088964	built on
0.0424839469	by evaluating
0.0424753453	this process
0.0424737233	to design
0.0424344216	by developing
0.0424339736	region of
0.0424269491	impractical to
0.0424168859	impossible to
0.0423539023	a shared
0.0423451716	in addition to
0.0423450405	fused with
0.0423378799	the most
0.0422948559	perform well in
0.0422887648	to investigate
0.0422025553	unsupervised learning of
0.0422001458	required for
0.0421905773	a modular
0.0421656296	to emphasize
0.0421592942	by humans
0.0421444781	ability of
0.0421070177	success of
0.0420940795	transmitted to
0.0420897492	to explain
0.0420853301	transferability of
0.0420772577	these algorithms
0.0420772254	stability of
0.0420724665	lost in
0.0420622184	network architectures for
0.0420370419	a stack of
0.0419804898	accuracy over
0.0419556181	with respect
0.0419343143	improvements in
0.0419262194	agreement with
0.0419093035	achieved by using
0.0418909329	different datasets
0.0418680252	extended to
0.0417899868	not possible to
0.0417892580	useful for
0.0417741475	scenes with
0.0417012530	learning framework to
0.0416895007	in order to improve
0.0416836229	the mean absolute error
0.0416815822	these techniques
0.0416746618	this observation
0.0416659416	to compensate
0.0416478601	more accurate than
0.0416467121	the curve
0.0415946057	all existing
0.0415918511	formulation of
0.0415275220	status of
0.0414851904	to satisfy
0.0414826064	understanding of
0.0414551908	to decide
0.0414484850	makes use
0.0414342619	new loss
0.0414288391	field of view of
0.0414246122	the signal to noise ratio
0.0414197151	the existing methods
0.0414072095	to decompose
0.0413664685	more recently
0.0413622133	choice for
0.0413614075	better quality
0.0413489272	by estimating
0.0413478570	convergence of
0.0413454068	reproducibility of
0.0413450405	comparisons with
0.0413328218	this methodology
0.0413299544	valuable for
0.0413080679	images with different
0.0413074992	applied in
0.0413034158	decrease in
0.0412990443	all other
0.0412835628	strengths of
0.0412651965	employed to
0.0412633882	comparing with
0.0412547938	solved with
0.0412535149	trends in
0.0412513944	detection and classification of
0.0412336077	an increasingly
0.0412309217	various medical
0.0412075120	the aim of
0.0412034397	three sub
0.0411954344	by computing
0.0411919857	the actual
0.0411764139	various noise
0.0411640530	produced from
0.0411513830	defined on
0.0411344216	by showing
0.0411302693	flexibility in
0.0411201231	a 3d convolutional neural
0.0411186269	a better understanding of
0.0411004013	available datasets
0.0410945476	competitive with
0.0410863727	insights on
0.0410701416	the true
0.0410658588	more suitable for
0.0410652111	able to improve
0.0409865620	the segmentation task
0.0409811217	examination of
0.0409787770	correlation with
0.0409724782	metric for
0.0408854738	to add
0.0408540804	an approach
0.0407998475	redundancy in
0.0407809815	success in
0.0407708467	introduced to
0.0407619666	a trade off
0.0407519881	among different
0.0407474950	to prevent
0.0407445575	process of
0.0407282773	strategy for
0.0407024243	to cope with
0.0406965763	to tune
0.0406702104	the output of
0.0406616815	a new dataset
0.0406571250	introduction of
0.0406503758	image reconstruction with
0.0406488618	to reflect
0.0406029146	other types of
0.0405932426	a 1d
0.0405739911	by generating
0.0405583609	the source
0.0405307678	pool of
0.0405075534	a huge
0.0404806301	progress in
0.0404806301	capabilities of
0.0404518040	to expand
0.0404279362	registration using
0.0404172839	several state of
0.0404096149	by at least
0.0403626591	mean absolute error of
0.0403587815	network trained on
0.0403007948	to retain
0.0402918162	novelty of
0.0402757231	new architecture
0.0402715660	this technology
0.0402677609	to reproduce
0.0402659554	the art on
0.0402552254	study on
0.0402274743	incorporated in
0.0402171947	a challenging
0.0402045848	variant of
0.0401798982	considered to
0.0401739834	a widely used
0.0401500958	to bring
0.0401475140	quantities of
0.0401468686	imaged with
0.0401183603	subjects with
0.0400798563	because of
0.0400719034	detection and segmentation of
0.0400294580	two orders of
0.0400075120	the features of
0.0399378206	requirements for
0.0399202938	modeling of
0.0398459298	the interpolated
0.0398233105	by experts
0.0397841742	capability of
0.0397823856	deep networks for
0.0397271920	evaluated with
0.0397271284	the existing state of
0.0397194405	also provides
0.0397073010	a unique
0.0396999398	a recursive
0.0396962243	smoothness of
0.0396244481	merits of
0.0395954665	working on
0.0395883432	laborious and
0.0395726678	information between
0.0395723430	the rapid development
0.0395170720	area of
0.0395092379	among other
0.0394875007	this direction
0.0394871668	artifacts such
0.0394865361	first study
0.0394692833	information through
0.0394545823	an fpga
0.0394484375	deployed in
0.0394431139	included in
0.0394324072	the segmentation quality
0.0394162287	a mean
0.0393972049	important task in
0.0393770650	independent of
0.0393742660	different parts of
0.0393551586	order to
0.0393429700	a generic
0.0393320013	a recurrent neural
0.0392227134	to find
0.0392108987	benefits of
0.0391658681	the recovered
0.0391645715	an empirical
0.0390890642	from multiple
0.0390752255	on device
0.0390361637	choice of
0.0390114546	the patient's
0.0390092249	for diagnosing
0.0390081346	other methods
0.0389979316	a baseline
0.0389722408	agnostic to
0.0389636624	able to provide
0.0388848058	many recent
0.0388636110	tuned to
0.0388580409	an upper
0.0388251004	to deploy
0.0387930389	represented in
0.0387689225	benefit of
0.0387617072	demand for
0.0387611228	one way
0.0387365593	history of
0.0387271011	a global
0.0387244020	the model's
0.0387223155	the initial
0.0387027576	information than
0.0386637073	a prominent
0.0386366132	to characterize
0.0386136025	series of
0.0386121254	this leads
0.0386025967	an appropriate
0.0385951716	a number of
0.0385823109	utilized to
0.0385671458	alternative to
0.0385590578	potential to
0.0385357010	the attacker
0.0384830540	to annotate
0.0384654698	still not
0.0384531543	learns from
0.0384495877	a way to
0.0384061797	the 3d structure
0.0384037797	between two
0.0383677054	a convex
0.0383425712	against other
0.0383320559	an emphasis
0.0383141011	ranges of
0.0383019151	accuracy on
0.0382962243	run in
0.0382670358	the concept of
0.0382393578	to aggregate
0.0382369561	recordings of
0.0382369561	trend of
0.0381952408	3d us
0.0381655608	more than one
0.0381559247	the success of
0.0381559247	the importance of
0.0381423638	the predicted
0.0381168962	extensions of
0.0380975058	under different
0.0380165678	from chest ct
0.0380159546	an output
0.0380101378	by quantifying
0.0379662559	a robust
0.0379189425	selected from
0.0379169713	robustness of
0.0379011391	spectrum of
0.0378697899	effects of
0.0378476704	popularity in
0.0378462227	non line
0.0378442708	investigation of
0.0378403510	capacity of
0.0378095845	the art results in
0.0378041436	to demonstrate
0.0377765504	the art object
0.0377292399	conducted to
0.0377254260	methodology for
0.0376809447	to propagate
0.0376754195	important problem in
0.0376263722	creation of
0.0376237044	width of
0.0376090325	a well known
0.0375950631	for detecting
0.0375948405	not possible
0.0375914583	likelihood of
0.0375835021	heterogeneity of
0.0375820543	by removing
0.0375704118	quality compared to
0.0375669410	an easy
0.0375654698	found at
0.0375432553	applicable for
0.0375047938	beneficial to
0.0374808473	registered to
0.0374673812	this fact
0.0374528366	in loop
0.0374460090	the previous methods
0.0374214604	similarly to
0.0373963801	better than other
0.0373770650	component of
0.0373657385	function based on
0.0373588860	to utilize
0.0373285834	probabilities of
0.0373157683	a given image
0.0373141011	concatenation of
0.0373078439	3d structure of
0.0372829210	the way for
0.0372686353	new state of
0.0372685777	variability of
0.0372346370	preservation of
0.0372269018	the network's
0.0372127457	parts of
0.0372075723	used to compare
0.0371999398	a reasonable
0.0371999398	for determining
0.0371747786	taken as
0.0371745458	idea of
0.0371706507	in order
0.0371686898	a customized
0.0371559247	the absence of
0.0371153232	to generalize
0.0370955845	evolution of
0.0370914851	for classifying
0.0370683330	to discriminate
0.0370623048	a typical
0.0370272026	significantly different
0.0370084941	often not
0.0369996488	methods do
0.0369837753	vulnerability to
0.0369780847	methods like
0.0369695951	assist in
0.0369589947	a study
0.0369410687	the outer
0.0369340846	the default
0.0369340846	the necessity
0.0368919039	accessible to
0.0368871053	integration of
0.0368695177	utilized for
0.0368601904	to check
0.0368585177	means of
0.0368388822	design of
0.0368268295	$ x
0.0368163425	a special
0.0368028229	integrity of
0.0367770016	approaches such as
0.0367768290	prevalence of
0.0366869671	implementations of
0.0366849725	a joint
0.0366829765	high accuracy in
0.0366685777	utilized in
0.0366522762	training set of
0.0366164743	a clear
0.0365798563	changes in
0.0365646174	autoencoder with
0.0365495669	for 3d object detection
0.0364891291	extent of
0.0364771964	execution of
0.0364732701	novel way
0.0364697824	this retrospective
0.0364683991	guidance for
0.0364673109	a novel architecture
0.0364609096	cost of
0.0364179380	variability in
0.0364137282	tool in
0.0364070951	hours of
0.0363978570	studied in
0.0363938630	impacts of
0.0363801538	a user
0.0363719281	histogram of
0.0363692414	done using
0.0363644578	a popular
0.0363581670	the k space
0.0363517399	diversity of
0.0363353694	the first approach
0.0362965718	due to lack of
0.0362863026	mm for
0.0362531490	all possible
0.0362514918	an uncertainty
0.0362014774	a sequential
0.0361933470	and eosin
0.0361844194	the image quality of
0.0361796530	the effectiveness
0.0361559247	the potential to
0.0361500400	size of
0.0361366132	a broad
0.0361278559	a deep neural network for
0.0361162344	features such as
0.0361106851	most important
0.0361101814	desirable to
0.0361088397	to operate
0.0360982269	by measuring
0.0360930086	3d convolution
0.0360701684	different approaches
0.0360590614	ratio of
0.0360566534	as measured by
0.0360539800	into four
0.0360439943	located in
0.0360168099	the perceptual quality of
0.0360109729	different cameras
0.0359943325	critical to
0.0359932553	progress on
0.0359860129	a single 2d
0.0359736165	a new method
0.0359036228	shortcomings of
0.0359026481	referred to
0.0358937951	time series of
0.0358932800	a predefined
0.0358819741	to deliver
0.0358732220	an artificial
0.0358665141	bottleneck in
0.0358606559	a two dimensional
0.0358572390	effect of
0.0358403510	inspection of
0.0358399071	all types of
0.0358278159	cascade of
0.0358258882	discussed in
0.0358002792	algorithms such as
0.0357882867	outbreak of
0.0357538720	to advance
0.0357233105	a deterministic
0.0356931777	adopted for
0.0356571745	the new method
0.0356526171	employed in
0.0356379621	for generating
0.0356134345	features across
0.0355951716	the lack of
0.0355627394	an algorithm based
0.0355503151	3d medical image
0.0355415098	an instance
0.0354696148	a very small
0.0354365343	same time
0.0354309473	to manage
0.0353425712	even better
0.0353332078	the primary
0.0353272441	the denoised
0.0353095845	the art performance for
0.0352996389	with very high
0.0352563320	the same dataset
0.0352477243	a dedicated
0.0352026171	technology for
0.0351986481	coefficient of
0.0351691848	this study aims to
0.0351651928	signal to
0.0351559247	the cost of
0.0351559247	the case of
0.0350870458	spread of
0.0350772254	half of
0.0350629059	the same patient
0.0350331808	exist in
0.0350251844	interpretability of
0.0350033569	several existing
0.0349970938	even more
0.0349813587	a novel unsupervised
0.0349733105	a valid
0.0349649868	more difficult to
0.0349366397	composition of
0.0349297581	recovery from
0.0348874658	a discussion
0.0348370146	a stochastic
0.0348368355	important to
0.0348048193	not suitable for
0.0347985650	achieved with
0.0347713730	popularity of
0.0347111385	comes with
0.0346958450	a new type of
0.0346955530	three types
0.0346559247	the advantages of
0.0346534390	image quality for
0.0346269728	a finite
0.0345749962	corrupted with
0.0345379181	applicability of
0.0345340996	to extend
0.0345178038	tests on
0.0345071630	or comparable
0.0345032551	back to
0.0344417961	variance in
0.0344339402	a diverse set of
0.0343565560	advantages of
0.0343524417	over state of
0.0343446671	learning method to
0.0343121844	especially at
0.0343045773	realism of
0.0343023931	build on
0.0343009809	quantification of
0.0342798218	a novel framework
0.0342535686	taken by
0.0342535246	a shallow
0.0342527329	pair of
0.0342335710	work aims
0.0342149871	case of
0.0342026171	embedded in
0.0341976829	an extension of
0.0341918511	basis for
0.0341687551	achieved using
0.0340828954	the second
0.0340546471	problem into
0.0340536538	the detection of
0.0340449118	challenge on
0.0340370083	amount of information
0.0340319814	deployment of
0.0340166317	a critical
0.0340162606	the analysis of
0.0340101760	for implementing
0.0339945871	two new
0.0339539277	to render
0.0339499398	a straightforward
0.0339397410	the value of
0.0339349262	the reconstruction of
0.0339123136	the previous state of
0.0338556686	problem in
0.0338462102	the field of computer vision
0.0338369556	3d human
0.0338321862	made by
0.0337888315	mixture of
0.0337852936	the burden of
0.0337795576	aid in
0.0337778193	to decrease
0.0337718784	results on three
0.0337679102	other conventional
0.0337609225	the efficiency of
0.0337502042	than other
0.0337396097	a set
0.0337391225	known to
0.0337292564	for assessing
0.0337246351	for 3d medical
0.0336986481	exploration of
0.0336918511	accuracies of
0.0336913904	a tool
0.0336727014	and then
0.0336333295	the proposed multi
0.0336275763	efficiency of
0.0336011372	difficulties in
0.0335537982	crucial to
0.0335532531	to screen
0.0335414808	models without
0.0334788334	both in terms
0.0334646641	a bidirectional
0.0334595456	other techniques
0.0334428688	uses only
0.0334338125	the diagnosis of
0.0334253124	on synthetic and
0.0334131269	the overall performance
0.0333958857	a learnable
0.0333686096	the corresponding
0.0333072515	the first study
0.0333045733	the process of
0.0333045733	the ability of
0.0332968937	collection of
0.0332654178	the number of parameters
0.0332581518	a cascaded
0.0332555956	complexity of
0.0332290683	two publicly
0.0332278873	the emergence
0.0332036657	the rest
0.0331891291	requirement of
0.0331559247	a range of
0.0331359327	of great interest
0.0330623048	a complete
0.0330524655	in terms of accuracy
0.0330509082	images contain
0.0330379181	usage of
0.0330303016	promise for
0.0329996425	the fovea
0.0329841726	leveraged to
0.0329701220	to discover
0.0329609096	generalization of
0.0329397410	of up to
0.0328971464	a general
0.0328845663	in terms
0.0328676455	and eventually
0.0328402901	the signal to noise
0.0328359327	the visibility of
0.0328343622	other existing
0.0328319814	property of
0.0327892580	to help
0.0327606610	dependency of
0.0327125827	a pre
0.0327104084	a great
0.0327075120	the utility of
0.0327037740	for predicting
0.0326559247	the effects of
0.0326254003	reliability of
0.0326164743	to match
0.0326086898	a prototype
0.0325820543	a convenient
0.0325755569	done on
0.0325663827	the most commonly
0.0325609225	the complexity of
0.0325536538	the training of
0.0325359484	over existing
0.0325171458	the relationship between
0.0324908332	a dataset of
0.0324843339	volume of
0.0324458450	a significant impact on
0.0324169713	power of
0.0323880688	then propose
0.0323670590	for solving
0.0323521405	to run
0.0323446287	for improving
0.0323332078	a reliable
0.0323071541	the loop
0.0322847746	a proper
0.0322829210	the role of
0.0322790155	to process
0.0322713264	an augmented
0.0322581518	a substantial
0.0322295177	adopted in
0.0322237073	a versatile
0.0322225657	dependencies in
0.0322028366	a moderate
0.0322018072	outcome of
0.0321953174	used to reduce
0.0321889517	the next
0.0321683510	presented as
0.0321637210	to control
0.0321376339	a novel generative
0.0321237239	regularization for
0.0320617598	a crucial
0.0320162606	the segmentation of
0.0320063754	studied for
0.0320035423	not fully
0.0319777527	the way to
0.0319746084	other than
0.0319653346	a simplified
0.0319379067	allows for
0.0319349262	the classification of
0.0319059022	in many applications
0.0318684021	the field of view
0.0318671458	the size of
0.0318596382	slice by
0.0318469358	efficacy of
0.0318178316	often leads to
0.0318080973	while most
0.0318052966	the region of interest
0.0317973202	to reverse
0.0317778193	to fit
0.0317725006	the alternating direction method of
0.0317693574	exploited to
0.0317456196	the potential
0.0316993496	the existence of
0.0316918457	addition to
0.0316788076	severity of
0.0316403511	many other
0.0315669110	product of
0.0315612198	a training set
0.0315370458	concept of
0.0315118173	a new deep learning
0.0315029210	the difficulty of
0.0315010039	a novel deep learning
0.0314949848	the possibility
0.0314925549	helps in
0.0314519285	a universal
0.0314463752	biases in
0.0314338125	the distribution of
0.0314338125	the generation of
0.0314045848	extension of
0.0313472763	the existing approaches
0.0313130982	the need to
0.0313045733	the ability to
0.0312573037	on different datasets
0.0312493281	the second step
0.0312350657	workflow for
0.0311981036	reconstruction via
0.0311543905	a big
0.0311467121	a practical
0.0311360834	the reliability of
0.0311252518	the presence
0.0311136076	a deep learning approach to
0.0311007533	a double
0.0311006069	both visually and
0.0310746618	a tedious
0.0310601687	topic in
0.0310590813	in summary
0.0310393680	a method for
0.0309853817	the inherent
0.0309781016	strategies for
0.0309379427	experiment with
0.0309164077	the advantage of
0.0308321566	to reveal
0.0308126254	reconstructed with
0.0307751167	auc of
0.0307678728	able to accurately
0.0307514106	a maximum
0.0307075120	the possibility of
0.0306734832	step by
0.0306649868	the topology of
0.0306259536	with other state of
0.0306083296	anomalies in
0.0306067121	a direct
0.0306062903	then used
0.0305545733	as compared to
0.0305179874	to yield
0.0305128893	new paradigm
0.0305000893	influence of
0.0303965372	a very low
0.0303734832	adaptation for
0.0303440109	most previous
0.0303360899	calculation of
0.0303359327	a training set of
0.0302926202	the art results for
0.0302852301	both synthetic
0.0302790444	construction of
0.0302462243	strength of
0.0302372175	also allows
0.0302122318	very different
0.0301871232	to allow for
0.0300935548	a detailed
0.0300746618	to balance
0.0299808475	a mean dice
0.0299481746	for estimating
0.0298768481	tedious and
0.0298677601	the gap between
0.0298419358	a new framework
0.0298246618	to bridge
0.0298090693	to update
0.0298082906	the network to learn
0.0297816189	this work aims
0.0297793326	to aid
0.0297700103	to share
0.0297395025	further reduce
0.0297364680	to derive
0.0296842113	a publicly available
0.0296559247	the feasibility of
0.0296386299	the level of
0.0295549824	an overall accuracy
0.0295473688	results in
0.0295393680	use of
0.0295022143	strategy to
0.0294825060	research in
0.0294625827	the number
0.0294019430	a very
0.0293664781	especially for
0.0293492088	then use
0.0293362543	this type of
0.0293035779	the recent success
0.0293025994	the first attempt to
0.0292750652	by identifying
0.0292551340	at improving
0.0292311904	presented for
0.0292210532	than state of
0.0292032536	reduced from
0.0291794110	generalizability of
0.0291475994	both simulated and
0.0291467121	a hierarchical
0.0291386299	the sensitivity of
0.0290768807	work well
0.0290566534	a critical role in
0.0289575120	in comparison with
0.0289575120	an ensemble of
0.0289566534	a linear combination of
0.0289557537	mean accuracy
0.0289295560	most suitable
0.0289086898	a balanced
0.0289008393	stack of
0.0288715663	in order to provide
0.0288512894	value of
0.0288412845	orders of
0.0288392659	a group
0.0288388286	to prove
0.0287778193	to gain
0.0287402512	a fast and accurate
0.0287266977	a very challenging
0.0287233201	a significant amount of
0.0287205948	the semantic information
0.0287194386	scalable to
0.0287124618	a scalable
0.0286843183	to conduct
0.0286553134	for many applications
0.0286532925	based system
0.0286386299	the degree of
0.0286275892	the majority of
0.0286184452	struggle to
0.0286064077	an average of
0.0286064077	an image with
0.0286060145	to keep
0.0285956009	a long
0.0285863815	compression with
0.0285674199	the abundance
0.0285393680	the application of
0.0285165101	adopted to
0.0284612897	by predicting
0.0284360834	a novel method for
0.0284338125	the design of
0.0283820367	cells with
0.0283343454	in order to make
0.0282709339	developed by
0.0282416629	frameworks for
0.0282362607	the art 3d
0.0281518329	a good
0.0281230982	the experimental results show
0.0281122739	the benefits of
0.0280426913	a progressive
0.0280169348	the novelty of
0.0280051673	step in
0.0280025994	a comparative study of
0.0279877658	for analyzing
0.0279770305	and time consuming task
0.0279655835	a dice score of
0.0279499757	3d u
0.0279366012	the desired
0.0279139834	the difference between
0.0278937951	as input and
0.0278283264	features into
0.0278243545	the non local
0.0278130982	the type of
0.0278081822	to allow
0.0277892580	corresponding to
0.0277609225	a lack of
0.0277497410	the extraction of
0.0277452751	the gap
0.0277091133	to confirm
0.0277051432	the center of
0.0276479066	architecture with
0.0276021903	method does not
0.0275806501	a method to
0.0275772244	annotated with
0.0275354594	on synthetic and real
0.0275207328	module to
0.0274891602	a patch
0.0274691052	the spatial resolution of
0.0274475629	significance for
0.0274338125	the combination of
0.0274316534	the second one
0.0274115294	the likelihood of
0.0273958857	for evaluating
0.0273419397	to end
0.0273115998	utility of
0.0272945877	an overview of
0.0272933363	at different
0.0272898492	the perceived
0.0272816809	deployed to
0.0272795835	a new algorithm
0.0272682595	the prediction of
0.0271344336	3d convolutional
0.0270627689	microscopy with
0.0270442660	the spatial distribution of
0.0270438951	paradigm for
0.0270218377	the use of deep
0.0270117720	to examine
0.0270020231	to illustrate
0.0269483476	promise in
0.0269195457	built in
0.0268925186	center of
0.0268622739	this problem by
0.0268559479	a separate
0.0268168682	the automatic detection
0.0268130982	the assessment of
0.0268001978	as much
0.0267771038	real time on
0.0267616877	information at
0.0267591115	a novel approach for
0.0267109327	a specificity of
0.0266785852	a new state of
0.0266770527	necessary for
0.0266719764	for segmenting
0.0266396486	a patient's
0.0266122739	the proposed system
0.0265804044	a particular
0.0265707647	also outperforms
0.0265597303	on three different
0.0265566534	an important problem in
0.0265393680	the form of
0.0264947552	system for
0.0264318626	work provides
0.0263698396	the 3d cnn
0.0263416331	to highlight
0.0263164453	taken into
0.0263084126	to train and test
0.0263081822	to take
0.0262655585	different from
0.0262300156	commonly used for
0.0261753633	to follow
0.0261081822	need for
0.0261064077	a fast and
0.0260958359	and easy to
0.0260739413	a central
0.0260686096	and thus
0.0260674199	to define
0.0260533651	the inner
0.0260407137	a non local
0.0260356009	a conditional
0.0260035923	features from different
0.0259655092	visibility of
0.0258628190	the idea
0.0258559911	different noise
0.0258318827	to cover
0.0257864165	19 patients
0.0257609225	the availability of
0.0257603803	and hence
0.0257273924	both local
0.0257144265	developed to
0.0256813337	the first one
0.0256645436	supervision for
0.0256632905	a generative
0.0256362056	a sensitivity of
0.0256332264	a considerable
0.0256279204	the superiority
0.0256233851	the severity of
0.0256230982	the structure of
0.0256017418	a novel attention
0.0255284041	to approximate
0.0255232822	a variety
0.0255167653	enough for
0.0254692069	a desired
0.0254578684	u net for
0.0254577180	a valuable
0.0253922086	calculated for
0.0253871315	limitation of
0.0253648013	all available
0.0253580799	structures from
0.0253378799	especially in
0.0252802205	the most widely
0.0252728975	the spatial distribution
0.0252421859	an array
0.0252209787	to track
0.0251828483	a hardware
0.0251544621	factors such
0.0251464316	the estimation of
0.0251450815	management of
0.0251443705	progression of
0.0251386299	the correlation between
0.0251359327	a crucial step in
0.0250808723	try to
0.0250765684	a hot
0.0250635181	novel method
0.0250493858	the case
0.0250362277	the development
0.0249453367	described in
0.0249265415	novel framework
0.0249139834	the contribution of
0.0248930086	a cascade
0.0248922086	addressed in
0.0248721450	available for
0.0248663436	not rely on
0.0248636031	an accuracy
0.0248434567	network without
0.0248045405	best possible
0.0247798608	the above
0.0247561837	novel graph
0.0247497410	without using
0.0247416629	transforms for
0.0247233201	two sets of
0.0246033345	and reproducibility of
0.0245630915	distance from
0.0245520408	a serious
0.0245502681	an image into
0.0245373355	a novel multi
0.0245326202	not available in
0.0245119871	the evaluation of
0.0244966490	the location of
0.0244916629	published in
0.0244877658	for reconstructing
0.0244015518	by pathologists
0.0243844194	the latent space of
0.0243775994	this paper focuses on
0.0243637214	making use
0.0243224121	causes of
0.0242972328	role of
0.0242743261	to deal
0.0242630915	embedded with
0.0242510028	a benchmark
0.0242407443	overall accuracy of
0.0242180854	the 3d shape
0.0242133915	novel deep
0.0242005488	images from different
0.0241783994	a certain
0.0241738555	the novel coronavirus
0.0241531095	fields from
0.0241502443	formulation for
0.0241268481	difficulty in
0.0241064077	to focus on
0.0240718963	necessary to
0.0240591083	the first two
0.0240429179	the convergence of
0.0240297208	found to
0.0240264191	directions for
0.0239979755	to offer
0.0239683428	the art methods for
0.0239303614	detection through
0.0239123136	the selection of
0.0238950096	\ \
0.0238704407	a nonlinear
0.0238467864	scans of
0.0238185704	allow for
0.0238095845	a need for
0.0237924448	an alternative to
0.0237764191	exploited in
0.0237741108	the user's
0.0237555305	a result of
0.0237540844	a machine
0.0237507706	the possibility to
0.0236955530	an ablation
0.0236745301	perspective of
0.0236539226	results on two
0.0236338063	scenes from
0.0236254230	variance of
0.0236152460	by increasing
0.0236046879	designed by
0.0235995213	the notion
0.0235760259	the detection of covid 19
0.0235638827	possibility to
0.0235254230	probability of
0.0235174373	an effective way to
0.0235174373	better understanding of
0.0235059631	the fastmri
0.0234581787	tuned on
0.0234457335	appear in
0.0233900104	investigated for
0.0233770516	for measuring
0.0233343666	a new data
0.0233187204	for studying
0.0232877527	the appearance of
0.0232829210	a review of
0.0232429440	a new model
0.0232170006	to perform well
0.0232169348	a fraction of
0.0231860556	many computer
0.0231766679	in response to
0.0231699217	to give
0.0231618458	first time
0.0231342416	details from
0.0231310748	different acquisition
0.0231126765	designed as
0.0230806501	the applicability of
0.0230429179	the calculation of
0.0229892709	both psnr and
0.0229829210	the idea of
0.0229740001	consumption of
0.0229495877	an algorithm for
0.0229320845	the amount of data
0.0229311806	on in vivo
0.0228840344	mainly due to
0.0228775994	the inclusion of
0.0228693578	interface for
0.0228655835	the incorporation of
0.0228655835	the notion of
0.0228579002	for training and testing
0.0228512894	interest in
0.0228299824	the spread of
0.0227943478	to see
0.0227764191	technologies for
0.0227724217	correct for
0.0227717829	burden of
0.0227338125	the power of
0.0227261570	applications due to
0.0226989168	the dimensionality of
0.0226692660	this results in
0.0226322501	this issue by
0.0225813306	most state of
0.0225671458	possible to
0.0225544728	capability to
0.0225510860	the requirement of
0.0225384766	then applied to
0.0225232065	free from
0.0225204565	to take advantage of
0.0225051432	to adapt to
0.0224983201	the unavailability of
0.0224966490	the benefit of
0.0224349262	the characteristics of
0.0224344800	synthesis from
0.0224316534	the gold standard for
0.0224316534	then used as
0.0224008393	validity of
0.0223775994	this paper aims to
0.0223671723	an end
0.0223610860	the sum of
0.0223074442	the retrieved
0.0223028723	the area of
0.0222957036	the difficulty
0.0222950611	of interests
0.0222448627	the creation of
0.0222448627	the extent of
0.0222177527	instead of using
0.0221837387	function for
0.0221795560	new perspective
0.0221788129	both quantitatively and
0.0221750361	various datasets
0.0221271508	the abdomen
0.0221064077	the integration of
0.0220983201	an application to
0.0220429179	the evolution of
0.0220429179	the diversity of
0.0220354145	seek to
0.0219989888	accuracy while
0.0219719632	a framework for
0.0219601814	discrimination of
0.0219416629	explanation of
0.0218937951	the position of
0.0218925981	used by
0.0218811467	other applications
0.0218800662	the mean absolute
0.0218762199	by using only
0.0218710726	the encoder and decoder
0.0218575454	the goal
0.0218168697	information such as
0.0217909385	an algorithm based on
0.0217908693	sample from
0.0217221808	to separate
0.0217005512	even with
0.0216871232	the progression of
0.0216860556	various computer
0.0216722036	the merits of
0.0216502681	to generate new
0.0216251915	considered in
0.0216168295	to noise
0.0216123159	available on
0.0215169348	an application of
0.0215077671	testing on
0.0215017779	relevance of
0.0214937951	the human visual system
0.0214646050	the need
0.0214596886	better visual
0.0214176657	both local and
0.0213717571	3d medical
0.0213458016	a vital
0.0213236774	an optimization
0.0213226328	using data from
0.0213107222	the feasibility
0.0213052966	the potential for
0.0212101814	prognosis of
0.0211867297	work aims to
0.0211789802	the area under
0.0211750361	better accuracy
0.0211656811	first attempt to
0.0211495877	the introduction of
0.0211419951	the superior performance of
0.0211271508	for recovering
0.0211249262	the capability of
0.0211101373	outside of
0.0210983201	an increase in
0.0210881331	often used
0.0209875994	a new method for
0.0209634766	the usefulness of
0.0209634766	the construction of
0.0209299858	an order of
0.0209242183	a part of
0.0209227735	cause of
0.0209161890	a predictive
0.0208811467	better reconstruction
0.0208718099	a factor of
0.0208671386	to correct
0.0208348821	each time
0.0208247743	contrast to
0.0207996216	commonly used to
0.0206718068	the definition of
0.0206281674	to account
0.0205890870	a closed
0.0205428866	a novel framework for
0.0205095845	the depth of
0.0205051401	the variance of
0.0204903305	a novel deep neural
0.0204876058	for future work
0.0204640181	dimensionality of
0.0204581787	limitation by
0.0204365336	the capability to
0.0203734693	taken with
0.0203490777	used in many
0.0203057871	a novel self
0.0203026209	combination with
0.0202101814	effort in
0.0201953291	not well
0.0201916629	flexibility of
0.0201692660	a mixture of
0.0201557455	done in
0.0201271508	a massive
0.0201268481	encoded in
0.0201155023	many different
0.0201064077	in patients with
0.0200983201	the rise of
0.0200384766	an approach to
0.0200319878	the best
0.0200051401	the robustness and
0.0200022273	patches from
0.0200021508	for obtaining
0.0199064943	implemented with
0.0198718099	then used to
0.0198718099	the recent success of
0.0198579002	the use of deep learning
0.0198252432	constructed to
0.0198063023	whole image
0.0197636372	validated with
0.0197237521	captured with
0.0197095845	and robustness of
0.0197036527	a series
0.0196860556	not consider
0.0196813337	3d reconstruction of
0.0196699217	to do
0.0196405352	used in clinical
0.0196165593	to state of
0.0196130915	jointly with
0.0196040616	not able
0.0196033345	and specificity of
0.0196033345	the generator to
0.0195666746	to outperform
0.0195442660	the outbreak of
0.0194892852	problem due to
0.0194830808	of interest in
0.0194797649	the implementation of
0.0194517779	factor for
0.0194316534	the visual quality of
0.0194124928	online at
0.0193727223	not take
0.0193726185	task due to
0.0193626140	both quantitative and
0.0192790444	feasible to
0.0192661145	both spatial and
0.0192339203	a better understanding
0.0192169348	the principle of
0.0190983201	a new approach for
0.0190930656	method allows
0.0190852444	factor of
0.0190829179	the management of
0.0190338846	found in
0.0190209327	a limited number of
0.0190112627	a simple but
0.0189970845	this paper provides
0.0189344316	widely used to
0.0189113846	to consider
0.0188655835	the relevance of
0.0188655835	the flexibility of
0.0188542660	more robust to
0.0188233396	location of
0.0188231493	way to
0.0188128539	a plug
0.0188028723	the risk of
0.0188025994	to correct for
0.0187983201	a new framework for
0.0187956122	the role
0.0187473168	the limitations of
0.0187000080	a semi
0.0186923480	then applied
0.0186923480	several recent
0.0186718099	a new approach to
0.0186149420	the first attempt
0.0185889563	a base
0.0185688219	output of
0.0185604617	the recovery of
0.0185095845	the behavior of
0.0184388702	a novel method to
0.0184388702	a generalization of
0.0184316534	an important task in
0.0184115294	the strength of
0.0183651401	a solution to
0.0183604617	the volume of
0.0183548692	a significant improvement in
0.0183280635	an analysis of
0.0183130982	the identification of
0.0183012993	a stack
0.0183012937	off between
0.0182790570	the input of
0.0182020110	the majority
0.0181869562	speed of
0.0181709685	group of
0.0181576213	a parametric
0.0181123904	the properties of
0.0180983201	a new algorithm for
0.0180678356	the absence
0.0180640181	difficulty of
0.0180602435	content from
0.0180442660	to achieve better
0.0180384766	the emergence of
0.0180215358	a mapping between
0.0179661212	explored in
0.0179517779	helps to
0.0179451094	reported in
0.0179295560	most popular
0.0179053021	results in terms of
0.0178868176	method over
0.0178693578	literature on
0.0178537898	the difficulty in
0.0178078439	a test set of
0.0177575517	the improvement of
0.0177169768	distillation for
0.0176956099	the ability
0.0176415593	an image to
0.0176271508	to formulate
0.0176062205	a study of
0.0175885523	not able to
0.0175146670	a novel approach to
0.0174666372	both synthetic and
0.0174417037	found on
0.0173480004	a collection of
0.0173480004	the probability of
0.0172930219	each video
0.0172109327	a large dataset of
0.0171250732	the field of machine
0.0171184549	but also to
0.0171150680	new method
0.0170853473	a novel algorithm
0.0170604617	the deployment of
0.0170534653	investigated in
0.0170442660	a family of
0.0170346224	and sometimes
0.0170338846	useful in
0.0170204565	a variant of
0.0170204565	a study on
0.0169966490	the perspective of
0.0169917075	a refined
0.0169894713	the novelty
0.0169635182	sufficient to
0.0169562247	a pretrained
0.0169322501	to aid in
0.0169095560	both visually
0.0168940815	and up to
0.0168765756	the left
0.0168627753	computer vision tasks such
0.0168542660	to generalize to
0.0168488426	topology of
0.0168331340	an error
0.0168100217	basis of
0.0168052966	a comparison of
0.0167627899	to employ
0.0166797823	a smartphone
0.0166745301	defined in
0.0166346326	the rise
0.0165823023	non imaging
0.0165152463	and testing on
0.0165024385	the generalizability of
0.0164706509	for in vivo
0.0164106082	aim of
0.0162924860	first step in
0.0162718068	the source code of
0.0162385629	to describe
0.0162373517	from chest
0.0162287620	expensive to
0.0162197018	the development of deep
0.0162121114	allows to
0.0161977357	search for
0.0161912017	the nature of
0.0161877997	the concept
0.0161789802	a robust and
0.0159994498	the problem as
0.0159291692	the first to
0.0159095560	both quantitatively
0.0158144651	a novel 3d
0.0158077594	to include
0.0158028723	the choice of
0.0157974927	principle of
0.0157047542	a recurrent
0.0156937951	the generalization of
0.0156322501	the popularity of
0.0155781961	an approach for
0.0155534386	many real
0.0155257978	approach does
0.0153728070	the quantification of
0.0152479063	a novel convolutional neural
0.0152168308	as input to
0.0151604617	the interpretation of
0.0151474182	all over
0.0151123904	the proposed method on
0.0150566061	a statistical
0.0150442660	a challenge for
0.0150442660	a cohort of
0.0150170245	on images from
0.0149384734	to serve as
0.0149242183	the uncertainty in
0.0148429014	new framework
0.0146983260	for guiding
0.0146944194	the limitation of
0.0146858577	estimation from
0.0146836912	of research in
0.0146633157	in case of
0.0146474434	novel method for
0.0146415856	available dataset
0.0145497474	and efficiency of
0.0144762512	a form of
0.0144762512	to assist in
0.0143536229	presented to
0.0143288525	a region of
0.0142988233	both in terms of
0.0142370130	a novel neural network
0.0141678768	enough to
0.0141322381	both qualitatively and
0.0141247937	a relatively
0.0141184549	for reconstruction of
0.0141060510	appropriate for
0.0140766883	works in
0.0140747556	for diagnosis of
0.0140636473	the same model
0.0140503340	a new method to
0.0140221240	the region of
0.0139994498	the capacity of
0.0139291692	the understanding of
0.0139291692	the representation of
0.0138271532	the existence
0.0138239183	this type
0.0137258193	to learn more
0.0137155871	the inference time
0.0137039909	an order
0.0137036912	a coarse to
0.0136841542	3d brain
0.0136819129	of view of
0.0136624679	also able to
0.0136436673	on data from
0.0135810711	many cases
0.0135787570	the outbreak
0.0135662864	a neural network to
0.0135610711	both simulated
0.0135442050	a novel convolutional
0.0135135040	a tool for
0.0134944019	costly to
0.0134734622	of objects in
0.0133856069	the rate of
0.0133584442	the input to
0.0133503579	using deep learning for
0.0133422298	an image from
0.0132551340	for calculating
0.0129994498	the speed of
0.0129620928	a challenging and
0.0129384734	the demand for
0.0129384734	in terms of accuracy and
0.0129291692	a model for
0.0128929769	a framework to
0.0128271532	to serve
0.0127804758	a resource
0.0127344757	both visual
0.0126063102	for identification of
0.0125974233	the 3d u
0.0124620928	the imaging system
0.0124484622	the reduction of
0.0124180094	a new deep
0.0123623511	the modeling of
0.0123422298	the variability of
0.0122679063	for 3d point
0.0122479063	for 3d object
0.0121954664	a combination
0.0121887355	and treatment of
0.0121474182	use only
0.0120443390	a bottleneck
0.0118265772	for dealing
0.0118183676	the efficacy
0.0117989943	a voxel
0.0116363309	the european
0.0115995897	both psnr
0.0115830808	in computer vision and
0.0113422298	a dataset with
0.0112891074	the knowledge of
0.0112891074	the model with
0.0112072540	the distance between
0.0111310748	the isic
0.0110729530	novel approach for
0.0106418395	the overall accuracy
0.0106104988	an increase
0.0105810711	new type
0.0105589048	novel approach to
0.0105539842	the diagnosis and treatment
0.0105477299	for classification of
0.0105315156	better performance in
0.0103093156	the application of deep
0.0103048728	for detection of
0.0102864248	to other methods
0.0102183419	novel technique
0.0101623248	the inclusion
0.0101310748	to observe
0.0101302587	used to model
0.0098541393	an ill
0.0098329530	an algorithm to
0.0097551144	system based on
0.0095405874	a method based on
0.0095135040	and quantification of
0.0092063102	an accurate and
0.0091623248	to contribute
0.0091214088	possible by
0.0088627241	a technique to
0.0088572652	new approach for
0.0085506310	novel framework for
0.0085315156	the similarity between
0.0083833136	to contain
0.0082479063	the number of training
0.0082199182	in applications such as
0.0082072540	the capabilities of
0.0082063102	this method to
0.0081117122	seen in
0.0078329530	with application to
0.0075997381	novel method to
0.0075974233	a proof of
0.0074413231	help to
0.0071928912	for patients with
0.0068751241	a new state
0.0068644067	the signal to
0.0062003645	the highest
0.0061545779	to focus
0.0060679063	the success of deep
0.0056681145	interest from
