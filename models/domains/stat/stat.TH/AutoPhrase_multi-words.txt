0.9661941116	kalman filter
0.9650375690	instrumental variable
0.9645375202	dynamical systems
0.9640512567	principal components
0.9638994726	neural network
0.9597064137	empirical bayes
0.9589428675	differential privacy
0.9582060022	neural networks
0.9570676703	support recovery
0.9567443822	total variation
0.9535185698	hypothesis testing
0.9531552537	wasserstein distance
0.9531427008	markov chain monte carlo
0.9527505632	white noise
0.9511169262	benford's law
0.9511080596	community detection
0.9509158426	mutual information
0.9507027333	supervised learning
0.9497034655	compressive sensing
0.9495177926	phase transitions
0.9494910563	social networks
0.9494578370	fractional brownian motion
0.9490062809	fisher information
0.9490024089	hilbert spaces
0.9486475536	phase transition
0.9485490549	random walk
0.9482066465	deep neural networks
0.9478881232	reproducing kernel
0.9478238519	causal inference
0.9478130783	feature selection
0.9476346036	gradient descent
0.9468010719	phase retrieval
0.9467870963	concentration inequalities
0.9453249859	markov chain
0.9452945893	causal effects
0.9452292899	riemannian manifold
0.9451746991	likelihood ratio
0.9451508215	machine learning
0.9450554798	correlation coefficient
0.9450425213	moving average
0.9447483266	anomaly detection
0.9446191227	negative binomial
0.9442788451	compound poisson
0.9441829826	treatment effect
0.9440376626	granger causality
0.9440219833	higher criticism
0.9439541152	particle filter
0.9428433898	algebraic geometry
0.9428020206	optimal transport
0.9426136389	support vector machines
0.9424773683	metric spaces
0.9421213307	importance sampling
0.9420991331	exponential family
0.9419716627	exponential families
0.9408574497	quadratic forms
0.9408045424	instrumental variables
0.9406295217	hilbert space
0.9404752175	random forest
0.9404254248	deep learning
0.9403853247	semidefinite programming
0.9403709204	ridge regression
0.9401980704	statistical physics
0.9398256972	relative entropy
0.9398079250	clinical trials
0.9397343542	shannon entropy
0.9394901325	dimension reduction
0.9392387405	compressed sensing
0.9384030822	confidence regions
0.9381105049	spectral clustering
0.9379053928	markov chains
0.9377513754	bayesian inference
0.9376362958	false discovery rate
0.9369599760	uncertainty quantification
0.9368420066	bayes factor
0.9366321903	potential outcomes
0.9366320309	brownian bridge
0.9364315003	sensitivity analysis
0.9362808408	persistence diagrams
0.9362575201	confidence interval
0.9359440434	smoothing spline
0.9354600536	logistic regression
0.9353301554	bayes factors
0.9351229551	reproducing kernel hilbert space
0.9350713114	false discovery
0.9349174196	conditional independence
0.9348541669	inverse problems
0.9344074387	experimental design
0.9341692470	stochastic gradient descent
0.9339680207	principal component
0.9339641041	oracle inequalities
0.9336878469	radon transform
0.9335035114	model selection
0.9334029671	propensity score
0.9332073167	principal component analysis
0.9331026324	dirichlet process
0.9329901309	random vectors
0.9329594285	confidence bands
0.9328069652	contextual bandits
0.9326544840	stochastic process
0.9326324545	reinforcement learning
0.9324304056	covariance matrix
0.9323007236	covariance matrices
0.9322918839	power law
0.9321278555	lie groups
0.9317880347	variable selection
0.9314154686	gene expression
0.9312381226	likelihood ratios
0.9310771084	proportional hazards
0.9309476300	unit root
0.9305346431	wishart matrices
0.9303251299	stochastic processes
0.9302975765	sufficient dimension reduction
0.9302764091	tail index
0.9301305767	convex optimization
0.9299969855	projection pursuit
0.9299968391	stochastic gradient
0.9295674743	unsupervised learning
0.9292671826	simulated annealing
0.9290969850	matrix completion
0.9290867995	fused lasso
0.9288751771	basis pursuit
0.9287360028	maximum likelihood
0.9282816742	optional stopping
0.9278145693	nonparametric regression
0.9277768848	armed bandits
0.9269893425	partially observed
0.9268838113	commutative algebra
0.9268770162	mixture model
0.9266192709	universally consistent
0.9264241676	persistent homology
0.9263908810	nuclear norm
0.9262437697	spectral density
0.9260665293	credible sets
0.9260479982	fourier transform
0.9257109508	lecture notes
0.9254256433	moderate deviation
0.9253832291	statistical learning
0.9253286193	fdr control
0.9253176044	edgeworth expansion
0.9252977306	brownian motion
0.9252946522	unit roots
0.9252473434	nearest neighbors
0.9251559218	differentially private
0.9251281994	sensitivity indices
0.9251258303	statistical inference
0.9249795342	gaussian process
0.9249780462	correlation matrices
0.9249684721	differential geometry
0.9248708834	breast cancer
0.9247184713	simpson's paradox
0.9247121234	approximate message passing
0.9246992839	random walks
0.9246290738	banach spaces
0.9246135625	average treatment effect
0.9244553124	persistence diagram
0.9242514986	rare events
0.9242170705	central limit theorem
0.9242133054	density estimation
0.9237765412	stochastic differential equations
0.9235842305	signal processing
0.9235648260	message importance
0.9234346434	iterated logarithm
0.9233335726	particle filters
0.9232280535	hidden markov models
0.9231057586	regularly varying
0.9230317806	treatment effects
0.9229794864	changepoint detection
0.9228709553	isotonic regression
0.9226595832	diffusion processes
0.9225226358	multiple testing
0.9225107102	riemannian manifolds
0.9225101722	active learning
0.9224933043	confidence intervals
0.9219543144	frobenius norm
0.9219041834	stochastic block models
0.9218727493	unobserved heterogeneity
0.9217487222	totally positive
0.9215281809	penalized likelihood
0.9214744680	breakdown point
0.9212949661	random fields
0.9212228771	clinical trial
0.9211702402	directed acyclic graphs
0.9211177002	infinitely divisible
0.9208732098	langevin dynamics
0.9208514276	kalman filters
0.9206838984	square root
0.9205482589	mixture models
0.9202389772	microstructure noise
0.9201064309	stochastic block model
0.9200515603	risk management
0.9200302412	akaike information criterion
0.9199578008	measurement error
0.9199488006	factorial designs
0.9198590739	gibbs sampling
0.9197798444	cumulative distribution function
0.9196758405	order statistics
0.9195457565	hard thresholding
0.9194877705	intrinsic volumes
0.9194304560	euler characteristic
0.9193228162	large deviations
0.9188276987	ordinary differential equations
0.9188037321	big data
0.9185704995	precision matrices
0.9184497791	stopping times
0.9183529167	smallest eigenvalue
0.9183288329	random forests
0.9182218560	inverse probability weighting
0.9178608383	ising models
0.9177745754	measurement errors
0.9176567483	factor analysis
0.9176300003	random graphs
0.9175727094	local minima
0.9174190521	sparse pca
0.9171654747	covariance operators
0.9169567108	complex valued
0.9169110385	summary statistics
0.9168021498	bayesian nonparametric
0.9167694097	stochastic optimization
0.9166696078	generalized linear models
0.9165888604	statistical mechanics
0.9165522946	sharpe ratio
0.9165193960	expected shortfall
0.9163557496	reproducing kernel hilbert
0.9158840378	randomized experiments
0.9157214131	spot volatility
0.9155082349	point processes
0.9154910267	auxiliary information
0.9152765198	shrinkage priors
0.9151458901	social network
0.9151185348	compactly supported
0.9151184332	wild bootstrap
0.9150585195	failure rate
0.9150020021	orthogonal arrays
0.9149339882	brownian motions
0.9148382513	dantzig selector
0.9147358708	random matrices
0.9147271559	distributionally robust
0.9146285506	reproducing kernel hilbert spaces
0.9145212239	lower bound
0.9144995291	null hypothesis
0.9143601758	kronecker product
0.9139636762	nuisance parameters
0.9139304159	markov random fields
0.9138610108	long memory
0.9138606160	gaussian noise
0.9135823814	gibbs samplers
0.9133417041	riemannian geometry
0.9133146054	irrepresentable condition
0.9132550491	bias correction
0.9132402507	panel data
0.9131732447	quadratic form
0.9130878890	gaussian processes
0.9125629151	wasserstein distances
0.9122764729	hazard rate
0.9122571070	sliced inverse regression
0.9122324835	gradient flow
0.9121865551	phylogenetic trees
0.9121620726	oracle property
0.9120340091	le cam
0.9119083501	mahalanobis distance
0.9117593142	random matrix
0.9117193363	contingency tables
0.9116766882	conditional expectation
0.9115952806	stationary processes
0.9115589002	maximum likelihood estimation
0.9115074030	normalizing constants
0.9113542279	density function
0.9113523305	doubly stochastic
0.9113426720	spike train
0.9112251960	minimax rates
0.9109582728	operator norm
0.9109100193	collaborative filtering
0.9108203157	average treatment effects
0.9108068503	cholesky decomposition
0.9107960712	competing risks
0.9107689439	gaussian graphical models
0.9106746400	markov chain monte
0.9105415156	topological data analysis
0.9103067037	false alarm
0.9099986497	block maxima
0.9097339822	stein's lemma
0.9097116596	fourier transforms
0.9097038368	low rank
0.9096588330	bayesian information criterion
0.9096243037	bayesian inversion
0.9095187804	fractional brownian
0.9094803827	locally stationary
0.9094357846	posterior distributions
0.9094057024	decision theory
0.9092672542	central limit theorems
0.9092489367	species sampling
0.9091023622	conjugate prior
0.9084634659	empirical process
0.9083163642	domination number
0.9080853313	halfspace depth
0.9080594972	trend filtering
0.9079637736	empirical likelihood
0.9077524710	null hypotheses
0.9075620414	frequency domain
0.9075055151	missing data
0.9075008569	scoring rule
0.9074831380	graphical models
0.9073301448	variable screening
0.9071780770	elastic net
0.9068162486	discovery rate
0.9067615275	linear regression
0.9065596972	cube root
0.9065575714	dimensionality reduction
0.9062632070	ordinary differential equation
0.9058828752	infinite divisibility
0.9058774028	empirical risk minimization
0.9057766850	random matrix theory
0.9056916806	false discovery proportion
0.9055663931	positive definite
0.9055034338	scoring functions
0.9054971645	higher order
0.9054343407	fading channels
0.9054247338	random field
0.9053430728	algebraic statistics
0.9053326644	early stopping
0.9052253443	discretely sampled
0.9052067664	pairwise comparisons
0.9051798527	sliding blocks
0.9051608149	likelihood ratio test
0.9050568689	game theoretic
0.9050200917	point clouds
0.9049987765	conformal prediction
0.9049900566	message passing
0.9048696786	test statistic
0.9048265591	normal distribution
0.9047436059	quantile regression
0.9045269256	empirical risk minimizers
0.9045024779	kendall's tau
0.9044851736	projected gradient descent
0.9043763281	structural breaks
0.9043364494	planted clique
0.9042851440	doubly robust
0.9042736971	covariance functions
0.9042028288	approximate bayesian computation
0.9040442045	wasserstein barycenters
0.9039194000	filter bank
0.9037713203	maximum likelihood estimator
0.9035657479	free energy
0.9035654650	saddle points
0.9033768316	information theoretic
0.9029364702	stochastic blockmodel
0.9026160113	outlier detection
0.9024602848	posterior contraction
0.9023880317	electronic commerce
0.9021390989	proper scoring rules
0.9018683045	control variates
0.9018402009	brownian semistationary
0.9018204561	variational inference
0.9016211103	monte carlo
0.9015424277	contingency table
0.9014623433	latent position
0.9013381272	kernel density estimation
0.9012538822	explanatory variables
0.9010218534	parameter estimation
0.9009365855	information geometry
0.9007791984	convex cone
0.9007437141	langevin diffusion
0.9005049255	convex programming
0.9005046736	discretely observed
0.9004965986	linear program
0.9003980308	posterior consistency
0.9002326635	kl divergence
0.9001963124	lower bounds
0.9001312175	randomly reinforced
0.9001035738	false discoveries
0.9000405162	partial differential equation
0.8999726688	poisson process
0.8999438869	metric space
0.8999358899	integer valued
0.8999177734	upper bound
0.8999152727	differential equations
0.8996890826	signal detection
0.8996488187	data augmentation
0.8996267231	differential equation
0.8994756616	expectation maximization
0.8994067598	empirical processes
0.8993707854	probability density
0.8991413234	data analysis
0.8991092187	stopping rules
0.8990130765	characteristic function
0.8989572248	absolute deviation
0.8988451107	regular variation
0.8988348540	gaussian mixtures
0.8987202971	change points
0.8986900567	key words
0.8985645682	fractionally integrated
0.8983334846	stock market
0.8981978152	loss function
0.8981123261	bregman divergences
0.8980879117	renewal processes
0.8980689837	convex bodies
0.8980660216	malliavin calculus
0.8979695424	interacting particle
0.8979405778	selective inference
0.8978407420	signal recovery
0.8977787069	linear algebra
0.8977113273	deep neural
0.8975704978	weak convergence
0.8974299910	chaos expansion
0.8973668609	bahadur representation
0.8972530628	survival analysis
0.8972249120	vector quantization
0.8970317595	information theory
0.8969986438	discrete distributions
0.8969734527	multiplier bootstrap
0.8969394374	heavy tails
0.8968744584	fourth moment
0.8967799688	ising model
0.8967563311	autoregressive processes
0.8967471850	mass spectrometry
0.8964807505	noninformative priors
0.8964039176	largest eigenvalue
0.8962983955	knockoff filter
0.8960864440	markov equivalence
0.8958285641	large deviation
0.8957663791	bayes risk
0.8956926427	pearson's correlation
0.8956304312	regret bound
0.8955773936	convex sets
0.8955392418	pattern recognition
0.8955076201	discriminant analysis
0.8954737878	matrix variate
0.8951958442	gaussian mixture
0.8951749838	piecewise deterministic markov
0.8951349277	false positives
0.8950474926	tensor completion
0.8949114263	spherically symmetric
0.8948075183	branching process
0.8944460050	variational bayes
0.8944449100	central limit
0.8940563668	stochastic volatility
0.8939548821	dynamic programming
0.8937022517	bregman divergence
0.8936011183	coordinate ascent
0.8932653135	dictionary learning
0.8931971374	pareto distribution
0.8931741615	elliptically contoured
0.8930312292	upper bounds
0.8929958985	probability distributions
0.8929052242	public health
0.8927097306	relu nets
0.8926937145	point process
0.8926584082	partial correlations
0.8926538469	confidence sets
0.8926039655	elliptical distributions
0.8922406176	thompson sampling
0.8921941433	change point
0.8921661795	latin hypercube
0.8918689427	stopping rule
0.8917331999	benign overfitting
0.8916701053	gibbs sampler
0.8916115985	sparse recovery
0.8915714089	decision theoretic
0.8914305569	square integrable
0.8914169153	maximum entropy
0.8913365920	variance reduction
0.8911363494	moderate deviations
0.8911022392	independent component analysis
0.8910885128	record values
0.8910588987	unmeasured confounding
0.8910555265	functional data
0.8909227213	partially linear
0.8908846550	kernel ridge regression
0.8908689994	le cam's
0.8907943192	pickands dependence
0.8907808854	detection delay
0.8907599182	linear programming
0.8907313062	convex relaxation
0.8907247118	invariance principle
0.8906428741	image processing
0.8906074708	preliminary test
0.8904384233	chi squared
0.8903784095	orthogonal polynomials
0.8903583781	elliptically symmetric
0.8902650537	multiple hypothesis testing
0.8902026261	besov spaces
0.8901853062	banach space
0.8901052783	spearman's rho
0.8900597761	standard deviation
0.8900078129	change point detection
0.8898644839	serial dependence
0.8898540492	profile likelihood
0.8898287864	posterior concentration
0.8898018628	closed form
0.8896232511	generalized pareto
0.8893866147	united states
0.8893105230	rademacher complexity
0.8891733574	nearest neighbor
0.8890324947	group testing
0.8890242211	determinantal point processes
0.8888470384	hinge loss
0.8886322902	semicircle law
0.8884389523	objective priors
0.8883994824	laplace transform
0.8883710885	estimating equations
0.8882511757	stein's method
0.8882492493	long term
0.8881479573	wasserstein metric
0.8881209290	optimal design
0.8880444317	scoring rules
0.8880086113	singular values
0.8879575833	weakly dependent
0.8879103597	hidden markov
0.8875260926	metropolis adjusted langevin
0.8875219530	log concave
0.8875196957	majority voting
0.8875179722	heat kernel
0.8874794102	sample splitting
0.8870434835	adaptive sensing
0.8869898731	toric ideal
0.8868901659	quickest change detection
0.8868313264	supremum norm
0.8868230794	autoregressive models
0.8868092724	random variables
0.8862222780	conjugate priors
0.8862027137	stein's unbiased risk
0.8861330819	asset price
0.8860445353	euclidean space
0.8860057183	restricted eigenvalue
0.8859359835	decision making
0.8859072011	context tree
0.8859055029	data science
0.8855645818	composite likelihood
0.8855524420	lebesgue measure
0.8854365756	hellinger distance
0.8852521124	conjugate gradient
0.8852305306	cox model
0.8852182805	sobol indices
0.8850984685	small area
0.8850421760	fusion center
0.8849991671	computationally tractable
0.8849536597	hypergeometric distribution
0.8848827974	integer programming
0.8848489368	em algorithm
0.8848119504	computationally efficient
0.8847411320	graph laplacians
0.8845426329	submatrix localization
0.8845232360	positive definiteness
0.8844168073	besov bodies
0.8843324529	stratified random sampling
0.8842187904	partially identified
0.8841392622	geometric ergodicity
0.8841301878	massive data
0.8839849429	support vector machine
0.8839676951	mediation analysis
0.8839557307	false positive
0.8839413642	reject option
0.8839277661	jeffreys prior
0.8839274992	change detection
0.8839180644	tail dependence
0.8837947519	outage probability
0.8837072514	regression function
0.8835226745	distance correlation
0.8832601621	random censorship
0.8832405793	probability theory
0.8832280996	edgeworth expansions
0.8832274705	conditional quantile
0.8830820502	random walk metropolis
0.8827831510	block bootstrap
0.8826692448	censored data
0.8826339260	max stable
0.8825858297	betti numbers
0.8825770267	wavelet coefficients
0.8824952673	double descent
0.8824946350	asset pricing
0.8824743750	coordinate descent
0.8824653449	real world
0.8821654765	covariance estimation
0.8821645538	hurst index
0.8821578591	large scale
0.8820825026	group lasso
0.8820653506	policy evaluation
0.8819847329	minimum aberration
0.8817872031	factor models
0.8817825908	random variable
0.8816667017	level sets
0.8816357904	preferential attachment
0.8815937038	saddle point
0.8815654210	bayesian network
0.8815169389	bandwidth selection
0.8814285997	spiked wigner
0.8812745853	linear models
0.8812745075	incomplete rankings
0.8810902545	individualized treatment
0.8809734475	real valued
0.8807810765	convergence rates
0.8807111997	categorical data
0.8805151239	partial sum
0.8805126794	nonlinear regression
0.8804810761	theoretical foundations
0.8802771845	strongly convex
0.8802238404	sample complexity
0.8801769064	van der
0.8801569289	filtered derivative
0.8800703008	asymptotically minimax
0.8799486541	heat equation
0.8799485144	applied mathematics
0.8798316515	waiting times
0.8798172646	normal distributions
0.8797591864	confidence region
0.8796680489	stock exchange
0.8794229247	real line
0.8790928712	contiguous alternatives
0.8790556799	generalization error
0.8790361165	long range dependent
0.8790162094	optimization problems
0.8789375756	scan statistic
0.8788306075	odds ratio
0.8787463135	gaussian random fields
0.8787336734	bayesian predictive densities
0.8787117358	condition number
0.8786030280	ultrahigh dimensional
0.8784308892	matrix factorization
0.8784083392	wavelet thresholding
0.8782163546	belief propagation
0.8781326721	inverse regression
0.8781147896	distribution free
0.8780353288	taylor expansion
0.8778812657	` `
0.8778496142	risk minimization
0.8777772548	semiparametric efficiency
0.8776704215	simulated data
0.8774967698	spatially inhomogeneous
0.8774545967	distance covariance
0.8774504160	asset prices
0.8773296189	piecewise constant
0.8772991321	causal discovery
0.8772206809	block thresholding
0.8772054969	blind source separation
0.8771823655	asymptotic optimality
0.8771259634	minimax optimal
0.8770363816	inclusion probabilities
0.8770237719	stochastic approximation
0.8768706223	component analysis
0.8768386257	sequential monte carlo
0.8768101745	global sensitivity analysis
0.8767144047	fourth moments
0.8764773952	linear systems
0.8764434712	information criteria
0.8762333148	data streams
0.8761552928	asymptotic efficiency
0.8760416327	impulse response
0.8755889998	adjustment sets
0.8755275366	fano's inequality
0.8755218129	stock returns
0.8754826447	trek separation
0.8754538231	jump activity
0.8754518062	bilinear forms
0.8752763007	magnetic resonance imaging
0.8750555426	stratified sampling
0.8749490128	hierarchical models
0.8747269125	confidence band
0.8747260027	control charts
0.8747236655	bayes estimators
0.8746672837	directed acyclic
0.8745172362	generating function
0.8743277618	akaike's information
0.8742816184	generative models
0.8742759512	langevin monte carlo
0.8742753302	vector valued
0.8742353460	fisher information matrix
0.8742067623	multiclass classification
0.8741357959	nonconvex optimization
0.8741080261	network analysis
0.8741069248	excess risk
0.8740888254	main effects
0.8738818134	multidimensional scaling
0.8738154403	latent variables
0.8736354257	local linear
0.8735766969	level set
0.8735555754	extreme values
0.8734656695	semiparametrically efficient
0.8733273627	theoretical justification
0.8732944843	compositional data
0.8732388559	quickest detection
0.8732313506	divergence measures
0.8731919065	partial differential equations
0.8731805068	recent developments
0.8729595734	decision maker
0.8729237067	posterior propriety
0.8726854623	identity testing
0.8725448772	observational studies
0.8725430990	arma models
0.8723943827	min max
0.8723841997	state evolution
0.8723248883	stochastic dominance
0.8723044894	objective functions
0.8721512869	semiparametric models
0.8721384510	spin glass
0.8720058054	convex hulls
0.8719262404	ranked set sampling
0.8718790630	regression models
0.8718090216	tikhonov regularization
0.8717622099	matching pursuit
0.8717459848	ergodic capacity
0.8717291324	bayesian nonparametrics
0.8716252450	spectral projectors
0.8716245065	undirected graphs
0.8715739473	hierarchical clustering
0.8715231176	linear discriminant analysis
0.8714695361	fisher metric
0.8714664551	subset selection
0.8712752625	gaussian process regression
0.8712057242	distributionally robust optimization
0.8711561964	tangent space
0.8708644887	minimum contrast
0.8708600022	covariance structure
0.8708541080	random measures
0.8706995305	error bounds
0.8706976219	quantum physics
0.8706366921	bandit problems
0.8706176276	wiener process
0.8706095705	semiparametric estimation
0.8705609553	high dimensional
0.8705491762	error rate
0.8705161459	serially correlated
0.8703324987	distribution function
0.8703094332	network tomography
0.8702216268	query complexity
0.8702017160	oracle inequality
0.8701835407	extremal index
0.8700562725	lepski's method
0.8699744850	ordinal patterns
0.8698263803	generative adversarial networks
0.8697801487	hill estimator
0.8696677203	bias reduction
0.8695358045	decision rules
0.8695017920	data assimilation
0.8694610215	inverse problem
0.8694423151	model checking
0.8693409668	ancestral graphs
0.8692591796	robust inference
0.8691942030	sparse signals
0.8691510754	false alarms
0.8691394220	sample size
0.8691265973	regression model
0.8691252388	dot product graphs
0.8690837437	rare event
0.8690834938	causal effect
0.8688141247	kernel regression
0.8686335015	bahadur efficiency
0.8685815882	vector autoregressive
0.8685268924	interaction effects
0.8684984159	proportional hazard
0.8684772006	graph laplacian
0.8684567689	bayesian networks
0.8684110261	loss functions
0.8683953993	multinomial logit
0.8681717501	linear processes
0.8681550596	sparse vectors
0.8680479716	random design
0.8680339051	state space
0.8679912587	significance level
0.8679462027	directed acyclic graph
0.8678934774	hypergeometric functions
0.8676498908	heavy tail
0.8675925857	empirical measures
0.8675658454	correlation function
0.8675405609	lasso estimator
0.8675201828	cumulative incidence
0.8674236338	positive semidefinite
0.8673449555	additive models
0.8672392797	countably infinite
0.8671312375	markov process
0.8670582475	exchangeable arrays
0.8670071991	moving averages
0.8669646716	sobolev space
0.8669231898	binary segmentation
0.8669228703	years ago
0.8668982706	high frequency
0.8668727670	optimality criteria
0.8668221203	stable distribution
0.8667805473	triangular array
0.8667739487	simple random sampling
0.8667077102	stochastic differential equation
0.8666742666	brain imaging
0.8666535945	binary classification
0.8665346427	naive bayes
0.8665264815	baseline hazard
0.8663939626	euclidean distance
0.8663614067	risk measure
0.8662776428	error terms
0.8662698088	irregularly spaced
0.8662541106	interval censoring
0.8661111769	quotient space
0.8660089570	composite hypotheses
0.8659265083	scatter matrix
0.8659164301	gold standard
0.8658696835	bipartite graphs
0.8658526067	shortest path
0.8658021629	bias corrected
0.8657875373	logarithmic regret
0.8657033841	weibull distribution
0.8656756618	principal components analysis
0.8656464509	score function
0.8656331175	poisson distribution
0.8656012631	initial condition
0.8655509457	archimedean copulas
0.8655374311	brain connectivity
0.8655294426	reversible markov chains
0.8654411082	decision trees
0.8654329863	geometrically ergodic
0.8653011618	markov processes
0.8652853694	standard errors
0.8652775932	survival data
0.8651004404	shape parameter
0.8650687896	experimental designs
0.8650284840	semi parametric
0.8649708080	companion paper
0.8649096485	lindley distribution
0.8648659136	random graph
0.8648423583	gaussian distributions
0.8647738033	restricted isometry
0.8645856508	periodically correlated
0.8645033510	cross validation
0.8644833165	statistical theory
0.8644642062	multivariate normal
0.8644466323	infinite dimensional
0.8644353872	gene trees
0.8643899763	differential entropy
0.8641085813	strongly consistent
0.8641050435	portmanteau test
0.8640298476	peer review
0.8638665097	gamma distributions
0.8638425159	piecewise polynomial
0.8638166251	permutation tests
0.8638106918	linear mixed models
0.8637552713	directed graphs
0.8637523128	worst case
0.8637013406	multivariate distributions
0.8636931071	information criterion
0.8635825631	data set
0.8635425696	hurst parameter
0.8635242897	hurst exponent
0.8634314718	game theory
0.8634119544	hawkes process
0.8634100823	stein discrepancy
0.8634032624	measurement noise
0.8631423587	riemannian metric
0.8628738072	partial correlation
0.8628699501	ground truth
0.8628231369	restricted isometry property
0.8627696279	robust estimation
0.8626537602	branching processes
0.8625060374	synthetic data
0.8623792344	alternating minimization
0.8622860527	convex functions
0.8621643190	absolute continuity
0.8620723033	variational approximations
0.8620363211	sparse linear regression
0.8618706485	skew normal
0.8618327117	limit theorems
0.8618257729	graphon estimation
0.8618246169	excursion set
0.8617699885	polynomial regression
0.8617180515	compares favorably
0.8616966314	signal strength
0.8615520877	quantile function
0.8615435335	poisson processes
0.8615160901	critical values
0.8615117865	internet traffic
0.8614547479	structure learning
0.8612393278	absolutely continuous
0.8611321064	excursion sets
0.8610827082	empirical risk minimizer
0.8610508920	penalized regression
0.8609482125	prediction intervals
0.8609215011	von mises
0.8607270275	fuzzy sets
0.8607172801	financial markets
0.8606898196	sparse networks
0.8606073309	large deviation principle
0.8606057333	critical points
0.8605695058	convex geometry
0.8605539319	bandit problem
0.8605227921	credible intervals
0.8604369076	functional principal components
0.8603674323	robust statistics
0.8601917227	gamma distribution
0.8601275408	asymptotically optimal
0.8601259246	noninformative prior
0.8601165244	strongly mixing
0.8600949668	spike trains
0.8600917618	relu networks
0.8600859530	statistical inferences
0.8599366354	quantum language
0.8598793859	tuning parameter
0.8597175413	cox regression
0.8597029316	local asymptotic normality
0.8596757892	statistical models
0.8595983224	moment condition
0.8595498945	indirect observations
0.8594915366	point patterns
0.8594162780	prior information
0.8592190812	random coefficient
0.8590710193	quantum state
0.8590698621	autoregressive model
0.8589471592	hamiltonian monte carlo
0.8589267622	reversible markov chain
0.8588872984	additive noise
0.8588540727	archimedean copula
0.8587465780	vc dimension
0.8586276910	financial assets
0.8586007934	latent variable
0.8584971240	shape restrictions
0.8584736183	gaussian mixture models
0.8584271121	species tree
0.8584110659	distance multivariance
0.8583826554	arrival times
0.8583599958	dependence measures
0.8583576717	factor loadings
0.8582370112	uniformly distributed
0.8581320453	long range
0.8581168989	long range dependence
0.8579899144	gaussian graphical model
0.8578916633	generic chaining
0.8577089316	pac bayesian
0.8576967574	renyi divergence
0.8576858627	benford behavior
0.8576531053	poorly understood
0.8575508244	hidden markov model
0.8575208931	limit laws
0.8575125435	bayes estimator
0.8574563218	low dimensional
0.8573501595	sample covariance matrices
0.8573499223	convex regression
0.8573406999	magnetic resonance
0.8573168741	nonparametric bayesian
0.8573162599	random effects
0.8572539929	transition probabilities
0.8571676134	prediction error
0.8571536775	quadratic variation
0.8571367346	alphabet size
0.8571077494	bernstein von mises
0.8570855048	cox proportional hazards
0.8570821672	huber regression
0.8569868385	normal approximation
0.8569528189	beta distribution
0.8568012873	gene regulatory
0.8567583888	deep neural network
0.8567560784	exponential distribution
0.8566709217	acyclic graphs
0.8565661262	whittle likelihood
0.8565360296	model averaging
0.8565177879	roughly speaking
0.8564450563	sobolev spaces
0.8563521989	key ingredient
0.8563293533	categorical variables
0.8562710957	credit risk
0.8561036294	quasi likelihood
0.8560902280	extremal dependence
0.8560873559	stable law
0.8560722820	squared error
0.8560699849	false rejections
0.8560251346	repeated measurements
0.8559406307	probability measures
0.8559299226	continuous functions
0.8559105832	weak dependence
0.8557772765	conditional probability
0.8556782965	normalizing constant
0.8555902768	debiased lasso
0.8555506872	density estimators
0.8552757601	bootstrap methods
0.8552589271	generalized bayes
0.8552193373	contamination model
0.8551441250	cumulative hazard
0.8550669510	stationary ergodic
0.8550067336	pastur law
0.8548699716	smoothing splines
0.8548522187	uniform convergence
0.8546583600	multinomial distribution
0.8546491459	probability density functions
0.8545932647	additive model
0.8544086534	stochastic differential
0.8543724167	strictly stationary
0.8540423562	computational biology
0.8539559996	subgraph counts
0.8539433170	fractional ornstein uhlenbeck
0.8539146791	boundary crossing
0.8537295806	berkson errors
0.8534678309	incomplete lineage sorting
0.8534072465	markov models
0.8533186970	biased coin
0.8533109618	suitably chosen
0.8532992542	doa estimation
0.8532968647	wasserstein space
0.8532665093	dependent random variables
0.8532228873	semi supervised
0.8532117818	kernel estimators
0.8530893018	objective function
0.8527978301	covariate adjustment
0.8527824643	wishart ensemble
0.8524400023	spiked eigenvalues
0.8524117309	geodesic distance
0.8523757224	bayesian model selection
0.8523586383	unbiased estimators
0.8523350327	light tailed
0.8520813520	false negative
0.8520754184	functional data analysis
0.8520748070	shapley effects
0.8520143363	hypothesis tests
0.8520074679	multiple hypotheses
0.8520053684	white gaussian noise
0.8519680396	wishart distribution
0.8519251545	hidden layer
0.8519183180	asymptotic independence
0.8518137475	seemingly unrelated
0.8518070785	compact sets
0.8518047851	fractional factorial designs
0.8517857107	cauchy distribution
0.8517593395	computational burden
0.8517372778	random effect
0.8517046504	independence testing
0.8515900303	linear inverse problems
0.8514197134	factor model
0.8514047779	garch models
0.8513964357	levy processes
0.8513594571	asymptotic normality
0.8513102413	continuously differentiable
0.8513101263	globally optimal
0.8512699288	approximate bayesian
0.8511149655	chi square
0.8509599235	unbiased estimation
0.8507632251	optimization problem
0.8507393370	steady state
0.8506964864	precision matrix
0.8506590792	false negatives
0.8506469675	von neumann
0.8505974374	optimal designs
0.8504581509	nonparametric inference
0.8504270974	sampling schemes
0.8502726324	image denoising
0.8501896693	degree distribution
0.8501195267	uniformly bounded
0.8500735472	recommender systems
0.8500551538	power spectra
0.8500493862	zonal polynomials
0.8500215828	finite dimensional
0.8499344487	estimating functions
0.8497163095	linear measurements
0.8496138900	ad hoc
0.8493711955	post change
0.8493202611	learning theory
0.8492786411	chain graphs
0.8492390752	nuisance parameter
0.8492365322	false discovery rate control
0.8492059434	telegraph process
0.8491127689	instantaneous frequency
0.8490602693	wishart matrix
0.8490123655	average run length
0.8490030828	saturated designs
0.8489668963	meta analysis
0.8489546903	quickest change
0.8487311905	easily verifiable
0.8487226303	test statistics
0.8486846876	autoregressive process
0.8486381990	error probability
0.8484464500	evolutionary trees
0.8484230589	renyi entropy
0.8484059591	wishart distributions
0.8483720415	likelihood estimator
0.8483368852	heavy tailed
0.8482152970	real life
0.8481277794	regret bounds
0.8481117310	garch processes
0.8480460881	option pricing
0.8480197709	lower dimensional
0.8479603687	kullback leibler divergence
0.8479454088	partial sums
0.8478593067	hazard rates
0.8477676411	influence functions
0.8477160950	social science
0.8476960266	total variation denoising
0.8476770559	overlap gap property
0.8475880562	autoregressive moving average
0.8474962079	log concavity
0.8474619192	data mining
0.8473741309	space filling
0.8473565830	power spectrum
0.8472627440	smooth function
0.8472459785	markov property
0.8471741944	response surface
0.8471323329	stochastic orderings
0.8470778902	gaussian random field
0.8470367776	batch means
0.8470155295	adaptive lasso
0.8469357395	fully connected
0.8469046872	principal component scores
0.8468455242	network models
0.8466185990	ergodic diffusion processes
0.8465500085	permutation test
0.8465003382	asymptotic minimaxity
0.8464059024	bayesian inverse problems
0.8464056499	persistent betti numbers
0.8462849403	cumulative sum
0.8462572016	quantum mechanics
0.8460641808	spectral methods
0.8459628023	euclidean spaces
0.8457276782	linear combination
0.8457201652	speech recognition
0.8457143266	blomqvist's beta
0.8455651010	directed graph
0.8455340541	poisson noise
0.8455194924	random vector
0.8455133399	parameter vector
0.8454170764	alternative hypothesis
0.8453937381	consistently estimate
0.8452592804	blind deconvolution
0.8452344076	likelihood ratio statistic
0.8452271931	l1 penalized
0.8452269074	sample covariance matrix
0.8451342120	identically distributed
0.8451323422	linear operator
0.8450773727	multiresolution analysis
0.8449662686	van der vaart
0.8449207056	explanatory variable
0.8449053816	auto regressive
0.8448440009	computationally expensive
0.8448173291	piecewise polynomials
0.8447403799	sequential analysis
0.8447189834	familywise error rate
0.8446199408	indicator function
0.8445050922	correlation coefficients
0.8445036702	moment inequalities
0.8444930891	ultra high dimensional
0.8444234808	expectation maximisation
0.8443867251	point cloud
0.8443267154	quantum homodyne tomography
0.8442912531	distribution functions
0.8441723594	latent structure
0.8440931105	sample sizes
0.8440814460	wrapped cauchy
0.8439120485	predictive density
0.8438653408	bayesian variable selection
0.8438650986	martingale difference
0.8437793559	rank correlation
0.8437772076	pseudo likelihood
0.8437606887	multi armed bandit
0.8436539471	cumulative distribution functions
0.8436272743	statistical analysis
0.8435837522	excess mass
0.8435057775	uniformity testing
0.8435050188	composite likelihoods
0.8434734303	generalized lasso
0.8434361478	high order
0.8433224675	infinite variance
0.8433118778	robust regression
0.8431460371	closely related
0.8430768952	small ball
0.8430288784	perform poorly
0.8429479474	computational cost
0.8429354317	strict stationarity
0.8429205251	convex combinations
0.8429110951	post selection inference
0.8428332024	nearest neighbour
0.8428105671	variational approximation
0.8426350189	high dimensions
0.8425957182	intensively studied
0.8425317037	strong mixing
0.8423271891	spatially dependent
0.8422911006	log likelihood
0.8422549802	sequential tests
0.8422508076	piece wise
0.8422489708	gaussian errors
0.8422246186	gram matrix
0.8422226110	continuous distributions
0.8422043945	bootstrap procedure
0.8419424000	prior distributions
0.8418747242	cramer rao
0.8418429691	rate distortion
0.8417749585	prediction errors
0.8417319496	integrated volatility
0.8417295277	finite population
0.8417228120	longitudinal data
0.8416727764	post hoc
0.8416694066	markov bases
0.8416162544	likelihood ratio tests
0.8415767562	dirichlet processes
0.8415657603	missing values
0.8415225375	indian buffet
0.8414997785	bayesian approach
0.8414352499	link functions
0.8414246455	nonparametric estimation
0.8413064239	familywise error
0.8412688593	exact recovery
0.8410877493	uniform attachment
0.8410722666	covariance function
0.8410612005	markov basis
0.8410371441	computationally cheap
0.8410259506	illustrative examples
0.8409798002	single index
0.8409773453	low frequency
0.8409740201	independence screening
0.8409597588	false null hypotheses
0.8409224908	convergence rate
0.8409151199	online learning
0.8409077780	frequentist coverage
0.8409077652	high dimensionality
0.8408691226	scale mixture
0.8407968550	temporal dependence
0.8407878970	local differential privacy
0.8407574437	generative model
0.8407182977	power function
0.8406836758	mixing distribution
0.8406598716	local polynomial
0.8406275380	information transfer
0.8404046378	hypotheses testing
0.8403994270	ornstein uhlenbeck process
0.8403199957	conditional moment
0.8402879414	poisson regression
0.8402344384	adaptive minimax
0.8402330503	rank based
0.8400147983	moment restrictions
0.8399642791	carma processes
0.8399057878	sparse regression
0.8398127998	surface area
0.8397727488	computational complexity
0.8397326712	x_ ij
0.8397262427	shrinkage estimators
0.8396971277	optimal stopping
0.8396615704	cholesky factor
0.8396488838	multivariate anal
0.8396294266	besov balls
0.8396254717	conditional growth charts
0.8396058983	diffusion coefficient
0.8395062039	spatio temporal
0.8392710367	wright fisher
0.8392612152	approximately sparse
0.8391852034	learning rates
0.8391525465	convolution theorem
0.8391035546	improper priors
0.8390975595	black box
0.8390459369	stieltjes transform
0.8388542026	branch lengths
0.8387714886	illustrative purposes
0.8387468448	stationary process
0.8387408025	signed rank
0.8387218554	fourth order
0.8386453485	multiple comparisons
0.8386183740	regularity conditions
0.8385347513	random elements
0.8384432762	sufficient condition
0.8384104194	testing problems
0.8384028762	simultaneous inference
0.8382831122	hausdorff distance
0.8382462536	exponential decay
0.8381396828	error exponent
0.8381357579	kernel estimator
0.8380636311	nonparametric instrumental
0.8380617116	lie group
0.8380612031	function spaces
0.8378403501	bahadur kiefer
0.8374941253	rank tests
0.8374616238	statistical evidence
0.8374122734	statistical query
0.8373816663	variance estimators
0.8373798491	link function
0.8372688984	infectious disease
0.8372663254	panel data models
0.8372624134	scale invariant
0.8372591203	varying coefficient
0.8372086486	triangular arrays
0.8371388664	unbiased risk estimate
0.8370933410	classification problem
0.8370057472	minimum description length
0.8369744885	linear regression models
0.8369712063	kernel methods
0.8367890723	optimality criterion
0.8367621317	post model selection
0.8366951071	pure jump
0.8366390479	confidence sequences
0.8366302087	recent advances
0.8366228253	correlation matrix
0.8365875344	dispersion models
0.8365445208	invariance principles
0.8365292727	computationally intensive
0.8365116085	regression trees
0.8364608193	information matrix
0.8364054951	intensity functions
0.8363935457	hilbert schmidt
0.8363295891	rotationally symmetric
0.8363027998	bayesian statistics
0.8362962591	shape constrained
0.8362759309	multivariate regression
0.8362515485	fold cross validation
0.8362368075	compound decision
0.8362363278	tail probabilities
0.8361535928	spectral densities
0.8360735281	longitudinal studies
0.8360451674	marked point
0.8360379323	open source
0.8360131870	learning algorithm
0.8359942712	concentration inequality
0.8359934027	dose response
0.8359356156	dna sequences
0.8358808341	notoriously difficult
0.8358806270	linear fractional stable
0.8357219831	communication constraints
0.8356729079	penalized estimators
0.8355016436	optimal bandwidth
0.8354429552	orlicz norm
0.8352761328	partial derivatives
0.8351963719	statistical framework
0.8351704363	error bound
0.8351226278	metropolis hastings
0.8350365367	markov chain monte carlo methods
0.8350065390	stochastic integrals
0.8349750673	stock price
0.8349276273	multi scale
0.8347802764	scale parameter
0.8347789409	length biased
0.8347778824	selection procedures
0.8347765575	generalized linear
0.8347324978	markov switching
0.8346925259	type test
0.8345964329	asymptotic variances
0.8345152892	neyman pearson
0.8345047644	counting processes
0.8344616993	special cases
0.8344454733	affine invariant
0.8343975730	high frequency data
0.8343236999	undirected graphical
0.8343104548	multiple regression
0.8342188104	large dimensional
0.8342128157	multiple testing procedures
0.8341939986	data processing
0.8341249197	enyi divergence
0.8341091340	detection problem
0.8340313863	shrinkage estimation
0.8340305666	data sets
0.8340023853	model misspecification
0.8339839249	matrix recovery
0.8339494758	evy process
0.8338432099	mixed membership
0.8338099465	auxiliary variable
0.8338096970	topological summaries
0.8338034568	stochastic resonance
0.8337607061	activation function
0.8336331798	penalty function
0.8335448878	covariance matrix estimation
0.8335022471	l1 norm
0.8334925889	quantum tomography
0.8334655708	algebraic varieties
0.8334483084	quadratic risk
0.8334186105	cross sectional
0.8330629236	ambient dimension
0.8330483918	neighborhood selection
0.8329350667	smoothed periodogram
0.8328797652	asymptotic properties
0.8328565944	scaling limits
0.8328395720	random sampling
0.8328026659	partial information
0.8327776276	design points
0.8327525027	euclidean norm
0.8327223014	gaussian priors
0.8325593940	small sample
0.8325508655	diffusion maps
0.8324943441	takes place
0.8324893273	accept reject
0.8323683745	measurement matrix
0.8322747599	natural numbers
0.8321671162	expected length
0.8321255975	latent factors
0.8321047395	data driven
0.8320691696	classification problems
0.8319103907	regression coefficients
0.8316736242	reversible jump
0.8316677148	stochastic ordering
0.8316465446	sampling designs
0.8315944983	soft thresholding
0.8315926515	linear predictor
0.8315827157	dually flat
0.8314642777	indirect inference
0.8314609268	convex function
0.8314313088	multivariate normality
0.8313330422	hidden regular variation
0.8313201460	asset returns
0.8312680819	dependence measure
0.8312205714	function space
0.8311474324	information measures
0.8311131875	bounded variation
0.8311130898	inverse gamma
0.8311079247	confidence set
0.8310773865	langevin equation
0.8310095037	computationally feasible
0.8309913121	current status data
0.8309589783	generalized linear model
0.8309307799	group action
0.8309189285	canonical correlations
0.8309178149	mcmc methods
0.8309024381	numerical integration
0.8308916549	approximation error
0.8308528091	optimal transportation
0.8307945502	measurable space
0.8307915574	greedy algorithm
0.8307167831	risk measures
0.8307086663	functional linear regression
0.8306890079	unlabeled data
0.8305500613	metropolis algorithm
0.8305268947	jump diffusion
0.8305058164	parametric inference
0.8303320640	semiparametric regression
0.8302031463	count data
0.8301508029	spanning tree
0.8301235348	spectral estimation
0.8300804334	special emphasis
0.8300539829	unit cube
0.8299883579	efficiency gains
0.8299676273	regularization methods
0.8299003272	block model
0.8298241006	broadly applicable
0.8297392410	connected components
0.8296666960	expected utility
0.8296516253	easily implementable
0.8296491058	mixed graphs
0.8296289655	posterior distribution
0.8295560298	sparse signal
0.8293251902	extreme events
0.8292623316	covariance parameters
0.8292257232	monte carlo simulation
0.8291339946	hermite polynomials
0.8291051712	smoothness classes
0.8289800282	cosmic microwave
0.8287802160	genomic data
0.8287648187	particle filtering
0.8287246136	predictive densities
0.8287176550	bayesian procedures
0.8287116345	diffusion process
0.8286737552	theoretical findings
0.8285202101	likelihood inference
0.8284031472	local alternatives
0.8283226126	stationary gaussian
0.8280837209	high dimensional data
0.8280774790	model selection consistency
0.8280110629	saddlepoint approximation
0.8279508122	sufficient statistics
0.8278532594	random projections
0.8277893935	current status
0.8276427256	canonical correlation
0.8275665977	spectral gap
0.8275447420	proposed procedures
0.8275390890	fractal dimension
0.8275192400	independent random variables
0.8274608777	computationally demanding
0.8273989385	state spaces
0.8273332977	local optima
0.8273225687	influence function
0.8272599772	empirical bayes posterior
0.8272548350	arbitrary dimension
0.8271966403	nonparametric density
0.8271653149	additive gaussian noise
0.8271263158	supervised classification
0.8269214110	rate optimal
0.8268748437	observed data
0.8268599411	dependent data
0.8267211166	cost function
0.8267186362	conditional density
0.8266821372	empirical evidence
0.8266647227	graphical model
0.8264769594	previous works
0.8264601827	optimal rates
0.8263934947	proportional odds
0.8263494996	sequential testing
0.8262960200	regression framework
0.8262545935	mcmc algorithms
0.8262095356	harris recurrent
0.8260886357	restrictive assumptions
0.8260151888	stable processes
0.8259607920	results extend
0.8259384689	error exponents
0.8259029908	characteristic functions
0.8258509461	kolmogorov smirnov
0.8257693208	probability distribution
0.8256215662	mathematical statistics
0.8256144888	smooth functions
0.8254669955	minimax optimality
0.8254462066	center outward
0.8254321229	quadratic loss
0.8252176888	moment generating function
0.8252064261	ornstein uhlenbeck
0.8252004550	asymptotically normal
0.8251593611	likelihood function
0.8251096997	polynomial chaos
0.8250579081	sufficient statistic
0.8250446039	heterogeneous treatment effects
0.8249300050	main novelty
0.8247885523	correction term
0.8247648075	interval estimation
0.8247138283	variance estimator
0.8246771456	hypothesis testing problem
0.8245735420	clustering algorithm
0.8245426381	dependence structures
0.8244658553	multistage sampling
0.8244383846	standard methods
0.8244276922	independence test
0.8244143359	slightly stronger
0.8243633446	regression problems
0.8243164944	partial differential
0.8242351316	measurable functions
0.8242008231	interior point
0.8240776939	covariate balance
0.8239978266	dirichlet process mixtures
0.8238927532	void size
0.8237919319	density ratio
0.8236662236	mutually independent
0.8236425162	stochastic orders
0.8235527937	realized volatility
0.8234296230	latent factor
0.8233282612	special attention
0.8232979312	kernel function
0.8232860155	inverse gaussian
0.8232511750	spatial data
0.8232341943	nonconcave penalized likelihood
0.8231643626	tree models
0.8231480368	probability space
0.8231088007	semiparametric inference
0.8230562259	conditional probabilities
0.8230436786	theoretical guarantees
0.8229176816	asymptotic variance
0.8228815007	deconvolution problem
0.8228067752	regularized estimators
0.8226915584	moderately large
0.8226821207	rosenblatt process
0.8226751265	asymptotically exact
0.8226458812	stochastic newton
0.8226450869	entropy estimation
0.8225160843	block models
0.8224087635	stable distributions
0.8222548993	generalization ability
0.8222211404	locally stationary processes
0.8222153768	langevin diffusions
0.8222140020	synthetic datasets
0.8221714074	learning algorithms
0.8221613203	locally private
0.8220858817	variance function
0.8219206125	asymptotic power
0.8217561766	medical imaging
0.8216735080	building block
0.8216651862	multivariate gaussian
0.8216571104	widely applicable
0.8216304909	strictly convex
0.8215637587	stochastic gradients
0.8214914859	type ii
0.8214771073	sparsity inducing
0.8214407055	binomial distribution
0.8214337244	minimax lower bounds
0.8214199289	step ahead
0.8214128272	sectional variation norm
0.8213479370	theoretical foundation
0.8213238284	markov properties
0.8212644080	correlation functions
0.8212177115	sequential decision
0.8211566925	commonly encountered
0.8211459470	olya tree
0.8210862143	case studies
0.8210641867	channel capacity
0.8209789778	joint distributions
0.8209700659	undirected graphical models
0.8208737525	parametric rate
0.8208343448	singular subspaces
0.8207547518	cramer von mises
0.8207003681	learning problems
0.8205735265	numerical experiments
0.8205697564	oracle properties
0.8205516930	regression analysis
0.8205281272	equi energy sampler
0.8203914584	valid inference
0.8203865228	smooth backfitting
0.8203637480	credible set
0.8203525337	population genetics
0.8203247482	autocorrelation function
0.8202212874	fractional brownian motions
0.8202113512	spiked covariance
0.8202112205	pairwise comparison
0.8201353468	absolutely regular
0.8201089423	independent component
0.8200074745	single trajectory
0.8199800883	inequality constraints
0.8199408262	sufficient conditions
0.8199047921	likelihood estimation
0.8199014280	probability mass function
0.8197136234	logarithmic factor
0.8196836787	minimax theory
0.8196741497	appropriately chosen
0.8196700683	tsallis entropy
0.8195604304	statistical error
0.8195030176	density deconvolution
0.8193166977	penalized maximum likelihood
0.8192260745	input output
0.8191526867	symmetric distributions
0.8191470490	besov classes
0.8191028448	marginal distributions
0.8190755820	markov random field
0.8190146701	monotone functions
0.8189925402	received considerable
0.8189102684	moving block bootstrap
0.8188866146	nonparametric density estimation
0.8188675260	conditionally independent
0.8186781012	moderate sample sizes
0.8185696492	probability measure
0.8184610927	parallel systems
0.8183636497	piecewise linear
0.8183590603	numerical methods
0.8182239232	risk assessment
0.8181878579	weight function
0.8181387784	existing tests
0.8180810156	modal regression
0.8180542362	echet means
0.8180526541	local rademacher complexities
0.8178970612	cross validated
0.8177979189	wide applicability
0.8177696810	latent space
0.8177154148	fixed effects
0.8175626202	quantum systems
0.8175100147	location parameter
0.8173847787	canonical correlation analysis
0.8173468331	completely random measures
0.8173172236	minimum variance
0.8170958959	qualitative robustness
0.8169014800	bh procedure
0.8168965298	power series
0.8167690154	whittle estimator
0.8167338269	folded concave
0.8166732371	multi dimensional
0.8166693926	tuning parameters
0.8165645894	intrinsic dimension
0.8163890445	existing estimators
0.8163599458	statistical learning theory
0.8163400023	sharp oracle inequalities
0.8163231038	sequential change detection
0.8162548774	maximum likelihood estimators
0.8162412922	normed division algebras
0.8161517013	james stein
0.8161316962	sparsity pattern
0.8161033967	sparse vector
0.8160022286	finite alphabet
0.8159570205	limiting distribution
0.8159106931	positive integer
0.8158820595	largest root
0.8158599060	monte carlo simulations
0.8158363015	smoothing parameter
0.8158022485	inference problems
0.8157655114	noisy data
0.8157047927	asymptotic equivalence
0.8156795238	finite sample
0.8156289483	semi selfdecomposable
0.8156268456	clustering algorithms
0.8153171545	random coefficients
0.8153008585	summary statistic
0.8152972868	false discovery rates
0.8152697812	proposed test
0.8151837521	random sets
0.8151733473	binary response
0.8151303430	unit sphere
0.8149782754	stress strength
0.8149741078	shape constraints
0.8148775969	gaussian random
0.8146493187	np hard
0.8145980771	high throughput
0.8143502795	open problem
0.8143492333	benjamini hochberg
0.8143353204	multivariate normal distribution
0.8142817672	spiked tensor
0.8142745245	random samples
0.8142336039	adjacency matrices
0.8141696996	hawkes processes
0.8141107096	minimization problem
0.8140765982	social sciences
0.8139891444	posterior probability
0.8139593467	semi definite
0.8139441343	fourier analysis
0.8139418473	nonparametric tests
0.8138400591	zeroth order
0.8137948139	model comparison
0.8137556161	conditional distributions
0.8137401089	cure rate
0.8136439154	causal models
0.8136337935	cramer rao bound
0.8135694973	low degree
0.8134909958	heteroscedastic regression
0.8134113771	cusum test
0.8133950045	confidence level
0.8133432064	finite mixture models
0.8132052273	empirical beta copula
0.8131652613	main contribution
0.8130063770	hermite rank
0.8129779290	perturbation bounds
0.8128215719	set valued
0.8127954661	mixing coefficients
0.8127397936	integral equations
0.8126164031	covariate adaptive randomization
0.8125798485	compatibility condition
0.8125517877	posterior predictive
0.8125125184	hazard function
0.8124898258	markov kernels
0.8123890869	rejection sampling
0.8123516993	orthogonal array
0.8122751889	structural break
0.8121772002	sample average
0.8121176912	conditional quantiles
0.8120701851	band limited
0.8120492418	nuisance functions
0.8119454974	tail bounds
0.8117902599	generalized inverse
0.8117356346	sliced inverse
0.8117210789	computational effort
0.8116915961	orthogonal series
0.8116466802	maximum likelihood estimates
0.8115273857	sparse graphs
0.8115142187	sparse principal component analysis
0.8113355798	small perturbations
0.8113313702	nuclear norm minimization
0.8112064348	vy measure
0.8111528193	perturbation theory
0.8111090299	logarithmic factors
0.8110920729	contraction rates
0.8110869340	sample compression
0.8110541545	square root lasso
0.8108011491	enyi entropy
0.8107825409	strictly positive
0.8107656385	spiked covariance model
0.8107240040	sample covariance
0.8107055132	garch model
0.8105582343	stein type
0.8105377480	moment conditions
0.8104959436	coverage probability
0.8104845781	orthonormal basis
0.8103521927	chain graph
0.8103488777	initial estimator
0.8103087488	wasserstein geometry
0.8101675412	network data
0.8101592941	multi task
0.8101408300	gaussian measures
0.8099670918	stochastic partial differential equations
0.8099599142	bayesian analysis
0.8099304434	conditionally conjugate
0.8099071426	variance estimation
0.8098837425	improper prior
0.8098748605	correlation structure
0.8097911052	auxiliary variables
0.8097785375	latin squares
0.8096155675	holonomic gradient method
0.8094531020	efficient algorithms
0.8094270582	hilbert valued
0.8094241170	posterior contraction rate
0.8093916955	sequential importance sampling
0.8093884186	spatial sign covariance
0.8092540354	random partitions
0.8091317986	dimension independent
0.8091199128	block structure
0.8090886540	posterior contraction rates
0.8090125501	multiplicative noise
0.8089620861	erdos renyi
0.8089084728	posterior convergence rates
0.8088923907	real data
0.8088618508	sensing matrices
0.8088491991	article investigates
0.8088483280	regression coefficient
0.8087781474	poisson point processes
0.8087540712	gaussian kernel
0.8087062313	counter examples
0.8085328910	sufficiently smooth
0.8085296116	directional data
0.8083907342	robust estimators
0.8081894323	random environment
0.8081784989	y_ ij
0.8081719023	bandit algorithms
0.8080985472	spectral analysis
0.8080855297	sampling method
0.8080441970	unknown parameter
0.8080298004	support function
0.8080196805	stationary increments
0.8079114182	pac bayes
0.8078519849	sequence length
0.8078409336	observation driven
0.8077363839	simulation experiments
0.8076477657	degree corrected
0.8076191112	max min
0.8075185084	data collection
0.8074276911	underlying process
0.8073797466	property testing
0.8073420635	group sparsity
0.8072134987	sparse precision matrix
0.8071967415	empirical risk
0.8071881823	ensemble kalman filter
0.8071116245	scatter matrices
0.8070859038	noise level
0.8070155890	nonparametric testing
0.8069815785	impossibility results
0.8069685427	bootstrap method
0.8068964261	dense subgraph
0.8068763979	black scholes
0.8068317609	marshall olkin
0.8068297487	low rank matrix
0.8067818021	asymptotic results
0.8066471700	cluster analysis
0.8066143393	counting process
0.8065962821	jensen shannon
0.8065764384	indian buffet process
0.8065131610	mis specification
0.8064083010	tuning free
0.8063865162	armed bandit problem
0.8063786155	super resolution
0.8063314648	survival function
0.8063249760	marginal distribution
0.8062899860	provable guarantees
0.8061984276	feynman kac
0.8061499376	probabilistic models
0.8061141704	training samples
0.8060702730	parameter space
0.8060696416	covariate adjusted
0.8059860346	linear functionals
0.8058403876	extensive simulation studies
0.8058357788	observed variables
0.8057543078	main result
0.8057292622	huber loss
0.8056771110	testing problem
0.8056649729	levy process
0.8055649761	estimation procedures
0.8055348705	minimax risk
0.8055234788	shiryaev roberts
0.8053874008	spatially correlated
0.8053102928	affine equivariant
0.8053045373	dimensional sphere
0.8051764237	large sample
0.8051319610	asymptotically efficient
0.8051211894	sobolev classes
0.8050816521	function classes
0.8050167633	key element
0.8049340379	conditional independences
0.8047696229	testing independence
0.8047094501	misspecified models
0.8045587302	data points
0.8043357463	chinese restaurant process
0.8042574189	adjacency matrix
0.8042240432	sample space
0.8041793096	random noise
0.8041656572	desirable properties
0.8041211466	negative binomial distribution
0.8040278810	rank test
0.8040034851	fractional levy
0.8039671175	stick breaking
0.8039366787	likelihood based
0.8039070254	stationary point
0.8038980683	functional linear
0.8038226923	quantum state tomography
0.8037058592	quantile process
0.8036146813	considerable attention
0.8036010593	er rao
0.8035669566	probit regression
0.8033368979	minimax rate optimal
0.8033330089	censored survival data
0.8032369053	survey sampling
0.8031171103	matrix valued
0.8030916203	bootstrap consistency
0.8029586118	vy driven
0.8029216910	statistical modeling
0.8029042899	adaptive estimation
0.8029027565	binary regression
0.8028778806	randomly sampled
0.8027864460	simulation studies
0.8027007203	expected loss
0.8026468313	hypothesis test
0.8026266840	proposed estimator
0.8025748417	additive functional
0.8023984353	regression adjustment
0.8023295348	data fidelity term
0.8022569742	policy learning
0.8022236532	residual variance
0.8021765777	proper scoring
0.8021714790	parametric model
0.8020854133	gaussian approximation
0.8019567491	kalman filtering
0.8018652613	statistical estimation
0.8018437293	closeness testing
0.8017602964	evy processes
0.8016836208	regression setting
0.8016736517	real datasets
0.8016645118	point wise
0.8015287125	user friendly
0.8014372445	probability density function
0.8014272699	gaussian process prior
0.8014131079	monte carlo methods
0.8012919986	noisy observations
0.8012517985	future research
0.8012141532	tensor pca
0.8011810592	hypergeometric function
0.8011673097	strong approximation
0.8009670415	statistical manifolds
0.8009464597	numerical simulations
0.8009456850	bracketing entropy
0.8008482789	model free
0.8007955112	binary data
0.8006296010	treatment assignment
0.8005657381	research areas
0.8005251067	integrated squared error
0.8005214535	normal mixtures
0.8004813476	positive definite matrices
0.8004317878	deviation bounds
0.8004084874	correct specification
0.8002386812	complex networks
0.8000873812	remain valid
0.8000725421	cornish fisher
0.8000317636	concave penalty
0.7999863612	estimation procedure
0.7999575490	scoring function
0.7998605392	reaction diffusion
0.7998486967	supercritical case
0.7998370686	ergodic diffusions
0.7998349064	close connection
0.7997678068	numerical examples
0.7997329728	causal structure
0.7996891355	density estimator
0.7996424402	newly defined
0.7996349479	minimum distance
0.7996077605	logistic distribution
0.7996059195	topological features
0.7995826578	kiefer wolfowitz
0.7995518242	sparsity level
0.7994069576	posterior concentration rates
0.7993017910	hilbert space valued
0.7992551310	selection procedure
0.7992257709	log gaussian cox
0.7991790144	low rank matrix recovery
0.7991020944	infinite series
0.7990856844	kullback leibler
0.7990738119	aberration criterion
0.7990668880	regular grid
0.7990290763	wavelet estimator
0.7990074086	anti concentration
0.7989734496	quasi maximum likelihood estimator
0.7989518478	optimal sequential
0.7989496417	incomplete data
0.7989451819	exact inference
0.7988496433	theoretically justified
0.7988257321	langevin algorithm
0.7988200882	fixed point
0.7988109233	minimax estimation
0.7987674345	independent components
0.7987561362	higher dimensions
0.7986889564	support size
0.7985464362	wald type
0.7984437804	universally optimal
0.7984263963	latent feature
0.7982870813	markov jump processes
0.7981743653	low rank matrices
0.7981252061	projective shape
0.7981001159	fixed design
0.7979954027	complex systems
0.7979405645	open problems
0.7978591185	general theory
0.7976410615	serial correlation
0.7975944043	testing procedure
0.7975689610	article develops
0.7975666498	ranked set
0.7974448278	limiting process
0.7973742504	wavelet based
0.7973695200	short memory
0.7972974725	toeplitz matrices
0.7972156101	manifold learning
0.7972015530	aggregation procedure
0.7971654050	joint distribution
0.7971511566	element wise
0.7970713904	sample means
0.7967681304	significance levels
0.7967614677	inductive inference
0.7967195537	privacy preserving
0.7965620470	multivariate density
0.7965022047	hyper parameter
0.7964785171	contraction coefficients
0.7964638070	posterior probabilities
0.7964560816	dependent processes
0.7964257402	microarray data
0.7963473738	recent years
0.7963345873	easily computable
0.7963317688	network structure
0.7962934308	hessian matrix
0.7962756499	multivariate analysis
0.7962533127	solution path
0.7962362973	phase space
0.7961806933	diffusion tensor
0.7961198455	sampling scheme
0.7960329258	orthogonal matrices
0.7958959567	local whittle
0.7958944674	respondent driven sampling
0.7958168228	surrogate loss
0.7957028211	significant improvement
0.7955547050	affine transformations
0.7955294033	stochastic recurrence
0.7954996917	sparsity constraints
0.7954959310	density level sets
0.7954710402	bootstrap based
0.7953916838	statistically efficient
0.7952998253	underlying graph
0.7952745194	density functions
0.7952582301	location scale
0.7952405243	parametric models
0.7951883953	low rank tensor
0.7950573776	median regression
0.7950401366	robbins monro
0.7950248646	extensively studied
0.7950199759	image analysis
0.7949537945	error variance
0.7948531594	numerical studies
0.7947637439	semi markov
0.7947227681	high dimension
0.7946990556	er von mises
0.7946443415	horseshoe prior
0.7945713298	empirical spectral distribution
0.7944680592	minimax rate
0.7944057987	increasing dimension
0.7943849408	dependency structure
0.7943277470	conditional sampling
0.7943229450	bernstein type
0.7943013260	resulting estimator
0.7942766907	adaptive estimators
0.7942405580	bayesian predictive
0.7941397701	quantum states
0.7941316810	multi armed bandits
0.7941110138	log normal
0.7940959326	penalized spline
0.7940929952	nadaraya watson
0.7940529220	sampling design
0.7939362691	gaussian graphical
0.7938280871	half line
0.7938196989	excellent performance
0.7937553653	super population
0.7937516754	practical relevance
0.7937038421	predictive inference
0.7936801218	numerical illustrations
0.7934406709	curved exponential family
0.7934264058	convex cones
0.7934109654	theoretical investigations
0.7933303958	family wise error rate
0.7932447342	gibbs posterior
0.7932437488	nonzero entries
0.7932078167	efficient estimation
0.7930460665	wigner function
0.7930452904	pitman yor
0.7930354495	coarse grained
0.7930129889	simultaneous confidence bands
0.7930027613	high resolution
0.7929445364	local polynomial regression
0.7928979482	spectral embedding
0.7928792471	weighted average
0.7928208633	regime switching
0.7927649664	heterogeneous data
0.7926610349	birth death
0.7926410189	likelihood estimators
0.7925800361	laplace distribution
0.7924697770	error rates
0.7923985645	stable laws
0.7922347467	nonparametric component
0.7921683129	null space property
0.7921403535	tail behaviour
0.7921257395	matrix denoising
0.7920753080	vice versa
0.7920057583	regularized estimation
0.7919860044	earlier results
0.7917928225	laplace transforms
0.7915934783	state space models
0.7915913049	estimation problems
0.7915531290	abrupt change
0.7915499924	stationary distribution
0.7915021747	concrete examples
0.7914290420	asymptotic analysis
0.7913548316	hierarchical bayes
0.7913201864	statistically significant
0.7912913122	experimental data
0.7912727388	gene tree
0.7912286046	complex wishart
0.7908844514	spectral method
0.7908026406	linear prediction
0.7907861906	global convergence
0.7907047836	impossibility result
0.7906907428	predictive distributions
0.7905953841	risk bounds
0.7904851022	dirichlet prior
0.7904317921	monte carlo method
0.7904059190	likelihood approach
0.7903423455	testing procedures
0.7902658541	successfully applied
0.7902371653	besov space
0.7901681586	tracy widom
0.7901553364	latent process
0.7901540839	extensive simulations
0.7901378015	fisher rao
0.7900943468	inhomogeneous poisson processes
0.7900924517	past observations
0.7900778323	thresholded lasso
0.7900568089	practically relevant
0.7900557690	sparsity promoting
0.7900140600	independent random
0.7900082986	dynamic systems
0.7899136634	ornstein uhlenbeck processes
0.7897646721	statistical accuracy
0.7897406161	stochastic block
0.7897358880	robust tests
0.7897125239	bayesian hierarchical
0.7897008990	covering numbers
0.7896809569	description length
0.7896415725	uniform consistency
0.7896031379	selection bias
0.7895730888	density matrices
0.7895203108	partially linear models
0.7895175385	mixed level
0.7894319364	minimum divergence
0.7894250243	random geometric graph
0.7894179509	relevant variables
0.7893145752	scaled lasso
0.7892830103	short note
0.7892650252	exponential random graph
0.7892391128	technical tool
0.7892180553	remains largely
0.7891636540	statistical significance
0.7891633907	discrepancy principle
0.7890803405	existing methods
0.7889602777	intermediate efficiency
0.7889501156	kl ucb
0.7889393032	receiver operating
0.7888560147	uniformly consistent
0.7887867142	scan statistics
0.7886808017	star shaped
0.7886604013	null distribution
0.7886453943	class labels
0.7886258386	infinite activity
0.7885944771	lipschitz continuous
0.7885252344	risk bound
0.7885188792	multi class
0.7884762913	convergence results
0.7884454132	short range dependent
0.7884267403	half space depth
0.7883809164	long standing
0.7883593497	bandit setting
0.7883567534	highly correlated
0.7883069219	asymptotically equivalent
0.7882442705	maximal correlation
0.7882109523	semi latin
0.7881285335	generalization bounds
0.7881214241	long run
0.7880383701	exchange rates
0.7878049936	small noise
0.7874163231	recent papers
0.7873877319	closed forms
0.7873704222	diffusion bridges
0.7873648574	global sensitivity
0.7873186138	population eigenvalues
0.7872976350	gaussian distribution
0.7872556509	recently gained
0.7872016022	kaplan meier
0.7871752986	poisson point process
0.7871293462	nonparametric estimators
0.7870712716	convolution type
0.7870404512	independence models
0.7870095970	degree corrected block
0.7869553546	mixing conditions
0.7868904911	cox ingersoll ross
0.7868309915	multi layer
0.7868071906	zig zag
0.7867331908	arbitrarily large
0.7867267970	brown resnick
0.7867229389	fisher snedecor
0.7866872126	convex loss functions
0.7866627644	linear transformations
0.7866433812	statistical methods
0.7866343219	cauchy stieltjes
0.7866178092	independence tests
0.7864617351	lasso type
0.7864032771	point estimation
0.7863028756	model adequacy
0.7862364682	statistical model
0.7862310141	iterative thresholding
0.7862241895	johnson lindenstrauss
0.7861708694	target density
0.7860782734	estimation error
0.7860402058	persistent betti
0.7859382227	step size
0.7858796982	semi supervised learning
0.7858324641	training data
0.7858167609	convex hull
0.7856440595	symmetric matrix
0.7856293489	local asymptotic mixed normality
0.7856177670	dependence function
0.7856048070	kernel density estimator
0.7855629038	proper learning
0.7854941372	loading matrix
0.7854815708	tangent spaces
0.7853857498	clopper pearson
0.7853763664	fairly general
0.7853759846	limit theorem
0.7853286943	distributed random variables
0.7852873570	inverse probability
0.7852356898	score functions
0.7850221869	filtering problem
0.7850192681	px da
0.7849478379	rao blackwell
0.7849465442	euler scheme
0.7849234302	chinese restaurant
0.7849192160	design matrices
0.7849078528	bayesian estimation
0.7848995983	sequential estimation
0.7848810702	wavelet analysis
0.7847981829	point pattern
0.7847591810	local asymptotic
0.7847413462	model choice
0.7845940273	passive learning
0.7845567672	multi variate
0.7845344315	nonparametric bootstrap
0.7843244949	standard gaussian
0.7842804428	learning rate
0.7842790364	strong convexity
0.7842300017	convergence speed
0.7842206781	heavy tailed distributions
0.7841510694	graphical gaussian
0.7841114424	random number
0.7840050624	randomly chosen
0.7839793188	change point localization
0.7839032642	genome wide association
0.7837754530	evy driven
0.7837474683	optimal allocation
0.7837342644	logistic model
0.7837069030	inferential procedures
0.7835096125	monotone function
0.7833907041	power functions
0.7833787237	jump size
0.7833739551	coverage probabilities
0.7833479773	crossover designs
0.7832796503	bayes optimal
0.7832639011	log determinant
0.7830520038	cell probabilities
0.7830060189	statistical independence
0.7829200737	cox process
0.7829115854	discrete choice
0.7828779426	prediction accuracy
0.7828472955	edge weights
0.7828426638	singular vector
0.7827372689	normal errors
0.7827077515	random measure
0.7826910868	stationary sequences
0.7826485646	briefly discussed
0.7826406860	kalman bucy
0.7826402286	complex models
0.7826258581	local asymptotic minimax
0.7826160806	bayesian updating
0.7825946192	importance weights
0.7825174030	strong dependence
0.7825132157	pre averaging
0.7824978906	statistical properties
0.7824691079	appropriately defined
0.7824480789	open question
0.7823618792	moore penrose
0.7823146881	convex set
0.7823050941	pearson correlation
0.7822988225	log concave densities
0.7822898020	behrens fisher problem
0.7822454379	order correctness
0.7822289915	newly developed
0.7822071179	order book
0.7821758423	lead lag
0.7820833252	convex relaxations
0.7820817520	berry esseen
0.7820171631	bernstein inequality
0.7819330832	log price
0.7818179165	short range
0.7817850215	binary choice
0.7816518321	error term
0.7816316512	specification tests
0.7815910784	related problems
0.7815686153	sequential detection
0.7815357150	super smooth
0.7812309267	dose finding
0.7810348252	galton watson
0.7809990622	attachment trees
0.7809271244	concave majorant
0.7808245823	frequentist inference
0.7808211851	simulation results
0.7807703729	stochastic volatility models
0.7807478499	gaussian fields
0.7806499565	test procedures
0.7806261726	test procedure
0.7805073527	newton raphson
0.7803641866	single index models
0.7802995896	kernel based
0.7802498297	estimation errors
0.7801256192	risk difference
0.7800836674	moment assumptions
0.7800585629	glivenko cantelli
0.7799012234	starting point
0.7797251263	singular subspace
0.7796177153	absolute moments
0.7795682688	mittag leffler
0.7795398456	structured sparsity
0.7795355126	dirichlet process mixture
0.7795171624	sample quantiles
0.7794264365	measurable function
0.7793446795	hodges lehmann
0.7793157946	feature space
0.7792324012	invariant distribution
0.7791849425	symmetric matrices
0.7791370525	optimal control
0.7790879593	quantile functions
0.7790444119	bayesian posterior
0.7789996319	total variation distance
0.7789965991	distance based
0.7789502058	spiked matrix
0.7789333078	vapnik chervonenkis
0.7789003151	fractional factorial
0.7788325723	fiducial inference
0.7787479980	homodyne tomography
0.7786909271	decision rule
0.7785711435	binary outcomes
0.7785228941	high accuracy
0.7785227546	delayed acceptance
0.7784730627	tree structured
0.7783756472	resolution iv
0.7783408376	short term
0.7783396460	renewal process
0.7783025637	graphical model selection
0.7781989921	l1 regularized
0.7780968570	coefficient functions
0.7780748321	computational challenges
0.7780046483	limiting behaviour
0.7779989767	low temperature
0.7779889832	density matrix
0.7779807622	exponentially fast
0.7779494620	completely randomized
0.7779139854	behrens fisher
0.7777415426	superior performance
0.7777213825	power variations
0.7777202593	laplace beltrami
0.7776337087	acceptance rejection
0.7776243879	finite set
0.7775691874	building blocks
0.7774431955	adaptive design
0.7774165084	grow exponentially
0.7773831244	multiple tests
0.7773693186	finite state space
0.7773517939	quantum fisher information
0.7773074619	asymptotic setting
0.7772581579	asymptotic consistency
0.7772480241	integral functionals
0.7772271643	marginal likelihood
0.7772175717	transition matrices
0.7772132319	covariance operator
0.7771969733	kernel density estimators
0.7771805154	penalty functions
0.7768964317	exact computation
0.7768963652	prior distribution
0.7768825161	generalized gamma
0.7768787838	trace regression
0.7768584430	estimation techniques
0.7767625572	pairwise distances
0.7767472023	sparse representation
0.7766784123	linear model
0.7766617357	real numbers
0.7766567675	multivariate elliptical
0.7765554705	minimization problems
0.7765072369	mild regularity conditions
0.7764632440	sufficiently large
0.7763438361	selection criteria
0.7762150853	horvitz thompson
0.7762021183	adaptive confidence bands
0.7761883686	depth functions
0.7761803335	theoretical properties
0.7760836450	sequence prediction
0.7760744112	cryo em
0.7760616807	grenander estimator
0.7759312305	convex penalty
0.7758928271	euclidean parameter
0.7758776213	laplace approximation
0.7757982378	quadratic variations
0.7756853751	test error
0.7756812161	linear mixed model
0.7755186349	random points
0.7754931923	finite mixtures
0.7754531433	contraction rate
0.7754350978	beta distributions
0.7753673103	community structure
0.7753154255	multiplicative constant
0.7752757333	reconstruction problem
0.7751387816	identified set
0.7750472126	exponential weights
0.7750197406	reference priors
0.7750096095	indicator functions
0.7749747072	kernel smoothing
0.7749337307	sequential change point detection
0.7749054275	multivariate quantiles
0.7748072799	gaussian copula
0.7747894371	consistency guarantees
0.7747705861	beta stacy
0.7747617409	quasi monte carlo
0.7747567382	maximum likelihood estimate
0.7747491941	increasingly popular
0.7745968497	determinantal point
0.7745931016	tensor product
0.7745518383	survival times
0.7745469306	statistical optimality
0.7745206978	existing results
0.7744795081	type estimators
0.7744618532	existing algorithms
0.7743825461	row wise
0.7743568579	divergence speed
0.7742594966	quantile based
0.7742500622	nonconcave penalized
0.7742401534	proper scoring rule
0.7742123639	identifiability conditions
0.7741806835	intensity function
0.7740963053	measure theoretic
0.7740673938	unifying framework
0.7740393569	effect models
0.7740341451	optimal detection
0.7738659446	gaussian shift
0.7737696414	local times
0.7736849215	continuous mark
0.7736387612	information content
0.7736295503	prior knowledge
0.7734712240	random projection
0.7733914549	empirical copula processes
0.7733478890	unit circle
0.7733348628	mathematical model
0.7733341026	theoretical aspects
0.7733179914	linear structural equation models
0.7733136567	stationary solutions
0.7732542480	event times
0.7732115383	ml degree
0.7731692300	weight functions
0.7731439730	posterior density
0.7731338634	sample eigenvalues
0.7728934041	low snr
0.7727221213	computational tractability
0.7726739517	convex program
0.7726733398	data compression
0.7725756684	efficiently computable
0.7725006849	arbitrarily small
0.7724909421	statistically optimal
0.7724717694	generalized hyperbolic
0.7724077425	learning problem
0.7723958508	rare weak
0.7723831628	set ups
0.7722896845	statistical power
0.7722364048	statistical inverse problems
0.7722130936	model selection criteria
0.7721308434	ordinary smooth
0.7720831159	misclassification error
0.7720772376	anderson darling
0.7720437831	statistical manifold
0.7720252498	scientific fields
0.7720182567	uniformly valid
0.7719336738	paper reviews
0.7719240364	finite horizon
0.7719155380	resulting estimators
0.7716941412	bayesian credible
0.7716931521	proposed method
0.7716578789	finite size
0.7716510123	mann whitney
0.7716253892	evy density
0.7715986040	multi step
0.7715655018	dependent random
0.7715578064	empirical characteristic function
0.7715062046	wald test
0.7714993994	recursive estimation
0.7714165084	great importance
0.7713996986	bivariate normal
0.7713830497	random graph models
0.7713550539	square error
0.7713248977	penalty term
0.7712090107	durbin watson
0.7711819589	asymptotic bias
0.7711776453	higher dimensional
0.7711767712	effect sizes
0.7711247948	large samples
0.7710787796	based methods
0.7710486924	davis kahan
0.7710314188	binary hypothesis testing
0.7709902172	analytically tractable
0.7709214634	multivariate extremes
0.7709144314	functional deconvolution
0.7709017103	stochastic geometry
0.7707964264	truncated samples
0.7707878690	error control
0.7707725980	order statistic
0.7707416717	ratio statistic
0.7707174261	ordinary least squares
0.7706260993	gumbel distribution
0.7706249132	sequential monte
0.7705810631	gene expression data
0.7705070531	crossing probabilities
0.7704862605	proposed estimators
0.7704329339	based clustering
0.7704221606	bayes rule
0.7702894650	simulation study
0.7702597678	reduced rank
0.7701970603	sensing matrix
0.7700968637	global optimization
0.7700891725	structural equation
0.7700734304	false rejection
0.7700647057	kolmogorov distance
0.7700500962	skew symmetric
0.7699963223	predictor variables
0.7699882766	goldenshluger lepski
0.7699609445	jensen shannon divergence
0.7699052783	conditional densities
0.7698543015	volatility process
0.7698372290	repeated measures
0.7698081033	coordinate wise
0.7696869199	strong law
0.7695307841	mixed normal
0.7693985153	moment inequality
0.7693622088	latent positions
0.7693420843	cluster structure
0.7692395673	epsilon machines
0.7692380939	differential operator
0.7690898491	equivalence classes
0.7689487823	testing monotonicity
0.7688719135	sufficiently sparse
0.7688254198	multi category
0.7687893761	volatility matrix
0.7687731176	correlated data
0.7686973703	margin condition
0.7686805432	bayesian nonparametric inference
0.7685980889	objective bayesian
0.7685539738	score test
0.7684889944	design based
0.7684498290	nonparametric statistics
0.7684182144	normal means
0.7683866837	poisson intensity
0.7683733720	finite variance
0.7683325124	uniform prior
0.7682984143	transition matrix
0.7681166876	average variance
0.7680979014	clustering problem
0.7680104192	likelihood functions
0.7679843456	birnbaum saunders
0.7679708715	finite sample size
0.7679581157	high dimensional inference
0.7678526678	recent results
0.7677918213	information flow
0.7676604682	distributional assumptions
0.7676349619	change point estimation
0.7675817520	fokker planck
0.7673797190	data depth
0.7673773926	linear constraints
0.7673524641	covariance structures
0.7673475089	multivariate data
0.7672420827	sparse linear
0.7671825042	unknown vector
0.7670482344	log linear models
0.7670162884	statistical efficiency
0.7669038340	sample paths
0.7667978245	exploratory data analysis
0.7666929761	data processing inequalities
0.7666580604	posterior inference
0.7665891636	optimal policy
0.7665778973	latent class models
0.7665706711	descent algorithm
0.7665350162	exponential growth
0.7665034341	estimation methods
0.7663475021	limit distributions
0.7663441481	local power
0.7661962768	tensor train
0.7661621537	statistical guarantees
0.7660386303	markov model
0.7659994695	effective rank
0.7659758093	stochastic models
0.7659287756	locally optimal designs
0.7658148736	response variable
0.7657844150	predictive risk
0.7657153429	survival probability
0.7656858395	sparsity assumption
0.7656241152	common practice
0.7655764172	model fitting
0.7655720999	hidden markov chain
0.7655291892	post stratification
0.7654514480	slowly varying
0.7653960696	coverage accuracy
0.7653059662	structural assumptions
0.7652287468	sharp bounds
0.7651654251	recently introduced
0.7651125330	euclidean ball
0.7651047574	p_r p_r
0.7650974704	additive regression
0.7650670931	sampling frequency
0.7650537539	consistency properties
0.7648781801	renewal theory
0.7648526852	conformal inference
0.7647941013	limit theory
0.7647387476	informative priors
0.7646897848	regression problem
0.7645834075	mixed integer
0.7645436204	nested sampling
0.7643559955	mixed effects
0.7642507864	regression depth
0.7642311072	lognormal distribution
0.7642021445	gauss markov
0.7641781544	strictly increasing
0.7640361792	aalen johansen
0.7640191249	single index model
0.7639603198	consistently estimated
0.7638858009	density estimates
0.7638254145	analytical expressions
0.7637971847	carefully chosen
0.7637454550	analogous result
0.7634727801	product measures
0.7633814337	linear forms
0.7632482896	projection depth
0.7632330429	distributional properties
0.7631434521	block wise
0.7631181776	space filling designs
0.7629767517	laplace deconvolution
0.7626538609	observational data
0.7625631090	linear predictors
0.7623911595	parametric families
0.7623231408	asymptotic mixed normality
0.7623029683	quantile processes
0.7622645177	sensor network
0.7622257593	tracy widom law
0.7622035335	conway maxwell poisson
0.7620982737	nonstationary processes
0.7619114062	easily implemented
0.7619095484	average causal effect
0.7618728940	sensitivity index
0.7618726947	autocovariance function
0.7618636487	multivariate statistics
0.7618058565	linear operators
0.7617220435	selection criterion
0.7616495438	optimal rate
0.7615722449	computationally attractive
0.7614909516	analytical expression
0.7613935508	limit distribution
0.7612746844	theoretical results
0.7612342515	product limit
0.7611198318	exponentially weighted
0.7611024578	selection consistency
0.7610929534	estimating equation
0.7610851215	statistical complexity
0.7610743203	l2 norm
0.7610523145	high temperature
0.7608569244	noise variance
0.7607998304	power laws
0.7607812966	fundamental question
0.7606711429	arbitrarily close
0.7605968709	technical contribution
0.7605496758	projection theorems
0.7605089932	type ii error
0.7605066755	treatment regimes
0.7604877276	uniform distribution
0.7604210456	potential outcome
0.7602588610	spectral radius
0.7602091072	simulation based
0.7602055066	dependent sequences
0.7601744688	average case
0.7601589675	random censoring
0.7601437666	statistical consistency
0.7600601188	asymptotic theory
0.7600490677	random sums
0.7599627012	competitive performance
0.7598701611	randomization tests
0.7598126554	leibler divergence
0.7597662972	mild condition
0.7597481271	tensor decomposition
0.7596331350	sufficiently small
0.7596100449	verifiable conditions
0.7596098741	nonzero coefficients
0.7595879816	spatially adaptive
0.7595281438	empirical process theory
0.7595134703	rademacher complexities
0.7594966066	faster rates
0.7594392867	recently developed
0.7594337702	necessarily identically distributed
0.7594217454	post processing
0.7594094413	interval censored
0.7593891012	dependent observations
0.7593884661	rank aggregation
0.7593802122	drift term
0.7592890519	performance bounds
0.7592364376	coupling argument
0.7592150853	blumenthal getoor
0.7591849171	energy distance
0.7591798428	central moments
0.7591243013	parameter estimates
0.7591173799	copula based
0.7590998483	multi modal
0.7590369377	empirical distribution
0.7590207205	likelihood equations
0.7589448985	random permutations
0.7588763160	compact support
0.7588384101	sampling distribution
0.7587833298	bernstein von mises theorem
0.7587055745	kernel density
0.7586656087	older class
0.7586297145	constructing confidence intervals
0.7585125536	limiting spectral distribution
0.7585058101	information divergence
0.7583754604	asymptotically pivotal
0.7583275717	cumulant function
0.7583028664	analytical results
0.7582899125	multiple change points
0.7582866171	reliability theory
0.7582170092	invariant tests
0.7581802171	dimensional projections
0.7581242722	slope heuristics
0.7580114373	directed edges
0.7578573082	identification problem
0.7577229430	improved estimators
0.7576907108	selection rules
0.7576853349	privacy guarantees
0.7576201598	unit vector
0.7575556522	arises naturally
0.7575300476	hyper parameters
0.7575163846	statistical tests
0.7575142590	exchangeable graphs
0.7574702440	growth rate
0.7574157135	estimation problem
0.7573430347	mild assumptions
0.7572512727	unbiased risk estimation
0.7572129369	coefficient matrix
0.7571905915	random intervals
0.7571738697	lipschitz constant
0.7571469146	real data sets
0.7571301748	computational efficiency
0.7568923189	information processing
0.7567565979	sample points
0.7567208639	high dimensional regression
0.7566438997	prior measures
0.7566098678	tail behavior
0.7566022735	arbitrary dependence
0.7565843808	generalized exponential
0.7565648698	information theoretic limits
0.7564633484	minimax bounds
0.7563353755	prior mass
0.7563280107	sensor networks
0.7563167084	factorial design
0.7562870524	essential graph
0.7561538466	spatial processes
0.7561281371	linear combinations
0.7559529643	graphical lasso
0.7559353977	log concave distributions
0.7559349930	synthetic examples
0.7558956024	kernel learning
0.7558883227	prior probabilities
0.7558835345	response variables
0.7558233518	riemannian metrics
0.7556861688	quantitative factors
0.7556348787	graph partitioning
0.7555743203	diagonal matrix
0.7555254141	tree structure
0.7555225826	kullback leibler loss
0.7554326178	fleming viot
0.7553702534	curie weiss model
0.7552368812	predictive performance
0.7552192196	normal random variables
0.7551905181	mixing density
0.7551236766	performance guarantees
0.7551114260	high dimensional linear regression
0.7551096967	limiting distributions
0.7550775935	smoothness conditions
0.7550454916	iterative algorithm
0.7549128978	proposed tests
0.7548638203	random graph model
0.7548537217	large datasets
0.7546724869	isotropic gaussian
0.7546023202	subspace clustering
0.7545842321	log linear
0.7545550821	weaker conditions
0.7545456927	conditional expectations
0.7545273226	low rank matrix estimation
0.7542592397	step mle
0.7542098016	sequential test
0.7541708404	von mises fisher
0.7541399470	sparse alternatives
0.7541396346	local maxima
0.7541265433	boundary conditions
0.7541257396	dynamic networks
0.7541122666	finite sample properties
0.7540381691	main contributions
0.7539263588	recent works
0.7538782384	faster rate
0.7538709342	empirical success
0.7538281579	whittle estimation
0.7537864868	regularization parameters
0.7534907486	shape parameters
0.7533320979	instance dependent
0.7532375816	reasonable assumptions
0.7532340031	marcenko pastur
0.7532122250	highly efficient
0.7531057158	squared error loss
0.7530548338	enko pastur
0.7530020448	proposed framework
0.7529897213	generalized pareto distribution
0.7529345214	sample path
0.7529083180	post selection
0.7528580792	spatial statistics
0.7527556542	computational limits
0.7525021303	discrete data
0.7523846795	perturbation bootstrap
0.7523831929	asymptotically distribution free
0.7523247519	closed form expression
0.7521777987	gaussian vector
0.7520795732	spatial extremes
0.7520723195	multiple sources
0.7520180690	barndorff nielsen
0.7519732251	quadratic functional
0.7518652388	dimensional space
0.7518340031	bradley terry
0.7518192477	community recovery
0.7517992615	unknown parameters
0.7517639938	state path
0.7516935698	type moderate deviation
0.7516612681	spectral domain
0.7514544562	control variate
0.7514158213	baum welch
0.7514003208	square loss
0.7513711762	nominal level
0.7511712176	mcmc algorithm
0.7511706083	memory parameter
0.7511272098	random processes
0.7511095287	asymptotic distributions
0.7510370472	data dependent
0.7510119319	moment matching
0.7510093011	sequential prediction
0.7510079976	asymptotically valid
0.7509779061	locally adaptive
0.7509674882	bayesian framework
0.7509524027	examples include
0.7509374334	spectral measure
0.7508891207	entropy rate
0.7508727209	numerical evidence
0.7508155843	symmetric channel
0.7507879970	underlying distribution
0.7507584647	optimization algorithms
0.7507085793	asymptotic regimes
0.7506423366	restricted strong convexity
0.7506099272	score statistic
0.7506077706	increasing domain
0.7504790001	seminal paper
0.7504430328	separation rate
0.7504231713	multi resolution
0.7504050745	cox processes
0.7503814326	unknown smoothness
0.7503679548	binary tree
0.7501594052	compound poisson processes
0.7501259190	bounded degree
0.7501008984	smoothness properties
0.7500845458	random sequences
0.7500696570	random geometric graphs
0.7499783891	finite mixture
0.7499101160	optimal weights
0.7498312386	numerical simulation
0.7498304691	asymptotically linear
0.7498091182	density power divergence
0.7497873990	largest eigenvalues
0.7497419672	multiple output
0.7496185980	fully bayesian
0.7496170452	empirical measure
0.7496142217	inverse binomial
0.7495560706	regression parameters
0.7494790952	variance bounds
0.7494520815	decision problems
0.7493401116	integral representations
0.7492313373	score matching
0.7491315803	binary variables
0.7491249083	coefficient function
0.7490510797	singular value decomposition
0.7489979940	dependent errors
0.7489829747	results imply
0.7489345881	pre change
0.7488594203	arma garch
0.7488490352	residual based
0.7488120382	communication cost
0.7488111461	resulting estimate
0.7487810297	deconvolution problems
0.7487431241	gross error
0.7486908133	unbiased estimator
0.7486103793	functional delta method
0.7485991383	functional spaces
0.7485914125	robustness property
0.7485768028	usual stochastic order
0.7485413531	high threshold
0.7482134693	negative values
0.7481981339	light tail
0.7480183115	hidden states
0.7479995657	global minimum
0.7479865362	reference prior
0.7479109289	local means
0.7479030493	monotone density
0.7478509767	nonlinear models
0.7478395742	independent observations
0.7477889239	random features
0.7477185548	minimax adaptive
0.7477166885	averaged version
0.7476446963	definite matrices
0.7476420831	pareto type
0.7476175911	quasi maximum likelihood
0.7474710590	markov regime
0.7472791653	absolute error
0.7472434441	dempster shafer
0.7472294215	briefly discuss
0.7471543402	stationary random fields
0.7470229393	posterior sampling
0.7469549556	change point tests
0.7469510560	minimax risks
0.7469020738	simulated examples
0.7469008543	weight matrix
0.7468536872	proposed methods
0.7467292453	input variables
0.7467128955	vertex set
0.7467098610	major challenge
0.7466448400	nested models
0.7465119915	additive functionals
0.7464706644	proposed algorithms
0.7464654505	grenander type
0.7464369868	trace class
0.7464063854	information theoretically optimal
0.7463890692	small area estimation
0.7462913456	spatial temporal
0.7462303110	concentration graph
0.7462130971	statistical problems
0.7461521480	proposed family
0.7460719321	functional covariates
0.7460180690	hayashi yoshida
0.7459698065	observation scheme
0.7459419589	tight bounds
0.7459388388	decomposable graphical
0.7459029001	network structures
0.7458401589	bayesian learning
0.7458182084	vector space
0.7457362883	fisher rao metric
0.7456940991	numerical implementation
0.7456135651	asymptotic distribution
0.7456038902	multi index
0.7454442508	design matrix
0.7454336365	laplace beltrami operator
0.7452849854	widely linear
0.7452418429	ergodic markov chains
0.7452347964	mixture distribution
0.7451888209	conditions ensuring
0.7450859210	sparse matrices
0.7450830809	fractional poisson
0.7450212651	gradient based
0.7450061606	reference measure
0.7449773016	low rank matrix completion
0.7449707630	prior probability
0.7449452946	base measure
0.7448932456	model classes
0.7448286151	response vector
0.7447491048	coefficient vector
0.7447162972	estimator attains
0.7446378070	bandwidth choice
0.7445737331	multiple wiener
0.7445289083	asymptotic behaviors
0.7444238375	eigenvalue density
0.7444196239	regularity assumptions
0.7443367005	additional assumptions
0.7442586515	model based
0.7441966649	point estimate
0.7441879607	minimum norm
0.7441199269	multi reference alignment
0.7440377739	markov matrices
0.7439505924	outcome regression
0.7438097465	growth rates
0.7437972844	estimation method
0.7437808310	autocovariance matrices
0.7437581432	fixed domain asymptotics
0.7437342534	asymptotic inference
0.7436866795	grows exponentially
0.7434776506	easily computed
0.7433726080	boundary bias
0.7433534681	largest order statistics
0.7433227179	probabilistic forecasts
0.7432593616	quadratic program
0.7432450476	adaptive procedure
0.7432052047	shape restricted
0.7431733448	treatment groups
0.7430965544	uncertainty principle
0.7430852627	weak conditions
0.7429644115	berry esseen bound
0.7429552275	observed entries
0.7428405836	selection rule
0.7428150349	application areas
0.7428020064	kernel ridge
0.7427409426	sparse additive models
0.7427359330	outcome variable
0.7426630604	sampling algorithm
0.7426329437	large data sets
0.7425838656	spectral theory
0.7425681087	conditionally gaussian
0.7425632038	optimality conditions
0.7425205616	enko pastur law
0.7424280759	specification test
0.7424225390	translation invariant
0.7424069102	parametric estimation
0.7423920173	hierarchical model
0.7423783220	population risk
0.7423759198	singular vectors
0.7422385031	gibbs measures
0.7422216176	sparse structure
0.7421990182	dependency graph
0.7421708917	bernoulli random variables
0.7421650744	random networks
0.7421540844	signal matrix
0.7421386814	learning task
0.7421153314	computationally intractable
0.7420857374	model parameters
0.7420732618	asymptotic behavior
0.7420166469	alpha skew
0.7419477308	theoretical result
0.7418217456	bayesian methods
0.7417475781	results suggest
0.7417042422	probabilistic model
0.7416742352	armed bandit
0.7416460177	generalized additive models
0.7415375123	results reveal
0.7415029323	sparse additive
0.7414848853	component functions
0.7414547901	prediction function
0.7413476602	matrix estimation
0.7412341812	weibull distributions
0.7411750111	smooth transition
0.7411704671	node degrees
0.7411196297	basis functions
0.7411184467	kernel matrix
0.7410652162	desirable property
0.7410058405	concentration bounds
0.7410057674	ergodic diffusion process
0.7409379341	monte carlo experiments
0.7408764881	convex aggregation
0.7408619564	volatility models
0.7408198257	unknown variance
0.7407941361	auto correlation
0.7407448948	inference methods
0.7407250220	smooth functionals
0.7407207280	likelihood estimates
0.7406170490	adaptive procedures
0.7406126059	failure times
0.7404026986	empirical distribution function
0.7403152557	mild conditions
0.7403139835	dimensional settings
0.7402936161	surrogate model
0.7402561125	binary search
0.7402154000	group sequential
0.7401335071	exponential weighting
0.7400993877	hanson wright
0.7400167687	provide theoretical
0.7399971753	coverage error
0.7399866452	variable importance
0.7399211698	component wise
0.7398882539	regularity properties
0.7398875152	finite order
0.7398872272	classification error
0.7398744874	bayes classifier
0.7398230300	estimator achieves
0.7397472443	moment based
0.7396594167	analytic expressions
0.7396137044	interval valued
0.7394618532	general semiparametric
0.7394255230	probability simplex
0.7394195841	variational analysis
0.7393071849	activation functions
0.7392556351	iterative algorithms
0.7391817135	estimation efficiency
0.7390125401	direct effect
0.7389227160	asymptotic relative efficiency
0.7389148217	newly proposed
0.7388035779	real case
0.7387936502	marked empirical
0.7387529057	cand \ ` es
0.7387032465	quantitative bounds
0.7385509139	population size
0.7385328093	spatial correlation
0.7384647411	score tests
0.7384527505	multi stage
0.7382143224	exchangeable random partitions
0.7381319110	sampling policy
0.7379744967	kohonen algorithm
0.7379460726	general framework
0.7379449639	elliptical distribution
0.7379141853	separable hilbert space
0.7379028789	long memory processes
0.7378747170	function estimation
0.7377326741	type theorem
0.7377042627	specification testing
0.7376791658	low noise
0.7375618871	training sample
0.7375407446	rank minimization
0.7375001057	homogeneous markov chain model
0.7374497555	block sizes
0.7374127383	noise levels
0.7373947961	analysis reveals
0.7373914497	asymptotically correct
0.7373538063	informative prior
0.7373338410	based inference
0.7373314678	left truncation
0.7372559437	low complexity
0.7371272362	computed efficiently
0.7371037148	glivenko cantelli theorem
0.7370392595	based algorithms
0.7370205054	exchangeable random
0.7369401281	random coefficient ar
0.7368733103	tail copula
0.7368116671	scatter estimators
0.7368087958	dynamic factor
0.7367375835	adaptive elastic net
0.7366860148	convergence properties
0.7366010748	response function
0.7365536801	pairwise interaction
0.7365296092	marginal regression
0.7365153194	main results
0.7364870527	penalized estimator
0.7364690318	target parameter
0.7364085083	gaussian kernels
0.7362790744	sample performance
0.7362500273	sobolev type
0.7362402605	fully adaptive
0.7361926720	multiple imputation
0.7360508918	squared loss
0.7360199143	exponentially small
0.7359832833	bayesian shrinkage
0.7359741043	combinatorial structure
0.7359480637	article focuses
0.7358869344	information leakage
0.7358280706	hierarchical bayesian
0.7357345049	low sample size
0.7356977496	concentration results
0.7356820808	probabilistic inference
0.7356738466	prior densities
0.7355933379	bayesian perspective
0.7355466663	bipartite graph
0.7354887935	linear span
0.7354722824	prior specification
0.7354672381	minimal sufficient
0.7353677759	marked point processes
0.7353199328	based estimators
0.7352809530	probability densities
0.7352440273	compound poisson process
0.7352192410	similar results
0.7351939030	beta binomial
0.7350872965	classical results
0.7349696837	exchange algorithm
0.7348981143	sparse group lasso
0.7347854306	spectral measures
0.7346284684	generating functions
0.7345587806	geometric interpretation
0.7345233801	linearly independent
0.7344271979	mixture components
0.7343598281	detection problems
0.7342705473	gaussian entries
0.7342074956	weak consistency
0.7342012401	leverage effect
0.7341351409	conditional variance
0.7340943025	uniform confidence bands
0.7339987627	transition densities
0.7339649704	statistical test
0.7339135164	key technical
0.7338922568	previous results
0.7337533620	adaptive sampling
0.7335409789	parameter values
0.7335390224	fisher matrix
0.7335139125	random functions
0.7334622857	density regions
0.7334587204	computational methods
0.7333547917	multiple testing procedure
0.7332902427	optimal convergence rates
0.7332642682	extreme points
0.7332326662	background knowledge
0.7332071188	lasso penalty
0.7331165750	bounded random variables
0.7330744312	stochastic dynamics
0.7328322280	financial data
0.7327686734	cross entropy
0.7326943931	bootstrap procedures
0.7326748653	markov kernel
0.7325830622	elliptical symmetry
0.7324814551	stationary distributions
0.7324814338	input parameters
0.7324759178	high dimensional sparse
0.7323645437	asymptotic expansion
0.7323403132	measure theory
0.7323294084	weak topology
0.7322207094	current literature
0.7321494061	error correction
0.7321422976	periodic function
0.7320840486	linear gaussian
0.7320191525	information theoretic lower bounds
0.7319945356	type inequalities
0.7319873398	theoretical analysis
0.7319555032	smoothness assumptions
0.7319463626	maximum pseudo likelihood
0.7319083118	multi object
0.7318984994	meta algorithm
0.7318262759	discrete random variables
0.7317163643	theoretical bounds
0.7316932755	gibbs type
0.7316783414	mixed graph
0.7316756654	asymptotic framework
0.7316604658	generalization performance
0.7316324042	group invariance
0.7316168574	subspace recovery
0.7315938068	block designs
0.7315872665	variable length
0.7315310338	double bootstrap
0.7314878979	finite moments
0.7314749021	computational costs
0.7312992922	degree heterogeneity
0.7312975012	weighted sums
0.7312919089	generalized entropy
0.7311664115	comparative study
0.7311052050	conditional dependence
0.7310575650	epidemic models
0.7309821277	noisy linear
0.7309739121	training error
0.7309084591	fokker planck equation
0.7308942024	hanson wright inequality
0.7308009243	high dimensional linear models
0.7307917581	private algorithms
0.7306756031	standard error
0.7306243297	smoothness level
0.7305958206	competing methods
0.7305316654	cross section
0.7305169756	constant fraction
0.7304559296	parameter spaces
0.7304062656	partition function
0.7303598371	large graphs
0.7303131738	adaptive designs
0.7302642298	support points
0.7301841777	dependent inputs
0.7301807106	correlated wishart
0.7301699465	independent and identically distributed
0.7301475505	statistical computational
0.7300941023	simple hypotheses
0.7300770353	control theory
0.7300671073	random series
0.7300629480	quasi bayesian
0.7300550343	convex body
0.7300449330	multi armed bandit problem
0.7300411283	strong consistency
0.7299994920	dependence properties
0.7299308320	linear stochastic
0.7299300478	additive components
0.7298468976	genome wide
0.7298448794	discrete observations
0.7296837355	group selection
0.7295874097	monitoring schemes
0.7295859781	estimation accuracy
0.7295248787	uniform norm
0.7295123148	developed theory
0.7294912808	particle systems
0.7294464774	approximate sparsity
0.7293790193	fast rate
0.7293478626	linear transformation
0.7293202367	bounded support
0.7292554717	proof techniques
0.7290685446	strongly correlated
0.7290087885	vasicek model
0.7289490456	variational problem
0.7288458785	existing approaches
0.7288384561	reconstruction algorithm
0.7287862507	variance functions
0.7287537995	model specification
0.7287049369	convergence guarantees
0.7285933986	adaptive estimator
0.7285693437	natural language
0.7285621529	estimating function
0.7285491113	prediction risk
0.7284827429	empirical variance
0.7284634850	main theorem
0.7284018324	significantly outperforms
0.7283895159	parameter vectors
0.7283381786	gaussian white noise
0.7282960905	confidence bounds
0.7281521658	diffusion models
0.7280325706	multi level
0.7279950284	markov decision
0.7279862018	ergodic diffusion
0.7279153099	nonparametric bayes
0.7278925928	jump rate
0.7278887283	numerical results
0.7278465153	sampling error
0.7278324236	kernel matrices
0.7277677912	evaluation metrics
0.7277255638	set size
0.7277211367	model complexity
0.7274347120	posterior convergence
0.7273844150	random dot product
0.7272710181	high quality
0.7272681827	fisher information metric
0.7272567736	explicit expressions
0.7272333288	degree distributions
0.7271147032	variance components
0.7271097992	lasso path
0.7270280952	quadratic functionals
0.7270205955	functional linear model
0.7269473893	sparse high dimensional
0.7268864899	previously established
0.7268577269	norm loss
0.7268517977	functional principal component analysis
0.7267927315	fisher matrices
0.7266938410	spectral algorithm
0.7266137595	tracy widom distribution
0.7265609128	parameter identifiability
0.7265453241	greedy algorithms
0.7264233712	gibbs point processes
0.7262957519	slower rate
0.7262322955	high probability
0.7261381287	inverse wishart
0.7261093259	smooth signals
0.7260813099	regularization method
0.7260606066	limiting laws
0.7260372210	matching priors
0.7260010379	log concave density
0.7259815852	moment generating
0.7259587205	moment estimators
0.7258955428	graph matching
0.7258273472	discrete distribution
0.7256646524	proposed procedure
0.7255926701	discrete choice models
0.7255598993	compact riemannian
0.7255396528	directional statistics
0.7255272458	low dimensional subspace
0.7255205810	randomization based
0.7254356604	standard normal
0.7254239633	proposed algorithm
0.7254216208	lower tail
0.7253884882	mixing properties
0.7253402712	detection boundary
0.7251179780	metric entropy
0.7249415599	isometry property
0.7248747909	dimensional signals
0.7248622884	ultra high
0.7248383707	streaming data
0.7247879195	block length
0.7247804804	fully nonparametric
0.7247664505	projection operator
0.7247329492	heteroscedastic noise
0.7246993405	tail asymptotics
0.7246760877	partial recovery
0.7246359958	significance testing
0.7245439319	nonparametric components
0.7244112391	independence assumption
0.7244027567	variable selection consistency
0.7242599537	asymptotic approximations
0.7242197997	optimality results
0.7242116665	predictive density estimation
0.7241515873	shrinkage prior
0.7241103928	small probability
0.7240635807	consistent tests
0.7240261605	horvitz thompson estimator
0.7238951723	minimax lower bound
0.7238741756	maximal inequality
0.7238651793	maximum likelihood degree
0.7238438820	controlling procedures
0.7236428709	computational lower bounds
0.7235731489	quantile estimation
0.7235050043	scale space
0.7233981755	higher moments
0.7233330896	efficient inference
0.7232847587	rate function
0.7232100212	labeled data
0.7231944823	classical methods
0.7230936828	proposed approach
0.7229600980	size increases
0.7228870189	regular graphs
0.7227937175	local dependence
0.7227804807	fixed alternatives
0.7227711328	multi armed
0.7227335253	relative efficiency
0.7226944117	sequential sampling
0.7224762299	sign consistency
0.7224368508	location parameters
0.7224164045	prior measure
0.7223973498	optimal sample complexity
0.7223937293	error probabilities
0.7223753254	gaussian mixture model
0.7223255205	holds true
0.7222354435	chain monte carlo
0.7220931991	threshold selection
0.7220780029	mathematical analysis
0.7220353594	dimensional case
0.7219682086	numerous applications
0.7219388215	tail parameter
0.7219293888	edge set
0.7219259291	squares estimator
0.7216978073	weighted bootstrap
0.7216604564	minimal penalty
0.7216448726	paper presents
0.7214847921	threshold autoregressive
0.7214414590	weak recovery
0.7214118474	positive semi definite
0.7213854894	asymptotic regime
0.7212026063	proposed methodology
0.7211354844	exponential tails
0.7210687574	geometric distribution
0.7210417728	white noise model
0.7210182476	group size
0.7210177830	cross correlation
0.7209283760	power behavior
0.7208059955	nonparametric models
0.7207900363	existing works
0.7207130195	fast computation
0.7206448007	exponential distributions
0.7206250597	obtained results
0.7205518362	structural change
0.7205233904	multivariate bernoulli
0.7204693551	randomization test
0.7204663289	fourier coefficients
0.7204128353	reduced rank regression
0.7203134816	asymptotic representation
0.7202615936	high level
0.7201953638	noisy measurements
0.7201831431	auto covariance
0.7201740629	asymptotic law
0.7201205000	exponential random variables
0.7200778823	short range dependence
0.7200753892	probabilistic properties
0.7199619169	conditional covariance
0.7199044320	missing observations
0.7198702599	optimal prediction
0.7198511130	diagonal entries
0.7198397469	microwave background
0.7197568066	optimal recovery
0.7197065284	extreme value copulas
0.7196263275	hamiltonian monte
0.7195988281	poisson distributions
0.7195866481	semiparametric transformation
0.7195305396	latent class
0.7194884846	shape theory
0.7193862328	previous studies
0.7192989231	conditional distribution
0.7192967623	consistency results
0.7192794536	curie weiss
0.7192619588	maximum score
0.7192277490	convex order
0.7190056586	spectral risk measures
0.7190016830	weak assumptions
0.7188564749	finite state
0.7188483192	largest singular
0.7186224237	alternative methods
0.7186021845	nonparametric regression function
0.7185319666	confidence levels
0.7184914646	mixed models
0.7184877957	high frequencies
0.7183798360	case control studies
0.7183719304	threshold parameter
0.7182925500	ls estimator
0.7182848812	exponential inequalities
0.7182797238	proportional hazards model
0.7182534116	probability converging
0.7182431894	stability property
0.7182402295	risk factors
0.7182398404	log canonical
0.7182298344	minimax regret
0.7182070885	asymptotically unbiased
0.7181641932	nonlinear filtering
0.7180873428	invariant measure
0.7179566932	general purpose
0.7179088993	exponential rate
0.7178274621	davis kahan theorem
0.7177226674	semi algebraic
0.7177202921	finite sample performance
0.7176703415	permutation based
0.7176688516	based approach
0.7176115883	fixed width
0.7175985999	data stream
0.7175468536	urn model
0.7174809211	symmetric spaces
0.7173760406	bayes theorem
0.7173574164	inference procedure
0.7173503132	inverse covariance matrix
0.7173202367	broad classes
0.7173055886	optimization algorithm
0.7172521280	rank sum
0.7172520148	underlying distributions
0.7172067355	durbin watson statistic
0.7171351908	practical applications
0.7170675655	practical aspects
0.7170670599	multiplicative factor
0.7170670373	real wishart
0.7170158747	mixed fractional
0.7169769559	theoretical guarantee
0.7168689350	type estimator
0.7168376218	open questions
0.7168000547	explicit formulas
0.7167314042	moment bounds
0.7166916501	realized covariance
0.7166838204	null distributions
0.7166554182	shape analysis
0.7166212944	failure probability
0.7165576728	practical implications
0.7165343979	sample optimal
0.7165333139	random trees
0.7165173548	underlying model
0.7164970284	structural models
0.7164629618	minimum sample size
0.7163904062	minimum distance estimation
0.7163779900	main ideas
0.7163261192	unit vectors
0.7161496151	bayesian paradigm
0.7160689668	dimension free
0.7160095582	manifold valued
0.7159801711	minimax separation rates
0.7159377078	quantum statistics
0.7158773864	bernstein type inequality
0.7158110764	statistical applications
0.7157871819	multiscale bootstrap
0.7157016863	adaptive nonparametric
0.7156780824	ratio test
0.7156621788	stationary points
0.7156020094	mixture component
0.7155968100	significantly outperform
0.7155785953	simulated datasets
0.7155651306	mixing condition
0.7154849818	projection estimators
0.7154690710	log likelihood ratio
0.7154388914	hidden variables
0.7153943852	spiked random
0.7153588074	paper considers
0.7153293576	karhunen lo \ ` eve
0.7152165798	selection problem
0.7151622674	kolmogorov smirnov statistic
0.7151568831	fixed sample size
0.7151118431	prediction interval
0.7150757020	causal states
0.7150715020	main tool
0.7149761181	target function
0.7149431781	evy measure
0.7148917802	power law decay
0.7148625028	proposed model
0.7148383091	curved exponential
0.7147274752	valid post
0.7147126937	recently proposed
0.7146782961	data generating
0.7146448562	robustness properties
0.7146418007	prediction regions
0.7146312417	maximum degree
0.7144892971	asymptotic dependence
0.7144143083	missing mass
0.7144061940	uniformly most powerful
0.7143951457	sequential hypothesis testing
0.7143417643	minimax estimators
0.7142608110	rigorous proof
0.7142535159	moderate deviation principle
0.7140654943	dependence structure
0.7140586649	generalized likelihood ratio test
0.7140523824	intensity estimation
0.7139920299	poisson binomial
0.7139862507	bounded domain
0.7139419037	functional linear models
0.7137536880	markov chain monte carlo algorithms
0.7136594390	equi energy
0.7136477922	clustered data
0.7135320350	asymptotic null distribution
0.7135230973	technical conditions
0.7135108072	high breakdown
0.7134381625	berry esseen bounds
0.7132143834	challenging task
0.7131847896	candidate models
0.7131343342	prediction problems
0.7131262110	random initialization
0.7128653040	poly logarithmic
0.7128645884	ergodic markov chain
0.7128613124	linear equations
0.7127407924	block size
0.7126260016	population level
0.7125521262	power spectral density
0.7124936557	stable tail
0.7124566423	sampling times
0.7124526076	extreme order statistics
0.7124034785	applied probability
0.7123810727	statistical functionals
0.7123686937	high frequency financial data
0.7123515248	special case
0.7123505958	parameter inference
0.7123308270	latent tree
0.7123146241	linear regressions
0.7120985644	generalization properties
0.7119269750	logistic regression model
0.7119266688	multiple change point
0.7119047169	density ratios
0.7118431965	jump process
0.7116218007	power loss
0.7116029544	fmri data
0.7115468236	graph based
0.7114172985	main technical
0.7114064173	nonparametric kernel
0.7113823876	estimated residuals
0.7113750832	case cohort
0.7113361769	bounded set
0.7113082580	undirected graph
0.7112991696	topological structure
0.7112839870	separation rates
0.7112059958	post lasso
0.7111578353	type deconvolution
0.7111212724	residual bootstrap
0.7111188916	model assisted
0.7110789117	independence criterion
0.7110630937	recent research
0.7110575870	statistical procedures
0.7110031745	active subspace
0.7109822122	practical applicability
0.7109462720	kaplan meier estimator
0.7109381179	problems involving
0.7108962772	driving noise
0.7108718869	spectrum estimation
0.7108239274	fast rates
0.7108017918	maximum mean discrepancy
0.7106758869	hermite processes
0.7106061834	wavelet estimation
0.7103703081	faster convergence
0.7103366183	optimal tests
0.7103100410	large sample asymptotics
0.7102791109	approximate likelihood
0.7102513041	linear dynamical systems
0.7101365678	phase type
0.7100098391	forward operator
0.7099953688	signal to noise ratio
0.7099637916	screening methods
0.7099324422	volatility estimation
0.7099116280	smoothness index
0.7097113572	rigorous analysis
0.7097076781	er rao bound
0.7096975467	asymptotically gaussian
0.7096877702	continuous variables
0.7096142422	bi degree
0.7095562784	spatial dependence
0.7094781846	generalized linear mixed
0.7094393873	latent variable model
0.7093623427	predictor variable
0.7092960957	smoothed bootstrap
0.7092757396	nonzero components
0.7091969895	pac bayesian bounds
0.7091829700	pair correlation function
0.7091566752	simultaneous confidence intervals
0.7091518107	index set
0.7090819549	mixing sequences
0.7090210800	partial likelihood
0.7090116353	recently received
0.7089287052	beta type
0.7089126670	fourier domain
0.7088548508	partial order
0.7088126984	recovery error
0.7087520203	missing entries
0.7087181523	representation theory
0.7085214681	classification rules
0.7084832729	theoretical claims
0.7084100589	deep networks
0.7084065253	scale parameters
0.7082762769	change point analysis
0.7082667339	function approximation
0.7082316587	tyler's m estimator
0.7082079716	related results
0.7081854131	bridge estimators
0.7081509536	deviation principles
0.7080436084	high quantiles
0.7080011573	error distributions
0.7079813251	local search
0.7079046339	previously proposed
0.7078349933	spiked model
0.7078100068	bounded interval
0.7077473174	minimax optimal rates
0.7076366477	uncertain prior
0.7075785884	varying coefficient models
0.7075536036	asymptotic level
0.7074983021	graphical criterion
0.7074837492	max stable processes
0.7072890068	relevant information
0.7072834185	applications include
0.7072135131	support set
0.7071060041	concave densities
0.7070926035	structured signal
0.7070171510	resampling scheme
0.7069655025	small samples
0.7069118822	linear spectral
0.7068923318	results hold
0.7067503073	gaussian random variables
0.7067428746	general setup
0.7067361334	logistic regression models
0.7065027915	widely applied
0.7064975831	blind source
0.7064516122	regression vector
0.7064345048	consistent model selection
0.7064241264	observation times
0.7063961720	holonomic gradient
0.7063035341	delta method
0.7062486937	bayes predictive
0.7061285783	inverse covariance
0.7061243670	modern scientific
0.7060800823	transformation function
0.7060384632	sharp minimax
0.7060095128	experimental results
0.7059385945	logistic loss
0.7058372254	statistical literature
0.7058349859	series expansion
0.7058285055	finite samples
0.7056884684	classical theory
0.7056271127	objective prior
0.7056050030	bayesian theory
0.7054596869	logistic models
0.7053979942	composite hypothesis
0.7053817431	approximate message
0.7052411712	spectral properties
0.7052304981	wavelet series
0.7050293832	maximization problem
0.7050284735	separation condition
0.7050037603	small sample sizes
0.7049577903	hierarchical structure
0.7049353258	piecewise constant functions
0.7048795144	metric measure
0.7048707223	random partition
0.7047656678	previously studied
0.7047459919	thresholding estimators
0.7047221184	dense regime
0.7046510921	recovery problem
0.7046217449	extensive numerical experiments
0.7045463258	success probability
0.7045013901	finite sample behaviour
0.7044793600	peaks over threshold
0.7044768655	analysis shows
0.7044000487	constraint based
0.7043837789	structural parameters
0.7043651502	canonical correlation coefficients
0.7043423035	statistically consistent
0.7043187557	effective dimension
0.7042564983	predictive distribution
0.7042288708	kernel estimates
0.7041712623	detection procedures
0.7041454768	asymptotically independent
0.7040817186	message passing algorithms
0.7039914826	critical point
0.7039535508	oracle type inequality
0.7038878793	ratio type
0.7038642402	case control
0.7038537023	asymptotic coverage
0.7037873355	high dimensional data analysis
0.7036860161	principal component regression
0.7036260009	regularized regression
0.7035466070	cusum statistics
0.7033000137	expectation maximization algorithm
0.7032352866	fisher's information
0.7031467003	linear inverse
0.7031149967	measurement vectors
0.7030966259	batch size
0.7030427137	goodness of fit tests
0.7030364908	sparsity constraint
0.7029533525	finite support
0.7029437005	stein unbiased
0.7028388504	null model
0.7028082703	small sample size
0.7027923878	score based
0.7027257116	real data examples
0.7026137688	hoeffding type
0.7025711957	approximation methods
0.7024882565	global optimum
0.7023896301	clustering method
0.7022753908	main challenge
0.7022570852	completion problem
0.7020988571	phase transition phenomenon
0.7020303938	boundary points
0.7020269820	completely random
0.7020173882	statistical experiment
0.7019269521	regression functions
0.7018553985	bounded continuous
0.7018090351	standard deviations
0.7016664438	kernel functions
0.7015343129	structural equation model
0.7015224042	pairwise markov
0.7013320539	high frequency asymptotics
0.7013009831	alternative hypotheses
0.7012616104	inference procedures
0.7012404071	previous approaches
0.7012388531	important role
0.7012076520	reasonable conditions
0.7011033601	numerical study
0.7010382528	extensive simulation
0.7010272071	reconstruction error
0.7010236083	individual tests
0.7009273012	arise naturally
0.7008694141	orthogonal polynomial
0.7007853460	error analysis
0.7006848961	exchangeable sequences
0.7006716371	ordered set
0.7006383928	ml estimation
0.7005097999	eigenvalue distribution
0.7004619118	measurement matrices
0.7004092002	weighted likelihood
0.7003925417	gaussian models
0.7003713004	gaussian vectors
0.7003123755	quadratic covariation
0.7002199171	stochastic gradient algorithm
0.7001230514	practical importance
0.7001027905	additional assumption
0.7000058941	sparsity assumptions
0.7000002720	general conditions
0.6999725219	euclidean metric
0.6999684229	finite markov
0.6999029841	limit law
0.6998818845	exact asymptotic
0.6998542121	initial conditions
0.6998418690	widely studied
0.6998226507	closed sets
0.6997933266	approximation theory
0.6997689447	map estimator
0.6997477434	hellinger loss
0.6997101811	equivalence class
0.6996419854	exponential inequality
0.6996228853	online regression
0.6996071700	independence model
0.6994939709	increasing function
0.6994735655	extensive numerical
0.6994605926	low power
0.6993539218	kernel hilbert space
0.6992517758	convex loss
0.6992118306	conditional independence relations
0.6991410332	exponential dispersion
0.6991223585	sample moments
0.6990643395	dimensional subspace
0.6990329171	lower bounded
0.6989299259	modern machine learning
0.6988977963	prediction loss
0.6988721297	independent increments
0.6988544955	simultaneous confidence
0.6987823947	additional information
0.6987174971	regularization parameter
0.6986890559	simulations confirm
0.6986859066	optimal shrinkage
0.6986627041	extreme quantiles
0.6986497064	berry esseen type
0.6986354012	normal law
0.6985785375	data types
0.6985431912	optimal solution
0.6985405476	maximum smoothed
0.6984914851	cluster tree
0.6983637680	barndorff nielsen and shephard
0.6982985793	variation distance
0.6981873719	maximum eigenvalue
0.6981090711	information theoretical
0.6980938718	drift coefficient
0.6978810130	local levels
0.6978768924	additional structure
0.6978298010	sparse poisson
0.6977598829	moving average processes
0.6977168126	modified cholesky
0.6976440538	copula density
0.6975832902	bradley terry model
0.6975262861	spiked population
0.6974803985	model based clustering
0.6973274206	heavy tailed data
0.6972699350	indirect effects
0.6971707993	shape invariant
0.6970142953	bootstrap version
0.6969970249	mild moment conditions
0.6969044345	location scale family
0.6968913895	consistent and asymptotically normal
0.6968759677	efficient estimators
0.6968694152	multi parameter
0.6968537652	theoretical framework
0.6968496843	technical tools
0.6968337029	potential applications
0.6968335264	marginal densities
0.6967927649	generalized linear mixed models
0.6967366250	baseline hazard function
0.6967309617	random effects model
0.6967183260	conditional inference
0.6966839613	general setting
0.6966786525	upper tail
0.6966358489	weaker assumptions
0.6965072564	spectral density matrix
0.6964658763	exact sampling
0.6964511602	current state
0.6964481590	matrix ensembles
0.6963996224	functional predictors
0.6962459503	linear regression model
0.6962151491	product space
0.6962151455	low rank approximation
0.6962077937	conditional moments
0.6961846969	high density
0.6961073594	mixture autoregressive
0.6960868586	shape matrix
0.6960396422	data collected
0.6959799084	rank correlations
0.6959456831	expected degree
0.6959210580	hazards model
0.6957806136	conditional kendall's tau
0.6956955198	increasingly important
0.6956912759	estimation theory
0.6955616119	grow large
0.6954995017	mixture priors
0.6954986625	general result
0.6953698702	sparse regime
0.6953648570	times series
0.6953018876	genetic data
0.6952978499	expected sample size
0.6951994197	stability properties
0.6951618929	decision functions
0.6951266488	concave penalized
0.6950805507	pair correlation
0.6949872349	intractable posterior
0.6949290542	high dimensional vector
0.6948188203	statistical hypothesis testing
0.6948111949	effective sample size
0.6947687973	results include
0.6945993502	multivariate density estimation
0.6945769751	extensive monte carlo
0.6944555107	arch models
0.6944326899	subspace analysis
0.6943562821	ipw estimator
0.6943543784	large covariance matrices
0.6942393873	conditional entropy
0.6942003935	binomial distributions
0.6941514954	generative adversarial
0.6941455626	underlying signal
0.6941431477	sharp oracle inequality
0.6940102149	resampling based
0.6939754649	approximate sampling
0.6938723539	optimal scaling
0.6938691927	pitman yor process
0.6938215729	matrix perturbation
0.6936800635	modern applications
0.6936581634	tensor valued
0.6935408032	heston model
0.6935188879	finite sample performances
0.6934714088	nonlinear regression models
0.6934095498	continuous distribution
0.6933901675	quasi likelihood analysis
0.6932996672	der vaart
0.6932633893	inhomogeneous poisson
0.6931587467	regular case
0.6931012316	urn models
0.6930495909	residual life
0.6929297240	desired level
0.6928669749	approximation algorithms
0.6926921552	average degree
0.6926892229	poisson dirichlet
0.6926686145	learning tasks
0.6925268233	probability mass
0.6924876895	uniform convergence rate
0.6924163877	symmetric stable
0.6923776148	power divergence
0.6923162923	cox models
0.6922845400	linear estimators
0.6922244197	constant factor
0.6920147090	separable covariance
0.6920114007	adaptive confidence sets
0.6919849435	relative performance
0.6919162420	kernel hilbert spaces
0.6918599451	normal mixture
0.6918532723	algorithm achieves
0.6918388225	screening property
0.6917794818	simulations illustrate
0.6916149475	quasi stationary
0.6916102445	rate optimality
0.6915833710	bootstrap approximations
0.6915535245	state domain
0.6915192369	optimal solutions
0.6914517365	density estimate
0.6914246352	shrinkage estimator
0.6914043333	stochastic heat
0.6912153004	complexity analysis
0.6912081784	positive dependence
0.6909688790	observational noise
0.6907040294	paper discusses
0.6905382954	inference tools
0.6904198926	feature vectors
0.6904145168	empirical spectral
0.6901828519	relative error
0.6900022158	parametric family
0.6899980840	geometric graphs
0.6899348497	mild assumption
0.6899175218	truncated pareto
0.6898335769	adaptive confidence
0.6897758496	varying coefficients
0.6897678459	natural extension
0.6897504773	minimum spanning
0.6897117084	finetti's theorem
0.6896962872	max domain of attraction
0.6896323718	based test
0.6896279025	fractional diffusion
0.6896027959	variational bayesian
0.6895010428	theoretic framework
0.6894952478	bayesian credible sets
0.6894538941	function class
0.6894484698	high dimensional covariance matrices
0.6894422175	bootstrap approximation
0.6894108348	numerical analysis
0.6893597371	gaussian designs
0.6891652221	long history
0.6891520469	bayesian hypothesis testing
0.6890937728	critical threshold
0.6890166573	large networks
0.6889826766	vector field
0.6889758295	empirical copula
0.6888171748	subject specific
0.6887889870	bayesian setting
0.6887249426	severely ill posed
0.6885643991	physical systems
0.6885350788	geometric approach
0.6885006982	small scale
0.6884895741	discovery rates
0.6883849908	perturbation analysis
0.6883287949	higher power
0.6883078953	survival models
0.6881362708	sequential procedures
0.6881074694	independence relations
0.6880706283	detection threshold
0.6880512343	poisson approximation
0.6880261588	dimensional subspaces
0.6879697809	data analyses
0.6879447165	spatial sign
0.6879251114	result implies
0.6879239336	bivariate extreme
0.6878158819	approximate factor
0.6877589839	based approaches
0.6877073379	empirical studies
0.6877014750	detection performance
0.6876653375	detection rules
0.6876156999	extreme value theory
0.6875752174	dynamic models
0.6874578955	vector machines
0.6874122301	mixing processes
0.6873410483	monotone regression
0.6872878558	procedure outperforms
0.6871772512	multivariate normal distributions
0.6870980282	diffusion equation
0.6870318905	hazard rate function
0.6869247919	empirical results
0.6869079543	functional time series
0.6868985198	noise matrix
0.6868509068	state dependent
0.6868434834	parametric bootstrap
0.6867949683	direct and indirect effects
0.6867574449	reduced bias
0.6867394450	mises theorem
0.6867180953	spatial domain
0.6866478936	equivariant estimators
0.6866300497	map estimate
0.6865017948	unit variance
0.6864457224	dimensional data
0.6864259821	complexity measure
0.6863859083	estimators achieve
0.6863810286	dimension grows
0.6863770302	sheds light
0.6862169416	distributional results
0.6861658644	asymptotic expansions
0.6861476883	high dimensional settings
0.6860745215	linear mixed
0.6856178624	log likelihood ratios
0.6855330462	probability generating
0.6854828743	ratio statistics
0.6853738241	deviation inequality
0.6852935897	infinite sequence
0.6852822281	estimated consistently
0.6852189056	random sample
0.6851764305	thresholding rules
0.6849868516	gaussian sequence model
0.6849801853	statistical research
0.6849535950	gaussian approximations
0.6849501473	quantum information
0.6848980107	result shows
0.6848603609	deviation probabilities
0.6848585379	leading order
0.6848443643	manifold estimation
0.6847249787	false alarm probability
0.6846537789	high dimensional setting
0.6844321216	conditions required
0.6843769827	shift parameter
0.6841420250	step sizes
0.6841301153	theoretical insights
0.6840386176	stationary gaussian processes
0.6840012156	nonparametric bayesian inference
0.6839775454	upper confidence
0.6839021826	point mass
0.6838055427	convergence result
0.6836020524	empirical likelihood approach
0.6835577145	ambient space
0.6835090316	unique solution
0.6834946123	bayesian risk
0.6834194801	partial least squares
0.6833720756	uniform bounds
0.6831646963	tail probability
0.6831469310	affine estimators
0.6830655127	extreme eigenvalues
0.6830647244	limiting case
0.6830630684	principal subspace
0.6830150944	original process
0.6828709300	block sparse
0.6827093426	norm minimization
0.6825771069	integral representation
0.6825611587	finite interval
0.6825346459	semiparametric efficient
0.6824610224	smoothness assumption
0.6824194348	structured distributions
0.6823936261	minimum risk
0.6823227279	block diagonal
0.6822980031	compact set
0.6822573479	independent sample
0.6821484150	privacy constraints
0.6821064062	efficient computation
0.6820868223	previous methods
0.6820329396	classical statistics
0.6820072433	accurately estimate
0.6819841812	normal vectors
0.6819517521	extensive experiments
0.6818589811	type inequality
0.6818530537	recovery guarantees
0.6817284592	stochastic systems
0.6816016330	explicit forms
0.6815728598	target distribution
0.6815663863	inference tasks
0.6815322671	multinomial distributions
0.6811909796	convex constraints
0.6811244654	statistical tools
0.6811232455	rank statistics
0.6810459452	sampled data
0.6809215489	quantum fisher
0.6808452602	independent samples
0.6807745367	riesz distribution
0.6807663983	penalized criterion
0.6806801222	data analytics
0.6806785149	mixture density
0.6805214313	empirically demonstrate
0.6804778708	adaptive wavelet
0.6803990701	posterior computation
0.6803886192	consistency result
0.6801953844	carlo simulations
0.6800073864	real world data
0.6799774510	error guarantees
0.6799541851	quasi maximum likelihood estimation
0.6799378919	network model
0.6798361161	power analysis
0.6798096502	model selection procedure
0.6796967546	frequentist coverage of adaptive nonparametric bayesian
0.6796302284	asymptotic expression
0.6793936743	monotonicity property
0.6792226223	compact interval
0.6792188808	iterative procedure
0.6791708626	error distribution
0.6791155178	marginal log linear
0.6788318338	sparsity levels
0.6787467530	gaussian orthogonal
0.6786710102	result holds
0.6785288887	exponentially distributed
0.6783814284	association studies
0.6782230681	scaling parameter
0.6781024446	infinite order
0.6779852503	moment constraints
0.6777250347	projection based
0.6777067349	nonlinear inverse problems
0.6776437684	dimensional euclidean space
0.6775944496	completely monotone
0.6775338569	gaussian matrices
0.6775142333	probabilistic approach
0.6774806584	adaptive lasso estimator
0.6773593310	originally proposed
0.6773473472	simulation study shows
0.6773276905	divergence based
0.6771551559	dimensional vector
0.6770348301	penalized contrast
0.6768345865	model selection method
0.6767926994	ml estimators
0.6766206102	step function
0.6766097023	skew normal distribution
0.6765429912	deviation bound
0.6765125924	performance measures
0.6764994262	noise density
0.6764979144	prediction performance
0.6764564027	quasi posterior
0.6764561203	bandwidth parameter
0.6764473838	metropolis hastings algorithm
0.6764452591	cross sectional dependence
0.6764224412	conditional density estimation
0.6764008148	statistical experiments
0.6763417975	general results
0.6763386905	general alternatives
0.6763048434	hidden variable
0.6762771880	statistical performance
0.6761503854	kernel mixture
0.6761399904	benjamini hochberg procedure
0.6761279571	linear discriminant
0.6761162365	scale free
0.6760792113	machine learning methods
0.6759685371	centered gaussian
0.6759248868	convergence holds
0.6758967711	sharp lower bound
0.6757420888	stationary solution
0.6756717031	lifetime data
0.6755094267	fully characterize
0.6755048860	generalized additive
0.6754693014	spectral algorithms
0.6753297536	monte carlo approximation
0.6751451268	vector fields
0.6750539997	single step
0.6749480053	practical implementation
0.6749169706	spline basis
0.6748682265	population covariance matrix
0.6747432971	independently distributed
0.6747218134	nonlinear processes
0.6746890322	interval censored data
0.6746806550	spatial regression
0.6746767153	bayesian regression
0.6746324148	true parameters
0.6746063343	existing procedures
0.6745965782	lasso based
0.6745542572	stronger assumptions
0.6745365047	adaptive density estimation
0.6744491130	key features
0.6744232682	sequential probability
0.6743912287	common problem
0.6743707461	large scale multiple testing
0.6742814945	information measure
0.6741692175	integrated squared
0.6741015682	dependent variable
0.6740803400	transformation model
0.6739438370	sample spaces
0.6739112891	robust estimates
0.6738982248	spectral representation
0.6738471339	marginal density
0.6738145243	class includes
0.6736791866	fast algorithms
0.6734764869	range dependence
0.6734290690	divisible laws
0.6734109493	pseudo posterior
0.6733693921	network size
0.6733378044	unknown regression function
0.6731359789	linear approximation
0.6730932820	cumulative distribution
0.6727703346	point estimates
0.6727284778	large sample sizes
0.6725873131	recursive algorithm
0.6725294351	contrast function
0.6723073746	ensemble kalman
0.6722512938	convolution model
0.6722469719	paper proposes
0.6722210472	generally applicable
0.6720894711	multiple comparison
0.6719774277	random errors
0.6719765356	privacy constraint
0.6719398488	training examples
0.6719049008	correlation structures
0.6717939553	simple random
0.6717215162	transition kernel
0.6716763254	local shrinkage
0.6716253672	smoothing parameters
0.6715153366	dimensional setting
0.6714968441	concentration rates
0.6714966600	minimal conditions
0.6714917771	sparsity conditions
0.6714551994	uniform limit theorems
0.6714356943	continuous function
0.6714295926	high dimensional space
0.6713779922	bernstein von
0.6711806985	problems arise
0.6711636182	leading constant
0.6711440901	fixed dimension
0.6710751100	high dimensional statistics
0.6710742158	gaussian regression
0.6710591357	shape space
0.6710326634	selection methods
0.6709933767	stochastic integral
0.6708927723	bias reduced
0.6708729567	design density
0.6707638729	stable motion
0.6706462830	sequential design
0.6706447358	sample canonical
0.6706316841	coverage properties
0.6706257158	main aim
0.6705749974	linear dependence
0.6705437344	mixture modeling
0.6705234312	fundamental importance
0.6705208651	remains valid
0.6705008340	bivariate copulas
0.6704736903	unbiased estimates
0.6703290501	likelihood principle
0.6701338628	nonparametric setting
0.6701174902	parametric form
0.6700698547	law of iterated logarithm
0.6700644313	risk function
0.6697800212	fundamental limits
0.6697709833	unified analysis
0.6697462176	variation norm
0.6696433767	bayes procedures
0.6696153455	theoretical performance
0.6695949351	missing at random
0.6693026907	fundamental problems
0.6692622013	optimal order
0.6690881308	fully observed
0.6689794601	unbounded support
0.6688274971	deviation inequalities
0.6686601102	half space
0.6686566615	group structure
0.6684361605	optimal performance
0.6682975413	analytic form
0.6679430786	shiryaev roberts procedure
0.6678942332	discrete random
0.6677651506	consistent estimation
0.6677561340	training set
0.6677267858	independent variables
0.6676693499	bayesian inverse
0.6676457818	population covariance matrices
0.6675637412	paper develops
0.6675542930	` adl
0.6673142987	high dimensional covariates
0.6672626073	quantile regression models
0.6672028108	optimal posterior contraction
0.6671742313	functional parameters
0.6670637121	positive probability
0.6670429530	norm penalty
0.6669868509	goodness of fit testing
0.6669212028	closed form expressions
0.6668741149	spectral density estimation
0.6668498394	results complement
0.6668492693	numerical method
0.6667508516	group sparse
0.6666646682	predictive power
0.6666599037	interaction model
0.6666297748	unknown drift
0.6666058887	regularization techniques
0.6665793104	smooth densities
0.6665418069	random times
0.6665132058	spike and slab priors
0.6664756092	partially linear model
0.6663892949	temperature data
0.6663816413	partial sum process
0.6663641795	order selection
0.6663215544	scale mixtures
0.6662801964	diffusion model
0.6662674155	information theoretically
0.6662088415	asymptotically consistent
0.6661405005	univariate distributions
0.6657608741	initial estimators
0.6656884320	multi sample
0.6656659617	continuous shrinkage priors
0.6656194981	real data analysis
0.6656058914	theoretical validity
0.6655756810	high dimensional models
0.6655619668	gaussian case
0.6655451715	global local
0.6655424899	valid statistical inference
0.6655290633	degree sequence
0.6654909014	lineage sorting
0.6654858878	minimax convergence rate
0.6654845519	approximation errors
0.6654432738	extended version
0.6653940936	temperature parameter
0.6653856535	population means
0.6653778479	unit ball
0.6653414211	convergence theorem
0.6653247825	convex analysis
0.6652671592	independent poisson
0.6649348335	explicit expression
0.6648821862	integrated covariance
0.6648503450	elliptical models
0.6647777602	chi square test
0.6647615116	sign covariance
0.6646472342	simulation study illustrates
0.6646471660	type bounds
0.6643906110	spectral norm
0.6643621032	local scale
0.6643512422	efficiency bounds
0.6642586691	tree based
0.6641129366	linear spectral statistics
0.6640983210	exponential family models
0.6640783376	minimax robust
0.6640039036	design theory
0.6639904915	search space
0.6639845954	sampling algorithms
0.6639552435	risk analysis
0.6638734720	strong sense
0.6638272925	hybrid estimator
0.6637862909	optimality properties
0.6637483544	gamma process
0.6637420809	laws of large numbers
0.6636854923	asymptotic sense
0.6636307118	correlated variables
0.6635774502	nadaraya watson estimator
0.6635663599	empirical distributions
0.6635174978	singular value thresholding
0.6634110154	regression parameter
0.6633876617	incomplete information
0.6633499485	nuclear norm penalized
0.6633086518	normalized maximum likelihood
0.6632936473	results cover
0.6632611162	significantly improve
0.6631583445	graph structure
0.6631511092	linear inverse problem
0.6629951597	jump measure
0.6629416135	phase retrieval problem
0.6627799928	standard assumptions
0.6626978822	minimax estimator
0.6625379524	regular models
0.6624154955	survival functions
0.6623641935	quantile estimators
0.6623123720	high dimensional gaussian
0.6623101247	explicit formulae
0.6621835581	random designs
0.6621710988	location scale mixture
0.6620975841	relevant features
0.6619376449	common change
0.6619014699	rosenblatt distribution
0.6618923641	regression settings
0.6618826504	theoretical predictions
0.6618666220	regression adjusted
0.6618571254	data sources
0.6618143742	descent algorithms
0.6617945220	continuous state
0.6617455565	robust mean estimation
0.6616165837	mixture prior
0.6615980233	challenging problem
0.6615624382	independent noise
0.6614534250	single observation
0.6614240072	sequential monte carlo methods
0.6614210868	symmetric positive definite
0.6613611904	natural exponential
0.6612783582	depth function
0.6610995857	pointwise estimation
0.6609551668	poisson random measures
0.6609541214	likelihood free
0.6608616222	extended empirical likelihood
0.6608518159	bernoulli distributions
0.6606660099	stationary gaussian process
0.6605521311	structured covariance
0.6605101207	high dimensional covariance
0.6604639664	representation theorem
0.6604542165	equation models
0.6603577948	based tests
0.6602061370	basic properties
0.6601104222	asymptotic minimax
0.6600959355	multiple testing problem
0.6599921549	consistency and asymptotic normality
0.6599828090	decision theoretic framework
0.6598884461	log density
0.6598092764	parameter free
0.6597874029	fixed domain
0.6597805860	sharp oracle
0.6597513652	numerical experiment
0.6596684672	bernoulli distribution
0.6594806015	important task
0.6593875738	divide and conquer
0.6593139438	tailed distributions
0.6592469565	max mixture
0.6591574640	tree space
0.6590320740	randomly weighted
0.6590145724	structural parameter
0.6589794488	asymptotic confidence
0.6588923808	sampling strategy
0.6588012917	sparse estimation
0.6587107366	real applications
0.6586885206	power properties
0.6586130498	distribution free tests
0.6586072995	decreasing density
0.6584691252	closed form solution
0.6583677582	results obtained
0.6580798116	nonparametric multivariate
0.6580540912	general state space
0.6578998606	local average
0.6578636044	specific examples
0.6578568578	small set
0.6578514825	fundamental statistical
0.6577350568	functional principal component
0.6577239775	permutation invariant
0.6576912888	case study
0.6576237190	numerical performance
0.6575047216	bayesian lasso
0.6574771147	underlying density
0.6573548499	alternative proof
0.6570289380	clustering methods
0.6570060585	beta mixing
0.6569341630	large scale inference
0.6569209332	results generalize
0.6568622687	structural assumption
0.6567281837	stable random fields
0.6566298753	integrated square
0.6566058783	prove consistency
0.6565141360	data matrix
0.6563621730	smoothness parameter
0.6563444970	growth charts
0.6562366936	sparse linear models
0.6561640036	classical result
0.6561459055	sampling methods
0.6560932268	state space model
0.6560443354	results provide
0.6559205881	asymptotic normal
0.6558164975	sample correlation
0.6558063291	potential function
0.6556773110	instrumental regression
0.6556740413	reweighted least squares
0.6555668496	stochastic volatility model
0.6555536035	lasso solution
0.6555194650	monte carlo simulation study
0.6554991236	normal gamma
0.6553862543	nonparametric methods
0.6553824175	important question
0.6553489018	monte carlo algorithms
0.6552920504	paper studies
0.6552677068	fully data driven
0.6550435331	high frequency observations
0.6549714299	mild regularity
0.6549449636	infinitely divisible distributions
0.6547341359	semiparametric estimator
0.6545443933	result extends
0.6545161778	linear unbiased estimator
0.6544575062	dirichlet distribution
0.6542890530	gaussian process priors
0.6542630524	strong evidence
0.6540941895	numerical approximation
0.6540520270	change point problems
0.6539584973	covariate distribution
0.6539321513	risk minimizers
0.6536721975	support vector
0.6535779611	gaussian white noise model
0.6535557026	covariate adaptive
0.6535225465	frequentist properties
0.6534097606	important case
0.6532969644	fixed size
0.6532707248	log concave maximum likelihood estimator
0.6531935822	self exciting
0.6531655556	variable selection problem
0.6531114361	artificial neural
0.6530925676	robust learning
0.6528525841	stochastic partial differential equation
0.6527852380	consistent estimators
0.6527655275	property holds
0.6527223046	pc algorithm
0.6525698731	independent copies
0.6525374463	posterior measures
0.6525108250	exponential concentration
0.6524622457	minimax error
0.6524204563	monotone hazard
0.6523805439	arm identification
0.6523541801	simultaneous testing
0.6523055227	lower and upper bounds
0.6522729033	alternative approaches
0.6521843943	parameter estimation problem
0.6521630000	ii distributions
0.6521605949	functional central limit theorems
0.6520891703	proposal distribution
0.6520051451	modeling framework
0.6518435162	random sequence
0.6518175356	paper introduces
0.6517742640	random intersection
0.6517498267	smooth density
0.6516694116	stable convergence
0.6515568153	key results
0.6513118778	symmetric group
0.6511466486	real world datasets
0.6509613097	existing theory
0.6508963822	practical situations
0.6508809099	analogous results
0.6508060787	observation noise
0.6507790932	type statistics
0.6506993419	consistency property
0.6505598288	variate normal
0.6505446477	semiparametric efficiency bound
0.6505092276	completely data driven
0.6505048308	main objective
0.6503856670	growth model
0.6503369195	high dimensional time series
0.6502895723	provide evidence
0.6500049002	exponentially large
0.6497073427	node degree
0.6496975271	hazard functions
0.6496220396	squared hellinger
0.6495724536	entropy estimators
0.6495707381	error density
0.6495622666	simulated and real datasets
0.6493808853	long run variance
0.6492946749	computationally efficient algorithm
0.6492696651	statistical methodology
0.6491252148	kernel estimation
0.6490905155	size biased
0.6489044462	simulation experiment
0.6488660764	noisy matrix
0.6487753516	proof technique
0.6485501217	spectral graph
0.6485358213	nonparametric maximum likelihood
0.6484616652	introduced recently
0.6484038066	oracle inequalities in risk minimization
0.6483099496	practical problems
0.6482064063	mathematical framework
0.6477894603	linear space
0.6477883473	simulations suggest
0.6474966190	possibly infinite
0.6474544061	finite fourth moment
0.6474035018	strong approximations
0.6473870700	nonparametric regression model
0.6473313300	robust estimator
0.6473064958	machine learning tasks
0.6472886051	likelihood ratio statistics
0.6472448747	matrix theory
0.6471592625	bayesian estimators
0.6468572652	uniform convergence rates
0.6465793293	white gaussian
0.6465616191	gaussian design
0.6464810258	noiseless case
0.6462511191	previous literature
0.6462197615	local linear regression
0.6461738466	gamma distributed
0.6461456056	competing risks data
0.6458628631	fixed number
0.6458023678	bivariate distribution
0.6457346174	high power
0.6457069519	exact expressions
0.6456534163	attention in recent years
0.6456519911	covariance estimator
0.6456221916	strictly consistent
0.6456145630	chi squared distribution
0.6454075162	dag models
0.6453494540	long range dependent sequences
0.6453387758	type large deviation
0.6452528796	pseudo random
0.6452128143	nonlinear model
0.6451952725	spatial point process
0.6451689722	estimator outperforms
0.6451077656	null and alternative hypotheses
0.6448467338	higher order moments
0.6447199743	derive explicit
0.6446745295	median of means
0.6446312913	upper and lower bounds
0.6446177716	median based
0.6444500580	division algebras
0.6444043329	probabilistic method
0.6443976901	significance test
0.6443258225	proposed test statistic
0.6442683232	positive random variables
0.6442407586	optimal approximate
0.6442043982	stationary time series
0.6442042541	ill posed inverse problems
0.6441415776	multivariate regular variation
0.6439568360	typically assumed
0.6439413743	sample correlation matrices
0.6439358485	resulting estimates
0.6438979452	self organizing
0.6438632793	maximum marginal likelihood
0.6438437206	poisson distributed
0.6436962893	differential equation models
0.6436577592	nonparametric techniques
0.6434547186	squared risk
0.6434269308	main focus
0.6434077726	geometric structure
0.6432748258	analytical approach
0.6432341676	asymptotic relative
0.6431693032	infinite dimensional space
0.6431683675	logit models
0.6431490038	semi martingale
0.6431155014	statistical practice
0.6428847972	graph selection
0.6427628879	significantly faster
0.6427531045	dimensional vectors
0.6426721575	covariance models
0.6426522416	state tomography
0.6425142171	gradient algorithms
0.6424611584	quantum hypothesis testing
0.6424169093	slope function
0.6422672320	underlying population
0.6419412360	random probability measures
0.6418791646	density power
0.6417116508	mathematical models
0.6416402303	simple hypothesis
0.6416091245	newton raphson algorithm
0.6414048995	programming problem
0.6413355852	real world networks
0.6412951706	neural network models
0.6412250527	data contamination
0.6412080729	nonlinear statistics
0.6411641679	posterior convergence rate
0.6410469425	expected values
0.6408919047	poisson dirichlet process
0.6408733738	predictive accuracy
0.6408733451	drift estimation
0.6408180164	bootstrap inference
0.6406883504	algebraic properties
0.6404541358	estimator satisfies
0.6404303541	complete data
0.6404148986	slow rates
0.6401460087	sample efficient
0.6401113106	statistical perspective
0.6399486178	quasi maximum
0.6398634353	proportion of true null hypotheses
0.6397704270	fast learning
0.6397223900	general form
0.6397204135	adaptive testing
0.6396191434	method works
0.6394250259	current methods
0.6393891415	detecting sparse
0.6393640532	reward distributions
0.6393138331	lower order
0.6391980397	naive estimator
0.6391772157	hypothesis testing problems
0.6390632682	estimation strategy
0.6389125292	convex combination
0.6389052430	low dimensions
0.6388791747	log log
0.6388218074	v fold
0.6388014389	unified framework
0.6386106738	multiple change point detection
0.6385829755	heteroscedastic data
0.6385559950	optimal threshold
0.6383687245	model building
0.6383616620	transformation models
0.6383389324	grenander type estimator
0.6381854729	finite sample bounds
0.6381436685	monte carlo study
0.6381362428	limit behavior
0.6380627031	classical setting
0.6379463608	transition probability
0.6378533257	multivariate setting
0.6378397324	direct application
0.6377581059	unknown covariance matrix
0.6377378033	hidden units
0.6377179534	optimal algorithms
0.6376772200	noise free
0.6376646845	stationary random
0.6374924112	spectral estimator
0.6374805796	noise model
0.6373127059	lasso problem
0.6372111125	nonlinear time series
0.6372109835	multiple linear regression
0.6372049081	local information
0.6371136080	long standing problem
0.6368854304	information rate
0.6368718821	semiparametric regression model
0.6368298678	response regression
0.6366256106	paper concerns
0.6364855385	clustering problems
0.6360422244	logarithmic terms
0.6360225766	unknown sparsity
0.6359953165	computationally simple
0.6359029102	raw data
0.6358934905	location scale model
0.6358422545	global testing
0.6356886207	vector machine
0.6351123386	local independence
0.6351006068	dimensional manifold
0.6350521444	generating mechanism
0.6350467380	model selection procedures
0.6350215483	noisy observation
0.6349152374	randomized experiment
0.6348950716	constrained optimization
0.6348920631	convergence complexity
0.6348061743	convex optimization problem
0.6347744127	unlike previous
0.6347629697	statistical risk
0.6347327671	robust procedures
0.6346901587	bias variance
0.6346362088	stochastic order
0.6345105190	deterministic function
0.6345008358	examples illustrate
0.6344794936	dimension reduction methods
0.6344526641	true null
0.6344332130	input distribution
0.6343503179	weakly consistent
0.6342415908	chi square distributions
0.6340842864	provide sufficient conditions
0.6339841970	sparse and low rank
0.6338528519	relative errors
0.6337729655	improved estimation
0.6337480466	simple form
0.6337243406	sharp lower
0.6336682147	multivariate linear
0.6336449167	complexity penalty
0.6334777683	existing literature
0.6334506851	valued random variables
0.6333115166	log likelihood function
0.6332576513	recursive kernel
0.6331611200	asymptotic normality result
0.6331192215	simulation examples
0.6330743195	maximum likelihood method
0.6329891835	variance decomposition
0.6328464118	kolmogorov smirnov test
0.6327730621	maximum likelihood type
0.6327251785	family wise
0.6326755457	risk estimation
0.6325820894	important issue
0.6325486503	gaussian measurements
0.6325228457	multivariate linear regression
0.6325124048	invariant density
0.6323627165	bootstrap tests
0.6322891719	law invariant
0.6322753484	sequential empirical
0.6322468906	sparse matrix
0.6321975338	mixture based
0.6316841545	empirical bayes methods
0.6314858787	location mixture
0.6314011837	individual sequences
0.6312485386	armed bandit problems
0.6312142375	consistent variable selection
0.6310100026	simultaneously estimate
0.6308651475	reconstruction method
0.6308120173	actual data
0.6307099661	nonparametric approaches
0.6306116487	low order
0.6306035433	self similarity
0.6305609938	wavelet estimators
0.6304284580	rate depends
0.6303911912	search algorithm
0.6303740912	dimensional spaces
0.6301696101	exact tests
0.6301678792	sequential change point
0.6301581480	spectral estimators
0.6300706156	extreme cases
0.6300519349	obtained rates
0.6299915850	minimum density power
0.6299060795	depth based
0.6299002033	regression quantiles
0.6297290305	order moments
0.6297067917	asymptotic behaviour
0.6294948124	continuous random variables
0.6294818341	closed testing
0.6294802802	uniform sampling
0.6294080015	test functions
0.6291709876	simulations demonstrate
0.6290880702	false alarm rate
0.6290869101	nonparametric priors
0.6289707417	problem arising
0.6288826367	source separation
0.6288120266	accelerated failure
0.6287362032	high dimensional sparse regression
0.6287187775	degrees of freedom
0.6286290140	asymptotic expressions
0.6283324512	communication systems
0.6282843169	penalized least squares
0.6282685994	pseudo marginal
0.6282643034	variance parameter
0.6282584405	direction method of multipliers
0.6281356658	brownian motion with hurst
0.6280705066	rate adaptive
0.6280554922	observation points
0.6278333841	log concave density estimation
0.6278125030	paper establishes
0.6276559186	covariate information
0.6275617740	data structures
0.6275066799	carlo simulation study
0.6274142423	series representation
0.6270322702	approach consists
0.6269385752	resulting posterior
0.6265735458	explicit bounds
0.6265192862	chi squared test
0.6264954254	spiked population model
0.6264582749	natural conditions
0.6264326932	flexible framework
0.6263308625	randomized algorithms
0.6262169020	underlying data
0.6261309363	importance measure
0.6260413863	lipschitz functions
0.6260019287	low rank signal
0.6259296650	arbitrary order
0.6259014622	converge weakly
0.6258561219	applications involving
0.6258036308	bayes estimation
0.6257746667	multivariate functions
0.6257729201	optimal sampling
0.6255873112	spline estimators
0.6255660901	large numbers
0.6253882200	received much attention
0.6252602162	real life data
0.6252453356	clique problem
0.6252130466	concentration bound
0.6251668529	statistical approaches
0.6250083650	weighted empirical
0.6249623833	parameter dimension
0.6248537858	sparse normal
0.6246037365	large dimensions
0.6245773726	memory processes
0.6245171031	taking into account
0.6243950778	average treatment
0.6243806818	signal to noise ratios
0.6240068207	recent studies
0.6239590205	goodness of fit test
0.6238080649	generalized likelihood ratio
0.6236650954	private estimation
0.6236438596	linear wavelet
0.6236410293	valid confidence intervals
0.6235298758	asymptotic validity
0.6233647015	false null
0.6233492297	sampling distributions
0.6233252134	stochastic matrices
0.6232066045	low dimensional structure
0.6232040139	taking values
0.6231139132	dependence conditions
0.6230961141	chi square distribution
0.6229353653	tail empirical process
0.6229309143	suitable choice
0.6229031270	important cases
0.6228472351	initial distribution
0.6228176687	bayes type
0.6227996049	likelihood based inference
0.6226744699	popular technique
0.6226344738	product structure
0.6223317235	information loss
0.6223304579	specific case
0.6222306696	reduction technique
0.6219898328	predictive models
0.6218647320	birth and death
0.6216095813	sparsity parameter
0.6215452576	asymptotically efficient estimator
0.6215346717	mild moment
0.6213327578	optimal treatment
0.6212355996	transformed data
0.6211102967	theoretical studies
0.6208868086	central role
0.6208518972	biased estimators
0.6205635840	index models
0.6201747983	gaussian location
0.6198480728	prior free
0.6198464704	treatment effect estimation
0.6198075428	empirical likelihood ratio
0.6197567662	gibbs point
0.6196246483	type bound
0.6195171870	discussion of ` `
0.6193212663	traditional approach
0.6193178003	variance covariance matrix
0.6193125659	minimax testing
0.6192168404	law of large numbers
0.6191215353	geometric rate
0.6190717243	unknown signal
0.6187969770	choice models
0.6184962664	partial likelihood estimator
0.6184097453	finite sample behavior
0.6183203030	response functions
0.6182660604	specific cases
0.6180324312	honest confidence
0.6180004452	cross covariance
0.6177340436	high dimensional robust
0.6176576905	kernel type
0.6175176843	unknown error
0.6173103466	distribution families
0.6172065035	projected gradient
0.6171521384	easy to implement
0.6171084231	sample size increases
0.6169731347	independent identically distributed
0.6169243283	minimax rates of convergence
0.6168785900	empirical performance
0.6167151873	smoothness class
0.6166988121	change point model
0.6164937606	gaussian random vectors
0.6163964629	thresholding algorithm
0.6161937183	financial time series
0.6161671468	kernel method
0.6161577819	hold uniformly
0.6161001595	intensity parameter
0.6160884897	dependent noise
0.6160651887	parameter identification
0.6160516638	identically distributed random variables
0.6159031436	regularization function
0.6158689742	relevant parameters
0.6157550396	empirical eigenvalues
0.6156854953	minimax sense
0.6156073413	subgaussian random
0.6155961305	minimax lower
0.6155704104	set theory
0.6154996165	probability matrix
0.6151554593	result applies
0.6151048918	mean residual life
0.6150731633	takes into account
0.6148522445	testing algorithms
0.6147627249	moment method
0.6146183614	paper investigates
0.6145285563	gaussian assumption
0.6144510470	resulting test
0.6143824701	gaussian random vector
0.6143375141	goodness of fit
0.6140885682	bayesian computation
0.6140656735	donoho and jin
0.6139250574	functional form
0.6139099590	least angle regression
0.6138659442	recently established
0.6138554474	unknown distribution
0.6138341560	da algorithm
0.6137908281	de biasing
0.6137306889	negative log likelihood
0.6135897835	selection method
0.6135858319	log factor
0.6133465090	row and column
0.6131950050	functional regression
0.6125262629	adaptive rate
0.6125256817	empirical applications
0.6125208770	exponential moments
0.6124715065	information metric
0.6123900703	structured linear
0.6123756179	bayes estimate
0.6122366597	normal random vector
0.6121777957	log factors
0.6120490154	minimum coverage
0.6119143490	mixing distributions
0.6116056316	censoring model
0.6114708623	max stable process
0.6114214410	likelihood method
0.6113897828	standard brownian motion
0.6112912041	fixed domain asymptotic
0.6112356892	data generating mechanism
0.6111338321	bayes posterior
0.6109453224	true parameter
0.6108559141	sequence data
0.6107367585	normalized partial
0.6107187191	weak regularity conditions
0.6106210960	type test statistic
0.6106075920	eigenvalue based
0.6105713280	spline regression
0.6104100771	pareto distributions
0.6103976902	promising results
0.6102724265	transition density
0.6102591670	optimal inference
0.6102333436	adjusted langevin
0.6101203887	jump processes
0.6100630129	information theoretic lower bound
0.6099865307	additive gaussian
0.6099716659	latent variable models
0.6099698052	differentiable functions
0.6099521454	efficient implementation
0.6098733646	function valued
0.6096041354	adaptive inference
0.6095184888	discrete variables
0.6092890519	dot product
0.6091490544	confidence distribution
0.6089439768	theoretical study
0.6089117062	efficient algorithm
0.6088768065	covariance kernel
0.6087020749	best arm identification
0.6086684438	graph models
0.6083942739	underlying parameter
0.6083624389	recent literature
0.6082514080	poisson sampling
0.6080629450	stochastic partial differential
0.6080443884	estimators perform
0.6077527267	semi parametric estimation
0.6075408000	linear complexity
0.6074740244	ordinary differential
0.6072898915	real world applications
0.6071589000	asymptotically efficient estimators
0.6071569241	sparse principal
0.6071332957	normal models
0.6070166236	type tests
0.6068115323	single sample
0.6068007682	stationary functional time series
0.6066976425	important examples
0.6065907523	drift parameters
0.6065424268	sure independence screening
0.6065048379	quasi likelihood function
0.6064985096	finite sample breakdown
0.6064720538	gaussian component
0.6062824643	bayesian models
0.6061668914	ill conditioned
0.6060878398	dependence assumptions
0.6060447113	empirical data
0.6059492861	screening procedure
0.6059130644	function values
0.6058387753	simulated data sets
0.6058362458	scaling limit
0.6057664412	degree corrected stochastic
0.6057415759	nonparametric rate
0.6056214545	multivariate hawkes
0.6055162794	normalized maximum
0.6054416603	asymptotic risk
0.6053769899	varying coefficient model
0.6051025490	extreme value index
0.6049231325	statistical behavior
0.6048316998	normal random variable
0.6047149800	type conditions
0.6046509402	potential functions
0.6045907085	cramer rao lower
0.6045865560	bayes consistency
0.6045716063	standard model
0.6045688246	testing hypotheses
0.6045504848	logarithmic term
0.6045403280	local rademacher
0.6044659438	variable selection methods
0.6044368806	limiting variance
0.6043700408	change point detection problem
0.6041796160	generalized method of moments
0.6041093007	achieve optimal
0.6040669859	multivariate location
0.6039005235	lo \ ` eve
0.6038042697	optimal learning
0.6037770680	machine learning algorithms
0.6037691005	strong assumptions
0.6037663898	illusion of progress
0.6037575001	inference method
0.6035919014	information geometric
0.6035025092	asymptotically normally distributed
0.6034592478	standard brownian
0.6034252657	observed sample
0.6033705294	resulting algorithm
0.6033349743	penalized maximum likelihood estimator
0.6032763812	powerful test
0.6032755106	empirical bayesian
0.6032697779	article introduces
0.6031693488	prior density
0.6031228397	lasso procedure
0.6030946647	modern statistics
0.6030301213	free approach
0.6029735020	general dependence
0.6027943933	analysis tools
0.6026691815	modulus of continuity
0.6025569239	support vector machines with applications
0.6025355201	sparse models
0.6024863137	spike and slab
0.6024279323	linear spaces
0.6023512557	concentration rate
0.6023014068	deconvolution model
0.6022055229	free probability
0.6021990584	deterministic markov processes
0.6021190277	possibly nonlinear
0.6020748870	eigenvalue condition
0.6019695410	inference functions
0.6017673866	parameter set
0.6017291092	rows and columns
0.6017270434	high dimensional problems
0.6016018573	target distributions
0.6015405688	order tensors
0.6014870895	james stein estimator
0.6014764096	obtain sharp
0.6014195017	efficient method
0.6013059650	modeling approach
0.6012173635	multiple index
0.6011414111	special structure
0.6011085997	robust optimization
0.6010360517	markov chain monte carlo algorithm
0.6010043154	estimation performance
0.6009172010	type i error
0.6009072111	high dimensional datasets
0.6006958539	linear state space models
0.6006292460	bernstein von mises theorems
0.6005796546	low rank structure
0.6005720042	signal plus noise
0.6004728963	natural estimator
0.6004605387	two parameter poisson dirichlet
0.5999367545	nonparametric maximum likelihood estimator
0.5999334419	selection problems
0.5998934686	bounded functions
0.5998761969	coefficient matrices
0.5997852692	high dimensional regime
0.5997589130	estimation consistency
0.5996896673	sampling points
0.5996416690	inferential model
0.5992585806	projection algorithm
0.5992004467	location scale distributions
0.5991899487	dimensional covariance matrices
0.5990971484	quantile estimator
0.5990084396	empirical findings
0.5989013258	heavy tailed errors
0.5988332942	quantile regression model
0.5987775772	approximation results
0.5987364688	general assumptions
0.5987081236	statistical analyses
0.5986644703	ornstein uhlenbeck type
0.5985094015	dimension parameter
0.5984635842	bayes error
0.5982693904	main result shows
0.5982176893	low dimensional space
0.5980232831	ill posed
0.5979874004	number of hidden units
0.5976494096	wise error rate
0.5976171610	quantum homodyne
0.5974577941	suitable assumptions
0.5972893956	information matrices
0.5971008237	estimation scheme
0.5970701207	com poisson
0.5970407269	2004 ims medallion lecture
0.5970318689	structural equation models
0.5968814721	reduction techniques
0.5968415836	obtain explicit
0.5966579465	classical estimators
0.5964731837	mixed model
0.5963831202	asymptotic tail
0.5962129287	full duplex
0.5961119882	nonparametric model
0.5959668721	standard normal distribution
0.5959396858	sparse estimators
0.5959087622	probabilistic analysis
0.5958908982	distribution testing
0.5958342341	local minimax
0.5957898185	homogeneous markov
0.5957298760	spatial point processes
0.5957224091	mixture regression
0.5951984077	important applications
0.5951248119	computational algebraic
0.5949537277	nonparametric estimator
0.5948065599	empirical loss
0.5947639639	random effects models
0.5946419423	graphical structure
0.5945958664	empirical covariance
0.5943371290	gaussian model
0.5941642887	based techniques
0.5941085729	nonparametric function
0.5940932142	reversible markov
0.5940670028	generalized likelihood
0.5939055288	generalized spiked
0.5938847970	likelihood ratio test statistic
0.5937956277	backward stochastic
0.5937553248	linear quantile regression
0.5937286738	results demonstrate
0.5936701140	synthetic and real world
0.5936660190	moving average process
0.5935677996	optimization methods
0.5935623926	precision matrix estimation
0.5935129166	present paper
0.5934120838	outperforms existing
0.5933507170	gaussian random variable
0.5932395715	sharp analysis
0.5930728735	step procedure
0.5929979811	approximate maximum likelihood
0.5929907051	biological data
0.5929440810	gaussian matrix
0.5928596197	simple conditions
0.5928281027	stochastic algorithm
0.5926631729	consistent estimates
0.5926356730	error estimates
0.5926322969	price process
0.5926003088	penalized estimation
0.5925360144	quasi likelihood ratio
0.5924808935	prediction based
0.5924628434	spherical gaussian
0.5924466527	modern data
0.5923435744	semiparametric model
0.5922674443	problem consists
0.5921098183	nonparametric prior
0.5920849113	walk metropolis
0.5920189628	finite measure
0.5919498040	correlation based
0.5919478320	reference alignment
0.5919333771	uniform bound
0.5919254649	bayesian method
0.5918524908	exact results
0.5918021571	unknown density
0.5917468400	long run covariance
0.5914550496	important special case
0.5913241039	dimensional parameter
0.5907878491	regression curve
0.5904391269	common factors
0.5904051175	minimax convergence rates
0.5901404472	right censored
0.5899283809	classical tests
0.5897928243	gaussian densities
0.5897712666	constrained maximum
0.5896054911	weighted least squares
0.5894244634	real examples
0.5890310247	derive convergence rates
0.5889950406	multivariate time series
0.5889201041	gaussian measurement
0.5888571201	weak law of large numbers
0.5887138494	dimensional unit
0.5884519128	constant factors
0.5882660980	decay rate
0.5879422386	empirical likelihood based
0.5878503602	standard approaches
0.5878089991	approximation algorithm
0.5877528808	curse of dimensionality
0.5876491302	deconvolution kernel
0.5876014821	piecewise deterministic
0.5873909137	thresholding procedure
0.5872554217	analyzing data
0.5872157641	er von
0.5871172886	mean integrated squared error
0.5870561656	noise distributions
0.5870375473	karhunen lo \ `
0.5870118537	real data set
0.5868806771	develop efficient
0.5866823264	efficient score
0.5866607566	mean field variational
0.5866125753	adaptive tests
0.5865491248	sample variance
0.5864414183	multivariate nonparametric
0.5863716018	variable bandwidth
0.5863072744	data point
0.5861540936	self adjoint
0.5860264029	kolmogorov smirnov type
0.5856859500	asymptotic approximation
0.5854661273	numerical solution
0.5853607853	large sample size
0.5853436638	mean square error
0.5852731804	probability estimation
0.5851518485	good turing
0.5851159779	discrete case
0.5848675882	world datasets
0.5848120051	conditional tests
0.5847766084	large dimension
0.5847552774	distribution dependent
0.5847465250	skewness and kurtosis
0.5845858918	optimal strategy
0.5844561625	statistical inverse
0.5844560398	functional autoregressive
0.5843361669	graph sampling
0.5840757062	consistency rates
0.5840709130	linear subspace
0.5840044597	weak moment
0.5839751310	best linear unbiased
0.5838603447	randomized clinical
0.5838520044	procedure performs
0.5834248060	stable process
0.5833416992	high dimensional sparse linear
0.5832885382	mathematical theory
0.5829290719	risk functions
0.5826787372	degree of freedom
0.5826669587	orders of magnitude
0.5823910704	topological data
0.5822434092	type priors
0.5820704050	normal model
0.5819010316	identity matrix
0.5818242272	stable random
0.5817819535	point estimators
0.5814582097	unit interval
0.5814438990	linear regression problem
0.5813486640	optimal design problem
0.5811853470	stochastic matrix
0.5811495697	establish minimax
0.5810706422	asymptotic covariance
0.5810516268	e commerce
0.5808492245	inferential methods
0.5807395227	specific classes
0.5806671100	large matrix
0.5803906761	uniform distributions
0.5803775336	probabilistic framework
0.5802990173	coefficient models
0.5800421619	integrated moving average
0.5799532390	independent random vectors
0.5799370864	called `
0.5798215424	data adaptive
0.5796889992	accelerated failure time
0.5796564267	allowed to grow
0.5796001968	large covariance
0.5794826371	averaged stochastic
0.5793023994	adaptive choice
0.5792865059	generalized estimating equations
0.5791256066	synthetic and real data
0.5790585666	minimax optimal rate
0.5790539745	family wise error
0.5790307274	high probability bounds
0.5789541924	computational guarantees
0.5787636170	information based
0.5783526015	acyclic graph
0.5783129626	real data application
0.5781125895	linear structural
0.5781093478	asymptotic performance
0.5781042041	paper shows
0.5778068460	method called
0.5777388265	generalized maximum
0.5776528312	improved performance
0.5776176855	dependence coefficients
0.5775017837	null space
0.5773272537	exact confidence intervals
0.5772034346	single point
0.5771650568	real dataset
0.5770044819	provide conditions
0.5770036590	squared distance
0.5768534885	gradient estimator
0.5767908571	likelihood theory
0.5767888202	statistics and machine learning
0.5767712446	correlation analysis
0.5766758034	large sample limit
0.5762737805	goldenshluger and lepski
0.5761614452	minimal assumptions
0.5760218737	bayesian nonparametric approach
0.5760188867	structural function
0.5759834864	parametric assumptions
0.5757954129	conditional likelihood
0.5757177836	main goal
0.5757008576	carlo simulation studies
0.5755881589	survey data
0.5755728402	competing estimators
0.5754323168	exact simulation
0.5748425361	statistical functional
0.5748000815	sum of squares
0.5747968353	detection procedure
0.5747910491	penalized least squares estimator
0.5742388136	empirical quantile
0.5741867232	location scale models
0.5740838088	standard statistical
0.5738732960	optimal adaptive
0.5738633898	method achieves
0.5738370274	traditional methods
0.5737974800	locally asymptotically
0.5737280786	minimax framework
0.5737087574	optimal estimator
0.5736734754	covariance parameter
0.5735629269	variance case
0.5733840211	theoretic approach
0.5732750441	general parametric
0.5731842261	regularized estimator
0.5731755576	order tensor
0.5729631316	matching problem
0.5727328608	drift parameter
0.5726641312	finite dimensional parameter
0.5724672374	statistical inverse problem
0.5724655524	binomial regression
0.5724389384	x ray
0.5723004373	change point problem
0.5720873790	regularized estimates
0.5720092958	mises fisher
0.5719130364	smooth functional
0.5717045393	group lasso estimator
0.5715766564	efficiency bound
0.5713079495	model uncertainty
0.5712597351	inner product
0.5712341792	unified theory
0.5710905862	true values
0.5710231214	large scale problems
0.5707206085	dimensional linear
0.5705484438	practical performance
0.5705479328	computational experiments
0.5705215848	inference problem
0.5701855106	estimator enjoys
0.5699454291	recovery of sparse signals
0.5699395893	semi parametric models
0.5698957812	galton watson process
0.5697183901	real data experiments
0.5696677093	b splines
0.5696634508	polynomial approximation
0.5695756751	mixed effects models
0.5693841959	regression estimates
0.5693831890	optimal estimation
0.5693587654	` ag
0.5693583617	larger class
0.5693294899	extensive simulation study
0.5693036355	recurrent markov
0.5691035433	self normalized
0.5688030878	main theoretical
0.5688010957	fractional ornstein
0.5686066259	f_ \ epsilon
0.5685965361	f_ \ theta
0.5683663450	true null hypotheses
0.5679906201	simulated and real data sets
0.5679722173	model assumptions
0.5679352547	infinite dimensional parameter
0.5677645552	allowed to vary
0.5676443860	log concave distribution
0.5676248239	empirical likelihood method
0.5675975038	provide rigorous
0.5675012274	bayesian model
0.5674817795	model selection problem
0.5671696601	exponential random
0.5671387029	zero inflated
0.5671320007	optimal convergence rate
0.5670550464	parametric component
0.5670527094	high dimensional random vectors
0.5670045379	main idea
0.5669533967	study shows
0.5669225298	machine learning techniques
0.5668728986	underlying function
0.5667604820	optimal linear
0.5666993463	sampling procedure
0.5665914669	general approach
0.5664602542	estimator performs
0.5664571208	classical approaches
0.5660350176	bayesian approaches
0.5660085308	classification methods
0.5659973640	dirichlet model
0.5658403285	simple examples
0.5657314077	drift and minorization
0.5656012445	gamma model
0.5654829147	long memory parameter
0.5653890949	data objects
0.5653199229	applications including
0.5650858666	weak limit
0.5649285694	univariate regression
0.5647210741	maximum likelihood approach
0.5645792038	copula models
0.5643721172	covariance estimators
0.5642514764	mixture distributions
0.5640657699	penalized empirical risk
0.5640471951	context specific
0.5640129397	limit process
0.5639175023	pseudo maximum likelihood
0.5639042388	b spline
0.5638904497	message passing algorithm
0.5636391070	point of view
0.5635933338	monte carlo sampling
0.5634036471	computer vision
0.5633476710	empirical copula process
0.5630115718	scalar response
0.5629037921	fan and li
0.5628896414	probability matching
0.5625768573	gaussian linear
0.5625540503	location model
0.5625505974	difficult problem
0.5624623222	regression estimation
0.5624506772	approximation problem
0.5623039684	divergence estimator
0.5622908206	statistical techniques
0.5621703579	subspace estimation
0.5619939365	parametric tests
0.5619224111	systematic study
0.5618560689	p boxes
0.5618220053	change point estimator
0.5617976648	real data applications
0.5617448505	sectional variation
0.5615950772	improved estimator
0.5614853868	machine learning applications
0.5613557570	model selection problems
0.5611094981	high dimensional covariance matrix
0.5610423296	marginal posterior
0.5606382438	numerical studies demonstrate
0.5605952802	paper describes
0.5605845914	gaussian distributed
0.5605669980	accurate estimation
0.5605472301	detailed study
0.5603887706	mean squared error
0.5600885229	high dimensional linear
0.5600637296	signal estimation
0.5600486499	simulated and real data
0.5597231037	estimator converges
0.5596549365	measure space
0.5595402049	graph estimation
0.5594738751	breakdown and groups
0.5594021526	long memory stochastic
0.5593946827	sparse covariance
0.5593203018	model includes
0.5592371347	frequency data
0.5590394177	finite rank
0.5588302826	bootstrap confidence intervals
0.5587916051	high dimensional logistic
0.5587464838	nonparametric problems
0.5587460782	asymptotically sharp
0.5586734772	statistical dependence
0.5586170775	standard estimators
0.5585659207	fast convergence
0.5584184248	probability weighted
0.5581118578	examples including
0.5578466618	multiple test
0.5578284411	matrix multivariate
0.5578194017	uniform in bandwidth consistency
0.5576249770	optimal filter
0.5575670825	two sided
0.5575636670	stationary sequence
0.5575455795	large sample theory
0.5573513713	experiments demonstrate
0.5571362198	kernel type estimator
0.5569252683	random dot
0.5568304827	statistical estimators
0.5566761038	strong laws
0.5566690568	provide explicit
0.5563224497	change point test
0.5563093190	lasso method
0.5560658187	problem arises
0.5560564390	pre and post
0.5559561272	sampling without replacement
0.5559551680	easy to compute
0.5558250604	ill posed linear inverse
0.5554594049	series models
0.5553526820	techniques developed
0.5553293327	true model
0.5552099869	statistical information
0.5551134713	model dimension
0.5548732328	diverging number
0.5546564774	stein's unbiased
0.5545762410	market data
0.5542385475	stochastic model
0.5539431744	sample drawn
0.5539294878	parameter estimator
0.5536838965	adaptive regression
0.5536083649	imaging data
0.5535707990	bayesian procedure
0.5534223290	previously obtained
0.5533059982	moving average random
0.5532445259	near epoch
0.5532189540	important practical
0.5532108688	asymptotic size
0.5531241621	measures of concordance
0.5530986808	sequential data
0.5529152503	nonparametric regression models
0.5528396362	data driven procedure
0.5525016429	error processes
0.5524300129	data splitting
0.5524109221	optimal test
0.5523279404	random function
0.5523177120	closed convex
0.5522583444	achieving optimal
0.5519299580	binary symmetric
0.5519273816	divergence estimators
0.5518986435	selection consistent
0.5517557269	simulation studies demonstrate
0.5513022842	accurate inference
0.5512598543	discrete models
0.5509846069	gaussian process model
0.5509257123	benjamini and hochberg
0.5508878260	functional analysis
0.5507310800	asymptotically normal estimator
0.5504371344	approach works
0.5504013652	bias variance trade off
0.5501758294	asymptotic covariance matrix
0.5501684181	weighted graphs
0.5501470594	estimation and variable selection
0.5499011058	carlo methods
0.5496761277	operating characteristic
0.5496584613	asymptotic limit
0.5494038439	recently shown
0.5493758373	problem dimension
0.5492401000	poisson point
0.5491625277	layer neural
0.5490095177	construct confidence intervals
0.5486775940	empirical examples
0.5485153423	general markov model
0.5483873033	strong control
0.5482810741	functional parameter
0.5481444340	fan et al
0.5480883133	information bound
0.5479632267	complex gaussian
0.5479583111	establish asymptotic normality
0.5479300129	single realization
0.5477135483	numerical results demonstrate
0.5473380779	variate distributions
0.5471750958	akaike information
0.5469500123	response data
0.5469050566	multivariate extreme value theory
0.5467895869	optimal regret
0.5465648684	bayesian optimization
0.5464544702	rank based inference
0.5462559205	optimal kernel
0.5462183604	approximate posterior
0.5461579512	computational algorithms
0.5461074262	mixture of normals
0.5455923985	generating process
0.5454534751	density based
0.5454328593	recent theoretical
0.5453080967	gaussian likelihood
0.5452248032	simple models
0.5449995235	asymptotic result
0.5449050115	de biased
0.5447768044	extreme value statistics
0.5446030246	inference algorithm
0.5444890749	price data
0.5444115955	study variable
0.5443676180	adaptive nonparametric estimation
0.5442376326	monte carlo algorithm
0.5442157267	rate optimal estimators
0.5441476074	optimal estimators
0.5441117245	science and engineering
0.5439853144	type distributions
0.5438034914	proposed scheme
0.5437158579	dimension increases
0.5436939712	uniform random
0.5436078832	model averaged
0.5436075993	numerical experiments on simulated
0.5432788324	lasso estimators
0.5431289507	sup norm
0.5431257456	well behaved
0.5429976360	derive sharp
0.5429037152	single index regression
0.5428371588	domain of attraction
0.5425396199	extreme value copula
0.5424541723	possibly dependent
0.5424457586	proposed approaches
0.5424102219	explicit form
0.5423363395	biased sampling
0.5421979647	regression estimators
0.5419637809	general bound
0.5416746478	effect estimation
0.5415711811	buffet process
0.5415309326	robust covariance
0.5414302524	computer science
0.5412717115	allowed to increase
0.5411698177	order autoregressive
0.5401703689	self contained
0.5401254220	stationarity and ergodicity
0.5399730059	transport problem
0.5399071778	conditional least squares
0.5396725840	selection scheme
0.5396631058	regression estimator
0.5396596153	learning framework
0.5394943022	functional principal
0.5388718016	large data
0.5388382962	general model selection
0.5387029022	data driven selection
0.5386991061	classical statistical
0.5386241099	_ \ ell
0.5386026044	average run
0.5383887231	model class
0.5383275293	nonparametric change point
0.5381552615	response adaptive
0.5381350933	size distributions
0.5380292281	gradient methods
0.5378421538	asymptotic normal distribution
0.5377083791	powerful tool
0.5374324500	sub gaussian
0.5374202184	results confirm
0.5372371573	gaussian variables
0.5369899049	type processes
0.5369161357	dimensional random vectors
0.5368250509	high dimensional estimation
0.5367811999	penalized maximum
0.5365929656	discrete probability
0.5363507719	practical algorithm
0.5363382803	multiple hypothesis
0.5362825632	cand \ `
0.5362281914	linear functions
0.5360634576	ii errors
0.5358786709	limiting behavior
0.5357216612	well separated
0.5357072981	sub gaussianity
0.5356839643	popular methods
0.5356765417	valued random
0.5356669210	statistical settings
0.5354955907	criterion function
0.5354124639	gradient descent algorithm
0.5352105672	testing multiple
0.5351166221	geometrically ergodic markov
0.5350122442	change point models
0.5348578897	weighted graph
0.5347162810	metropolis adjusted
0.5346425101	extreme order
0.5343734615	suitable conditions
0.5342126075	valued data
0.5341337391	function on scalar
0.5338598348	rate of convergence
0.5337678820	two layer neural
0.5337624178	recent paper
0.5337310438	gaussian quasi likelihood
0.5336532092	minimum mean squared error
0.5335534202	data matrices
0.5332096990	switching models
0.5330787673	general methodology
0.5330423789	direct and indirect
0.5328108168	diffusion coefficients
0.5327804294	motion with hurst parameter
0.5327263753	geometric median
0.5327046576	limit results
0.5325206153	off line
0.5323871014	data generating process
0.5322286248	underlying structure
0.5319966829	establish consistency
0.5319068448	second order cone
0.5318961646	self similar
0.5318858616	lack of fit
0.5318545968	small size
0.5318360808	approach yields
0.5317566680	bayesian nonparametric estimation
0.5315898280	prove strong consistency
0.5314336679	method of moments
0.5308877828	empirical characteristic
0.5308249201	estimation and hypothesis testing
0.5307614037	unbiased estimate
0.5307131294	interval estimators
0.5305081285	central wishart
0.5303225901	model selection approach
0.5302197758	inference results
0.5301752183	uhlenbeck process
0.5301732792	reduction methods
0.5299417898	unknown function
0.5298860804	exponential models
0.5297564030	frequency estimation
0.5296328108	paper examines
0.5295207427	dependent case
0.5293951146	multivariate stochastic
0.5292248227	one sided
0.5291895122	bias and variance
0.5291205132	high dimensional linear model
0.5290655531	simple linear
0.5290646375	adaptive bayesian
0.5290129323	joint density
0.5289656134	slope parameter
0.5287997456	sharp asymptotic
0.5287769263	computational statistical
0.5286667880	construct estimators
0.5286162456	well posedness
0.5286014034	based estimator
0.5283406879	large probability
0.5283015303	censorship model
0.5280624890	small constant
0.5277009761	rates of convergence
0.5276406765	sampling problem
0.5273321100	asymptotic risk bounds
0.5271826272	efficient estimator
0.5270986807	right censoring
0.5262359137	gaussian cox
0.5261892866	monotonicity properties
0.5260904776	location and scatter
0.5257327421	noise variables
0.5255441812	popular models
0.5253295710	run length
0.5253013855	likelihood estimate
0.5249796777	sample case
0.5248507243	large number
0.5246245537	nonparametric bayesian approach
0.5244956598	new york
0.5243646706	speed of convergence
0.5241700986	concave density
0.5241328285	constrained least squares
0.5240682734	strong law of large numbers
0.5239844543	unknown scale
0.5239602859	sparse gaussian
0.5237928496	adaptive randomization
0.5237030963	sample based
0.5232272149	nonlinear autoregressive
0.5227757536	homogeneous poisson
0.5227315949	simple procedure
0.5224900644	likelihood based methods
0.5222730948	uniform in bandwidth
0.5222398546	number of mixture components
0.5221865385	linear functional
0.5219431020	random set
0.5219005102	first passage
0.5218373057	optimal testing
0.5218063260	dimensional spiked
0.5215956141	co kriging
0.5214844524	max linear
0.5212869559	asymptotic convergence
0.5211835769	correlated errors
0.5204763145	efficient methods
0.5204393490	probability models
0.5202658000	support estimation
0.5202025409	multivariate dependence
0.5201936752	univariate and multivariate
0.5201014343	low computational
0.5199456900	extreme value analysis
0.5199394185	least square
0.5198981050	point estimator
0.5198127065	de la
0.5197732647	local linear estimator
0.5197056800	univariate random
0.5196281245	optimization techniques
0.5196196034	fixed design regression
0.5195520722	estimator selection
0.5194944415	observation model
0.5191841237	method yields
0.5189758727	establish asymptotic
0.5185664606	parametric regression
0.5185111559	random process
0.5182559329	optimal bayesian
0.5181927763	expression data
0.5181693415	limiting spectral
0.5180541078	generating distribution
0.5177283548	structural properties
0.5175285745	regression method
0.5174975632	bayesian and frequentist
0.5173178070	domain asymptotics
0.5170962994	matrix completion problem
0.5170426052	functional estimation
0.5167964165	consistent estimator
0.5167468194	sided tests
0.5166710190	converges almost surely
0.5165671252	gaussian correlation
0.5165631465	true distribution
0.5164871740	properties including
0.5164606079	short and long
0.5163836271	upper and lower
0.5163479667	non trivial
0.5163189137	covariance matrix estimator
0.5162013414	conditional limit
0.5160148719	gaussian sequence
0.5158658167	classical approach
0.5158213175	series estimator
0.5157598477	generalized gaussian
0.5155068278	estimation in high dimensional
0.5154786895	linear state space
0.5152275641	statistical hypothesis
0.5151726341	theoretically optimal
0.5151084135	inference framework
0.5150701159	algorithm called
0.5148574611	estimated parameters
0.5147861504	bootstrap confidence
0.5146064737	type algorithm
0.5144068947	minimax results
0.5142219946	parameter estimators
0.5141413053	underlying regression
0.5140734783	finite and infinite
0.5131324239	least squares
0.5130842175	minimum mean squared
0.5129950406	normalized sums
0.5128969360	synthetic and real world data
0.5125614555	gamma random
0.5124848130	classical multivariate
0.5124315575	discovery rate control
0.5124062610	least concave majorant
0.5124021054	two layers neural
0.5123936203	interaction models
0.5121821257	model selection methods
0.5121418905	shown to converge
0.5119244248	multivariate extreme
0.5115981830	drift function
0.5111473242	structural information
0.5108094343	article considers
0.5106817373	means problem
0.5106747747	location and scale
0.5106661475	heavy tailed distribution
0.5101687586	important problems
0.5098919658	local and global
0.5097008035	optimization based
0.5096898902	positive and negative
0.5094933116	noise process
0.5093687810	studies demonstrate
0.5092975529	optimal weighted
0.5092097717	including consistency
0.5090056434	consistent and asymptotically
0.5082306077	bandwidth kernel
0.5080205279	function satisfies
0.5079961373	distributed observations
0.5078850921	criticism test
0.5078558876	discrete and continuous
0.5078341439	statistical method
0.5077915872	polynomial rate
0.5077677677	asymptotic conditional
0.5076302943	order of magnitude
0.5074898940	time varying
0.5074406406	paper demonstrates
0.5072260567	model errors
0.5070882465	linear and nonlinear
0.5067975095	high dimensional limit
0.5067924603	well conditioned
0.5065896440	sample complexity bounds
0.5064526792	analysis of variance
0.5063404971	geometric graph
0.5062673737	global and local
0.5059795802	sparse and dense
0.5059590441	two armed bandit
0.5058872298	provide sharp
0.5058093713	empirical application
0.5056566715	linear regression problems
0.5056085202	log linear parameters
0.5055307316	asymptotic confidence intervals
0.5055228330	order derivatives
0.5054623246	applications to real data
0.5054071570	inference for high dimensional
0.5053375631	called ` `
0.5052478324	multivariate garch
0.5052435782	process converges
0.5050454586	main purpose
0.5050236566	location and scale parameters
0.5047404473	density operator
0.5047255654	asymptotically unbiased estimator
0.5047207530	ill posedness
0.5045928050	probability of causation
0.5044057967	high dimensional asymptotic regime
0.5044013614	local alternative
0.5043152638	autoregressive time series
0.5042544392	unified approach
0.5040565199	optimization procedure
0.5039190121	detection method
0.5035827548	asymptotic distributional
0.5035243254	mathematical properties
0.5032883052	real and complex
0.5032210976	power distribution
0.5032160544	most probable
0.5028997433	propose and analyze
0.5026273313	probability model
0.5026160639	attachment model
0.5025774523	polynomial time algorithms
0.5025327832	testing framework
0.5024708787	point process model
0.5023658517	generalized least squares
0.5023275509	f_ \ alpha
0.5023083158	large and moderate
0.5022588758	drift and diffusion
0.5020053734	well posed
0.5019656435	means and variances
0.5018528316	integer valued time series
0.5018403502	convergence analysis
0.5018212211	underlying probability
0.5017598013	number of samples required
0.5015838989	linear process
0.5015676369	regularized least squares
0.5015622191	fast rates of convergence
0.5015275556	bootstrap approach
0.5012851951	discrete or continuous
0.5011684501	finite sample sizes
0.5011454931	u statistics
0.5010012823	theoretical support
0.5009040945	conditional maximum
0.5008294937	nonparametric framework
0.5006782379	obtain asymptotic
0.5006741825	statistical problem
0.5006600331	signal to noise
0.5005515148	exact solution
0.5004131579	classical method
0.5002712021	independent and identically
0.5002297505	form statistics
0.5002009838	inference algorithms
0.5001472448	normal density
0.5000777356	stage procedure
0.4999490907	parameter selection
0.4999288101	probability function
0.4998558876	continuous and discrete
0.4997855625	negative log
0.4997207479	variable selection and estimation
0.4996327647	dimensional diffusion
0.4995966009	treatment and control
0.4994865452	data based
0.4993267866	truncated data
0.4991836573	outcome model
0.4990229353	spike and slab prior
0.4990045442	degree of ill posedness
0.4986815660	non central wishart
0.4986380119	multivariate case
0.4985714346	simple closed form
0.4984019257	estimation and model selection
0.4983886129	important statistical
0.4981863207	nonparametric procedures
0.4981643132	self normalization
0.4981028736	log concave maximum likelihood
0.4981012766	general linear
0.4978813931	analysis framework
0.4977577639	unified treatment
0.4976456946	estimation and prediction
0.4976432785	univariate gaussian
0.4973729185	k nearest neighbor
0.4973216122	unknown distributions
0.4971964728	poisson model
0.4971958541	theoretical and practical
0.4970742101	definite functions
0.4970382598	off diagonal
0.4968339501	extreme value distribution
0.4966817732	pseudo maximum
0.4966642472	covariance model
0.4965671219	prediction problem
0.4963908714	classical linear
0.4963581711	general formula
0.4962795652	finite dimensional distributions
0.4961989828	derive upper bounds
0.4960184095	difference in means
0.4957289204	exponential bounds
0.4954809577	nonstationary time series
0.4954621754	theoretically and empirically
0.4952920079	univariate case
0.4952158138	noise distribution
0.4951575662	positive density
0.4950897220	non negative
0.4950020493	variance based
0.4948654764	results showing
0.4945448889	best subset selection
0.4944362685	volatility model
0.4943941217	cox proportional
0.4943736069	based measures
0.4943164240	random error
0.4943131310	methods require
0.4942494893	functional central limit
0.4937576442	modern statistical
0.4935261255	existence and uniqueness
0.4930445151	sampling techniques
0.4930439028	general case
0.4930075671	state estimation
0.4925543499	derive upper
0.4924417045	multi reference
0.4921296851	method requires
0.4917591947	corrupted by additive
0.4916978868	practical utility
0.4916334151	_ \ alpha
0.4913427426	carlo algorithm
0.4913192219	fractional gaussian
0.4910046666	quasi monte
0.4909455821	empirical study
0.4909371739	gaussian density
0.4906737004	type models
0.4901875639	markov transition
0.4900799044	underlying parameters
0.4900571257	parametric and nonparametric
0.4900227048	carlo sampler
0.4897612573	exponential convergence
0.4896420430	time consuming
0.4894924612	shapley value
0.4893805743	examples demonstrate
0.4893346968	resulting method
0.4892565365	establish sufficient conditions
0.4885651060	simultaneous estimation
0.4879208983	multivariate generalized
0.4879058735	extreme value
0.4877486136	optimal choice
0.4876736090	restaurant process
0.4876208438	rates of contraction
0.4875607203	based procedures
0.4874804793	latent variable graphical model selection via
0.4873740377	two stage
0.4873638840	oracle type
0.4872275007	numerical model
0.4871807440	binomial model
0.4871654317	random tensor
0.4870775564	distribution regression
0.4870621895	tensor data
0.4863671063	second order
0.4863324377	regularized maximum
0.4861583320	size and power
0.4857131145	large sample properties
0.4856581890	lower and upper
0.4855767611	finite sample distribution
0.4855255118	noise regime
0.4853719872	weak and strong
0.4853171952	finite sample bound
0.4853080471	real and simulated data
0.4850888952	spline estimator
0.4849321472	decision process
0.4849297806	algorithm for computing
0.4848562654	arbitrary covariance
0.4847388648	estimation of linear functionals
0.4847028437	for real normed division
0.4846583031	tending to infinity
0.4846076403	normal limit
0.4845575962	uniformly minimum
0.4844125846	finite sample results
0.4843971053	a b testing
0.4840011856	high dimensional distributions
0.4838475541	smoothed likelihood
0.4838331503	valued function
0.4837061687	procedure called
0.4836612728	dynamic model
0.4836104236	markov random
0.4832999507	pearson type
0.4832282758	derive simple
0.4832189154	data samples
0.4832114494	linear estimation
0.4829891130	derive asymptotic
0.4827199585	important properties
0.4822805238	high dimensional linear regression model
0.4822100008	kumaraswamy g
0.4821829114	sufficient dimension
0.4819999143	design of experiments
0.4817947547	estimation and inference
0.4817432368	tests of independence
0.4816637218	symmetric distribution
0.4816011102	likelihood based estimation
0.4815207527	introduce and study
0.4813588552	correct model
0.4812471847	regression with random design
0.4812382859	sequence model
0.4812073125	proposed class
0.4811863429	rare and weak
0.4809039331	frequentist and bayesian
0.4806673500	statistic based
0.4806312957	statistical and computational
0.4803693100	temporal and spatial
0.4802753028	strong uniform
0.4801640626	estimation framework
0.4801449462	probability and statistics
0.4800542127	change of measure
0.4799540629	small fraction
0.4796650597	tend to infinity
0.4796085291	set estimation
0.4795404653	high dimensional case
0.4795262301	robust and efficient
0.4794496152	ill posed inverse problem
0.4794126292	simulated and real
0.4791924734	independent gaussian
0.4790628773	paper explores
0.4789627388	theory developed
0.4788578486	samples drawn
0.4786643276	near optimal
0.4785530295	uniform rates
0.4785489428	statistics literature
0.4782187657	online algorithm
0.4779199462	theoretical and numerical
0.4778309480	test of independence
0.4776052508	scalar parameter
0.4775275412	uniform confidence
0.4774757510	complex data
0.4773730996	stationary and ergodic
0.4772633800	number of clusters
0.4769548581	population covariance
0.4767113429	eigenvalues and eigenvectors
0.4765349175	valued observations
0.4764538122	penalized log
0.4763968039	sparse principal component
0.4762852575	based method
0.4759610177	smirnov statistic
0.4758508571	sparse precision
0.4757585839	sample behavior
0.4756858854	paper extends
0.4753865454	detection and estimation
0.4753635552	dependent error
0.4753251520	mixtures of gaussians
0.4753050344	regression methods
0.4748923999	important problem
0.4747879726	variation regularized
0.4742181705	long memory time series
0.4739830986	crucial role
0.4738936725	analyzing high dimensional
0.4737840487	standard bayesian
0.4737428839	mis specified
0.4737071351	positive real
0.4735275263	poisson dirichlet distribution
0.4735090262	tail empirical
0.4731871845	proposed distribution
0.4731816260	bootstrap algorithm
0.4731462244	death processes
0.4729562948	additive white
0.4729119604	coefficient of variation
0.4728709074	non identically distributed
0.4727870883	parametric methods
0.4727788999	r von mises
0.4727135476	prediction and estimation
0.4725606285	true regression function
0.4724018746	dimensional regression
0.4722391064	sensitive to outliers
0.4721691301	ball method
0.4720943761	expected error
0.4720368109	errors in variables
0.4719971250	perform inference
0.4719403052	data driven bandwidth
0.4718459732	exact test
0.4715928024	detection algorithm
0.4714793957	positive rate
0.4713318861	non parametric
0.4712028024	risk minimizer
0.4705554149	key tool
0.4704029967	classification and regression
0.4703919950	converges weakly
0.4701116872	corrupted by noise
0.4701067853	concentration of measure
0.4699931593	minimal markov
0.4699539528	finite dimensional linear
0.4699100421	derive minimax
0.4698388019	propose and study
0.4698077322	fast algorithm
0.4697740573	nonparametric approach
0.4695995581	covariance graph
0.4695798432	annals of statistics
0.4695164993	provide finite sample
0.4693934890	functional dependence
0.4692727823	models with latent variables
0.4692242810	shrinkage and selection
0.4689418168	polynomial time algorithm
0.4688922309	status data
0.4686670793	high dimensional multiple
0.4686145135	block gibbs
0.4682560197	nonlinear least squares
0.4681020463	tight lower
0.4677035245	continuous time processes
0.4676954424	high dimensional consistency
0.4671829181	estimation algorithms
0.4671274460	bayesian prior
0.4670479609	linear function
0.4668946154	upper bounded
0.4668001213	statistical procedure
0.4666765794	computational and statistical
0.4665840849	method outperforms
0.4664089943	independent normal
0.4663665436	estimating parameters
0.4662821824	proofs rely
0.4660967543	bayesian mixture
0.4660079638	inhomogeneous random
0.4656482470	binomial and poisson
0.4655763857	provide asymptotic
0.4654651987	small simulation study
0.4652850772	optimal experimental
0.4652300403	expectation and variance
0.4648714714	vector parameter
0.4647716383	gaussian prior
0.4647269995	^ 4 5
0.4647000304	linear unbiased
0.4642201136	type ii errors
0.4641640363	error covariance
0.4639447633	general method
0.4638046662	rank matrices
0.4637881950	based models
0.4637027493	selection operator
0.4636568293	theory and practice
0.4635956308	right censored data
0.4633949778	key step
0.4633756346	model called
0.4631875339	slab priors
0.4629736317	linear and quadratic
0.4629683966	proof of concept
0.4629487561	bayesian non parametric
0.4625665775	distributed estimation
0.4625439662	valued functions
0.4624545850	shannon divergence
0.4624172867	regression and classification
0.4623304408	data examples
0.4619328805	empirical estimator
0.4619084547	unknown matrix
0.4615718435	independent bernoulli
0.4614780002	normality results
0.4614740659	true posterior
0.4612672031	maximization algorithm
0.4612427214	p_ \ theta
0.4609421255	gaussian data
0.4608261403	stochastic linear
0.4603354628	almost surely
0.4603248829	least favorable
0.4599014152	optimal smoothing
0.4597407947	constant functions
0.4596329715	results require
0.4596141653	mixed data
0.4595109926	oracle estimator
0.4594029890	constructing confidence
0.4590489198	consistency and asymptotic
0.4590451944	statistical decision
0.4587896477	data modeling
0.4587591101	problems including
0.4587264323	consistent test
0.4587085963	define and study
0.4583894513	discovery proportion
0.4583629971	optimal minimax rates
0.4583390938	time changed
0.4577242821	learning methods
0.4575690415	family of distributions
0.4573957656	approximation result
0.4573352026	high dimensional random
0.4572035296	sampling model
0.4571125261	regression type
0.4570902933	mean squared prediction error
0.4569738991	inner products
0.4568347415	time series
0.4567983182	method of maximum likelihood
0.4567165482	problem of estimating
0.4564452983	structured data
0.4562159903	heavy tailed random
0.4560969239	diverge to infinity
0.4560518381	positive constant
0.4556507606	low signal
0.4554530649	plug in estimators
0.4553539665	simulation algorithm
0.4548687690	theoretical perspective
0.4548374610	establish uniform
0.4548241430	asymptotic property
0.4543023780	self decomposable
0.4540635697	article proposes
0.4536098791	component scores
0.4533070865	leq \ infty
0.4531964501	linear least squares
0.4531409001	results improve
0.4531324405	normally distributed
0.4530340052	sure screening property
0.4528947946	linear estimator
0.4526867564	explicit representation
0.4525171511	models include
0.4525160149	method performs
0.4521963039	l_ \ infty
0.4521906446	uniform error
0.4521048153	optimal bound
0.4520853539	functional central limit theorem
0.4519354470	matrix models
0.4519288248	expected number
0.4516767492	multiple samples
0.4512974177	central subspace
0.4512928044	current paper
0.4510265320	_ \ lambda
0.4509527988	poisson random
0.4508132413	unknown covariance
0.4506655989	linear latent
0.4503462913	de finetti
0.4502899043	without replacement
0.4502396363	point and interval
0.4500873646	two sample test
0.4499831057	point process models
0.4496630279	optimal rate of convergence
0.4494144771	model components
0.4491761297	threshold estimator
0.4486621750	geometric properties
0.4486344865	fractional stochastic
0.4484213656	\ ` adl \ ` ag
0.4483799313	functional limit
0.4481288708	weighted estimators
0.4480946067	moving block
0.4479858666	proof relies
0.4475362364	non gaussian
0.4472251705	least absolute
0.4470099434	squares estimators
0.4467976655	dimensional continuous
0.4467161904	k means clustering
0.4466307742	diverges to infinity
0.4464727971	u statistic
0.4460199628	neighbor classifier
0.4459169052	estimation algorithm
0.4456368025	testing method
0.4455245345	normal random
0.4454664579	real and simulated
0.4454480297	unknown noise
0.4451958873	degree polynomial
0.4451942191	carlo experiments
0.4451660595	range dependent
0.4447752316	averaging estimator
0.4446111435	process prior
0.4445637419	method for constructing
0.4445319252	local geometry
0.4443453616	theoretical and empirical
0.4439173629	provide numerical
0.4439113814	high dimensional scaling
0.4436235890	rate of decay
0.4435730328	minimal number
0.4433390187	bias and mean square error
0.4432451192	number of assets
0.4432433208	key component
0.4430896695	optimal rates of convergence
0.4430324172	log concave maximum
0.4430270153	time varying arch
0.4430199657	regularized m estimators
0.4429156121	robust nonparametric
0.4428644643	private data
0.4428425572	theory and methods
0.4427774510	parametric approach
0.4424646621	stationary linear
0.4422489044	noise models
0.4418038843	establish sufficient
0.4416244966	illustrated on simulated
0.4416199072	functional delta
0.4415935987	binary random
0.4414712248	feature models
0.4408531483	trade off
0.4407559353	composite null
0.4406786775	convergence and asymptotic normality
0.4406683345	approximation properties
0.4405755793	memory parameters
0.4405182402	cut off
0.4405154807	sample performances
0.4402497987	shown to depend
0.4401559150	computer codes
0.4401514674	simulated and real data examples
0.4400663414	prior data
0.4400276606	alarm rate
0.4399888648	resulting model
0.4398462913	de finetti's
0.4394272048	ii error
0.4392642295	number of edges
0.4388737729	simulations and real data
0.4385881151	graph theory
0.4382106171	alternating direction method of
0.4381427417	samples required
0.4381077004	single change
0.4380569141	range dependent data
0.4378523803	adaptive version
0.4378121695	thresholding methods
0.4376797015	strong theoretical
0.4376135565	ill posed inverse
0.4370846637	lasso and dantzig
0.4370457773	data dimension
0.4370209393	sparse high dimensional linear
0.4369252787	classical empirical
0.4369146171	high dimensional generalized linear
0.4366952181	information contained
0.4366821989	gradient method
0.4366783682	learning models
0.4365676259	matching upper and lower
0.4364127223	choice model
0.4362084852	becoming increasingly
0.4359850982	testing equality
0.4359058168	detecting change
0.4357335810	mean field limit
0.4355595538	introduced and studied
0.4355018130	input space
0.4354956797	exact minimax
0.4351350994	varying function
0.4351103792	high frequency financial
0.4350771816	independently and identically
0.4347996848	simple and efficient
0.4346018490	optimal minimax
0.4342307998	posterior analysis
0.4339261746	r package
0.4338675331	process of order
0.4337731130	key role
0.4337275992	obtain asymptotically
0.4332823589	largest order
0.4331631986	processes indexed
0.4331044125	non stationary
0.4330152734	size requirement
0.4329897981	differential equation driven
0.4326596134	estimation and testing
0.4326376361	graph model
0.4326271343	low rank covariance
0.4323737701	nonparametric test
0.4323115466	column sums
0.4320497286	process priors
0.4315179671	total causal
0.4312141847	functional models
0.4312136952	true density
0.4310834002	classical case
0.4310773021	spatial point
0.4308654311	bayesian variable
0.4306827307	powerful tests
0.4304698095	leave one out
0.4303814972	proposed and studied
0.4303810120	beta process
0.4299903364	performance analysis
0.4298253589	spurious local
0.4298116442	classical and bayesian
0.4294888091	local asymptotic mixed
0.4292833485	definite matrix
0.4290293442	paper proves
0.4289830649	sample testing
0.4289765270	separable hilbert
0.4288122057	scale model
0.4285221671	side information
0.4284125511	general settings
0.4282909342	nonparametric additive
0.4280958078	high dimensional parameter
0.4280855338	number of measurements
0.4278780892	bayes procedure
0.4278675331	sample of size
0.4272865377	varying tails
0.4272391367	infinite sample
0.4272064800	dimensional parameters
0.4270062833	sequence of random variables
0.4269720323	bayesian point of view
0.4269218250	pointwise asymptotic
0.4266456789	^ tx
0.4265027145	loss of power
0.4264458113	_ t \ geq
0.4264352140	methods developed
0.4263557023	theoretical and computational
0.4262586394	two sample testing
0.4259820602	iid random
0.4259521729	sparse bayesian
0.4258487159	^ 2_1
0.4257390158	alternative models
0.4256690600	high dimensional functional
0.4256498395	discrete time observations
0.4255157822	previous paper
0.4254363184	high noise
0.4252275075	rank matrix recovery
0.4251880798	posterior rates
0.4251368636	based algorithm
0.4250349256	grow to infinity
0.4248027150	rate of contraction
0.4247586621	general nonparametric
0.4247238047	unbiased risk
0.4244769661	dimensional covariates
0.4242418857	derive exact
0.4241917305	e chet
0.4236955493	o lya
0.4235819559	central limit theorems for
0.4235423608	uniform limit
0.4233457331	joint probability
0.4232165320	input data
0.4232120304	selection algorithm
0.4230679035	finite discrete
0.4226418948	loss of information
0.4223581086	heterogeneous treatment
0.4223304805	observed time series
0.4222248869	present numerical
0.4219548390	decision processes
0.4217585967	continuous shrinkage
0.4215258713	based procedure
0.4214324734	selected model
0.4214150108	computer code
0.4213478614	variable models
0.4213370087	inequalities in risk minimization
0.4212431873	corrected estimator
0.4212272901	one bit
0.4210058393	optimal bayes
0.4209492637	measures of association
0.4208288837	design problem
0.4207611545	matching lower
0.4204686130	dependent time series
0.4200095501	sums of independent
0.4200088165	proposed statistics
0.4199922788	discrete time
0.4198974026	continuous time
0.4198141930	model order
0.4196930896	experiments on simulated data
0.4195704411	observed random
0.4194524296	perhaps surprisingly
0.4192918564	classifier technology and
0.4191677773	number of iterations
0.4191384298	limiting null
0.4189556927	high dimensional multivariate
0.4189197315	local estimation
0.4188550290	number of neurons
0.4188239142	exponential family of distributions
0.4185435224	theoretical point of view
0.4184060042	derive optimal
0.4183939774	driven sampling
0.4182639338	1 bit
0.4180291601	fit test
0.4179571404	the past decade
0.4178591349	problem of recovering
0.4176742890	non degenerate
0.4172998789	stopping time
0.4172997567	linear structural equation
0.4172668208	theoretic properties
0.4170978715	minimax rate of convergence
0.4169875344	empirical probability
0.4169669727	model structure
0.4169046066	multiple random
0.4167944229	nonparametric confidence
0.4166528103	limiting normal
0.4165645380	simulation and real data
0.4163698777	p values
0.4163652032	small and large
0.4159991715	provide simple
0.4154268297	power spectral
0.4152858757	theory and applications
0.4151903552	off policy
0.4151627825	le p \ le
0.4149122864	an extensive simulation study
0.4145877417	adaptive group
0.4145755737	learning setting
0.4145341059	dt + \ sigma
0.4145163951	experiments on synthetic
0.4144723771	statistical point of view
0.4144271366	step down
0.4143998174	o lder
0.4143552622	role played by
0.4143305955	random orthogonal
0.4142578912	synthetic and real
0.4141721821	discrete times
0.4140189911	covariate space
0.4139783431	infinite number
0.4136495317	no longer
0.4136181921	_ \ mathrm
0.4135230075	presented to illustrate
0.4134696624	article presents
0.4133539035	exponential covariance
0.4132743581	results apply
0.4132288923	non asymptotic oracle inequality
0.4129507311	random gaussian
0.4129016182	class classification
0.4125130663	mixed linear
0.4124474436	exploratory data
0.4123552450	numerical evaluation
0.4123281542	giving rise to
0.4122076674	key idea
0.4119037222	fixed time interval
0.4117570391	large scale data
0.4116616543	_ \ mathcal
0.4116473939	decision problem
0.4115171250	general class
0.4114872603	confidence sets based
0.4114338549	least squares regression
0.4112824133	simple model
0.4112426067	robust to outliers
0.4112045262	computer experiments
0.4111447728	missing not at
0.4110270926	sub exponential
0.4109831334	equations driven
0.4103911253	practical point of view
0.4102977969	regression case
0.4102522586	fixed and random
0.4101504252	construct asymptotically
0.4101058874	fractional stable
0.4100030207	optimal error
0.4098275534	penalized empirical
0.4096763839	world networks
0.4091588390	model size
0.4090042950	estimation rates
0.4088450703	sparse random
0.4085914074	provide theoretical guarantees
0.4084952893	deviation principle
0.4084353231	estimator and derive
0.4083135783	convex compact
0.4083030428	all or nothing
0.4081031181	ergodic process
0.4079218241	joint asymptotic
0.4078950943	group model
0.4071915771	sample data
0.4071907974	type i
0.4071685078	independent and identically distributed random
0.4069209844	density model
0.4067218421	spectral distribution
0.4065509438	sequential hypothesis
0.4065475165	good turing estimator
0.4062997504	log rank
0.4062889083	structure estimation
0.4062692345	frequency observations
0.4062609971	regression curves
0.4060799647	markov chain model
0.4060287881	optimal properties
0.4056666648	bernoulli random
0.4053601114	gaussian white
0.4053057751	dimensional stochastic
0.4052095187	paper addresses
0.4050483254	independent data
0.4049718614	lot of attention
0.4048045082	provide examples
0.4047841947	distributed random
0.4045262933	prove asymptotic
0.4041147102	general noise
0.4040174298	specific model
0.4039718096	reduction method
0.4035166567	least squares linear regression
0.4032959781	distributed statistical
0.4032475321	independence structure
0.4032438635	sparse group
0.4030866605	first order autoregressive process
0.4029517718	number of samples
0.4022226178	sample properties
0.4020112721	large sample behavior
0.4019356907	larger number
0.4014421077	algorithm converges
0.4010315055	distributed data
0.4006260198	mean field
0.4005383330	provide sufficient
0.4005330394	simulations and real
0.4001631040	norm based
0.3997543521	stationary data
0.3996125983	among other things
0.3994183807	transition phenomenon
0.3992879902	linear fractional
0.3992647134	derive general
0.3992512127	_ i \ geq 1
0.3992410063	so called
0.3991654482	distributions defined
0.3991274705	set of points
0.3990610784	number of classes
0.3987601030	classical problem
0.3986888455	non markovian
0.3984085066	least squares estimation
0.3983627331	positive semi
0.3983514392	estimation approach
0.3983298790	norm penalization
0.3982420217	data driven method
0.3981779967	compared to existing methods
0.3981631342	problem of reconstructing
0.3978683429	finite second moment
0.3978560443	watson statistic
0.3978273305	dimensional multivariate
0.3977496079	non euclidean
0.3974549822	driven stochastic
0.3972819929	method of proof
0.3971672743	hazards regression
0.3970366853	continuous data
0.3970164089	chain monte carlo algorithm
0.3969300927	gradient algorithm
0.3969079973	approximation and estimation
0.3968469391	tensor model
0.3965411114	closed form formula
0.3963161937	variable model
0.3962817412	sample coverage
0.3962290558	least squares estimator
0.3961008852	full generality
0.3960915653	sup norm loss
0.3958903152	data generated
0.3957005397	sparse data
0.3956622298	concave density estimation
0.3955848352	optimal local
0.3954185787	models including
0.3953653908	selection and estimation
0.3951858061	last decade
0.3951150813	continuous random
0.3950723065	fixed sample
0.3950185908	individual data
0.3949108195	variable selection in high dimensional
0.3948271777	study confirms
0.3946508844	_ \ theta
0.3946462049	non asymptotic
0.3944467179	second moment
0.3944003255	locally d optimal
0.3941136225	popular statistical
0.3940172534	probability of error
0.3939535983	x_ n
0.3937901158	real random
0.3937834985	distribution estimation
0.3936551320	multivariate regular
0.3936432017	high dimensional statistical
0.3936154572	discrete fourier
0.3933761342	space time covariance
0.3933375882	positive definite functions on
0.3929358760	linear ill posed
0.3928288454	weighted sum
0.3927460873	well understood
0.3923490559	self similar processes
0.3919763720	follow up
0.3919377916	linear shrinkage
0.3917322417	order autoregressive process
0.3914597755	statistical data
0.3913033698	number of columns
0.3912284213	lim_ n \ to \ infty
0.3911111980	optimal bounds
0.3909308468	low and high
0.3904846303	~ \ cite
0.3903917909	broad class
0.3903863765	index data
0.3903250515	response models
0.3903035998	popular approach
0.3902605345	valued time series
0.3902579390	stochastic dynamical
0.3902431914	statistic for testing
0.3900937807	product graphs
0.3900348600	under minimal assumptions
0.3898072629	gaussian time series
0.3895626681	sample problem
0.3894779700	general distributions
0.3894100497	concentration properties
0.3893753625	smallest eigenvalues
0.3890576281	t tessellations
0.3890227788	derive closed form
0.3890097361	variable regression
0.3887525757	likelihood test
0.3887163380	population model
0.3886961042	independent identically
0.3884053944	approach leads
0.3878839477	bayesian decision
0.3878675753	_ \ infty
0.3875815221	wide applications
0.3875671566	eqnarray *
0.3875357511	shown to achieve
0.3869410198	asymptotic error
0.3869022865	parametric estimators
0.3867160127	asymptotic oracle
0.3866606816	strong consistency and asymptotic normality
0.3866429822	normal data
0.3865005040	root n consistent
0.3863718766	high dimensional bayesian
0.3862984654	squared errors
0.3862049944	autoregressive moving
0.3861727869	et al
0.3860952985	while maintaining
0.3860768454	field limit
0.3858601580	data driven choice
0.3855901757	non linear
0.3855007935	one parameter exponential family
0.3853427445	pre specified
0.3853339539	process regression
0.3851537170	study nonparametric
0.3851066801	e vy
0.3849185402	error loss
0.3848705503	deviation theory
0.3848610837	squares estimation
0.3846372189	non linearity
0.3845399353	model space
0.3845126942	measure of evidence
0.3844543062	estimator and establish
0.3841778556	problem of determining
0.3841131858	probability weighting
0.3840613610	paper offers
0.3840180263	popular tool
0.3838715594	stationary markov
0.3835965985	selection approach
0.3834403466	size distribution
0.3834159558	statistical approach
0.3831466106	multivariate distribution
0.3831071419	groups of variables
0.3830892484	asymptotic null
0.3829406737	regression algorithms
0.3828878739	generalised linear
0.3828233756	taken into account
0.3825306469	data application
0.3824321263	based confidence intervals
0.3823417860	stochastic partial
0.3821716982	sub populations
0.3821552292	density models
0.3821308634	type distribution
0.3817189626	shown to attain
0.3816580596	concave distributions
0.3815172468	k 1
0.3815127295	derive sufficient
0.3814141982	carried out
0.3813886833	number of jumps
0.3811978611	random data
0.3809780899	dimensional problems
0.3807825401	number of regressors
0.3807405856	methods for estimating
0.3807240733	s & p 500
0.3804677183	non homogeneous
0.3802647146	number of communities
0.3801727911	establish strong
0.3799665144	parameter poisson dirichlet
0.3797442301	real log
0.3795334343	_ \ epsilon
0.3795114361	spectral cut off
0.3791822097	number of observations
0.3791706859	provided to demonstrate
0.3790635186	distribution theory
0.3787605754	bayesian estimator
0.3787224422	error in variables
0.3786942630	karhunen lo \
0.3786093978	value at risk
0.3785073652	index estimation
0.3782238116	adaptive test
0.3778281160	experiments confirm
0.3777828236	class of priors
0.3776664920	sparse deep
0.3776423698	type model
0.3776414050	sheds light on
0.3774101835	sequential importance
0.3772190962	little attention
0.3770158978	consistency and convergence
0.3767878274	point detection
0.3767193480	nearly tight
0.3767013584	norm error
0.3765806809	number of steps
0.3762945658	sampling rate
0.3760806003	hidden regular
0.3760418557	multiple output regression
0.3759149560	conditional quantile function
0.3757770389	testing data
0.3757660225	sequential change
0.3756933892	partial linear
0.3755759671	non overlapping
0.3753618831	process mixture
0.3753513727	empirical version
0.3753250395	homogeneous markov chain
0.3752731659	subspace spanned by
0.3752039842	driven by fractional
0.3751512060	parametric estimator
0.3751393438	shown to hold
0.3750495907	markov jump
0.3750097109	number of data points
0.3749919507	order terms
0.3746878750	order asymptotics
0.3746040543	discrete graphical
0.3745818272	less restrictive
0.3743720401	conditional extreme
0.3743559362	average processes
0.3741794113	sharp phase
0.3739795744	space models
0.3737140957	method proposed
0.3736107867	this paper develops
0.3734903519	model inference
0.3734853865	sigma ^ 2
0.3733697232	asymptotic concentration
0.3732372972	proposed bootstrap
0.3732008482	data generating distribution
0.3731556777	\ cdot
0.3731405017	two fold
0.3729880554	failure time
0.3727903046	scale family
0.3726866485	asymptotic oracle inequality
0.3726718386	problems arising
0.3725091158	efficient sampling
0.3722859741	goes to infinity
0.3722669880	coefficient model
0.3721275659	families of distributions
0.3720808648	correctly specified
0.3720539988	non convex
0.3719310990	linear and non linear
0.3718753037	type estimation
0.3717233632	in sharp contrast
0.3715664717	likelihood analysis
0.3714172766	tests and confidence
0.3712533908	& p 500
0.3710114686	finite number
0.3709641313	spherical random
0.3709321737	simple approach
0.3709183605	tends to infinity
0.3708214820	functional central
0.3705258698	model error
0.3704735406	average causal
0.3704707302	paper aims
0.3703839758	general high dimensional
0.3703111450	dimensional variable selection
0.3696040670	estimation and model
0.3695050500	geometric characterization
0.3691876780	under high dimensional scaling
0.3691768737	provide general
0.3690514574	explicit formula
0.3689162493	multivariate random
0.3684030600	identified models
0.3683048676	time series models
0.3680688311	hold uniformly over
0.3679498901	time to event
0.3678378586	free tests
0.3677721356	based bootstrap
0.3676217820	dimensional feature
0.3676139655	multivariate normal mean
0.3673423466	roberts procedure
0.3673418558	two sample tests
0.3670802531	observed at discrete
0.3667675646	local differential
0.3667072064	non reversible
0.3666994897	_ 0
0.3665623198	coverage of adaptive
0.3664068406	algorithms for computing
0.3662538739	matrix normal
0.3661211163	class of models
0.3659144760	linear convergence
0.3654979785	number of features
0.3654084518	number of species
0.3653605880	sparse estimates
0.3653536170	algorithm for learning
0.3653180140	conditional average treatment
0.3651571647	model estimation
0.3650405911	continuous probability
0.3650045818	finite state markov
0.3647536900	least squares estimators
0.3646895060	log gaussian
0.3646667350	automatically adapts to
0.3646642847	take into account
0.3646133164	sample error
0.3645178970	dimensional set
0.3642618087	indexed by functions
0.3642267444	testing and estimation
0.3642190471	concentrates around
0.3641575932	user specified
0.3638619339	finite sample analysis
0.3637931270	time series analysis
0.3637722954	bernstein von mises theorems for
0.3637579985	n ^ 1 2
0.3635994702	general gaussian
0.3634146856	class of loss functions
0.3629870267	robust test
0.3628556847	this paper proposes
0.3628220191	extend results
0.3627887648	square errors
0.3627384538	effective sample
0.3627360093	matrix model
0.3627130815	out of sample
0.3627065644	mathbb r ^ n \ times
0.3626695139	joint estimation
0.3625206205	information bounds
0.3623951722	based estimation
0.3623463270	likelihood methods
0.3622645743	\ citep
0.3621144347	parametric framework
0.3620712372	statistical network
0.3620608133	continuous time observations
0.3617801474	^ 2d
0.3617335736	continuous time stochastic
0.3615804377	method relies
0.3615315040	sample behaviour
0.3613148276	mean square
0.3613023200	sample autocovariance
0.3612534242	more precisely
0.3612276657	adversarial networks
0.3610952617	sparse model
0.3609703810	into account
0.3608744732	models involving
0.3604627925	alternative approach
0.3601132493	testing based
0.3597383256	$ means clustering
0.3596596356	motivated by applications
0.3595624078	chain monte carlo algorithms
0.3594995652	obtained by minimizing
0.3594267034	x_ 1
0.3592645664	dimensional time series
0.3592487791	present results
0.3590784578	thresholding estimator
0.3589739720	rigorous theoretical
0.3589530599	general model
0.3588812807	put forward
0.3588729186	a unified approach
0.3585110884	under mild conditions
0.3583653264	the shelf
0.3581574827	\ approx
0.3581202428	go to infinity
0.3579203895	conditional kendall's
0.3578484209	number of blocks
0.3577031386	series forecasting
0.3574152873	density and regression
0.3573554209	t_ n
0.3572504586	driven procedure
0.3571202248	precise characterization
0.3568079235	observed diffusion
0.3567768369	strong law of large
0.3567447860	shown to perform
0.3566900640	^ 1
0.3565139025	\ theta_i
0.3563054581	nearly optimal
0.3561588248	empirical beta
0.3560666318	adaptive posterior
0.3559798993	class of prior distributions
0.3559673945	first order
0.3558198293	selection properties
0.3557134277	there exists
0.3555519992	uniform asymptotic
0.3552653405	constrained maximum likelihood
0.3552413244	central problem
0.3551733976	valid confidence
0.3550745104	likelihood type
0.3549785006	\ mathrm poly
0.3548606127	b stat
0.3544913367	series analysis
0.3544784916	built upon
0.3542563715	algorithm to compute
0.3542079291	scale multiple testing
0.3540552872	positive random
0.3539916496	this paper introduces
0.3538453857	important tool
0.3538175989	gaussian error
0.3537023788	^ 3
0.3536432040	standing problem
0.3535783155	singular value
0.3533397552	class of estimators
0.3533313781	general stochastic
0.3532488515	strong consistency and asymptotic
0.3530693991	bayes methods
0.3530594547	problem at hand
0.3529619289	distributed variables
0.3525656659	hold out
0.3525472927	\ dots
0.3525313748	inference in high dimensional
0.3523543905	= 1,2
0.3523000362	family distributions
0.3522885570	this paper investigates
0.3521986080	taking advantage of
0.3521573745	continuous time markov
0.3520568937	standard tool
0.3518944294	squares regression
0.3517486936	selection for high dimensional
0.3516689637	differential equations driven by
0.3516504368	^ 5
0.3515654727	\ epsilon_
0.3514859906	_ k \ in \ mathbb
0.3514719447	parametric efficiency
0.3513670835	estimation and hypothesis
0.3513036791	matching minimax
0.3511878082	process framework
0.3510319881	maximum likelihood estimation for
0.3510148689	under mild assumptions
0.3508105339	power to detect
0.3508040628	squares estimates
0.3507858962	rate functions
0.3507250545	plug in estimator
0.3506687433	based model
0.3504682526	without losing
0.3503342001	bernstein von mises theorem for
0.3500172214	multivariate gamma
0.3499309973	rank matrix
0.3499242355	increase to infinity
0.3498659245	conditional survival
0.3497858962	order parameter
0.3497180257	theoretic lower
0.3495843325	frechet mean
0.3493662139	gaussian stationary
0.3491340209	shown to yield
0.3489087194	method to estimate
0.3488541310	dependent stationary
0.3487881616	this paper considers
0.3487847607	weak law of large
0.3487721963	first stage
0.3487548863	high dimensional generalized
0.3481263889	large random
0.3480142059	improves upon
0.3479636602	squares problem
0.3479378787	\ equiv
0.3478188199	finite data
0.3474954025	performance compared
0.3474823944	theoretical understanding
0.3474700178	\ citet
0.3473765946	under suitable regularity
0.3473735061	non central
0.3472177200	general loss
0.3471084351	establish consistency and asymptotic
0.3469625414	after model selection
0.3467670804	number of predictors
0.3466699332	p value
0.3464541670	measure of uncertainty
0.3464434216	generalized extreme value
0.3462800169	quantum hypothesis
0.3462758013	\ theta_0
0.3460838274	results rely
0.3458697682	_ 1 \ leq
0.3458103532	learning techniques
0.3455681848	partitioned into
0.3455288821	second kind
0.3454304783	optimal model
0.3454252917	matrix estimator
0.3453999744	non decreasing
0.3451937637	method for estimating
0.3450800169	state hidden
0.3450524904	provide exact
0.3450472051	this paper presents
0.3450338708	framework for modelling
0.3449820607	components analysis
0.3449752700	non gaussian noise
0.3449244770	models in high
0.3448556641	class of distributions
0.3448474025	f _n
0.3447957746	results illustrate
0.3447613522	compared to existing
0.3447387176	provided to illustrate
0.3446308883	there exist
0.3446036140	not necessarily
0.3445006826	index estimator
0.3444869235	number of outliers
0.3444308783	two step
0.3441643323	distance estimation
0.3440787761	noisy case
0.3436738019	without imposing
0.3435681848	divided into
0.3434926267	central limit theorem for
0.3434469800	\ cdots
0.3431106637	\ subseteq
0.3430205135	errors in variables model
0.3430148809	general multivariate
0.3429134933	existing test
0.3428315457	variety of fields
0.3426714325	a real data set
0.3426082385	right truncated
0.3423873414	limited number
0.3423482365	regularized empirical
0.3422476901	problem parameters
0.3421379866	optimal statistical
0.3421229279	random linear
0.3420360419	decomposed into
0.3420340282	takes advantage of
0.3418803004	studies and real data
0.3418303886	insight into
0.3417773209	classes of functions
0.3417418849	obtain exact
0.3416990700	probability bounds
0.3415325054	number of nodes
0.3410083311	ratio tests
0.3409622553	\ texttt
0.3409187160	time series forecasting
0.3408540924	range dependent time series
0.3407818045	closed form expressions for
0.3407591478	linear state
0.3406228343	by efron et al
0.3406062245	error process
0.3404376040	classical nonparametric
0.3402708300	assumption of independence
0.3402638875	error estimation
0.3400469096	non negligible
0.3399362654	moderate sample
0.3398885373	problem of computing
0.3397730763	conditional mean
0.3396821027	driven models
0.3396344355	^ \ dagger
0.3394660522	theoretic lower bound
0.3394588526	art algorithms
0.3393797946	erd \ h o s r
0.3392948908	optimal number
0.3392399951	original model
0.3390627852	o lder classes
0.3386929064	priori information
0.3385059820	present article
0.3384416322	estimation and variable
0.3384051033	computational lower
0.3382219245	commonly used
0.3382016159	density level
0.3381816721	set of candidate
0.3380210279	illustrated by simulation
0.3379707359	\ to0
0.3379354034	projection onto
0.3377942486	prove strong
0.3377747766	bivariate case
0.3376721423	information theoretic lower
0.3375846471	convex risk
0.3375519868	nearly linear time
0.3374803342	universal constant
0.3374416322	limit of large
0.3374416322	testing in high
0.3374374080	under weak assumptions
0.3374169544	data structure
0.3373861036	widely used
0.3373827705	stochastic multi
0.3373495379	number of vertices
0.3372552589	local empirical
0.3372282561	continuous time process
0.3368071218	wide range of
0.3367696685	rate estimation
0.3366763506	two sample
0.3365444435	mass function
0.3364046701	well suited
0.3363850934	$ \ rho_ 12
0.3363337253	one step
0.3363175825	\ rho
0.3362579294	robust version
0.3362343653	\ circ
0.3361348904	classes of distributions
0.3360898335	nearly unstable
0.3360391993	special class
0.3360357120	simultaneous confidence bands for
0.3359038043	presented to demonstrate
0.3358174951	conducted to illustrate
0.3358116834	restricted strong
0.3357937819	hochberg procedure
0.3357344866	n ^ 1
0.3356868944	\ quad
0.3355680589	order cone
0.3354872780	^ 2
0.3354685770	derive non asymptotic
0.3354050043	dynamical system
0.3353438774	grows to infinity
0.3352526449	\ theta_n
0.3352176546	comprehensive simulation
0.3352053330	\ stackrel
0.3351642054	\ otimes
0.3350083651	y_ n
0.3349121883	nonparametric mixture
0.3347937265	design setting
0.3347595514	chain monte carlo methods
0.3346775967	d optimal designs
0.3345795486	resulting confidence
0.3345786017	conditional average
0.3345325285	suitable regularity
0.3345091961	study asymptotic properties
0.3344270259	integrated empirical
0.3344263396	provide empirical
0.3344238997	noise condition
0.3343887432	\ qquad
0.3343573284	normalized random
0.3342308539	well defined
0.3342205091	\ scriptscriptstyle
0.3342046793	\ lambda
0.3341407070	multiple change
0.3340979812	general asymptotic
0.3340556671	data model
0.3336134543	wider class of
0.3336063280	global markov
0.3335433893	set up
0.3334210283	\ wedge
0.3333943487	larger than
0.3333390756	arbitrary number
0.3331894286	\ pi_0
0.3331642054	\ beta_
0.3331017467	van de
0.3330272571	beta copula
0.3329245195	\ leq1
0.3328990370	dimensional distributions
0.3328733314	symmetric positive
0.3327526656	sum_ j
0.3326859290	\ ldots
0.3325961843	normality result
0.3325494648	one dimensional
0.3325270004	application to real data
0.3323618893	generalized extreme
0.3321317984	number of change points
0.3321003845	linear observations
0.3320407673	m estimators
0.3319646023	empirical analysis
0.3318514945	frequency sampling
0.3318168384	discriminate between
0.3318015365	real data example
0.3317607936	k means
0.3316859290	\ cite
0.3315788591	continuous case
0.3315778427	time inhomogeneous
0.3315330060	almost sure
0.3314910190	number of groups
0.3313489724	post model
0.3313287159	\ psi
0.3312176546	broader class
0.3311495540	finite fourth
0.3310405198	algorithm proposed
0.3306731346	kullback leibler divergence between
0.3306726583	dimensional statistics
0.3305930450	function based
0.3305661898	abrupt changes
0.3305027205	bayesian point
0.3304923301	fundamental problem
0.3304860188	range of besov
0.3304205239	rank matrix estimation
0.3302891385	\ sigma_n
0.3302726052	number of signals
0.3302458001	step estimator
0.3302430899	passing algorithms
0.3302125577	posterior measure
0.3297819805	probability functions
0.3297753131	samples generated
0.3295073567	testing for high dimensional
0.3294493449	multivariate statistical
0.3293235395	high degree
0.3292508121	\ biggr
0.3292043766	polynomial time
0.3291484506	\ eta
0.3290485091	finitely many
0.3289689938	\ nu
0.3289163479	\ mu
0.3287367357	mar \ v
0.3286915442	estimation procedure based
0.3285244041	non asymptotic concentration
0.3284245195	\ geq2
0.3283231997	insights into
0.3282684796	square distribution
0.3282286802	\ le1
0.3282168678	non gaussianity
0.3281371084	construct confidence
0.3281105365	with high probability
0.3280534352	two dimensional
0.3280283866	this article presents
0.3280201119	simple to implement
0.3279867476	true signal
0.3278043795	adaptive kernel
0.3277550376	frequency asymptotics
0.3276853205	optimal algorithm
0.3275128194	error models
0.3274913027	risk functional
0.3274532406	analysis of contingency
0.3274408159	sparsity oracle
0.3273737533	monte carlo markov
0.3272796722	\ lesssim
0.3272204709	\ vartheta
0.3271844444	converges weakly to
0.3271404224	\ omega
0.3270906300	symmetric random
0.3269887000	_ 1
0.3268896753	without relying
0.3267009583	+ 1
0.3266963702	number of parameters
0.3266182547	non iid
0.3266154740	technique for estimating
0.3264437214	near optimality
0.3259908160	\ vert
0.3257900249	dimensional nuisance
0.3256020610	worse than
0.3255947660	rank one
0.3255910375	tailed errors
0.3255226899	\ geq1
0.3254847776	\ rm
0.3254088237	multivariate central limit
0.3250902766	over parameterized
0.3250491232	does not require
0.3248813952	optimal up to logarithmic factors
0.3248451852	\ neq
0.3247474446	approximation method
0.3247182986	ordinary least squares estimator
0.3247099127	\ ensuremath
0.3245931108	fr \
0.3245721721	training dataset
0.3244384744	\ pi_
0.3244264216	regression approach
0.3244176032	\ vee
0.3243177081	^ 4
0.3243020897	simple sufficient
0.3237466092	general theorem
0.3237167436	the optimal minimax rate
0.3236886459	risk estimate
0.3235726406	\ sigma
0.3235270424	penalized least
0.3234824828	two stage procedure
0.3234259988	provide simulation
0.3234176032	\ biggl
0.3234060644	optimal convergence
0.3233343456	\ kappa
0.3231252962	life data
0.3228788622	simple algorithm
0.3225412334	\ mathsf
0.3224617265	identically distributed data
0.3223634159	dependence functions
0.3223219731	study minimax
0.3222880834	based on minimizing
0.3222514764	step up
0.3220501445	\ ll
0.3220314874	paper makes
0.3219789549	relations between
0.3218917627	high dimensional asymptotic
0.3218330980	\ rangle
0.3218280081	binary hypothesis
0.3217027819	optimal asymptotic
0.3216678351	estimation properties
0.3216496401	probability ratio
0.3214847493	differential equation driven by
0.3214795662	\ delta_n
0.3214573564	matching upper
0.3213715110	learning applications
0.3211761885	gaussian observations
0.3211503029	asymptotic bounds
0.3211342631	csisz \
0.3207940251	process models
0.3207717435	presence of outliers
0.3207352060	obtain consistent
0.3204817839	\ xi
0.3201485840	functional central limit theorem for
0.3198909010	\ bigl
0.3197697253	proofs rely on
0.3194981517	in high dimensions
0.3194770524	framework for studying
0.3194555967	dx_t =
0.3194449694	framework for analyzing
0.3192168503	number of components
0.3192031218	great deal of
0.3190572516	\ longrightarrow
0.3190545996	nonparametric maximum
0.3190293540	greater than
0.3188330980	\ bigr
0.3186329378	\ pi
0.3185640043	mean excess
0.3185221565	upper bounds on
0.3184264113	d 1
0.3182318317	function estimator
0.3181604759	similar result
0.3180621946	slower than
0.3180582125	matrix regression
0.3179437096	= 0
0.3178620252	mean squared errors
0.3176024827	data distribution
0.3175960520	large scale multiple
0.3175536694	method to construct
0.3173866168	a wide range
0.3172589832	\ mu_n
0.3170703026	service time
0.3165943295	^ 6
0.3165231435	\ xi_
0.3163637378	consistency of maximum likelihood
0.3161678598	time dependent covariates
0.3159384744	\ mapsto
0.3159155686	paper derives
0.3158182659	varying parameters
0.3157915193	problem of selecting
0.3157447427	random probability
0.3155631024	linear dynamical
0.3154997220	local likelihood
0.3154817839	\ sim
0.3154675066	\ textbf
0.3153973612	non asymptotic upper bounds
0.3152914313	run variance
0.3152807201	under suitable conditions
0.3149911779	process mixtures
0.3148746187	time periods
0.3148700818	popularly used
0.3147814982	data illustrate
0.3146930308	isotropic positive
0.3146497145	true underlying
0.3145358619	rank 1
0.3145313615	orthogonal matching
0.3141198221	consistent variable
0.3140810518	prove upper bounds
0.3140672228	measure of dependence
0.3140305006	means estimator
0.3140001822	parametric density
0.3139988756	\ lambda_n
0.3139896134	interplay between
0.3139321436	number of particles
0.3138675407	optimal sample
0.3138420293	prior based
0.3138085339	multivariate function
0.3137855001	minimax optimal rate of convergence
0.3136702446	space time
0.3135536962	tailed noise
0.3134917846	^ \ ast
0.3133466498	time horizon
0.3131664765	\ operatorname
0.3131521048	m estimation
0.3131454644	\ tau
0.3130820272	mat \
0.3129834040	shed light
0.3129432347	= \ arg
0.3126816734	series data
0.3125982427	\ varepsilon_i
0.3125668489	large values
0.3124584832	two component
0.3123612126	studies confirm
0.3123150093	\ epsilon
0.3123110000	a small simulation study
0.3122860543	based framework
0.3121708286	faster than
0.3120530089	order to improve
0.3119029930	critical value
0.3118423217	tusn \
0.3117696464	\ emph
0.3117558444	simple method
0.3117374555	nonparametric method
0.3117106757	\ leq
0.3114533569	spectral statistics
0.3113699263	art methods
0.3113291229	\ bf
0.3112344259	\ tilde
0.3110961151	occupation time
0.3110483427	\ delta
0.3110386235	as special cases
0.3109860862	optimal posterior
0.3109472279	order efficiency
0.3108110973	variables regression
0.3107910274	frequentist coverage of adaptive
0.3106714927	based on high frequency
0.3105842532	based statistics
0.3104792158	matrix with independent
0.3103700762	bayes approach
0.3100818469	a priori knowledge
0.3098247645	erd \
0.3097737283	provided to support
0.3097607804	\ langle
0.3096136912	local convergence
0.3094858846	non parametrically
0.3094676377	compared with existing
0.3092280956	\ varphi
0.3092156553	score estimator
0.3092061122	sampling problems
0.3091795268	parameters estimation
0.3091499201	improve upon
0.3090775883	mean integrated squared
0.3088163587	carlo algorithms
0.3088059905	explicit upper
0.3087129711	nonparametric statistical
0.3087110330	bayesian optimal
0.3086670144	cram \
0.3086126679	\ sigma_
0.3085578176	non adaptive
0.3084673344	\ delta_
0.3084523410	general markov
0.3083456341	_ i = 1
0.3083069076	time dependent
0.3081966374	\ theta_t
0.3081039176	\ lambda_
0.3079049835	under mild regularity conditions
0.3078972039	linear combinations of
0.3078579969	dependent covariates
0.3077607804	\ mbox
0.3076689494	dimensional linear model
0.3075292640	non regular
0.3074546728	bayesian information
0.3071464060	\ infty
0.3071127929	generalized functional
0.3070403137	applications in machine
0.3069709298	norm regularized
0.3068533129	\ theta
0.3067353418	multivariate central
0.3066750869	world applications
0.3065047701	mixture of normal
0.3064499939	\ psi_n
0.3064345723	more generally
0.3063203912	number of covariates
0.3062762947	convergence in probability
0.3061913108	asymptotic mixed
0.3061596893	non parametric tests
0.3061258309	model parameter
0.3060839245	important application
0.3060373607	algorithm for solving
0.3059932742	\ textit
0.3059408555	\ em
0.3057607804	\ overline
0.3056712176	convergence of moments
0.3056150241	nonparametric estimation of
0.3054476413	matrices with independent
0.3052866677	establish conditions
0.3052060401	problem of constructing
0.3050108162	\ ell
0.3049682818	m estimates
0.3047973248	bit matrix
0.3046705118	per iteration
0.3046276333	framework for modeling
0.3046027430	convergence in distribution
0.3045834249	minimax convergence
0.3044197256	more importantly
0.3040730223	\ ln
0.3040520641	method based
0.3038612566	\ theta_
0.3038591820	sharp upper
0.3037924101	range of applications
0.3036542388	smaller than
0.3035527288	\ int_
0.3035168325	increasing number
0.3034671885	aims at
0.3034158691	learning approach
0.3033756572	effects models
0.3033725513	while retaining
0.3033631074	particular emphasis
0.3033428683	governed by
0.3032902451	data arising
0.3032888758	echet mean
0.3032846664	third and fourth
0.3031790085	study asymptotic
0.3029308556	simultaneous variable selection
0.3026802430	tree estimation
0.3025732418	time scale
0.3024817826	moments estimator
0.3024586753	sample situations
0.3024234895	time series modeling
0.3023691730	weak regularity
0.3021837947	high dimensional model
0.3019916174	estimators obtained
0.3018474854	exact confidence
0.3016651482	for real normed
0.3015653844	important class
0.3014891701	poincar \
0.3013620258	asymptotic upper bounds
0.3009612916	weaker assumptions than
0.3009022451	statistical results
0.3006694995	methods based
0.3005073158	building upon
0.3004507782	variance unbiased
0.3003985304	dependent functional
0.3002150621	a_ n
0.3001983733	standard regularity
0.3000850049	local limit
0.3000017551	test based
0.2998577159	\ geq0
0.2996489884	unknown number
0.2993699589	important special
0.2992714004	problem of finding
0.2992153738	third order
0.2990755218	^ n_
0.2989759262	constructed based
0.2989722105	converge in distribution
0.2989021930	\ xi_n
0.2988470487	full rank
0.2987656815	study illustrates
0.2986169257	\ geq
0.2985969256	measures of dependence
0.2985337130	independent copies of
0.2983216363	\ sf
0.2981817857	dt +
0.2980160984	recent result
0.2979872135	optimal nonparametric
0.2978167671	in high dimensional settings
0.2976868385	t \ ge0
0.2975729820	\ varepsilon
0.2975159415	p 1
0.2974493326	sample test
0.2973679610	spanned by
0.2973059723	waiting time
0.2971946306	consistent estimate
0.2971911492	schr \
0.2969806767	class of functionals
0.2969762522	n ^ 2 5
0.2968093140	temporal data
0.2966615092	\ phi
0.2961857934	x_ t
0.2961320463	performs well
0.2958914799	\ frac
0.2956919209	sparse logistic
0.2953400830	data distributions
0.2952849778	time varying coefficients
0.2951085555	bounded random
0.2948751111	conditional growth
0.2945652339	\ rightarrow \ infty
0.2941774496	wide class
0.2941615004	time homogeneous
0.2940746913	\ epsilon ^ 2
0.2940488127	more sophisticated
0.2938782993	problem in statistics
0.2937735646	closed form formula for
0.2936625748	an important tool
0.2936605791	non central limit theorems
0.2936523911	under mild regularity
0.2936386559	total variation distance between
0.2933434450	near linear time
0.2932956279	number of factors
0.2930604820	\ mathrm
0.2927533242	estimators defined
0.2926684477	previous work
0.2926491163	non asymptotic bounds
0.2926418243	illustrated through
0.2926374953	relationship between
0.2925313545	based on continuous time observations
0.2924476619	approach to construct
0.2923526659	order optimal
0.2923107772	second order statistics
0.2923085947	non vanishing
0.2923024619	problem of detecting
0.2922948448	standard linear
0.2922813288	e values
0.2921990633	\ text
0.2921664284	\ bolds
0.2921131835	paper deals with
0.2920496715	non null
0.2920287512	\ limits_
0.2919553174	rate control
0.2918343456	\ widehat
0.2917408377	bayesian quantile
0.2916994462	a separable hilbert space
0.2916846970	^ \ star
0.2916690090	\ le
0.2916531336	squares estimate
0.2913953478	l moments
0.2913926473	event data
0.2913088683	\ varrho
0.2912175467	gr \
0.2911597333	m 1
0.2911385161	wishart model
0.2908418243	relationships between
0.2908380812	birg \
0.2907212522	2s +
0.2907156158	model framework
0.2905958576	applied to obtain
0.2904176761	skew t
0.2903280119	dimensional inference
0.2902563189	non stationary processes
0.2900176349	viewed as
0.2898133490	carlo test
0.2897570618	thorough numerical
0.2897222451	obtain results
0.2895897672	dimensional regime
0.2894603136	design regression
0.2894255954	general state
0.2893901407	\ mathit
0.2893629708	+ \ epsilon
0.2893601564	set of observations
0.2893414172	finite sample properties of
0.2893391479	^ 1 2
0.2892489204	\ sqrt
0.2891949870	this paper addresses
0.2891867092	\ mu_i
0.2891750816	noise limit
0.2891340140	illustrative example
0.2889146443	an open question
0.2889021930	\ propto
0.2888657356	establish non asymptotic
0.2886942386	high dimensional variable
0.2886277137	without requiring
0.2883852707	part ii
0.2882750678	non negative matrix
0.2882347426	p_ x
0.2882299442	stemming from
0.2881124937	number of terms
0.2880768891	locally optimal
0.2880566545	average number
0.2880431501	infinitely many
0.2879530930	this article proposes
0.2879525076	attention in recent
0.2878104416	nonparametric random
0.2877261800	upper bound on
0.2877153088	suffer from
0.2876608630	go beyond
0.2876022162	copula process
0.2875716238	bayesian linear
0.2874947607	problem of identifying
0.2874561568	simultaneous variable
0.2872693613	very mild conditions
0.2872504582	\ mu_
0.2868991972	experiments illustrate
0.2868916658	detailed analysis
0.2867343126	zero sum
0.2866244525	\ boldsymbol
0.2864832929	few years
0.2864656747	general convex
0.2863760819	the maximum likelihood estimator
0.2862360384	\ prod_
0.2860139417	distribution based
0.2857233068	distance estimator
0.2857175869	process indexed
0.2855952729	order to construct
0.2855867547	better understanding
0.2854758808	nystr \
0.2854758808	gin \
0.2853730573	data sampled
0.2853477610	caused by
0.2853365876	non stationarity
0.2850882439	variety of settings
0.2849707004	plug in approach
0.2847960535	expressed in terms
0.2844672406	non symmetric
0.2843635480	a central limit theorem
0.2843456979	\ eps
0.2843404018	mean estimation
0.2841999294	study demonstrates
0.2841412311	proposed estimation
0.2841371091	bias and mean square
0.2840495350	regarded as
0.2838313094	= \ sum_ i = 1
0.2838227377	probability of false
0.2837375025	restricted parameter
0.2837176275	testing methods
0.2833375834	squares approach
0.2833372175	the present paper
0.2832231128	dimensional probability
0.2831943741	variance covariance
0.2830145659	$ \ mathbb l _2
0.2829688144	uniform central
0.2828524150	\ hat
0.2825617785	broader class of
0.2825142844	alternative method
0.2822993186	this paper explores
0.2822875331	posterior contraction rates for
0.2822801875	selection in high dimensional
0.2821577063	field theory
0.2821550171	parameter function
0.2821542863	sharp oracle inequalities for
0.2821309808	valid confidence intervals for
0.2820041256	no matter
0.2818449680	above mentioned
0.2818250814	this paper discusses
0.2816926505	sufficient conditions for
0.2816187311	in total variation distance
0.2816054015	1 \ leq i \ leq
0.2814586189	= \ int_
0.2814319332	dimensional data analysis
0.2812387830	scale data
0.2810977838	provide non asymptotic
0.2809987602	rank estimation
0.2809930326	mean shift
0.2806964199	algorithm to estimate
0.2804883638	\ rightarrow
0.2804693993	dimensional linear regression
0.2801481733	a closed form expression
0.2799703957	connection between
0.2799418247	marginal log
0.2798012396	\ alpha
0.2797987524	an abrupt change
0.2797804283	non smooth
0.2797358981	random model
0.2795914839	increases to infinity
0.2794508443	\ left
0.2792785617	the null hypothesis
0.2792605691	wide range of applications
0.2792399455	seminal work
0.2792150330	nonparametric two sample
0.2791625001	parametric statistics
0.2789767750	rank structure
0.2789509932	non compact
0.2787498938	indexed by
0.2786936601	$ \ mathbb l _p
0.2785103726	aimed at
0.2784774098	\ widetilde
0.2784670204	test statistic based
0.2780676725	= 1
0.2780341612	projections onto
0.2778689293	\ sigma ^ 2
0.2778107654	construct confidence intervals for
0.2776939828	order moment
0.2776417391	\ lambda_2
0.2774768574	valid statistical
0.2774342218	kernel mean
0.2774139030	fit tests
0.2773631873	memory stochastic
0.2772864810	$ th order
0.2771782882	non centrality
0.2771471517	problem of testing
0.2771386129	test for high dimensional
0.2768508613	control studies
0.2767609059	two level
0.2767591927	time delay
0.2767357441	\ cal
0.2766451771	sub sampling
0.2765938759	\ big
0.2765791668	efficient procedure
0.2765480946	general models
0.2764699720	information about
0.2764672756	a log concave density
0.2764578725	1 \ epsilon
0.2764065260	measures defined
0.2763042188	time and space
0.2762996926	while keeping
0.2760096964	performs better than
0.2760075180	provide consistent
0.2759467692	large enough
0.2758675586	periodic mean
0.2754946061	mean vector
0.2754768574	correlated random
0.2754310820	procedures for testing
0.2754208831	= \ int
0.2751568044	applications ranging from
0.2751192685	estimation of conditional
0.2747992027	two step estimation
0.2747478132	extended empirical
0.2746895507	deviation results
0.2745471725	own right
0.2743963573	necessary and sufficient
0.2741627292	system identification
0.2741227333	algorithm for estimating
0.2740428394	\ min_
0.2740387493	in recent years
0.2740218412	motivated by
0.2740052129	dimensional random
0.2739996720	closely related to
0.2739219890	number of variables
0.2738249109	and type ii errors
0.2737750555	concentration inequalities for
0.2737537099	the last two decades
0.2736688144	simple proof
0.2736536530	an asymptotic expansion
0.2735526114	coming from
0.2735497170	dealing with
0.2734262342	plus noise
0.2731824374	procedure to estimate
0.2731564499	sum process
0.2729793572	gaussian markov
0.2729588062	_ t \ in \ mathbb
0.2728638463	asymptotic properties of
0.2725613230	procedure based
0.2722339729	\ boldsymbol x ^ \ rm
0.2720940591	up to logarithmic factors
0.2720407133	upper bounded by
0.2719834358	nonlinear inverse
0.2718073109	limit theorems for
0.2717782390	\ theta_1
0.2715040961	sub optimal
0.2714457110	per unit
0.2713985018	a simulation study shows
0.2712980997	\ mathrm opt
0.2712614398	three dimensional
0.2712221101	family of tests
0.2710861318	process model
0.2707945285	common approach
0.2704951576	davies and u
0.2704053224	class of functions
0.2703792429	this article
0.2703714208	\ sum_
0.2703647757	generalized version
0.2703321542	type 1
0.2702223315	number of examples
0.2701462024	\ mathcal
0.2700732649	set of variables
0.2699772136	replaced by
0.2698842622	non zero components
0.2695641548	taking values in
0.2694228695	frequently used
0.2691984747	under consideration
0.2691426728	well chosen
0.2691376822	formulated in terms
0.2690960758	this paper studies
0.2688831538	\ varepsilon ^ 2
0.2688494545	^ \ otimes
0.2685600602	iid case
0.2684093781	this short note
0.2683288252	\ exp
0.2682913683	via monte carlo
0.2682883818	an iterative algorithm
0.2682564473	\ mathbf
0.2682562166	perform well
0.2682435164	an important issue
0.2681641979	sequence of observations
0.2681374676	relatively small number
0.2681212594	this note
0.2678418731	second order stationary
0.2678362582	number of points
0.2677356701	m estimator
0.2676876817	class of problems
0.2676205882	_ n
0.2675259819	not necessarily identically
0.2675084332	an open problem
0.2674858415	non uniform
0.2674707546	a simulation study
0.2674651883	sz \
0.2673689610	mean difference
0.2673267227	chi ^ 2
0.2673018724	motivated by recent
0.2672651728	more accurate
0.2671578768	finite time
0.2670837283	approximate maximum
0.2670280135	bayesian multiple
0.2669917859	second stage
0.2668355369	sure screening
0.2668265890	y_ t
0.2667055057	does not hold
0.2666117849	sampling based
0.2665179530	so far
0.2662609611	a priori
0.2662270219	a_ p
0.2660439474	much simpler
0.2659264125	provide strong
0.2658009114	dependencies between
0.2657521940	large class of models
0.2656938348	comment on article by
0.2656842941	sparse parameter
0.2654560704	well specified
0.2653148076	arising from
0.2653045851	vector based
0.2652979923	the false discovery rate
0.2652671587	inspired by
0.2651874641	\ ell_2
0.2651655514	correspondence between
0.2650921443	estimator proposed
0.2650612491	ill posed problems
0.2650204042	tests for testing
0.2649775025	linear regression model with
0.2649296789	f divergences
0.2648147864	\ pmb
0.2647122578	limiting behavior of
0.2646110582	rely on
0.2645855147	under model misspecification
0.2644884733	a high dimensional setting
0.2644803216	compared to previous
0.2644619717	a real data application
0.2644399473	observed process
0.2643083775	single parameter
0.2642762806	0,1 ^ 2
0.2642609331	time instants
0.2642168126	mean and variance
0.2639927673	\ beta
0.2639760607	deals with
0.2639120705	interpreted as
0.2638538513	standard approach
0.2638436974	plug in
0.2632943746	influenced by
0.2632613365	\ to \ infty
0.2631642469	non uniqueness
0.2631460388	non standard
0.2631415958	over besov balls
0.2631150017	number of tests
0.2630941794	\ gamma
0.2630710889	test for testing
0.2630059214	precise characterization of
0.2629250425	$ \ ell_0
0.2628575282	among others
0.2628099767	lower bounds for
0.2626469781	n 1
0.2626254273	this article considers
0.2626198291	student t
0.2626137646	matrix based
0.2625958138	more powerful
0.2625109785	works well
0.2624805504	up to constant factors
0.2624524164	robust statistical
0.2623979770	broad class of
0.2623436096	variety of applications
0.2622895064	a logarithmic factor
0.2622531408	erd \ h o s
0.2621143773	based on thresholding
0.2620857880	^ \ alpha
0.2620751375	without knowing
0.2618969354	tend to
0.2618917712	one hand
0.2617916472	sample mean
0.2617395121	on line
0.2616995328	\ pm
0.2616592235	confidence intervals for
0.2613483802	\ ell_ \ infty
0.2612717403	| rho
0.2612443992	data sample
0.2612274159	popular class
0.2611936601	1 \ le i \ le
0.2611145200	test statistics based
0.2610573632	robust with respect
0.2610173062	\ | _2 ^ 2
0.2610133594	bounded away from zero
0.2609741389	\ ge
0.2609006401	large number of
0.2607623230	\ begin align *
0.2607319570	$ n ^ 1
0.2606908099	left and right
0.2604852514	stage estimator
0.2604556572	non asymptotic oracle inequalities
0.2603267891	drawn from
0.2602379895	population mean
0.2601811002	second order stationarity
0.2600947717	non local
0.2600522992	asymptotic mean squared
0.2599612456	\ sup_
0.2599534012	accompanied by
0.2599183517	large sample behavior of
0.2598118007	long range dependent time
0.2597009107	well studied
0.2596648217	depend on
0.2596525269	observed at high
0.2596484469	\ nabla
0.2595720132	the maximum likelihood estimate
0.2595599794	maximum mean
0.2594182072	certain regularity conditions
0.2593996429	bbb r
0.2592493751	ask whether
0.2592343152	n ^ 2
0.2590544631	well established
0.2590175736	properties compared
0.2589948899	conditions for consistency
0.2588461342	sum of squared
0.2587820697	testing against
0.2587790254	framework to study
0.2584488281	\ xi_t
0.2584466003	two real data examples
0.2583890112	n ^ 3
0.2583121034	converge weakly to
0.2582822545	two factor
0.2581199147	\ lambda_i
0.2581092910	differences between
0.2580632609	risk bounds for
0.2580266179	\ xi_i
0.2579415076	stochastic differential equations with
0.2578778816	nearly minimax
0.2578294898	connections between
0.2578043993	general metric
0.2577017391	zero mean
0.2576942511	bayesian generalization
0.2575957405	bounded from below
0.2575330861	depend upon
0.2575273109	alpha = 1
0.2573816060	1 \ alpha
0.2571969121	an information theoretic
0.2570483001	much wider
0.2570176028	noisy high
0.2568978791	even though
0.2568714483	+ \ varepsilon
0.2568513081	= \ lim_
0.2568482359	illustrated by numerical
0.2566704658	equipped with
0.2565995358	true function
0.2565244674	\ psi_
0.2564134248	mean variance
0.2562669172	weaker than
0.2561894905	space of probability measures
0.2561069353	the sample size increases
0.2560852467	by introducing
0.2559878922	two distinct
0.2557171007	obtain optimal
0.2556124594	t \ geq0
0.2555908636	model defined
0.2555447939	some mild conditions
0.2554019196	belong to
0.2553723215	non zero
0.2553283096	approach to estimate
0.2551376656	first exit
0.2551199291	construct adaptive
0.2549601779	\ ^ o semimartingale
0.2548777249	relies on
0.2547956162	r rao
0.2546723677	general algorithm
0.2545347061	hinges on
0.2544583781	more complicated
0.2542496502	good performances
0.2540517352	general class of
0.2539279596	x_ i
0.2538589145	serve as
0.2537162974	finite sample performance of
0.2535140201	sample distribution
0.2534585749	pure jump l \
0.2533255367	maximum likelihood estimation of
0.2532855472	two real data sets
0.2531757145	belongs to
0.2530695836	depending on
0.2530178310	detailed analysis of
0.2530001808	one parameter
0.2529846663	dependent gaussian
0.2527732685	a similar result
0.2525779721	differs from
0.2524984592	non stationary time series
0.2523589226	model with unknown
0.2523079390	the high dimensional setting
0.2518812439	framework for testing
0.2518252784	doing so
0.2516993538	explicit expressions for
0.2516651489	procedure proposed
0.2515905244	robust alternative
0.2515652036	analysis of high dimensional
0.2515523508	the true regression function
0.2514995358	function defined
0.2514929874	the art methods
0.2514907335	numerical properties
0.2513368363	sum_ i = 1 ^ n
0.2512881958	\ inf_
0.2511590215	priori knowledge of
0.2510241824	common mean
0.2508727247	process theory
0.2507842435	\ frac12
0.2507772562	provide convergence
0.2507726638	u processes
0.2507702199	explicit error
0.2507702199	large relative
0.2507561607	\ mathbb
0.2506883556	linear statistical
0.2506348564	expected number of
0.2505578692	parametric statistical
0.2504984625	general framework for
0.2504576451	pertain to
0.2503530669	a fully data driven
0.2502911934	\ | _
0.2502750966	more broadly
0.2502725597	wasserstein distance between
0.2500890508	adaptive estimation of
0.2500479244	class of algorithms
0.2500290073	asymptotic lower
0.2500165125	estimation of high dimensional
0.2498748341	mean and covariance
0.2498420206	coincides with
0.2498260031	p 2
0.2496516775	degenerate u
0.2495891000	compromise between
0.2495440751	optimal designs for
0.2495291082	a stochastic differential equation
0.2494501701	z_ i
0.2493979614	departures from
0.2492768367	and van der vaart
0.2492506450	at discrete times
0.2492366308	represented by
0.2491893719	confidence bands for
0.2491219639	subject to random
0.2491043011	stems from
0.2490999058	this paper
0.2489717671	gives rise
0.2488699263	a finite population
0.2488392911	asymptotic statistical
0.2487623230	\ end align *
0.2486539856	to noise ratio
0.2485685264	this paper examines
0.2485049405	establish rates
0.2484882522	much broader
0.2484778729	confidence regions for
0.2484003406	error of order
0.2483554490	same order of magnitude
0.2483516071	functions defined
0.2483323705	time domain
0.2482604034	subjected to
0.2481809395	a special case
0.2480062135	scale models
0.2480043997	serves as
0.2479525595	component regression
0.2479510707	mixing time
0.2479490734	thought of as
0.2479151463	_ *
0.2478910061	the sample size
0.2478345035	earlier work
0.2478323786	sample distributions
0.2476096077	small values
0.2475711504	without assuming
0.2475282224	selection techniques
0.2475177101	for low rank matrix
0.2474675588	first order autoregressive
0.2472688834	an unbiased estimate
0.2472258459	| _0
0.2471670108	no change
0.2470956883	number of times
0.2470771835	optimal rates for
0.2469299319	order to obtain
0.2468364300	t 1
0.2467776433	\ hat \ sigma
0.2466744674	\ rightarrow0
0.2464999163	a directed acyclic graph
0.2464839251	driven by
0.2462733289	linear time series
0.2462659297	recent work
0.2460913331	simultaneous variable selection and
0.2460317635	devoted to
0.2459101375	d dimensional
0.2458575495	\ | ^ 2
0.2458510592	lower bounds on
0.2454857044	asymptotically equivalent to
0.2454822194	popular method
0.2454364540	fractional brownian motion with
0.2454112530	three parameter
0.2453470505	new tests
0.2452975713	\ bx
0.2450557888	do not require
0.2449965392	+ 2
0.2448622198	confidence intervals based
0.2448491535	characterized by
0.2447707295	relation between
0.2446701306	aiming at
0.2445649629	asymptotic normality of
0.2442796890	focused on
0.2441054557	$ \ ell_
0.2440705484	akin to
0.2439891697	data applications
0.2437931243	well known
0.2437838720	these two estimators
0.2437620221	\ bar
0.2435926028	space setting
0.2435798482	approach to estimating
0.2434880942	\ sigma ^ 1
0.2434366075	lead to
0.2433906740	confidence sets for
0.2433073611	focuses on
0.2432445373	a posteriori
0.2432121603	mean values
0.2431884942	d optimal
0.2431632930	n + 1
0.2431519961	supported by numerical
0.2431206406	depends on
0.2429617215	more realistic
0.2427839239	lower bound on
0.2425830549	non ergodic
0.2425055834	vector of parameters
0.2424224187	derive rates
0.2423721716	time average
0.2422166822	corresponds to
0.2420545752	passage time
0.2419211083	bayes method
0.2417091250	| t |
0.2416940766	\ _x
0.2414720033	subset \ mathbb r ^ d
0.2414705484	attempting to
0.2414087868	based upon
0.2414040944	unknown change
0.2413469621	largest eigenvalue of
0.2412065695	s_n =
0.2411824868	determined by
0.2411744421	construction of confidence
0.2410991068	measure based
0.2410944566	ranging from
0.2410873750	recent advances in
0.2410349293	driven approach
0.2409594201	method of estimation
0.2408999896	t ^ 1
0.2408998609	suffers from
0.2408532912	some theoretical results
0.2408282033	estimated from data
0.2406507594	belonging to
0.2405846084	1 2
0.2404335012	sum_ i = 1 ^
0.2404030699	class of multivariate
0.2403714749	deal with
0.2403088968	running time
0.2401838868	nearly linear
0.2401522573	close to
0.2400399289	non identical
0.2399378411	bayesian inverse problems with
0.2397037117	an important role
0.2395503433	each iteration
0.2395316040	the average run length
0.2394577678	theoretical point
0.2393277089	linear spectral statistics of
0.2392527693	^ *
0.2392356001	$ norm
0.2391834225	p variate
0.2390971308	ev \
0.2390554980	time invariant
0.2390530527	effect estimators
0.2389263471	low sample
0.2389227781	for such data
0.2389156266	\ zeta
0.2389136618	procedure for estimating
0.2388598643	stage least squares
0.2387789091	q function
0.2387065713	focusing on
0.2386939916	implied by
0.2386265991	generated by
0.2385323368	the best achievable
0.2383149090	two sample problem
0.2382793023	this article introduces
0.2382688494	complemented by
0.2382499058	difference between
0.2381847999	$ \ ell_1
0.2380455351	approach for estimating
0.2380384522	limiting distributions of
0.2379958532	regression based
0.2379558077	this paper derives
0.2379329993	while preserving
0.2379195969	and multiple output regression
0.2378493529	tests based on
0.2376586669	moderate deviations for
0.2376354315	processes sampled
0.2375498263	general properties
0.2375388888	relations among
0.2375107493	\ to 0
0.2375037605	squares method
0.2374979247	\ sigma_t
0.2374706806	relatively small
0.2374445157	determine whether
0.2374270001	l ^ 2
0.2373889276	tradeoff between
0.2373791515	based estimates
0.2373674196	u and v
0.2372908822	\ gg
0.2371628597	y | x
0.2370777521	statistics for testing
0.2370432887	sample bounds
0.2370216145	\ ell_1
0.2369423670	set of conditions
0.2367823198	accuracy of estimation
0.2366435968	k 2
0.2366257063	leads to
0.2364777003	general upper
0.2364405371	$ \ ell_p
0.2363643422	geometric mean
0.2361345676	based on
0.2360837420	induced by
0.2360163837	relying on
0.2358867000	high computational
0.2358831290	normal mean
0.2355311128	other related
0.2355008396	$ \ ell_2
0.2354779019	the true density
0.2354035532	learning literature
0.2353828426	over parametrized
0.2353480074	^ \ top
0.2353123280	upper bounds for
0.2350268654	non separable
0.2350228862	supported by
0.2347828833	$ l_1
0.2347125472	in survey sampling
0.2347015822	mean embedding
0.2346537815	inferences about
0.2346344774	f divergence
0.2346007604	point analysis
0.2343141804	develop asymptotic
0.2342086792	method to obtain
0.2340397446	multi way
0.2339834512	method for high dimensional
0.2339723048	consistent estimation of
0.2339706406	focus on
0.2338206400	non centered
0.2337201749	few samples
0.2336508864	1,1 ^ d
0.2335343227	uniform convergence rates for
0.2333760963	and vice versa
0.2333129066	most notably
0.2332912191	\ epsilon_i
0.2332441782	selected estimator
0.2330915284	\ nu_
0.2330872784	first exit time
0.2329580762	\ rho_
0.2329222749	\ ell_0
0.2329094413	\ underline
0.2329077820	tending to
0.2328335752	^ k 1
0.2326384540	many practical applications
0.2324249451	\ mid
0.2323714749	concerned with
0.2323465433	_ j
0.2323014992	$ dimensional
0.2322196358	world data
0.2321008644	learning based
0.2320914814	r type
0.2320847053	tighter than
0.2319996283	the sample covariance matrix
0.2319992206	x_ k
0.2319632409	diverging number of
0.2319018978	for finite sample sizes
0.2318105967	study asymptotic properties of
0.2316956026	selection in regression
0.2316916197	non i.i.d
0.2316157616	advantages over
0.2315399463	| _2 ^ 2
0.2315149885	power against
0.2315083110	an empirical application
0.2314404676	trade off between
0.2314299238	efficient estimation of
0.2313456946	\ log
0.2313372506	an oracle inequality
0.2311045541	distribution supported
0.2309623784	mean square errors
0.2309328102	number of nonzero
0.2307944663	log n
0.2306965346	time series data
0.2306945880	minimax lower bounds for
0.2306777420	time frequency
0.2306664930	algorithms based
0.2305468032	lower bound for
0.2304760325	captured by
0.2304254524	mean absolute
0.2300669659	provide theoretical guarantees for
0.2299890056	this paper describes
0.2299850108	explicit formula for
0.2298738582	the data generating process
0.2298273037	dimensional gaussian
0.2296281516	proof uses
0.2295740304	on riemannian manifolds
0.2295452753	limiting distribution of
0.2295407103	problem of model selection
0.2295000492	estimators for estimating
0.2293985663	= \ frac
0.2292959936	distinguish between
0.2291179033	results establish
0.2290435276	particular attention
0.2289145405	^ \ frac
0.2287884732	goodness of fit tests for
0.2286867468	this paper establishes
0.2286717080	expressed in terms of
0.2286222993	two step procedure
0.2285179911	more general
0.2282176332	partial sums of
0.2281807833	asymptotic behavior of
0.2281788899	\ begin
0.2281630214	the total variation distance
0.2281191622	gaussian stochastic
0.2278923476	sufficient and necessary
0.2278473614	i = 1
0.2278410160	tests based
0.2277707610	adaptive markov
0.2276569167	interactions between
0.2275989967	information theoretic limits of
0.2275519197	rates of estimation
0.2275016834	an upper bound
0.2274937134	original data
0.2273774022	absolute value
0.2271764635	referred to as
0.2271102872	non informative
0.2270981550	illustrated by
0.2270850291	a low rank matrix
0.2270581178	many covariates
0.2270456458	approach based
0.2270437869	set of parameters
0.2270105015	so called `
0.2269209692	iterated logarithm for
0.2268481450	\ begin equation *
0.2267937538	proportion of true
0.2267692699	methods proposed
0.2265991266	max domain of
0.2265403402	minimax lower bound for
0.2264815498	error bounds for
0.2264730815	\ lim_
0.2264246207	e x_
0.2263811272	to construct confidence intervals
0.2263362423	incorporation of
0.2263231606	presence of noise
0.2262550200	correspond to
0.2260652086	asymptotic theory for
0.2260331079	contrast to previous
0.2259908459	an invariance principle
0.2259578913	proposed confidence
0.2259303834	$ th moment
0.2259204380	each node
0.2258134928	$ l ^ 2
0.2257649701	\ beta_0
0.2256859135	regression with unknown
0.2254639074	testing equality of
0.2252544436	weak convergence of
0.2251947427	affected by
0.2251330757	large sample properties of
0.2249181932	non convex optimization
0.2248944468	step approach
0.2247974498	refers to
0.2246166050	\ | _2
0.2245176370	robust to model
0.2245100159	i = 1,2
0.2245077732	non parametric bayesian
0.2244127786	sampling models
0.2244011097	of two random
0.2243149083	an explicit expression
0.2242463633	under certain conditions
0.2242362284	and real data examples
0.2240533075	new central limit theorem
0.2236105986	non convexity
0.2236010032	a heavy tailed distribution
0.2235280669	distance between
0.2234954217	interval 0
0.2233508261	provide sufficient conditions for
0.2231436467	infinity norm
0.2230563045	a convex optimization problem
0.2230002711	| |
0.2228220603	the central limit theorem
0.2226953156	more important than ever
0.2226902212	b ^ h
0.2226847252	mean squared
0.2226764019	least squares algorithm
0.2225110534	^ d
0.2224450480	testing whether
0.2223731069	more flexible
0.2222965030	_ t \ in
0.2222712885	| ^ \ alpha
0.2219629289	\ displaystyle
0.2219142016	l _p
0.2218122073	regression model with
0.2217959853	an explicit form
0.2216960926	this paper concerns
0.2216763697	broad family of
0.2215669751	class model
0.2215568639	least angle
0.2214662641	\ _t
0.2214614924	the true parameter
0.2214564482	\ times
0.2213888891	obtained by
0.2213738894	\ int
0.2213327957	achieved by
0.2211871392	variety of problems
0.2211259015	squared distribution
0.2210007729	each entry
0.2209698557	from random matrix theory
0.2208096971	converges to
0.2207822137	harmonic mean
0.2206948626	adl \
0.2206348757	x | y
0.2200061098	each sensor
0.2199116205	relationships among
0.2198528140	give rise to
0.2197556291	for ergodic diffusion processes
0.2195399244	the conditional quantile function
0.2194990267	fourier transform of
0.2194915032	t \ ge 0
0.2193973270	routinely used
0.2190283205	| b |
0.2189236692	an undirected graph
0.2189049293	classical model
0.2188632432	laplace transform of
0.2188458265	bayesian approach to
0.2187814965	^ t
0.2186591658	access to
0.2185906871	contingency tables with
0.2184463265	approximated by
0.2183813232	general procedure
0.2182456359	^ 0
0.2181216560	perform very well
0.2178573522	resort to
0.2178386149	multiple linear
0.2178244468	spatial random
0.2177865770	minimax estimation of
0.2177713572	\ hat \ theta
0.2176914026	a case study
0.2175699435	rather than
0.2174859403	new insights
0.2174591217	interested in
0.2174394989	proposed to estimate
0.2174370514	very popular
0.2173979039	\ asymp
0.2172185456	\ in \ mathds
0.2171991532	$ l_2
0.2171703404	of such data
0.2171248255	general statistical
0.2170296559	x \ _i
0.2168377217	the general problem
0.2165834217	k nearest
0.2165344251	different kinds
0.2163086592	the long run
0.2162974993	at least
0.2161100498	\ end equation *
0.2161088330	joint estimation of
0.2160891917	= \ sum_
0.2160348222	\ max_
0.2158959313	applied to
0.2158451172	correlations between
0.2158241777	degree of smoothness
0.2157634000	bayesian nonparametric estimation of
0.2156601790	linear parameters
0.2156244708	gamma 0
0.2155851787	less than
0.2155238894	\ ast
0.2154992938	each agent
0.2154744633	class of processes
0.2153198524	positive part
0.2152448108	based on observations
0.2152114498	n ^ 1 \ sum_
0.2152038671	observed through
0.2150902576	$ x_ ij
0.2150351483	\ right
0.2150140307	two groups
0.2149654017	non sparse
0.2148609821	\ in \ mathcal
0.2146084495	defined by
0.2145671360	generalized linear models with
0.2144582796	an infinite dimensional
0.2144124670	most importantly
0.2143674398	the art
0.2142909953	$ dimensional gaussian
0.2142650770	\ boldmath
0.2141070398	class of densities
0.2140418821	previously known
0.2138735400	n ^ \ alpha
0.2137837712	smallest eigenvalues of
0.2137460001	converges to zero
0.2137095019	decide whether
0.2136981482	at hand
0.2135777800	statistical inference based
0.2134776565	\ sqrt \ log
0.2133795282	non monotone
0.2132676960	\ boldsymbol \ theta
0.2131080799	class of loss
0.2129913817	independence of two
0.2129136198	one step estimator
0.2129131474	wide class of
0.2127004547	more specifically
0.2126060864	new perspective
0.2125790555	an unknown
0.2125360170	methodology based
0.2124663960	the true model
0.2123639075	large sample theory for
0.2123609575	two step approach
0.2123391222	non differentiable
0.2122738491	\ ell_p
0.2122513563	provide upper
0.2122408472	$ nn
0.2121547880	endowed with
0.2119387418	proof relies on
0.2117408841	data driven choice of
0.2116081654	a long standing
0.2115988638	scale distributions
0.2115707569	| x_i
0.2115581149	mean vectors
0.2114104189	the false discovery proportion
0.2113473518	a real data analysis
0.2113301538	the univariate case
0.2113116321	regression with random
0.2112659550	the matrix completion problem
0.2109610740	rate for estimating
0.2108682362	widespread use
0.2108591958	two phase
0.2108160539	a single realization
0.2106829967	\ binom
0.2105172489	size goes to infinity
0.2104883820	multiple change points in
0.2104293125	does not exceed
0.2103282132	t test
0.2101139495	l statistics
0.2101049233	^ \ beta
0.2100834316	distances between
0.2096163224	best arm
0.2095943508	maximum likelihood estimators for
0.2095362471	s ^ 2
0.2095240218	a closed form
0.2095034165	one step sparse
0.2094917254	robust against
0.2094881077	asymptotic distribution of
0.2094373199	order to estimate
0.2093125935	non parametric regression
0.2092952762	\ alpha_n
0.2092300971	na \
0.2091961895	sample complexity bounds for
0.2090713148	does not exist
0.2090082393	technique based
0.2089646447	out of sample prediction
0.2088864136	\ in \ mathbb
0.2088819694	determining whether
0.2088588354	compared to
0.2088332395	uniformly over
0.2088060928	$ \ chi ^ 2
0.2088023501	interest rate
0.2087901849	non singular
0.2087869963	much smaller
0.2086858537	oracle inequalities for
0.2086539522	pertaining to
0.2085942777	first kind
0.2085628102	number n of
0.2085027526	a fundamental role
0.2083775014	conditionally independent given
0.2082916573	least squares method
0.2082834024	different ways
0.2082797783	bayesian density
0.2082149976	\ mathbb r ^ d
0.2081495678	\ colon
0.2081097974	comparing two
0.2080421895	right tail
0.2079784329	recovery of sparse
0.2079446477	under mild
0.2077690173	behave like
0.2077031538	change point detection in
0.2075987425	closed form expression for
0.2074829106	propose to estimate
0.2074104323	finite mixtures of
0.2073732889	in addition
0.2073093403	modified version of
0.2072878497	estimation of parameters
0.2072679506	for small sample sizes
0.2071682755	existing ones
0.2071179249	family of estimators
0.2071027739	+ \ infty
0.2070523971	a phase transition
0.2070505691	| \ hat \ beta
0.2070249914	error model
0.2069569876	= 2
0.2068755324	as soon as
0.2068236683	respect to
0.2066634626	range of problems
0.2065571738	series model
0.2065479039	\ xi_1
0.2064843353	second contribution
0.2064351776	time scales
0.2064062927	assumed to
0.2062543635	tight bounds on
0.2060982440	\ rightarrow 0
0.2060711825	subject to
0.2059950235	statistical analysis of
0.2059297148	non parametric estimation
0.2058647642	several examples
0.2058460009	much larger
0.2057808723	p_ i
0.2057015287	new insights into
0.2056262305	sum of independent
0.2055950255	\ lambda ^ 0
0.2055208422	| \ ge
0.2053232973	new techniques
0.2053227808	not require knowledge
0.2052901041	new approaches
0.2052796421	do not
0.2052367812	\ min
0.2052105831	arrive at
0.2051610170	criterion based
0.2051044701	n ^ 4
0.2049922550	within gibbs
0.2049619587	under weak
0.2048586230	notion of
0.2047811068	the gaussian case
0.2046770870	family models
0.2046687783	allowed to
0.2043712510	the long memory parameter
0.2043700280	aims to
0.2043163729	methods to estimate
0.2042816815	supported on
0.2041825942	consists of
0.2041767913	xx ^
0.2041182572	rate data
0.2040981257	| \ mathcal
0.2039810602	\ chi ^ 2
0.2039584768	large class of
0.2039298631	side result
0.2038651129	followed by
0.2037604836	\ mathscr
0.2037257226	the decision maker
0.2037201368	this thesis
0.2037126881	very high dimensional
0.2035827941	m_ n
0.2035528767	\ `
0.2035309691	multiplied by
0.2035276837	series setting
0.2035241782	the empirical copula process
0.2034037311	increasing number of
0.2032955786	upper bound for
0.2032557820	rate of estimation
0.2032430957	one way
0.2032155073	explicit formulas for
0.2032143105	\ mathbb r
0.2031699629	measure of statistical
0.2031173814	^ \ gamma
0.2031134724	t statistic
0.2029881348	\ ell_
0.2029613135	under very general conditions
0.2029590130	conditions for exact
0.2028972341	other hand
0.2028650048	comment on
0.2028180469	variety of examples
0.2027671925	arbitrarily close to
0.2027028561	a simple proof
0.2026957480	confidence sets based on
0.2026526885	sequences of random
0.2026122479	least squares criterion
0.2026116369	much more
0.2025545153	non normalized
0.2025469610	goes to zero
0.2025309806	hidden markov models with
0.2024936032	a numerical study
0.2024199347	estimators based
0.2022550379	new framework
0.2021639911	much larger than
0.2021626396	time reversible
0.2020614913	test proposed
0.2020000697	acting on
0.2019011243	sequence of random
0.2018864841	an exponential family
0.2018458224	robustness against
0.2017943185	rates of posterior
0.2016309775	linear combination of
0.2016137115	detecting changes in
0.2015662662	shown to provide
0.2015207611	3 4
0.2014696639	number of
0.2014262775	not identically distributed
0.2014019715	least squares estimates
0.2012940149	bounded away from
0.2011884870	to detect
0.2011282897	approach relies on
0.2011258921	$ variate
0.2010745215	demonstrated through
0.2009901088	third moment
0.2009642121	a linear regression model
0.2009596673	much weaker
0.2009352286	analysis methods
0.2009126868	converge to
0.2009107344	almost sure convergence
0.2008584959	the familywise
0.2007847703	does not
0.2007460453	non identically
0.2006488158	\ ` es
0.2004970713	the data generating distribution
0.2004760988	model selection using
0.2004589448	converges in probability
0.2003239835	estimation of multivariate
0.2001684575	0 1
0.2001579295	starting from
0.2001317267	related to
0.2001025851	model setting
0.2000707393	true probability
0.2000340921	samples drawn from
0.1999954568	leibler divergence between
0.1999600453	non normal
0.1999544467	consistent model
0.1997824045	stochastic comparisons of
0.1997507900	within cluster
0.1997014913	stochastic regression
0.1996896124	by monte carlo simulations
0.1996091211	full bayesian
0.1995974993	= o
0.1994213904	robust alternative to
0.1993706555	m_n ^
0.1993456979	coordinate system
0.1992721659	this paper shows
0.1992378827	expressed as
0.1992177953	become increasingly
0.1991161547	under local alternatives
0.1990445869	\ begin equation
0.1989961182	nonparametric regression model with
0.1989732121	a powerful tool
0.1988680904	version of
0.1988387350	dependence between
0.1986023758	= n ^ 1
0.1985778186	properties of
0.1984832663	consisting of
0.1984727940	exactly equal
0.1984232093	convergence of empirical
0.1984176735	on simulated data
0.1984061734	non increasing
0.1982983117	problem of choosing
0.1982672427	equations driven by
0.1981851765	statistical inference for
0.1981757236	better than
0.1980636308	density with respect
0.1980012947	finite sample analysis of
0.1979770695	non asymptotic confidence
0.1979164206	leading to
0.1978901919	step towards
0.1977863281	context of high dimensional
0.1976982012	a minimax lower bound
0.1976449056	linear inverse problems with
0.1976263923	large deviations for
0.1975991977	look at
0.1975276837	stationary stochastic
0.1974096367	the unit interval
0.1973815462	annals of
0.1973772953	normal estimators
0.1973413171	owing to
0.1973261295	contrary to
0.1972866491	several authors
0.1972860890	kernel estimation of
0.1972580917	introduced by
0.1972428364	defined as
0.1972395747	shed light on
0.1972340119	tries to
0.1971564661	three step
0.1970860028	\ leq p \ leq
0.1970258943	the unit sphere
0.1970206029	using auxiliary
0.1965630165	$ dimensional vector
0.1965487998	process indexed by
0.1962866491	each vertex
0.1962313019	from noisy observations
0.1962098472	i + 1
0.1961904147	application to real
0.1961889344	_2 ^ 2
0.1961168350	combined with
0.1960929701	computer models
0.1960579183	a real dataset
0.1960424692	small time
0.1959403679	linear regression with
0.1959125208	high dimensional mean
0.1959027304	n ^ \ frac
0.1958182140	bivariate random
0.1957183869	willing to
0.1956273487	mutual information between
0.1955438093	stationary functional
0.1955207810	variation distance between
0.1955203707	a constant factor
0.1955005340	properties of maximum likelihood
0.1954953792	much faster
0.1954351910	an ergodic diffusion
0.1953624206	estimator based
0.1953082317	_ i
0.1952849520	maximum likelihood estimation in
0.1952185737	x _i
0.1951974615	before and after
0.1951556533	| x |
0.1949599432	most powerful
0.1949069375	non parametric statistics
0.1948939247	strong consistency of
0.1948691722	probability tending to one
0.1948289507	two fundamental
0.1946948429	growing number of
0.1946050163	one sample
0.1945750972	one parameter exponential
0.1945623751	non additive
0.1945162564	while ensuring
0.1943532338	equal to 1
0.1943266870	under suitable assumptions
0.1941840854	question of whether
0.1941619050	virtue of
0.1941050295	community detection in
0.1940994823	student's t
0.1940514986	laws of large
0.1937912778	tends to zero
0.1936021794	models with latent
0.1935255380	currently available
0.1934666263	good finite sample
0.1934450767	_ + ^
0.1934409678	the so called
0.1933663961	convergence rates for
0.1932986969	two components
0.1932157089	linear time
0.1931280046	\ | _1
0.1930885353	phase transitions in
0.1930837613	random fields with
0.1930409962	equivalence between
0.1930288442	obtained from
0.1930247693	\ ell_q
0.1929952421	= \ exp
0.1929939281	\ geq 1
0.1929696426	similar processes
0.1929569038	non asymptotic minimax
0.1926504065	shown to
0.1925840608	_ i = 1 ^ n
0.1925211749	independent samples from
0.1922671895	1 + \ alpha
0.1921983733	for instance
0.1921933267	value theory
0.1921922196	set of samples
0.1920383339	new feature
0.1919758654	0,1 ^ d
0.1919719052	two parameter
0.1919632200	a functional central limit theorem
0.1918664062	efron et al
0.1918395539	hypothesis testing for
0.1918114317	the optimal rate
0.1916800599	law of large
0.1916487840	an explicit
0.1916108795	\ mathcal o
0.1915697958	1 alpha
0.1915547727	likelihood ratio tests for
0.1915541022	mixtures of gaussian
0.1913575230	equivalent to
0.1912700048	k monotone
0.1912475626	of low rank matrices
0.1911808733	flexible class of
0.1911657305	least squares estimate
0.1911481191	first and second order
0.1910807303	the familywise error rate
0.1910288442	estimated by
0.1909947082	the problem of estimating
0.1909812125	best subset
0.1906208824	non zero coefficients
0.1906182817	data driven method for
0.1906028726	model approach
0.1906002210	r ^ d
0.1905996601	true regression
0.1905899006	stem from
0.1905689620	large class
0.1905606202	prove non asymptotic
0.1904080531	ratio of two
0.1903771488	characterization of
0.1903485989	based on u statistics
0.1903363956	ill posed linear
0.1903259624	in high dimension
0.1902829341	equation driven by
0.1902711429	an ar
0.1902081009	likelihood based inference for
0.1902062819	a unified framework
0.1901826801	results presented
0.1901197598	geometric characterization of
0.1900904430	the negative log likelihood
0.1900536852	apart from
0.1900151772	parameter estimation for
0.1899588951	nearly matching
0.1899121162	some numerical experiments
0.1899023698	1 \ varepsilon
0.1898628956	information contained in
0.1898560561	$ \ mathcal
0.1898374463	= f_
0.1897441353	exact expressions for
0.1896573859	for high dimensional data
0.1896308133	_ t
0.1895712857	\ in \ cal
0.1895356593	in gaussian white noise
0.1894085787	limit theorem for
0.1894040963	prior knowledge of
0.1891847916	wide variety of
0.1891128620	ratio model
0.1890559720	originating from
0.1888335665	the other hand
0.1887840209	total number of
0.1886963326	an arbitrary
0.1886302379	tests for high dimensional
0.1886284456	n k
0.1884311763	e chet mean
0.1884277715	models considered
0.1883713156	more precise
0.1883709556	a by product
0.1883600646	$ \ ell_q
0.1881965357	analysis relies on
0.1881122884	this end
0.1880948093	basic properties of
0.1880361071	g priors
0.1880153527	$ \ alpha
0.1879580169	$ consistent and
0.1879381467	driving l \
0.1878814397	a recent result
0.1878808257	problem of optimal
0.1877730813	+ w
0.1877620030	aim at
0.1877064949	best linear
0.1876621826	denoted by
0.1875970006	quantum system
0.1875906295	extreme eigenvalues of
0.1875855656	two layer
0.1875827613	kernel k
0.1874500721	the average treatment effect
0.1874013879	strong law of large numbers for
0.1873938769	in other words
0.1872430789	an important
0.1872406367	linear functionals of
0.1872364957	study convergence
0.1872166523	the high dimensional regime
0.1871598711	sample simulation
0.1870523417	theoretical properties of
0.1870387327	the minimax optimal rate
0.1870278611	x_t =
0.1868752778	written as
0.1868231288	applicable to
0.1868024326	| _ \ infty
0.1867601358	in practice
0.1867402543	order to avoid
0.1867245364	learning mixtures of
0.1867192333	structural properties of
0.1866391615	three problems
0.1866328532	rich class of
0.1865790444	the regression function
0.1864676959	real time
0.1862327271	accounts for
0.1862188103	a fractional brownian motion
0.1861546612	class of continuous
0.1860877388	quantity of interest
0.1860379200	non causal
0.1860150071	ordinary least
0.1858498486	cand \
0.1858002778	produced by
0.1857643048	arise naturally in
0.1857097048	this problem arises
0.1856250462	primary interest
0.1856140165	two way
0.1855740823	\ mathbf x
0.1855722095	accounting for
0.1855703645	come from
0.1855374028	non asymptotic oracle
0.1855098767	a key tool
0.1854292203	proportional to
0.1853160973	markov bases for
0.1852819239	\ neq 0
0.1852484430	\ ge 0
0.1852367910	based on gaussian
0.1851693499	goodness of fit test for
0.1851672079	gaps between
0.1851250158	these results
0.1850928346	weighted sums of
0.1850173406	construction of optimal
0.1850121364	much attention
0.1849901733	accounted for
0.1849683190	close to 1
0.1849408359	class of tests
0.1849404715	broad range of
0.1849196859	other applications
0.1848792542	according to
0.1848253745	the key idea
0.1847474930	j = 1
0.1846856029	root n
0.1846439322	an ill posed
0.1845933392	\ in 0,1
0.1844755147	$ ary
0.1844265583	\ alpha 1
0.1843557953	an empirical bayes
0.1842776563	smooth enough
0.1842562225	sufficient condition for
0.1841431572	v statistics
0.1840442984	$ y = x \ beta
0.1840088720	asymptotic behaviour of
0.1839519510	a random vector
0.1839244292	an explicit formula
0.1839130378	an efficient
0.1839091416	1 \ gamma
0.1838659889	the maximum likelihood degree
0.1838134828	on synthetic data
0.1838133219	the square root lasso
0.1837990270	deviation principle for
0.1837568285	two layers
0.1837446951	test statistic based on
0.1837157478	$ fwer
0.1836995788	brownian motion with
0.1836809301	recent developments in
0.1836680816	at random times
0.1836552892	\ star
0.1836536627	new data driven
0.1836067248	family of models
0.1836017197	multivariate extreme value
0.1835754611	time series model
0.1835516341	classes of models
0.1834897933	$ l_
0.1834753172	class of linear
0.1834622872	modeled by
0.1833759875	limit theory for
0.1832683601	estimation of
0.1830603744	the likelihood ratio test statistic
0.1830164992	under general conditions
0.1830133571	bounds on
0.1829295142	necessary and sufficient conditions
0.1829043182	fast enough
0.1827428488	converges at
0.1825921139	for long range dependent
0.1824524971	theoretical justification for
0.1824071796	comments on
0.1823736210	residual sum of
0.1823701837	general sufficient
0.1823027094	chernozhukov et
0.1822235433	popular tool for
0.1822162627	\ hat p_r
0.1821440986	simulation studies show
0.1821159785	uncertainty quantification for
0.1820927314	each row
0.1819962139	sub linear
0.1819735785	the propensity score
0.1819724891	an unknown parameter
0.1818951288	results apply to
0.1818008074	compared with
0.1817630372	sample bias
0.1817324457	the likelihood ratio test
0.1817125038	questions about
0.1816796183	this result
0.1816473240	stronger than
0.1815890100	consistent estimates of
0.1815568504	linear quantile
0.1815428108	\ end equation
0.1815000562	adaptive estimation in
0.1814798870	extended to
0.1814682699	processes indexed by
0.1814454869	\ subset
0.1814071250	divided by
0.1812504332	wide applications in
0.1811947997	based likelihood
0.1811129030	makes use of
0.1810577963	able to detect
0.1810428277	gap between
0.1809701098	closed form expression of
0.1809326960	x y
0.1809295759	easy to
0.1808920239	a large number
0.1808365976	trying to
0.1808145367	second order structure
0.1807784972	a compact set
0.1805911250	two step estimator
0.1805296555	\ theta _n
0.1804879536	for hidden markov models
0.1804741667	defined in terms
0.1804144927	\ beta _
0.1803510785	confidence interval for
0.1803507162	case of gaussian
0.1801041854	initial value
0.1801009022	| ^ 2
0.1798488205	terms of power
0.1798262900	based on continuous
0.1798180315	wish to
0.1798005013	t \ geq 0
0.1797836107	efficient algorithms for
0.1797468373	presence of
0.1797038454	\ ge0
0.1796764729	estimator based on
0.1796371816	deviations from
0.1795229470	monotonicity properties of
0.1794368504	general family
0.1794297467	survival time
0.1793741116	an application
0.1793642780	with long range dependence
0.1793285664	mathbf r
0.1793244377	independent interest
0.1791974314	the ambient space
0.1791862761	depends only on
0.1791651879	non constant
0.1791355506	derived from
0.1791232671	attributed to
0.1791038544	concentration inequality for
0.1790425697	non positive
0.1790398360	sub class
0.1789825173	transformed into
0.1788467967	one and two
0.1788094614	in finite samples
0.1787524327	a wide variety
0.1786436381	amenable to
0.1786356848	illustrated via
0.1786330570	$ \ cal
0.1786009582	this problem
0.1785775643	for high dimensional regression
0.1785740494	to overcome
0.1784901837	scale problems
0.1784900280	| _2
0.1784693870	non response
0.1784548989	$ \ theta
0.1783065871	clinical trials with
0.1782876290	well approximated
0.1782870855	powerful tool for
0.1782270885	a single
0.1782023666	bounds for
0.1781366473	recent results on
0.1781175223	r ^ n \ times
0.1780976172	explicit formulae for
0.1780758553	a convex body
0.1780664210	the standard normal distribution
0.1780203439	the art algorithms
0.1780000689	dependencies among
0.1779698007	more robust
0.1778741352	bias and mean
0.1778458455	generated from
0.1778080475	bounded below
0.1776395319	non sequential
0.1776201715	these results hold
0.1776000052	to estimate
0.1775625970	validated through
0.1775285257	constructed based on
0.1774495456	generated according to
0.1773920322	attracted much
0.1773722431	\ int_0 ^
0.1773448071	k = 1
0.1773219794	difficult to
0.1772449591	need to know
0.1772042968	based methods for
0.1771553731	accordance with
0.1770106861	ij |
0.1769795782	unable to
0.1768738075	several applications
0.1768426803	some mild assumptions
0.1767957433	attached to
0.1767953537	_ m
0.1767753830	both simulated and real data
0.1767620513	+ \ delta
0.1767594643	likelihood ratio test for
0.1767567153	an alternative
0.1767202523	a riemannian manifold
0.1767020337	change point detection for
0.1766884389	the minimax rate
0.1766869624	also discuss
0.1766633056	$ fold
0.1766617567	well approximated by
0.1766431804	$ r_i
0.1765698501	mathbb r ^ d \
0.1765428712	the main idea
0.1764941332	near linear
0.1764806228	too small
0.1764737880	| \ cdot \ |
0.1763634118	the slope heuristics
0.1763535610	application to
0.1762821697	illustrated by means
0.1762178715	runs in time
0.1761994756	characterised by
0.1760847556	to compute
0.1760694457	differ from
0.1760505914	one by one
0.1760271021	nonparametric estimators of
0.1759602811	run time
0.1759160793	extensively studied in
0.1758600885	estimation in nonparametric
0.1758548989	$ \ hat
0.1758541680	as soon
0.1758228985	a gaussian random field
0.1757144705	1 \ delta
0.1756826565	near minimax
0.1756288175	require knowledge of
0.1755384832	\ | \ hat
0.1755340124	with missing observations
0.1755038038	parametric estimation of
0.1754825471	\ sqrt n
0.1754340546	capable of
0.1753842064	recently introduced by
0.1753727985	consistent estimators for
0.1753574724	gaussian mean
0.1752838692	to select
0.1752323871	the true distribution
0.1752281687	a small number
0.1752048152	a key step
0.1751669327	| _1
0.1751421467	$ l_0
0.1751200595	based on empirical
0.1751140839	minimal assumptions on
0.1750674362	special cases of
0.1749593128	accomplished by
0.1749374444	in high dimensional regression
0.1748543067	a crucial role
0.1748542792	and social sciences
0.1748200163	represented as
0.1748035885	draws from
0.1747942220	thanks to
0.1747885108	non asymptotic framework
0.1747567117	some regularity conditions
0.1746900689	^ \ infty
0.1746827479	sample fr \
0.1745712939	| 1
0.1744425587	extracted from
0.1744210923	the log likelihood ratio
0.1744147340	concentration properties of
0.1743799600	improvement over
0.1743145528	over threshold
0.1742446750	contraction rates for
0.1742387057	fundamental role in
0.1741835660	a general framework
0.1741523028	with unequal
0.1741482777	$ th
0.1741026679	whether or not
0.1740839904	first order methods
0.1740199094	second order parameter
0.1739522304	limited number of
0.1737395781	based on local
0.1737000052	a simple
0.1736152509	problem in statistical
0.1734487991	assumptions on
0.1734000086	p = q
0.1733990087	s ^ 1
0.1733550924	the single index model
0.1733478923	based on estimating
0.1733026156	this manuscript
0.1732522668	a wide range of applications
0.1732390610	mean squared prediction
0.1731971048	1 norm
0.1731831356	not too large
0.1731823580	bounds for sparse
0.1731631163	representation theorem for
0.1731279420	the design matrix
0.1731068919	some additional assumptions
0.1730760059	long time
0.1730041800	several numerical examples
0.1729669395	extensively used
0.1729652194	an illustration
0.1729379198	time interval
0.1728327486	h 1
0.1727466750	this article studies
0.1726894151	balance between
0.1726840591	applies to
0.1725794707	explained by
0.1725710933	_ p
0.1725548989	$ \ sigma
0.1725464683	the elastic net
0.1724921577	non convex loss
0.1724856492	collections of
0.1724390688	two points
0.1724304699	versions of
0.1723897583	the training dataset
0.1723029329	at most
0.1722789719	^ p
0.1722562228	t _1
0.1722220731	for high dimensional linear regression
0.1721297540	confidence intervals based on
0.1721137647	discussed in detail
0.1720434941	to construct
0.1720099808	\ mathbf s _n
0.1719921532	estimators based on
0.1719761162	the extremal index
0.1718283799	assessed through
0.1717871506	p_ n
0.1717788674	able to
0.1717673626	main advantage of
0.1717495603	convex and non
0.1717015091	long memory time
0.1716979846	random walk on
0.1716628999	distinguishing between
0.1716463401	\ varpi
0.1715548989	$ \ beta
0.1715344382	sparse high
0.1714632363	away from
0.1714509563	the maximum likelihood estimators
0.1714058650	to avoid
0.1713806888	estimation under
0.1713666309	the change point problem
0.1713476620	performs better
0.1713056492	to solve
0.1712524591	an iterative
0.1711411332	more efficient than
0.1710701152	\ mathbf y
0.1710498973	more or less
0.1710313468	two parts
0.1709834956	mathematical properties of
0.1709556129	discrimination between
0.1709299761	a scalar response
0.1709241746	optimal estimation of
0.1708574590	under strong mixing
0.1707439246	class of adaptive
0.1706580037	\ boldsymbol x _i
0.1706261048	normal linear
0.1706135227	performance in terms
0.1705876996	consistent against
0.1705361335	modeled as
0.1705287858	consists in
0.1705262289	a single observation
0.1705259989	cumulative distribution function of
0.1705125257	convergence rates of
0.1704933676	h \
0.1704792467	illustrated by means of
0.1704749115	\ mbtheta
0.1704375878	large deviations of
0.1704162214	to obtain
0.1703833359	very flexible
0.1703556664	$ \ phi
0.1702794459	minimax rates for
0.1702757071	process driven by
0.1702694382	procedures based
0.1702649696	deviation inequalities for
0.1702360382	this regard
0.1701154571	in machine learning
0.1701151870	triangular arrays of
0.1700663369	probability tending to
0.1700462271	sampled from
0.1700389269	prior distribution on
0.1700326739	equal to
0.1699410208	small enough
0.1699352689	convex hull of
0.1698015736	o s r \
0.1697847012	full dimensional
0.1697548817	cope with
0.1695711151	$ \ mathbf
0.1693466128	based on simple
0.1693411419	perform better than
0.1693007948	link between
0.1692870775	central limit theorem with
0.1692834696	order approximation
0.1692644019	the moment generating function
0.1691694224	from noisy measurements
0.1691564885	kappa \
0.1691397858	the noise level
0.1690957393	index regression
0.1690795304	each component
0.1690321570	way contingency
0.1690267572	theoretical understanding of
0.1690266047	if and only if
0.1690255310	based on exponential
0.1689601568	a unified treatment
0.1689021705	one parameter family
0.1688954499	high degree of
0.1688689247	first hitting time
0.1688275816	a gaussian mixture model
0.1687454611	to achieve
0.1687252097	p ^ 1
0.1684899731	$ l_p
0.1684746179	\ geq 0
0.1683759532	l ^ 1
0.1683746243	distribution of random
0.1683541680	soon as
0.1681971386	for large scale
0.1681467756	$ \ widetilde
0.1680265455	$ n ^ 2
0.1679448387	know whether
0.1679271857	asymptotic analysis of
0.1679246399	principal component analysis for
0.1679197756	while achieving
0.1679189327	description of
0.1678088781	mean discrepancy
0.1677959250	the error distribution
0.1677862155	bayesian hypothesis
0.1677628033	the asymptotic covariance matrix
0.1677604821	behavior of
0.1677306532	easy to use
0.1676817468	\ alpha_k
0.1676444515	similar to
0.1676208605	theory of optimal
0.1676156335	\ mathfrak
0.1675435518	an analytic
0.1675375846	much less
0.1674638869	the high dimensional case
0.1674488885	an experiment
0.1673674611	\ theta_2
0.1673599869	two consecutive
0.1673315025	$ dimensional euclidean
0.1672834696	order structure
0.1671798217	method performs well
0.1671711178	class of probability
0.1671646044	p q
0.1671125007	aspects of
0.1670524380	a compound poisson
0.1669949803	$ n ^ 4
0.1669871459	give sufficient conditions
0.1668834696	type large
0.1667296904	sampled at
0.1665234262	to date
0.1665058719	a logarithmic term
0.1664856492	irrespective of
0.1664697246	l _2
0.1664651003	\ sum_ j
0.1664486213	le r
0.1664460269	a level
0.1662834696	adaptive density
0.1662723979	estimation of gaussian
0.1662190181	number of relevant
0.1661933872	links between
0.1661704499	regression models with
0.1661430267	in state space models
0.1661285331	deviation inequality for
0.1661028187	h 1 2
0.1660775461	\ ast \ mathcal n
0.1660285441	+ z
0.1659284604	to accomplish
0.1659136841	a modified version
0.1658760338	statistical properties of
0.1658713472	least squares problem
0.1658087829	used to construct
0.1657857177	the minimax sense
0.1657703379	drift estimation for
0.1657145996	some special cases
0.1656751085	the first step
0.1656447981	unit ball of
0.1656319866	the nonparametric maximum likelihood estimator
0.1656196763	a minimax sense
0.1655718826	$ \ varepsilon
0.1655138392	uniformly distributed on
0.1654748165	\ mathbb e
0.1654712615	arise from
0.1652968554	a broad range
0.1652904965	an interesting
0.1652520588	r ^ p
0.1652415445	\ log n
0.1651950103	sufficient conditions under
0.1651806255	convergence analysis of
0.1649861374	analytical expressions for
0.1648199110	assumptions about
0.1648080816	problem of learning
0.1648009881	dependence among
0.1647539935	the minimax separation
0.1646760688	too much
0.1646537214	these estimators
0.1646467411	this issue
0.1646234696	related problem
0.1645928577	samples from
0.1645805489	non parametric estimators
0.1645687959	exponential bounds for
0.1645244875	consistent estimate of
0.1644003456	relatively simple
0.1643653957	an oracle property
0.1643314730	\ rightarrow \ mathbb r
0.1643257341	$ \ mathbb
0.1643219727	a key component
0.1642194382	the time of
0.1641899982	no effect
0.1637850848	to understand
0.1636822043	epsilon 0
0.1636469681	l \
0.1636365643	| _
0.1636101657	weak assumptions on
0.1635898903	high dimensional linear regression with
0.1635715801	spite of
0.1635711151	$ \ delta
0.1635345975	also provide
0.1635097035	\ ge 1
0.1634544903	parametrized by
0.1634420234	new test statistic
0.1634169009	class of
0.1633698386	to choose
0.1633398552	the number of observations
0.1633301887	defined on
0.1632906197	this paper extends
0.1632747799	does not depend on
0.1632495612	$ \ omega
0.1632115353	become popular
0.1632086522	$ n \ to \ infty
0.1631757431	tends to
0.1631005532	the stick breaking
0.1630731299	sums of random
0.1630449359	classes of
0.1630016158	value thresholding
0.1629761470	rrr ^
0.1629678254	gives rise to
0.1629630034	^ q
0.1629548989	$ \ epsilon
0.1629254532	support vector machines with
0.1628655877	an unknown signal
0.1628479126	decay rate of
0.1628367135	an unknown distribution
0.1628212187	y \ mathbf
0.1627830667	from discrete observations
0.1627264682	linear regression models with
0.1626205195	consistent estimators of
0.1625780511	quadratic forms of
0.1625319356	+ \ frac
0.1625103182	\ bullet
0.1625092224	time points
0.1624922644	generalization bounds for
0.1624578874	r ^ n
0.1624512599	paper focuses on
0.1624418541	\ bbu_1
0.1624104987	test statistics for
0.1623489740	special class of
0.1622731604	a multivariate normal distribution
0.1622438465	independent random variables with
0.1622372789	a log factor
0.1622292774	good performance
0.1622127247	the population covariance matrix
0.1622065168	an effective
0.1621626399	particularly suitable
0.1621563688	improvements over
0.1621204434	the ambient dimension
0.1621204173	thus allowing
0.1620744137	supposed to
0.1620536924	this purpose
0.1620309908	the precision matrix
0.1619710717	\ ell ^ 1
0.1619643888	prior work
0.1619281569	prove consistency of
0.1618105974	the sample autocovariance
0.1618035019	required to
0.1617917025	in high dimensional linear models
0.1617776210	a data driven
0.1617364696	_ k \ in
0.1617156848	test based on
0.1616942004	some cases
0.1616348894	received much
0.1616270752	the minimax lower bound
0.1616254017	divergences between
0.1616243002	analysis of
0.1615974294	mean pattern
0.1615936607	frequentist properties of
0.1615649463	simultaneous estimation of
0.1615290085	two independent samples
0.1614916770	range of models
0.1614504509	bounded above
0.1613039410	\ bbu_2
0.1612775498	event time
0.1612027449	a complete characterization
0.1612022920	portion of
0.1611961646	to perform
0.1611334696	point problems
0.1610819528	1 dimensional
0.1610591252	a popular tool
0.1610538473	class models
0.1610228059	class of gaussian
0.1609881427	other areas
0.1608947958	a unifying
0.1606923439	concentration bounds for
0.1606491353	non central limit
0.1606040002	knowledge about
0.1606000450	an asymptotic
0.1605549309	procedures based on
0.1605549212	1 + \ epsilon
0.1604775693	spectral analysis of
0.1604633275	through simulation studies
0.1604395512	with or without
0.1604168934	in high dimensional linear regression
0.1603697742	from noisy
0.1603501891	begin by
0.1602410343	gibbs sampler for
0.1601786420	$ \ mu
0.1601089271	a high dimensional linear
0.1601025585	procedure based on
0.1599789198	upper and lower bounds on
0.1599534846	a long history
0.1599531589	2 3
0.1599108576	approach to
0.1599040075	by proposing
0.1598627613	very small
0.1598339621	an exponential
0.1598120503	$ x_1
0.1596862538	due to
0.1596827715	index model
0.1596808537	convex combination of
0.1595844152	in high dimensional statistics
0.1595826673	analysis of random
0.1595775880	regularity assumptions on
0.1595103182	\ pi_i
0.1594855527	\ mapsto \ mathbb r
0.1593444515	relative to
0.1593106327	\ log \ log
0.1592824787	^ 2 \ log
0.1592543967	linear and non
0.1592299570	problems arising in
0.1592199004	^ n
0.1592174611	\ lambda_1
0.1591786420	$ \ lambda
0.1591303681	s_ n
0.1589622431	first two moments
0.1588777720	an unbiased estimator
0.1588505134	| z
0.1588419018	| x
0.1587825794	boundary value
0.1585857713	the log likelihood function
0.1585628978	\ leq 1
0.1584406854	least squares projection
0.1584266182	an important application
0.1583793392	regularly varying with
0.1583626826	relatively few
0.1583595757	log ^ 2 n
0.1583460044	the ground truth
0.1583309238	these bounds
0.1582768632	more powerful than
0.1582712606	y |
0.1581976842	by applying
0.1581781326	$ \ rho
0.1579727463	each individual
0.1579499357	this context
0.1578743307	change points in
0.1577403402	limit laws for
0.1577355046	y_i =
0.1577162736	more challenging
0.1577153144	check whether
0.1576982366	did not
0.1576645791	of true null hypotheses
0.1576600384	the change of
0.1576007405	case of finite
0.1575694618	x and y
0.1575559345	the posterior distribution
0.1575468603	expressions for
0.1575194382	point test
0.1575136360	the missing mass
0.1574808535	average value
0.1574155604	problem of estimation
0.1573558885	null distribution of
0.1573492950	functional time
0.1572711151	$ \ gamma
0.1572474790	\ lambda_0
0.1571526739	the spectral norm
0.1571420428	mean functions
0.1571192490	tail asymptotics of
0.1571120974	= 3
0.1570968494	$ \ pi
0.1568726042	a key role
0.1568466240	robust estimation of
0.1568205113	researchers often
0.1568016920	and real data analysis
0.1567772320	as small as
0.1567536258	examined through
0.1567422871	non asymptotic risk
0.1566691980	finite number of
0.1565825604	contaminated by
0.1565721922	in fact
0.1565062151	explicit expression for
0.1564253481	unlike most
0.1563583391	natural generalization of
0.1562955046	geometric ergodicity of
0.1562003616	2 \ alpha
0.1561788239	the optimal convergence rate
0.1561570439	the optimal sample complexity
0.1561244584	a family of estimators
0.1560398767	markov basis for
0.1559926113	numerical evaluation of
0.1559536407	nonparametric part
0.1558263978	many real world
0.1557953414	practical utility of
0.1556851237	expected value
0.1556693407	extension of
0.1556153501	existence of
0.1555753834	r von
0.1555217251	significantly better
0.1555204513	does not imply
0.1555167063	technique based on
0.1554608443	lower and upper bounds on
0.1554000298	t = 1
0.1552765497	to determine
0.1552536398	the stochastic block model
0.1552273549	non negative random
0.1552147655	+ \ sigma
0.1551129585	an exact
0.1550996489	reconstruction from
0.1550094991	memory time series
0.1549936145	higher than
0.1549726137	analysis of data
0.1549498082	estimation of large
0.1547770246	a unified
0.1547618827	= \ infty
0.1547275083	$ optimal designs
0.1547242714	from statistical physics
0.1546496977	estimation via
0.1546008629	achieved through
0.1545770559	sub models
0.1545590049	mild conditions on
0.1545437609	analogous results for
0.1545418041	estimators for linear
0.1545320463	qualitative robustness of
0.1545153454	an adaptive
0.1544473119	try to
0.1543824466	the total number
0.1543622874	sure independence
0.1543392336	a sparse vector
0.1543141618	available online
0.1542533929	sparsity assumptions on
0.1542165955	theoretical guarantees for
0.1542136685	the restricted isometry property
0.1542127177	similarity between
0.1541759188	parameterized by
0.1541721846	a nonparametric regression model
0.1540667516	under regularity conditions
0.1540505395	the work of
0.1540204504	an empirical study
0.1539705114	number of false
0.1539497468	t ^ 2
0.1538743361	estimation based on
0.1538220188	for change point detection
0.1538179331	do not assume
0.1538169745	\ | _0
0.1538115688	a lot of attention
0.1538072606	a change of
0.1537994247	sparsity assumption on
0.1537567034	estimation for high
0.1537535837	the real line
0.1537303152	consistency of
0.1537125897	a general methodology
0.1536935420	\ subset \ mathbb r ^
0.1536697591	illustrated with
0.1536369238	e optimal
0.1536368750	even if
0.1536272676	nonparametric estimation for
0.1535750224	satisfied by
0.1535662287	the high dimensional linear
0.1535541734	random variables with
0.1535472885	supplemented by
0.1535435051	convergence rate of
0.1535391793	two examples
0.1535294158	d_n \
0.1535035459	more general setting
0.1534821314	drift coefficient of
0.1534796622	scale mixtures of
0.1534298404	tau =
0.1533951265	singular vectors of
0.1531803375	level sets of
0.1531628077	a kernel density estimator
0.1531217779	estimation of high
0.1530570600	a wide array of
0.1530473812	also discussed
0.1530421243	an unknown vector
0.1530366157	two block
0.1530228402	larger class of
0.1530094191	an alternative approach
0.1529822443	$ \ boldsymbol
0.1529276671	easier than
0.1529182472	a functional central limit
0.1528979617	measured by
0.1528903080	evaluated at
0.1528611405	approach based on
0.1528123354	a random variable
0.1527767743	an extended
0.1527051404	risks data
0.1526981817	barndorff nielsen and
0.1525999285	\ ^ o
0.1525933642	this paper offers
0.1525395204	to assess
0.1525330203	problem of multiple
0.1525269902	theoretical foundation for
0.1524484996	each step
0.1524139073	rests on
0.1523918740	contribute to
0.1523901013	very large
0.1523269605	the quadratic covariation
0.1523263459	equal to zero
0.1523154109	\ h o
0.1522736536	p 500
0.1521867322	a real valued
0.1521797509	consistency and asymptotic normality of
0.1521792199	linear model with
0.1521352268	minimax optimal rates of
0.1520809887	r ^ 2
0.1520804915	distribution of order
0.1520780285	as opposed to
0.1520659910	+ \ lambda
0.1520595765	$ l_ \ infty
0.1519880185	test statistics based on
0.1519337961	the end of
0.1519186814	regret bounds for
0.1518381521	t \ in 0
0.1518319904	time to event data
0.1518162354	each cluster
0.1517981586	the limit of
0.1517981586	the consistency and
0.1517788027	results hold for
0.1517162727	a model selection procedure
0.1517010641	x_ n +
0.1514875021	one stage
0.1514768746	conditional distribution of
0.1514184803	formed by
0.1513542052	subsets of
0.1513269346	the unit circle
0.1512713890	strong enough
0.1512671294	the potential of
0.1512134319	the statistician
0.1512039922	on off
0.1511605401	arises naturally in
0.1511117973	\ alpha_0
0.1511038578	in functional linear regression
0.1510973238	$ \ widehat
0.1510906736	attempt to
0.1510898985	a self contained
0.1510414060	following question
0.1510078730	second order asymptotic
0.1509582732	quite general
0.1509379696	an algorithmic
0.1509337961	the principle of
0.1508974070	hypotheses about
0.1508924640	relatively little
0.1508919472	non parametric density
0.1508733923	minimum number of
0.1508042120	result holds for
0.1507320054	an unknown density
0.1507048895	set of random
0.1506153644	sample covariance matrices of
0.1505745334	new results
0.1505609492	$ \ ell ^ 1
0.1505413724	sampling from
0.1504885336	$ \ nu
0.1504563383	a standard tool
0.1504479821	the inverse covariance matrix
0.1504029008	a given point
0.1503655555	number of hidden
0.1502909504	a linear functional
0.1502671294	a factor of
0.1501599899	an additional
0.1501511241	parameter estimation in
0.1501285588	the probability density function
0.1501117973	\ beta_n
0.1500981586	a series of
0.1500695760	maximum likelihood estimators of
0.1500290535	order information
0.1500204737	an em algorithm
0.1500126169	very little
0.1499869495	exponential inequalities for
0.1499568892	with regularly varying
0.1499427771	c 0,1
0.1499106094	a general
0.1498918755	future work
0.1497671294	the perspective of
0.1497408523	for high dimensional sparse
0.1497180592	almost sure limit
0.1496993231	invariance principle for
0.1496739552	asymptotic optimality of
0.1496727813	discrepancy between
0.1496351750	the test statistic
0.1496025002	a small fraction
0.1496011384	the minimum description length
0.1495606886	an extensive simulation
0.1495569010	problem of nonparametric
0.1494691613	_t =
0.1494609599	popular method for
0.1494436134	number of latent
0.1493438060	computation time
0.1493382333	to evaluate
0.1493014146	geometric properties of
0.1491818640	k ^ 2
0.1491564829	less than 1
0.1491117973	\ sigma_i
0.1490896945	mild assumptions on
0.1490552059	quantities of interest
0.1490252393	converge at
0.1490130655	seen as
0.1489639899	non robust
0.1489535536	the drift coefficient
0.1489174061	observed at
0.1489087241	more and more
0.1488841192	complemented with
0.1488252801	s 1
0.1487866132	\ in \ mathbb r ^
0.1486905147	a high dimensional
0.1486865103	c ^ 1
0.1486797694	$ divergence
0.1486745466	distributions over
0.1486225340	equivalence classes of
0.1486219681	the selection of
0.1486175517	most basic
0.1485938024	want to
0.1485889828	seeks to
0.1485351307	the maximum likelihood method
0.1484929470	optimal rates of convergence for
0.1484692088	\ sim \ mathcal n
0.1484531320	subset of
0.1484069995	performance analysis of
0.1483629384	a large class
0.1483497668	methods based on
0.1483463185	converges in distribution to
0.1483038648	other contexts
0.1480867097	_ +
0.1480744997	drift parameters of
0.1480366585	selected by
0.1479840185	time point
0.1479822443	$ \ tau
0.1479327394	convergence of
0.1478695440	wants to
0.1478548977	adapted to
0.1477422800	integer valued time
0.1477179933	the art results
0.1476824291	as close as
0.1476785907	small compared to
0.1476749286	the true signal
0.1476525496	random walks on
0.1476491235	as large as
0.1476429902	particularly useful
0.1476219681	the problems of
0.1475559463	variable selection in
0.1475451413	a_n \
0.1474239866	on real world
0.1474137994	a universal constant
0.1472935420	\ sup_ t \ in
0.1472693092	+ \ tau
0.1472245937	achieves near
0.1471994061	set of
0.1471959739	numerical experiments show
0.1471644854	conditions on
0.1469853218	and real data applications
0.1469772553	centered at
0.1469272536	$ \ tilde o
0.1468466007	lack of
0.1468042174	distributional properties of
0.1467844069	starting point for
0.1467560596	\ | x \ |
0.1467423243	m m
0.1467211386	sums of
0.1467199592	finite sample behavior of
0.1467039860	take advantage
0.1466814797	autoregressive process with
0.1466792619	bayesian inference for
0.1466724705	bridge between
0.1466579519	described by
0.1466495048	needed to
0.1466314255	ij =
0.1466272505	linear system
0.1465707423	structural changes
0.1465654696	as far as
0.1464920864	the noiseless case
0.1464410241	simulations indicate
0.1464302769	based only on
0.1464187454	range of
0.1463560782	the ideas of
0.1463525336	with and without
0.1463455545	the latent positions
0.1463438196	full range
0.1463408821	by exploiting
0.1462715808	smoothness conditions on
0.1462671294	the subject of
0.1462671294	the tails of
0.1462670533	a distribution free
0.1462598391	this paper generalizes
0.1462430346	the true posterior
0.1462156854	the target distribution
0.1461728244	in high dimensional sparse
0.1461436381	tailored to
0.1461181397	each stage
0.1460713263	l ^ p
0.1460291182	a suitable
0.1459916023	from observational data
0.1459790054	\ sum_ i = 1 ^
0.1459385287	the problem of detecting
0.1458862167	_ k
0.1458728188	set of data
0.1458664405	problem of approximating
0.1458560782	the fields of
0.1457889029	some numerical examples
0.1457573935	the parameter space
0.1457502813	regardless of
0.1457499915	to identify
0.1457464761	$ c 0
0.1457397917	while controlling
0.1457381648	non asymptotic analysis
0.1456971528	many authors
0.1456219681	the location of
0.1456219681	the effects of
0.1456219681	the sparsity of
0.1455952001	a priori information
0.1454901418	stein's method for
0.1454469184	converge to zero
0.1454447812	statistical estimation of
0.1454099178	$ 1 \ delta
0.1453917925	the rows of
0.1452943926	independence between
0.1452671294	the focus of
0.1452671294	the observation of
0.1452671294	the sensitivity of
0.1452537417	through numerical experiments
0.1452467225	\ subset \ mathbb
0.1451872613	$ \ varphi
0.1451351799	to infer
0.1451223719	relatively low
0.1451040300	robust mean
0.1450776566	\ alpha_
0.1449337961	the deviation of
0.1449081737	upper and lower bounds for
0.1448522461	divergence between
0.1448383659	$ \ operatorname
0.1448129685	1 3
0.1447465792	or equivalently
0.1446865158	$ d = 2
0.1446341646	possible extensions
0.1445947638	the spiked covariance model
0.1445925869	practical implementation of
0.1445842323	the ratio of
0.1445252801	i 1
0.1444878052	mixtures of
0.1444449997	\ | x \
0.1444070339	$ t 0
0.1443604878	an interpretation
0.1443576103	linear models with
0.1443441584	in high dimensional data
0.1443251676	the empirical distribution function
0.1442671294	the dependence of
0.1442671294	the dimensionality of
0.1442615328	builds on
0.1442293935	the square of
0.1442244721	this approach
0.1441570210	consistent estimator of
0.1441537093	\ mh
0.1441385345	a response variable
0.1440800584	lies in
0.1440752269	\ hat \ beta
0.1440211002	$ erm
0.1439733117	an adaptive estimator
0.1438925707	various fields
0.1438840134	$ o_p
0.1438805946	a change point
0.1438731381	possibly non
0.1438635804	\ in \ mathbb r
0.1438631321	| \ mu
0.1438322996	$ \ eta
0.1438198072	question whether
0.1437974019	of independent random variables
0.1437642457	non existence
0.1437502342	family of
0.1436936609	hitting time
0.1436894115	a network of
0.1436442902	small number of
0.1436436660	the general case
0.1436276836	= x_i
0.1436267336	the true function
0.1435842323	the rank of
0.1435769613	$ \ exp
0.1434799700	restricted to
0.1434276438	consist of
0.1433923874	this upper bound
0.1433905004	popular class of
0.1433560782	the approach of
0.1433548498	$ \ mathscr
0.1433152682	model selection with
0.1432851121	analysis of large
0.1432813697	^ k
0.1432671294	the hypothesis of
0.1432293935	the entropy of
0.1431871367	with respect to
0.1431741512	more conventional
0.1431594198	differential equations with
0.1431508930	maximum likelihood estimator for
0.1431082275	an estimation procedure
0.1431043372	holds even
0.1430064996	$ \ ell_ \ infty
0.1429944255	each other
0.1429815660	generalization of
0.1429728217	for use in
0.1429650387	nonparametric regression with
0.1429612255	of non negative
0.1429390453	asymptotic expansion of
0.1429290276	delta method for
0.1429012097	$ p \ ge
0.1428477341	financial time
0.1428366091	converges in distribution
0.1428361576	to infinity
0.1427955038	a random sample
0.1427136600	making use of
0.1426954602	an unknown function
0.1426883888	the covariance matrix
0.1426731778	the finite sample performance
0.1426001626	further study
0.1425842323	the order of
0.1425604685	\ mathbb p
0.1425480877	in many cases
0.1425141666	asymptotically normally
0.1424978414	the original
0.1424944118	conditions under
0.1424552447	the selected model
0.1424146283	constructed from
0.1424143111	this paper deals with
0.1423867142	new model
0.1423461608	for high dimensional linear
0.1423152681	non asymptotic error
0.1422876835	outperforms other
0.1422671294	the integral of
0.1422293935	a test of
0.1422293935	a model of
0.1422293935	the likelihood of
0.1421493339	class of random
0.1421345771	does not depend
0.1421067824	powers of
0.1420981586	the results of
0.1420669652	non linear regression
0.1420604227	a sample of
0.1419937381	stationary time
0.1419823011	dominated by
0.1419815157	variant of
0.1419451764	a probability density function
0.1418898218	arises from
0.1418796412	functions defined on
0.1418787224	mathematical framework for
0.1418679288	$ v_m
0.1418646365	class of stationary
0.1418083456	under weak conditions
0.1417841834	the em algorithm
0.1417339781	an efficient estimator
0.1416795777	and so on
0.1416618827	1 \ sqrt
0.1416043059	sample size goes to infinity
0.1414957918	with hidden variables
0.1414471556	comparable to
0.1413756860	the modeling of
0.1412671294	the process of
0.1412671294	the prediction of
0.1412509260	provide necessary and sufficient
0.1412434609	under certain assumptions
0.1412384100	used to generate
0.1412293935	the gradient of
0.1412238299	based on random
0.1411780670	a view to
0.1411457976	types of
0.1411253115	these questions
0.1411139065	non independent
0.1411135903	a real life
0.1410968830	an empirical
0.1410205946	$ \ mathsf
0.1409973104	and real world data
0.1409935219	fast algorithm for
0.1409791110	the interest of
0.1409435957	contained in
0.1408940804	comes from
0.1408720627	used to estimate
0.1408688781	representation of
0.1408656960	presented here
0.1408214921	too large
0.1407643485	definition of
0.1407549897	new approach
0.1407449884	thresholds for
0.1407336040	$ \ bar
0.1407126671	these models
0.1406788393	mixture models with
0.1406720865	simulation results show
0.1406601918	p n
0.1406041559	$ h_0
0.1405949061	fast rates for
0.1405842323	the parameter of
0.1405380049	theoretical guarantees on
0.1405273819	the true
0.1405149169	necessary conditions
0.1404991828	association between
0.1404674334	independence structure of
0.1404558769	first order asymptotic
0.1404492022	\ mu_1
0.1404272058	probability density function of
0.1404178216	the model space
0.1404151126	weighted sum of
0.1404027488	functionals of
0.1403756860	the challenge of
0.1403421774	with missing values
0.1402750031	m dependent
0.1402737075	$ i = 1
0.1402671294	the frequency of
0.1402671294	the inference of
0.1402528970	as well as
0.1402333635	to address
0.1402293172	these conditions
0.1402197184	the first stage
0.1402121428	these methods
0.1401825506	many popular
0.1401800745	shrinkage priors for
0.1401741828	comparisons between
0.1401640695	signal plus
0.1400985168	large compared to
0.1400878270	the number of variables
0.1400597628	\ tilde \ omega
0.1400464560	significance test for
0.1400104388	sample tests
0.1399905646	the signal to noise ratio
0.1399812126	$ \ ell
0.1399502397	empirical version of
0.1398800517	raised by
0.1398578999	problem of high
0.1398252982	a critical threshold
0.1398142089	shrinkage estimator for
0.1397381322	mathematical theory of
0.1397300511	with probability at
0.1397170294	bounded from above
0.1396894115	a group of
0.1396894115	a population of
0.1396733315	significantly different
0.1396349216	^ 2 +
0.1396309636	conducted to
0.1396155269	large relative to
0.1395524179	regression function at
0.1395413299	the minimax risk
0.1395281438	to work with
0.1393666754	a constructive
0.1393560782	the edges of
0.1393435252	advantage over
0.1392306946	across multiple
0.1392106644	results rely on
0.1391725924	the maximum likelihood estimates
0.1391588447	more difficult
0.1391470736	families of
0.1391243180	probability measures on
0.1391206791	different scales
0.1390800787	least concave
0.1390719789	a consistent estimator
0.1389832021	two ways
0.1389632242	+ \ gamma
0.1389623632	new theoretical results
0.1389257628	the way for
0.1389210373	together with
0.1389185010	performance relative to
0.1389029201	a consequence
0.1388862233	the number of change points
0.1388704497	referred to
0.1388604532	the paper also
0.1388221127	models with
0.1388126421	robust test for
0.1387926771	robustness properties of
0.1387343739	effective way
0.1386613342	approach to model
0.1386514224	in order to
0.1386280076	lambda 0
0.1386056126	these issues
0.1385563059	$ q_
0.1385209854	+ \ xi
0.1383917925	the sign of
0.1383644472	the gaussian sequence model
0.1383560782	the precision of
0.1383543511	delta 0
0.1383407026	to bypass
0.1383358401	the observed data
0.1381875148	numerical performance of
0.1381495889	paid to
0.1381207202	unknown probability
0.1381205946	$ \ delta_n
0.1381031726	the present article
0.1380481414	for stochastic block models
0.1380269034	case of independent
0.1379648735	random samples from
0.1378868576	a finite sample
0.1378603330	of sample covariance matrices
0.1378581715	great interest
0.1378291334	= 1 ^ n
0.1378280735	n \ to \ infty
0.1378227322	practical use
0.1378126918	$ \ xi
0.1377809581	k = 2
0.1377780458	by means of
0.1377726576	a recent paper
0.1377513533	impact on
0.1377508379	this paper deals
0.1377103808	attained by
0.1377085168	proposed by
0.1376944403	\ det
0.1376884627	space model
0.1376847434	to learn
0.1376464646	joint distribution of
0.1376196148	focus here
0.1375960287	defined via
0.1375826255	useful tool
0.1375728552	u &
0.1375702183	explicit expressions of
0.1375259148	the response variable
0.1374991829	this framework
0.1374937943	= \ omega
0.1374533590	best fit
0.1374482649	equality between
0.1374332771	adjacency matrix of
0.1374285510	a general theorem
0.1374274262	equivalence class of
0.1373917925	the maximization of
0.1373917925	the mse of
0.1373560782	the quantiles of
0.1373560782	the scale of
0.1373560782	the dimensions of
0.1373183423	the source of
0.1373051967	estimators under
0.1372362720	new paradigm
0.1372264928	an optimal
0.1371994771	collection of
0.1371734913	maximum likelihood estimator of
0.1371336899	$ \ psi
0.1370900741	spectral properties of
0.1370885718	existing literature on
0.1369933884	studied in detail
0.1368539974	useful tools
0.1367980769	the most popular
0.1367806272	^ * _
0.1367245813	well suited for
0.1367243368	proved to
0.1365329057	first and second
0.1365323305	c 0
0.1365268036	the posterior measure
0.1364646473	an adaptive procedure
0.1363956494	more tractable
0.1363699406	further results
0.1363560782	the distance to
0.1363560782	the loss of
0.1363560782	the regime of
0.1363560782	the sizes of
0.1363472095	refer to
0.1363420327	if and only
0.1362899681	formulated as
0.1362671852	functional form of
0.1361829234	\ |
0.1361611532	\ hat \ theta_n
0.1361428141	based on recent
0.1361278573	optimal choice of
0.1361184061	confirmed by
0.1360911293	estimators over
0.1360834166	general high
0.1360390195	the nominal level
0.1359844108	$ \ theta_0
0.1359599917	= \ mathbf
0.1359460037	classical ones
0.1359345330	to reduce
0.1358797528	very accurate
0.1358756860	the stability and
0.1358383596	two state
0.1358147232	only slightly
0.1357757944	v _
0.1357669322	constructed using
0.1357525566	defined through
0.1357262531	locally stationary time
0.1356697882	$ \ kappa
0.1356005219	conditional mean estimator
0.1355703439	second step
0.1355024313	also provided
0.1354973647	this setting
0.1354604770	the finite sample properties
0.1353865329	the model parameters
0.1353796987	sample theory
0.1353756860	the failure of
0.1353756860	the phenomenon of
0.1353700107	a gaussian process
0.1353291087	as efficient as
0.1353251267	j \ leq
0.1352807196	also present
0.1352584537	performance of
0.1352119753	controlled by
0.1352073686	\ gamma_
0.1351756860	the theory to
0.1351695740	non asymptotic results
0.1351594200	number of data
0.1351415075	collected at
0.1351095768	these tests
0.1351057238	more informative
0.1350629976	of clusters in
0.1350431759	to recover
0.1350411770	parameter of interest
0.1348266402	neural networks with
0.1347922795	number of model
0.1347866163	experimental results on
0.1347854542	new procedure
0.1347705223	$ k 1
0.1347521513	a nonparametric
0.1347354121	construction of
0.1347276749	a limited number
0.1347169642	inference on
0.1346865969	the change point
0.1346457272	\ hat \ rho
0.1346199203	unbiased estimators for
0.1345903090	the multivariate case
0.1345887189	an importance sampling
0.1345700853	averaged over
0.1345069978	\ in \ mathbb z
0.1344923720	in high dimensional gaussian
0.1344801012	a scalar parameter
0.1344783910	bound on
0.1343756860	in term of
0.1343756860	the projection of
0.1343756860	the paper by
0.1343749934	compatible with
0.1343606818	normalizing constant of
0.1342341982	very mild
0.1341875297	\ mapsto \ mathbb
0.1341165395	without making
0.1340327195	$ s_0
0.1340171392	the ordinary least squares estimator
0.1339230419	the group lasso
0.1339203506	$ l_q
0.1337787428	by employing
0.1337668392	e |
0.1337029593	values of
0.1336675981	constructed by
0.1336641039	a discretely observed
0.1336564986	convergence properties of
0.1336118612	= \ max
0.1335861796	uncertainty about
0.1335391959	not identifiable
0.1335171828	fourier coefficients of
0.1334780632	by adding
0.1334398301	sharp bounds for
0.1333618851	class of sparse
0.1333528840	t x
0.1333195430	$ l ^ 1
0.1332673994	a positive constant
0.1332251377	maximum likelihood estimate of
0.1331925134	asymptotic expansions for
0.1331750980	many scientific
0.1331250085	this class
0.1330451561	not well understood
0.1330298852	appeared in
0.1330244017	the excess risk
0.1330154925	the fusion center
0.1329907906	$ \ mathbb r ^ 2
0.1328934485	$ \ epsilon 0
0.1328754650	class contains
0.1328687031	analogous to
0.1328196084	possibly different
0.1327478948	involves only
0.1327174436	dimensional distribution
0.1327068405	bounded from above by
0.1326501887	as long as
0.1325865544	against outliers
0.1325810526	recent interest
0.1325747506	demonstrated via
0.1325340041	the unit ball
0.1325024292	$ d \ geq
0.1324590962	and also to
0.1324276588	r \
0.1324114003	the directions of
0.1323901352	a natural extension
0.1323756860	the uncertainty of
0.1323756860	the convergence to
0.1323446969	in high dimensional linear
0.1323415013	led to
0.1323411026	to ensure
0.1323157792	separation between
0.1323118746	the maximum likelihood
0.1322176622	x_i =
0.1321880552	this question
0.1321604493	markov bases of
0.1321538029	the convex hull
0.1321302695	this work proposes
0.1321260388	$ nearest neighbor
0.1320686874	at high frequency
0.1320501150	large values of
0.1320484477	bayesian estimation of
0.1320237654	regularized least
0.1320176028	generalize well
0.1319115444	bounded away
0.1318982161	variety of
0.1318736509	the second stage
0.1318570554	method based on
0.1318427331	a theoretical perspective
0.1318312260	two random vectors
0.1318108848	2 \ beta +
0.1317949724	in many applications
0.1317908830	developed by
0.1317802602	the oracle estimator
0.1317413730	central limit theorem in
0.1317290389	two steps
0.1317119348	not clear
0.1316428030	nature of
0.1316395617	fit into
0.1315422811	obtained via
0.1315173903	often involves
0.1314156480	to improve
0.1314037901	results about
0.1313877487	condition on
0.1313793775	looking at
0.1313792053	density estimation on
0.1313756860	the observations in
0.1313756860	in distribution to
0.1313664766	two data sets
0.1313405296	to generate
0.1313379502	the bandwidth of
0.1313374213	conditioned on
0.1313178149	p \ rightarrow \ infty
0.1313086781	new algorithm
0.1312332564	most recent
0.1312255608	obtained through
0.1311374388	provide conditions under
0.1311243522	the adaptive lasso
0.1310855845	_ i = 1 ^
0.1310705579	a linear transformation
0.1310365037	$ r_0
0.1309221527	bias than
0.1309211864	an efficient algorithm
0.1308800611	a loss of
0.1308724093	other methods
0.1307714076	exposed to
0.1307700152	$ \ alpha = 1
0.1307314685	this work
0.1307102508	asymptotic results for
0.1306934061	start by
0.1306717770	theta =
0.1306566549	\ log p
0.1306480392	asymptotic equivalence of
0.1306463945	a unified theory
0.1305710448	r estimators
0.1304545458	$ \ varepsilon 0
0.1304525732	_ i \ in \
0.1304236334	an extensive
0.1303728334	$ convergence
0.1303576419	ideas from
0.1303496340	\ mathcal e
0.1303495351	particularly interested
0.1303379502	the index of
0.1302322393	\ log ^ 2
0.1301795332	the global optimum
0.1301780670	the topic of
0.1301363158	lasso +
0.1301310836	the unknown function
0.1301273332	data consist of
0.1301059603	frequentist coverage of
0.1300686451	the literature
0.1300569447	z estimation
0.1300447852	the diffusion coefficient
0.1300443855	a theoretical analysis
0.1300348596	class of statistical
0.1299967286	from noisy data
0.1299928321	large classes of
0.1299629105	random fields on
0.1299061223	formula for
0.1298875154	the geometric median
0.1298806900	common practice in
0.1298558802	\ theta ^ 0
0.1298414729	function belongs to
0.1298152666	also presented
0.1298037605	specific class of
0.1297840416	introduction to
0.1297716929	one group
0.1297621127	estimators for
0.1296590962	and not on
0.1296511209	studied by
0.1296492930	limit behavior of
0.1295756914	an instrument
0.1295495454	treated as
0.1294640186	oracle inequality for
0.1294470342	computed using
0.1294214237	an algorithm
0.1294147471	different regimes
0.1294051330	with probability 1
0.1294012644	very recently
0.1293756860	the classification of
0.1293756860	the treatment of
0.1293736645	\ to \ mathbb r
0.1293698080	\ mathbf z
0.1293558079	the central subspace
0.1292860431	$ 0
0.1292703001	validated by
0.1292557411	approach to estimation
0.1292412612	via simulations
0.1292290160	test statistics under
0.1292081896	fundamental limits of
0.1291825478	to analyze
0.1291438257	$ \ bf
0.1291413768	\ mathbb r ^ n
0.1291125000	characteristics of
0.1291120039	the local geometry
0.1290976780	some interesting
0.1290949626	unknown regression
0.1290698655	nonparametric estimator of
0.1290561192	a convex program
0.1290288994	so as to
0.1290219180	formulas for
0.1290052109	these algorithms
0.1289982272	an important problem
0.1289924795	to quantify
0.1289848495	m g
0.1289766222	the maximum likelihood estimation
0.1289740178	order 1
0.1289524420	results concerning
0.1289256969	allowing for
0.1289104532	for linear regression models
0.1288676124	a two step procedure
0.1288619924	guided by
0.1288375085	\ theta \ in \ theta
0.1287533713	\ arg
0.1287185620	work aims
0.1287097030	$ \ pi_0
0.1286686100	comparison between
0.1286512987	an appropriate
0.1286253582	_n =
0.1286138802	the current status
0.1285831997	\ sigma_1
0.1285717145	various types
0.1285461129	risk over
0.1285005386	$ \ mu_
0.1284920509	an intuitive
0.1284623089	corrupted by
0.1284598736	n \ rightarrow 0
0.1283982976	the asymptotic distribution
0.1283524296	to compare
0.1282293512	new technique
0.1282226567	in ultra high
0.1282204462	much smaller than
0.1282138109	played by
0.1282042363	in terms of
0.1281756860	the size and
0.1281084726	existing work
0.1281072590	non parametric estimator
0.1281019890	an interval
0.1280839715	\ bbb
0.1280776566	\ beta_i
0.1280583056	performance guarantees for
0.1280361418	resulting from
0.1280343232	\ tau_
0.1279843836	information criteria for
0.1279730606	converging to
0.1279546937	$ a \
0.1279509054	insensitive to
0.1279014665	intervals based on
0.1278970181	necessary and sufficient condition
0.1278797821	to handle
0.1278372253	the iid case
0.1278336262	$ a_0
0.1278254158	under very mild
0.1278253900	numerical experiments on
0.1277656478	handled by
0.1277608385	data example
0.1277540751	also extend
0.1277399398	to illustrate
0.1276631072	by minimizing
0.1276452685	maximum likelihood estimators in
0.1275943492	as opposed
0.1275506525	completely different
0.1275328214	more complex
0.1275229083	in dependence of
0.1275208867	of nodes in
0.1275056298	then apply
0.1274895945	the usual
0.1274692432	the minimum description
0.1273756860	the independence of
0.1273756860	the condition of
0.1273709938	several interesting
0.1273220891	d = 1
0.1272960571	various settings
0.1272512823	often require
0.1272169465	two populations
0.1271474607	a common approach
0.1271110683	copies of
0.1271057952	full posterior
0.1270935835	grow at
0.1270766206	| \ leq
0.1270735515	of gaussian random fields
0.1270728307	good practical
0.1270662633	also established
0.1270417622	the sample space
0.1270368518	also develop
0.1270141811	\ x_i \ _ i
0.1270080859	two group
0.1269787978	consistency properties of
0.1269696702	further improve
0.1269562285	correlation between
0.1269260622	needs to
0.1268496079	these rates
0.1267831219	designed to
0.1267025247	^ c
0.1266531325	invariant under
0.1265873783	very weak
0.1265299358	metric entropy of
0.1265258312	mean response
0.1264666452	inference about
0.1264347359	all nodes
0.1264213352	approach leads to
0.1264203015	n \ times n
0.1263788721	estimation of smooth
0.1263736645	the surface of
0.1263697324	more recently
0.1263498733	a short
0.1263453855	prediction performance of
0.1262827347	\ sqrt \ frac
0.1262568018	matrix completion with
0.1262042886	\ hat \ psi
0.1261958628	this paper aims
0.1261864882	in such settings
0.1261723117	through simulations
0.1261261562	bayesian analysis of
0.1260999407	$ \ tilde
0.1260945852	tools from
0.1260277662	n 2
0.1260181055	criteria based on
0.1259826364	geometric structure of
0.1258874533	dt \
0.1258819438	each point
0.1258593117	tests for
0.1258587722	$ n ^ \ frac
0.1258100655	0,1 ^
0.1257551095	these quantities
0.1256843154	tool for
0.1256512533	\ _i
0.1256102745	$ p n \ rightarrow
0.1256014685	up to
0.1255640111	assumptions made
0.1255297846	^ s
0.1255271213	not only
0.1255037493	nonparametric test for
0.1254527458	high dimensional non
0.1253906976	of ill posedness
0.1253806847	suprema of
0.1253638348	provided by
0.1252751024	relied on
0.1252685598	the likelihood function
0.1251979642	pairs of
0.1251909453	an initial
0.1251379502	a model to
0.1250899926	+ q
0.1250457085	degree d
0.1250317030	under certain regularity
0.1250250203	$ \ delta_
0.1250077313	\ mathbb r _ +
0.1249849720	this property
0.1249795669	new challenges
0.1249649696	becomes large
0.1249494744	a wide range of
0.1249490627	also prove
0.1249459138	a single sample
0.1249208265	defined over
0.1249165053	the identity matrix
0.1248761060	this case
0.1248066649	asymptotic theory of
0.1247811874	^ \ nu
0.1247807486	4 \ alpha
0.1246831416	not always
0.1246299424	requires only
0.1246073809	deduced from
0.1245987302	x_i ^
0.1245966535	$ \ rm
0.1245957523	$ f_1
0.1245316427	estimation of linear
0.1244472648	\ end
0.1244464469	the linear regression model
0.1243791795	benefit from
0.1243480317	the social sciences
0.1243222115	spectral representation of
0.1242493153	m n
0.1242105513	simulations show
0.1240545663	a wide variety of
0.1240373740	as good as
0.1240339468	eigenvalues of
0.1240131073	spectral distribution of
0.1240019738	class of stochastic
0.1239972391	also obtained
0.1239948646	especially useful
0.1239649508	the kernel density estimator
0.1239438997	any restriction
0.1239338400	holds for
0.1239265008	scale mixture of
0.1239225884	by deriving
0.1239091361	in science and
0.1238964445	confidence bounds for
0.1238904147	the dimension increases
0.1238734376	the asymptotic variance
0.1238525327	sample size n
0.1238223218	first moments
0.1238193218	coincide with
0.1237733533	$ block
0.1237677314	appears to
0.1237524278	also derived
0.1237386266	an infinite
0.1236982395	more stable
0.1236928387	a fast algorithm
0.1236831806	y x
0.1236732263	the drift parameter
0.1236683399	many applications
0.1236278608	in sup norm
0.1236211261	make use of
0.1236152261	established under
0.1235777448	$ n \ gg
0.1235398134	a fractional brownian
0.1235353991	$ m_0
0.1235174143	also investigate
0.1234792256	to build
0.1234343882	an essential
0.1234290016	well known problem
0.1234195424	through extensive
0.1233398788	an unknown matrix
0.1233378543	choice of
0.1233116612	asymptotics for
0.1233072997	through numerical
0.1233062017	sufficient conditions on
0.1232567794	the alternative hypothesis
0.1232506340	no information
0.1232440517	the slope function
0.1232229268	best known
0.1231896382	\ max
0.1231702510	by integrating
0.1231382580	x_i +
0.1231360474	cross validation for
0.1231250725	the true underlying
0.1230843381	the total variation
0.1230800097	modelled by
0.1230666383	of outliers in
0.1229865218	the above mentioned
0.1229491881	function f
0.1229337784	to implement
0.1228957670	= \ theta
0.1228918195	covered by
0.1228626429	by studying
0.1228492829	these problems
0.1228392405	suited for
0.1228298481	two cases
0.1228218725	very general
0.1227647183	a central role
0.1227524206	act as
0.1227459538	emerged as
0.1226859843	^ r
0.1226790187	\ sigma_0
0.1226281254	these findings
0.1226051386	numerical results show
0.1225800081	in observational studies
0.1225718081	important problem in
0.1225391876	also illustrate
0.1224798104	also derive
0.1224648495	also shown
0.1224492264	$ statistic
0.1224433983	without loss
0.1224122752	$ \ bolds
0.1224117504	uniform consistency of
0.1223790457	theoretical side
0.1223789684	solved by
0.1223756860	the information in
0.1223672514	means under
0.1223604923	inference for
0.1223453761	weighted least
0.1223452130	$ wasserstein
0.1223379502	the volatility of
0.1223134929	event of interest
0.1223035438	3 2
0.1222874060	order to achieve
0.1222368781	$ n ^ 3
0.1222015764	estimated from
0.1221729556	= 1 ^
0.1221633265	dimension d
0.1220561836	a heavy tailed
0.1220129988	a fairly general
0.1219528381	a new central limit theorem
0.1219412852	by considering
0.1219267476	method relies on
0.1219186738	to calculate
0.1218538256	estimates of
0.1218440080	only requires
0.1217968703	adapt to
0.1217913599	a strong law of large numbers
0.1217844607	| \ theta
0.1217368096	an adversary
0.1217289938	between nodes
0.1217226567	quantified by
0.1216816536	the cumulative distribution function
0.1216678919	alpha 1
0.1216502929	processes driven by
0.1216404260	a wide class
0.1216344808	a power law
0.1216271990	under weaker assumptions
0.1216175075	more easily
0.1215943903	the weak topology
0.1215941602	coverage probabilities of
0.1215851376	many interesting
0.1215738316	constraints on
0.1215163305	general form of
0.1214891247	g family
0.1214407682	the problem of testing
0.1214407591	a general result
0.1213771638	\ sqrt n \ log
0.1213565404	a note on
0.1213102964	adapts to
0.1211795444	autoregressive models with
0.1211350410	also establish
0.1211277617	an in depth
0.1210988689	also called
0.1210985195	also studied
0.1210447567	three parameters
0.1210433854	first step
0.1210117145	$ minimization
0.1209922421	as well
0.1209907295	existing results on
0.1209747089	a semi parametric
0.1209693717	asymptotically normal under
0.1209653978	k \ epsilon
0.1209588636	some specific
0.1209153981	fundamental problem of
0.1208906252	\ boldsymbol \ beta
0.1208462657	certain sense
0.1208304827	each case
0.1208209296	spectral gap of
0.1208063651	ratio between
0.1207880775	\ _
0.1207830031	parameter estimation of
0.1207683604	asymptotic performance of
0.1207552753	defined in terms of
0.1207483148	further demonstrate
0.1207244112	estimation method for
0.1206552455	$ recovery
0.1206423169	each observation
0.1206088003	$ p_k
0.1205826982	\ ge 3
0.1205684460	the fact
0.1205195236	the finite sample
0.1205073858	does not involve
0.1204942167	concentrate on
0.1204934390	$ family
0.1204711595	integral over
0.1204450306	quite different
0.1203771209	a low rank
0.1203654220	any order
0.1203572907	$ d_
0.1203201534	does not need
0.1203079277	1 + 1
0.1203038771	\ geq 2
0.1202890478	an em
0.1202811003	$ f_0
0.1202746840	\ delta 0
0.1202395162	\ geq 3
0.1202200033	$ d \ geq 2
0.1201396810	this method
0.1201350739	bounded by
0.1201034443	a strictly stationary
0.1200955226	both cases
0.1200702748	critical points of
0.1200686599	the upper and
0.1200686599	in probability to
0.1200510407	then extend
0.1200478270	methods for
0.1200393774	the hessian
0.1200204875	a linear model
0.1200005422	10 ^
0.1199721630	most commonly
0.1199470865	asymptotic distribution under
0.1199468583	problem of parameter
0.1198800774	difference in
0.1198761595	explicit form of
0.1198756849	inferred from
0.1198690750	theta |
0.1198642624	$ metric
0.1198494404	density f
0.1197742430	+ b
0.1197589175	method uses
0.1197237360	many cases
0.1197047227	$ stable
0.1196891495	two main
0.1196231127	d \ geq 2
0.1195297746	an estimator
0.1195168338	moment conditions on
0.1194671342	gaps in
0.1194667566	$ d \ ge
0.1194611993	a selective
0.1193951853	small subset of
0.1193529260	very fast
0.1193474814	discussion of
0.1193441099	theoretical support for
0.1192598414	these approaches
0.1192002496	the space of probability measures
0.1191897086	a wavelet based
0.1191453488	sample of size n
0.1191447102	time step
0.1191201331	the multi armed
0.1191051527	the computational burden
0.1190769567	an approximate
0.1190553966	values at
0.1190475607	\ sum_ k
0.1189713706	restrictions on
0.1189526225	m ^ \ star
0.1189307359	\ mathcal f
0.1189102089	$ q = 1
0.1189052723	some sense
0.1188992485	systems with
0.1188933317	of center outward
0.1188253863	also apply
0.1188136925	joint density of
0.1187920830	best approximation
0.1187905109	\ frac \ log
0.1187739543	a nearly optimal
0.1187707014	distribution of
0.1187625179	a gaussian prior
0.1187275298	k n
0.1187075300	the chi square
0.1186795920	different groups
0.1186211338	sequential detection of
0.1186202551	recovered from
0.1185928257	i = 0
0.1185902557	the memory parameter
0.1185850980	further extend
0.1185596417	these cases
0.1185475516	powerful than
0.1185194582	significantly more
0.1185074027	$ c_
0.1184987421	$ 1 \ alpha
0.1184688289	adaptive version of
0.1184687960	of phylogenetic trees
0.1184414380	unbiased estimator of
0.1184045542	also obtain
0.1183829246	the sup norm
0.1183396078	more important
0.1183274387	more efficient
0.1183078841	fields such as
0.1183031656	not directly
0.1182848221	two real data
0.1182566584	known in advance
0.1182504673	some examples
0.1182133885	$ component
0.1181993036	^ \ omega
0.1181725638	by adapting
0.1181703454	very few
0.1181515663	exploited to
0.1181244744	the same
0.1181196854	general assumptions on
0.1180853757	two samples
0.1180485007	\ br
0.1180471490	built from
0.1180461154	test statistic under
0.1180444573	a stochastic process
0.1180423445	stable l \
0.1180203932	+ \ beta
0.1180201765	true value
0.1180002381	key role in
0.1179880639	a natural
0.1179720934	a large class of
0.1179710418	^ \ rm
0.1179572370	ill posedness of
0.1179530993	$ means
0.1179489749	$ f_
0.1179313032	two approaches
0.1179243396	statistical guarantees for
0.1178951429	\ to \ mathbb
0.1178515465	theoretical analysis of
0.1178253396	problem into
0.1178215258	\ mathbb r ^ +
0.1178206124	offered by
0.1177723001	distinct from
0.1177426243	$ \ vartheta
0.1177258637	to noise
0.1177250430	estimation of density
0.1177250423	under appropriate conditions
0.1177110210	fail to
0.1176926835	a small simulation
0.1176912190	prone to
0.1176822305	not satisfied
0.1176685149	sets of
0.1176604156	while allowing
0.1176576717	these theoretical results
0.1176422089	$ distance
0.1176401602	selection via
0.1176035269	estimators in high
0.1175914940	int \
0.1175738955	dependence on
0.1175553664	a single parameter
0.1175242054	= \ alpha
0.1175084178	performance bounds for
0.1175051316	by projecting
0.1174703956	several important
0.1174433481	a fundamental problem
0.1174330275	characterizations of
0.1173825749	an optimization problem
0.1173783569	the origin
0.1173740824	$ d = 1
0.1173723184	$ p_x
0.1173179411	a precise characterization
0.1172929575	these procedures
0.1172748819	terms of
0.1172424145	maximum likelihood estimator in
0.1171957820	for self normalized
0.1171926906	small values of
0.1171413634	a simple test
0.1171177825	1 4
0.1170775820	an extension of
0.1170598741	some applications
0.1170299877	$ fdp
0.1170074910	inference under
0.1169985429	well known results
0.1169544126	other words
0.1169109153	two types of
0.1168955107	natural extension of
0.1168607414	good statistical
0.1168417578	the asymptotic null
0.1168356105	q = 1
0.1168335434	an accurate
0.1168149230	= \
0.1167753226	widely used in
0.1167228788	$ \ mathcal g
0.1167146355	and sufficient for
0.1167054998	other approaches
0.1166832124	generally not
0.1166752143	model with
0.1166609103	function defined on
0.1166216228	$ moment
0.1165874338	correlation among
0.1165818750	estimator converges to
0.1165789421	estimation rate
0.1165775245	in large dimensions
0.1165762036	also demonstrate
0.1165759783	algorithms for
0.1165505629	kernel estimator of
0.1165391374	an appropriate choice
0.1165102597	a random walk
0.1164949791	v s
0.1164873520	\ phi_p
0.1164407682	the problem of learning
0.1164324396	the new test
0.1164149537	$ \ log
0.1164100503	sampling distribution of
0.1164078174	an elementary
0.1163504864	to allocate
0.1163049149	take advantage of
0.1163048006	some simulations
0.1163043501	a large collection
0.1162812876	\ alpha 1 2
0.1162731556	two important
0.1162591314	denote by
0.1162466576	by proving
0.1162389238	an intriguing
0.1162029973	$ 1
0.1161649901	procedure proposed by
0.1161523634	\ mathbf w
0.1161293121	effects under
0.1161174950	processes with
0.1161111239	very general conditions
0.1160929882	a wide class of
0.1160683218	also considered
0.1160592749	very close
0.1160455123	different dimensions
0.1160373957	paper provides
0.1159875880	by providing
0.1159848892	a general setting
0.1159168173	the post change
0.1158990505	relate to
0.1158959494	all cases
0.1158943748	the unknown density
0.1158828501	separated from
0.1158818024	$ \ theta_
0.1158675385	an additive
0.1158566658	the problem of parameter estimation
0.1158538256	approximation of
0.1158415929	two point
0.1158258124	a challenging problem
0.1158170303	by discussing
0.1158110672	to alleviate
0.1157951724	estimation for linear
0.1157837189	tuned to
0.1157529802	a non trivial
0.1157250430	estimation of regression
0.1156975411	an i.i.d
0.1156963107	results allow
0.1156672442	a low dimensional
0.1156659985	$ y_1
0.1156477825	by allowing
0.1156393442	computational time
0.1155820183	paper aims at
0.1155599806	estimated via
0.1155462778	a cross validation
0.1155157334	a log concave
0.1155120465	other measures
0.1154937157	the main goal
0.1154607690	$ \ sqrt
0.1154478771	an auxiliary
0.1154477992	the principal subspace
0.1154340217	associated with
0.1154242838	method for
0.1153913266	$ t ^ 2
0.1153490054	in order to avoid
0.1153433565	the main
0.1152836828	alpha 0
0.1152192571	algorithm based on
0.1152041590	various examples
0.1151846061	$ o
0.1151707014	estimators of
0.1151537577	testing for
0.1151496499	bias due to
0.1151376633	quality of
0.1151190639	to extract
0.1151097957	very low
0.1150849742	_n = \
0.1150636363	this gap
0.1150409005	results for
0.1150088667	k \ log
0.1150075293	heaviness of
0.1150071991	a broad class
0.1149932014	state of
0.1149665914	a given number
0.1149621141	notions of
0.1149578185	computed from
0.1149436840	considered as
0.1149396441	faced with
0.1148547171	$ process
0.1148367921	kinds of
0.1148361589	certain conditions
0.1147560008	the proof relies
0.1147024334	any dimension
0.1146828759	relatively large
0.1146673499	by showing
0.1146563540	classification under
0.1146393797	the unknown parameter
0.1145820584	model selection for
0.1144770236	used in practice
0.1144401777	do not exist
0.1144401352	combination of
0.1144373717	$ v_
0.1144330390	$ regularization
0.1143787279	advantage of
0.1143758678	also introduce
0.1143530252	result regarding
0.1143486990	by utilizing
0.1143321376	general conditions on
0.1143151622	the parametric component
0.1143081897	$ t_n
0.1142733423	x_n \
0.1142575141	a byproduct
0.1142322685	inequalities for
0.1142244112	asymptotic distributions of
0.1141999374	based method for
0.1141896415	this model
0.1141884840	cross validation in
0.1141666184	the selected estimator
0.1141285884	perturbed by
0.1141199609	with hurst parameter
0.1140872870	the optimal filter
0.1140769732	the second step
0.1140711437	inference based on
0.1140684863	the beta process
0.1140559367	long memory in
0.1140402088	the true covariance
0.1140218632	distribution belongs to
0.1140164236	$ \ alpha \ in
0.1139979667	obtained using
0.1139954573	different approaches
0.1139867960	cast as
0.1139561002	nonparametric tests for
0.1139331890	zero coefficients
0.1138130299	oracle inequalities with
0.1138091198	give explicit
0.1138045185	the sparsity pattern
0.1137950665	one or more
0.1137790709	an attractive
0.1137761450	the input space
0.1137728528	$ h_1
0.1137177458	imposed by
0.1136884513	the last decade
0.1136843949	$ k \ geq
0.1136678923	three cases
0.1136649677	a multivariate distribution
0.1136639406	estimation in high
0.1136528775	q 1
0.1136484026	for locally stationary
0.1136364979	a first step
0.1136262006	growing interest
0.1136215578	give sharp
0.1136104511	general result on
0.1135543221	exit time
0.1135407568	necessary condition
0.1135034181	an online
0.1134726934	characterized in terms of
0.1134634397	no assumptions
0.1134559575	\ bbb r
0.1133154265	strategy based on
0.1133112031	a decision theoretic
0.1132747472	very simple
0.1132664245	much better
0.1132337233	with missing data
0.1132329547	this estimator
0.1132042701	curse of
0.1131942995	results indicate
0.1131764220	used to obtain
0.1131634116	also investigated
0.1131574069	moments of
0.1131358830	derived using
0.1130084338	on cran
0.1129661642	$ n_1
0.1129601201	by constructing
0.1129526040	not too
0.1129345673	known covariance
0.1129127694	$ m
0.1128948231	\ rightarrow \ mathbb
0.1128834768	zero entries
0.1128462559	data from
0.1128453411	representations of
0.1128280894	two applications
0.1128001640	same asymptotic distribution
0.1127983156	these inequalities
0.1127946355	approximation to
0.1127674954	new methodology
0.1126875327	the classical
0.1126790752	exact distribution
0.1126525473	suffices to
0.1126458257	rho ^
0.1126281589	each group
0.1125802182	a max stable
0.1125504257	fixed time
0.1125468286	appropriate conditions
0.1125361445	first establish
0.1125107216	emphasis on
0.1125066172	in contrast to
0.1124541123	particular cases
0.1124310531	= \ sum_ j
0.1124281766	response y
0.1124266031	$ q
0.1123954701	the nonparametric maximum likelihood
0.1123913079	$ \ sum_ i = 1
0.1123563602	$ q_n
0.1123375128	encoded by
0.1123312244	other cases
0.1123146784	optimality properties of
0.1122941634	$ \ | \ cdot
0.1122541977	important role in
0.1121936377	different types of
0.1121614605	computationally more
0.1121464377	the left and
0.1121196654	some mild
0.1120871894	then derive
0.1120601201	by comparing
0.1120516322	$ \ mathbb r ^ d
0.1120439534	much lower
0.1120236663	by establishing
0.1120100382	very good
0.1120093847	imposed on
0.1120063949	inference via
0.1119852873	$ x_ 1
0.1119414594	concentrated on
0.1119176696	various applications
0.1118953148	breakdown point of
0.1118715862	$ 1,1
0.1118704473	$ \ lambda_
0.1118682636	illustrated on
0.1118561536	with applications to
0.1118057612	a computationally efficient
0.1118036358	in most cases
0.1117812933	x_t ^
0.1117780429	| f
0.1117363722	provide examples of
0.1117162690	the test statistics
0.1116992635	an extra
0.1116721077	non asymptotic lower
0.1116553128	suggested by
0.1116551935	the main results
0.1116334923	by analyzing
0.1116315374	important applications in
0.1116267537	believed to
0.1116267537	contributes to
0.1115951826	$ \ mathfrak
0.1115854778	to derive
0.1115745141	by combining
0.1115643289	$ \ sigma_
0.1115502619	best invariant
0.1115380119	algorithm for
0.1114939344	novel methodology
0.1114827778	work extends
0.1114347796	$ lipschitz
0.1114314978	a fundamental
0.1114117383	learned from
0.1113807769	various classes
0.1113790576	crucial role in
0.1113550264	$ m_
0.1113246481	sensitive to
0.1113125641	the supremum norm
0.1112984286	= 0,1
0.1112844155	minimax optimality of
0.1112373609	up to constants
0.1111567184	quadratic forms in
0.1111269750	f _
0.1111172686	overview of
0.1110302989	advent of
0.1109698209	formulated in terms of
0.1109394882	demonstrated by
0.1109218836	inference methods for
0.1109127694	$ d
0.1108920364	\ log k
0.1108856261	a chi squared
0.1108615099	practical interest
0.1108284134	$ 0 \ le
0.1108235165	matching upper and
0.1108223054	$ ball
0.1108216846	many situations
0.1108182017	$ n \ times
0.1107965173	$ x \ in \ mathbb
0.1107928039	kind of
0.1106902102	a geometrical
0.1106811861	$ p_0
0.1106778171	based on kernel
0.1106765637	by replacing
0.1106709254	a key
0.1106631766	depends only
0.1106510620	investigated through
0.1106403940	n \ to \ gamma
0.1106106166	n n
0.1105381003	\ mathfrak c
0.1105266350	= 1 2
0.1105154382	very useful
0.1105142952	the entire
0.1104595545	without additional
0.1104532685	for functional data
0.1104384997	l ^ \ infty
0.1104207188	results on
0.1104151718	tail behavior of
0.1104138634	through simulation
0.1103937196	probability 1
0.1103670052	this assumption
0.1103542804	an inhomogeneous
0.1103456387	= x
0.1103446499	theorems for
0.1102654852	order than
0.1102581260	also proved
0.1102158462	an inverse problem
0.1102041291	evaluation of
0.1102024788	new test
0.1101940894	posterior consistency for
0.1101722898	shrinkage estimation of
0.1101653074	more likely
0.1101534675	and real data sets
0.1101379622	theoretical work
0.1101259139	no assumption
0.1101204375	mean residual
0.1101094885	e ^
0.1101032822	response given
0.1100642771	placed on
0.1099973329	x \ theta
0.1099726497	some additional
0.1099623403	and massam
0.1099535074	a general class
0.1099311861	$ m_n
0.1098936452	through examples
0.1098667363	detect changes
0.1098327776	$ \ sigma ^ 2
0.1098163947	$ \ mathit
0.1098143492	the probability simplex
0.1098059552	by investigating
0.1098056244	derivation of
0.1097841297	\ bf x
0.1097835097	test for
0.1097776612	this phenomenon
0.1097457051	for estimating
0.1097334167	converges in probability to
0.1097054296	arise in
0.1096993100	interaction between
0.1096943441	statistical tests for
0.1096134800	for binary classification
0.1096029595	by presenting
0.1095059590	nonparametric methods for
0.1095031857	large numbers of
0.1094886584	continues to
0.1094837345	derived under
0.1094784875	new goodness of fit
0.1094574459	\ sqrt k
0.1094521016	generalizations of
0.1094277531	$ \ frac
0.1094047515	the main focus
0.1093872668	driven method for
0.1093720658	three real
0.1093398432	better performance
0.1093363993	$ \ pi_
0.1093229894	empirical work
0.1093142022	p = 2
0.1092869659	$ k
0.1092851193	new representation
0.1092343375	under minimal
0.1092300074	the quotient
0.1092263290	then propose
0.1092225540	reduces to
0.1092083390	more than
0.1092058558	also reveal
0.1091923166	computed by
0.1091908678	assumption on
0.1091832515	the degree corrected
0.1091780559	this fact
0.1091710337	integrated mean
0.1091600146	such as
0.1091455084	by virtue of
0.1091450407	analysis aims to
0.1091173765	less sensitive
0.1091101732	estimation over
0.1091065910	powerful tool to
0.1090908018	studied under
0.1090830039	well posedness of
0.1090702279	_n \
0.1090411731	an oracle
0.1090223979	gained from
0.1089917476	statistic based on
0.1089897651	\ leq 2
0.1089148870	one or two
0.1088994387	second moments
0.1088869659	$ f
0.1088697114	and slab priors
0.1088537255	performed by
0.1088446598	achievable by
0.1087774309	invariance under
0.1087602501	different methods
0.1087111560	$ g
0.1086932845	given data set
0.1086891299	framework for
0.1086869659	$ p
0.1086857155	each time point
0.1086661990	$ \ overline
0.1086441814	in signal processing
0.1086294839	th order
0.1086282374	absence of
0.1085812207	$ r = 1
0.1085742045	then applied
0.1085709481	markov chains with
0.1085363266	many areas
0.1085294911	a social network
0.1085279609	some special
0.1085249816	small fraction of
0.1084318410	an abrupt
0.1083969798	further develop
0.1083849317	$ h_
0.1083845688	used to assess
0.1083765425	a constant
0.1083607682	sequence of
0.1083446220	arising in
0.1083419045	each variable
0.1082988305	observation time
0.1082912830	1 +
0.1082487297	diffusion processes with
0.1082131098	any specific
0.1082050940	forms of
0.1081942290	on spheres
0.1081870682	further propose
0.1081666462	coupled with
0.1081464594	many important
0.1081257822	the nuclear norm
0.1081026941	iterative algorithm for
0.1080893455	\ mathbb c ^
0.1080857770	by letting
0.1080661846	also compare
0.1080612322	regularity conditions on
0.1080611321	theory provides
0.1080085120	quantities such as
0.1080036255	employed to
0.1079962348	a few
0.1079869431	guidance on
0.1079573668	an abstract
0.1079516904	central role in
0.1079412519	$ \ sigma_n
0.1079367732	at random
0.1079248006	directly from
0.1078974748	consistent under
0.1078899188	the phase transition
0.1078890523	$ projection
0.1078798094	results presented in
0.1078334284	under suitable
0.1078313445	the theoretical results
0.1078203191	first develop
0.1078129026	an optimal rate
0.1078010379	a polynomial time algorithm
0.1077938188	no prior
0.1077898591	the self similarity
0.1077898125	covariance matrix of
0.1077833637	weighted average of
0.1077707867	derive new
0.1077626931	estimated using
0.1077503500	_i \
0.1076912523	any prior
0.1076678805	$ \ langle
0.1076458129	mean zero
0.1076302941	$ \ theta_1
0.1075857770	by examining
0.1075685576	the purpose
0.1075626809	many samples
0.1075262873	develop new
0.1075175966	an outcome
0.1075006873	segregation and
0.1074506715	role in
0.1074440028	$ t \ to \ infty
0.1074426044	follow from
0.1074422562	more common
0.1074395639	not hold
0.1074186885	nodes with
0.1074124915	many algorithms
0.1074104757	$ risk
0.1073651799	separated by
0.1073600325	give rise
0.1073464377	$ independent and
0.1073376269	an observation
0.1073259380	$ \ varrho
0.1073238702	and v statistics
0.1073043138	correction for
0.1072924629	$ k_
0.1072856888	d = 2
0.1072767904	$ w_
0.1072720286	a small subset
0.1071976498	no additional
0.1071830254	and tao
0.1071799394	justified by
0.1071635322	does not rely on
0.1071306796	a characterization
0.1071222784	almost optimal
0.1070994046	in many fields
0.1070950182	model selection via
0.1069923568	the introduction
0.1069629659	further establish
0.1068624133	approaches zero
0.1068336906	asymptotically normal with
0.1068157358	building on
0.1067610122	distribution in terms
0.1067562694	less sensitive to
0.1067315098	any alternative
0.1066856748	consistency of maximum
0.1066694190	than existing
0.1066683101	a chi square
0.1066630202	any continuous
0.1066445575	the ising
0.1066347849	the number of parameters
0.1066121920	also propose
0.1065799126	fails to
0.1065734230	guarantees for
0.1065679965	agreement with
0.1065657408	$ o \ left
0.1065645195	$ p_1
0.1065204793	$ concave
0.1065151055	the empirical characteristic
0.1065011305	two decades
0.1064944639	parameter value
0.1064607085	r ^ 3
0.1064222671	$ u
0.1063658441	$ m_2
0.1063443273	a polynomial rate
0.1063091759	up to logarithmic
0.1062954498	areas such as
0.1062923066	a practical point of view
0.1062633875	a popular approach
0.1062151965	two alternative
0.1062141761	starts with
0.1062033078	not unique
0.1061138092	phase transition in
0.1061057370	some conditions
0.1060728818	zero one
0.1060719217	illustrated using
0.1060625373	includes many
0.1060563031	evaluated by
0.1060509282	m = n
0.1060285235	conjectured by
0.1060184656	$ contamination
0.1060129330	the number of nodes
0.1059672089	$ loss
0.1059654112	$ k = 1
0.1059538113	also addressed
0.1059389117	then develop
0.1059124609	covariance matrix from
0.1059093738	an edge
0.1058881408	data set from
0.1058285859	but not necessarily
0.1058214911	an elliptic
0.1057901502	most important
0.1057643865	\ cal m
0.1057601105	of order 1
0.1057026205	\ in 0
0.1056614148	unified framework for
0.1056554133	understanding of
0.1056452629	aiming to
0.1056292843	investigate whether
0.1056283313	order k
0.1056059765	performed using
0.1056038369	the number of samples
0.1055968810	model with random
0.1055562888	\ ge 2
0.1055549846	one component
0.1055150399	not exist
0.1054999601	a non asymptotic
0.1054883321	for linear spectral statistics
0.1054397326	named as
0.1054350706	$ \ alpha 1
0.1054117417	$ a_n
0.1054086922	a data set
0.1053807159	$ n
0.1053702131	first introduce
0.1053454873	at infinity
0.1053452179	by numerical simulations
0.1053126460	foundation for
0.1052961069	different fields
0.1052846494	solution to
0.1052596808	conclude by
0.1052501725	a certain sense
0.1052158584	the true probability
0.1051940807	the current paper
0.1051852771	to provide
0.1051710323	$ 0 \ alpha
0.1051561420	the resulting
0.1051559898	as corollaries
0.1051369197	used to quantify
0.1051332595	any additional
0.1051187121	by taking
0.1051104950	a so called
0.1051019036	this situation
0.1050775007	n m
0.1050562180	an unknown probability
0.1050333662	the unknown regression
0.1050289202	derived by
0.1050054222	form expression for
0.1049838668	an asymptotic framework
0.1049790403	new algorithms
0.1049745320	these assumptions
0.1049641861	$ x_k
0.1049611915	likelihood estimation of
0.1049546380	bases for
0.1049019186	choices of
0.1049011841	full likelihood
0.1048944764	= \ sigma
0.1048516469	real data from
0.1048490144	$ 2 \ times
0.1048465411	attention to
0.1048302493	adaptive over
0.1048016964	consistency result for
0.1047995989	learning rates for
0.1047971070	a high frequency
0.1047947356	$ b_n
0.1047834408	this letter
0.1047634534	aspect of
0.1047178053	reduced to
0.1046991543	based approach to
0.1046636352	asymptotic expansions of
0.1046493808	$ aggregation
0.1046245591	posed by
0.1046166547	not true
0.1045955537	the observed process
0.1045729889	structural changes in
0.1045578844	+ d
0.1045408904	in turn
0.1044978672	two or more
0.1044909014	$ tensor
0.1044825940	the finite sample behavior
0.1044821391	modeled using
0.1044569979	p \
0.1044463389	by incorporating
0.1043876699	very efficient
0.1043831341	$ l ^ \ infty
0.1043826323	calculated from
0.1043731908	other components
0.1043702400	the covariate space
0.1043581455	to discriminate
0.1043472074	autoregressive model with
0.1043433368	theorem for
0.1043417999	certain cases
0.1043025101	also known as
0.1042957582	differential equation with
0.1042849317	$ r_n
0.1042776524	logistic regression with
0.1042687552	a previous paper
0.1042664629	but also
0.1042031004	the empirical distribution
0.1041660226	empirical distribution of
0.1041632290	depend only
0.1041597368	obtained under
0.1041593837	an integral
0.1041313125	then construct
0.1041174254	deviation from
0.1041005472	lower than
0.1040745273	estimation of covariance
0.1040719094	the model
0.1040716165	rates of convergence for
0.1040610215	some well known
0.1040504992	connected to
0.1040202092	in small samples
0.1040198614	occurs at
0.1039915320	other tests
0.1039887466	extensions of
0.1039764685	in particular
0.1039698118	faithful to
0.1039666919	an original
0.1039540201	these ideas
0.1039264192	$ type
0.1039127691	a non parametric
0.1038864284	a riemannian
0.1038478857	$ \ ell ^ 2
0.1038439325	system parameters
0.1038225075	$ n \ geq
0.1038015443	y =
0.1038003931	$ \ alpha_n
0.1037831835	corresponding empirical
0.1037797014	networks with
0.1037454813	dedicated to
0.1036623604	other problems
0.1036592461	sets of random
0.1036574009	^ 2 5
0.1036304197	an adequate
0.1036049565	a finite dimensional
0.1035974958	absolutely continuous with
0.1035968111	tail probability of
0.1035904870	then introduce
0.1035703778	two key
0.1035695884	only require
0.1035605856	$ i_
0.1035557952	a trade off between
0.1035191258	in reproducing kernel hilbert
0.1035167760	$ penalty
0.1035032239	refer to as
0.1034981037	$ t_
0.1034671484	conclude with
0.1034587172	diffusion process with
0.1034550971	$ separation
0.1034455927	many statistical
0.1034285685	a range
0.1033909558	robust to
0.1033887563	most popular
0.1032816950	the slope parameter
0.1032393362	natural way
0.1032255642	number of support
0.1032225352	family of probability
0.1031862027	members of
0.1031730640	these estimates
0.1031291901	with unknown variance
0.1031242316	the preliminary
0.1031234757	non asymptotic oracle inequalities for
0.1030683749	p \ infty
0.1030608958	application of
0.1030520733	the bivariate case
0.1030371703	observations from
0.1030292806	numerical example
0.1030100524	\ sigma _
0.1029978424	asymptotic expansion for
0.1029791813	definitions of
0.1029753134	applications such as
0.1029571273	the drift function
0.1029541728	exact recovery in
0.1029391479	roots of
0.1029226144	finite set of
0.1028877405	even larger
0.1028528514	$ \ zeta
0.1028490122	an individual
0.1028236724	with respect
0.1028043507	also study
0.1027762786	with infinite variance
0.1027483737	limitations of
0.1027279566	relative efficiency of
0.1027110426	the empirical copula
0.1026844111	a complete
0.1026785365	three main
0.1026742141	this paper focuses
0.1026726153	$ \ lambda_i
0.1026657858	one parameter family of
0.1026302941	$ \ mbox
0.1026258056	comparison of
0.1026224562	the integrated volatility
0.1025934971	^ n \ times p
0.1025801698	$ m_1
0.1025763053	sqrt n
0.1025074795	x_j \
0.1025005153	\ le \ infty
0.1024982468	interpretation of
0.1024854444	for community detection
0.1024413523	collected from
0.1024404548	$ p = 2
0.1024281042	~ \
0.1024138846	noisy measurements of
0.1024127694	$ x
0.1023810968	kernel estimators of
0.1023727858	the existing literature
0.1023604923	form of
0.1023555731	$ \ xi_
0.1023429090	some basic
0.1023087018	of components in
0.1022890691	most common
0.1022381557	a finite number
0.1022347847	conditions for
0.1022329890	for small samples
0.1022311516	error bound for
0.1022123300	account for
0.1021745778	value index
0.1021707543	$ x \ mapsto
0.1021614258	one point
0.1021504696	estimator for
0.1021168688	an example
0.1020802036	$ y
0.1020792683	order 2
0.1020781342	to study
0.1020708289	class of markov
0.1020583616	empirical mean
0.1020527378	but only
0.1020444620	$ \ beta_
0.1020263906	appearing in
0.1020163670	many problems
0.1020097216	the context of
0.1020047255	adjusting for
0.1019973817	$ x_i
0.1019764549	the proofs rely
0.1019739198	$ r_
0.1019244544	an open
0.1019221566	by adopting
0.1019130632	the sample variance
0.1018950540	strong consistency and asymptotic normality of
0.1018744888	$ \ mathrm
0.1018660261	$ test
0.1018624864	asymptotic normality under
0.1017684570	$ d_1
0.1017431454	do not depend on
0.1017278749	this area
0.1017077016	the number of covariates
0.1017021322	sample properties of
0.1016930909	$ s_n
0.1016930781	value decomposition
0.1016864715	the true number
0.1016810890	to minimize
0.1016481367	$ \ boldsymbol \ theta
0.1016452692	differentiability of
0.1015816591	intensity function of
0.1015816255	^ \ theta
0.1015717703	chosen by
0.1015484335	leave one
0.1014955266	of nonzero coefficients
0.1014907792	uniformly most
0.1014463389	by developing
0.1014424854	the two sample problem
0.1014304862	| \ hat
0.1014296219	$ \ chi
0.1014155127	more computationally
0.1013777954	$ \ lambda_n
0.1013248198	predicted by
0.1013075828	more recent
0.1012978140	a real world
0.1012972462	coverage probability of
0.1012898670	the trade off between
0.1012793827	asymptotic power of
0.1012407909	the asymptotic
0.1012023651	very sensitive
0.1011662295	a large
0.1011337257	$ n \ rightarrow \ infty
0.1011187118	subclass of
0.1011145710	give sufficient
0.1011088030	estimator of
0.1010783349	$ \
0.1010707812	full data
0.1010324046	for constructing
0.1010240511	+ \ sqrt
0.1010230052	a rigorous
0.1009913684	used to
0.1009573464	singular values of
0.1009541660	a class of
0.1009146228	main interest
0.1008914647	designed for
0.1008512672	method for high
0.1008407901	$ 0 \ leq
0.1008402454	the asymptotic optimality
0.1008136390	and wong
0.1008097216	a variety of
0.1007909156	1 p
0.1007887696	possible values
0.1007887473	limiting distributions for
0.1007795859	the invariant density
0.1007681410	approach allows
0.1007043130	$ \ mathrm poly
0.1006798738	a specific
0.1006707805	this family
0.1006699437	the ill posedness
0.1006641886	the estimation error
0.1006444054	to establish
0.1004957575	a non asymptotic oracle
0.1004824461	also enables
0.1004667230	the exact solution
0.1004013734	solely on
0.1003670672	$ r ^ 2
0.1003428664	0 \ leq
0.1003316256	asymptotic validity of
0.1003221128	some constant
0.1003177555	$ b_
0.1002988604	model with gaussian
0.1002943572	growing interest in
0.1002855807	a random process
0.1002643685	method allows
0.1002633935	p 0
0.1002322603	valid under
0.1002098693	two families
0.1001952077	then derived
0.1001773242	known results
0.1001503441	choice between
0.1001259188	not observed
0.1001236117	these indices
0.1001055861	other things
0.1001001171	known variance
0.1000934199	distribution via
0.1000862742	$ d_2
0.1000795955	$ close
0.1000593056	statistics based on
0.1000571160	$ 1 2
0.1000570583	$ \ alpha 0
0.0999739963	abrupt changes in
0.0999711133	a gaussian vector
0.0999635597	\ pmb \ theta
0.0999625105	guaranteed to
0.0999618572	obtained for
0.0999556541	a new
0.0999548738	a common
0.0999455041	$ x_0
0.0999427077	the internet
0.0999358069	tens of
0.0999350616	efficient estimators of
0.0999305444	\ theta ^ *
0.0999202133	results obtained by
0.0999179948	a loss function
0.0998701188	framework provides
0.0998368659	$ \ left
0.0998348331	any parametric
0.0998313140	likelihood estimation for
0.0998249633	available information
0.0998210641	structure of
0.0998124165	the null distribution
0.0998110708	= t
0.0998003931	$ \ psi_n
0.0997808978	boundedness of
0.0997713238	test whether
0.0997565312	by assuming
0.0997317417	result gives
0.0997178534	$ \ int_
0.0996971481	a random matrix
0.0996690672	the unconditional
0.0996673984	\ hat \ gamma
0.0996587899	\ chi ^
0.0996271724	existing results for
0.0995900527	good properties
0.0995786097	behaves as
0.0995534483	the objective function
0.0995379029	\ mathbb r ^ p
0.0995376224	a hypergeometric
0.0994619720	em algorithm for
0.0994378655	known about
0.0994296429	an extreme
0.0994205875	a positive definite
0.0994088065	a finite
0.0993994473	bound for
0.0993904709	the search
0.0993783090	the non stationary
0.0993071765	simple proof of
0.0993017093	strategy for
0.0992697438	r ^ m
0.0992215804	tail probabilities of
0.0991348191	not yet
0.0991197830	p = 1
0.0990574079	$ h_n
0.0990465631	not consistent
0.0990227068	such methods
0.0990104415	two kinds
0.0989693156	exact distribution of
0.0989538318	$ entropy
0.0989380738	$ \ delta 0
0.0989307402	property of
0.0989248149	time complexity
0.0989205434	$ x_
0.0989041421	particular case
0.0988982867	a rich class
0.0988779943	locally d
0.0988674914	parts of
0.0988627131	to represent
0.0988337998	the latter
0.0988221131	take values
0.0988219335	other properties
0.0987750320	intended to
0.0987407980	assessment of
0.0987170943	n \ in \ mathbb n
0.0987121124	\ mathbb s ^
0.0986344918	t \ in \ mathbb
0.0986123789	also applicable
0.0986095589	required by
0.0985982278	results show
0.0985977150	by solving
0.0985852499	x \ mapsto
0.0985582890	a pre specified
0.0985512562	such models
0.0985472619	also explore
0.0985332792	the number of vertices
0.0985278785	new procedures
0.0985008099	square root of
0.0983999616	results lead to
0.0983849317	$ d_n
0.0983833805	these designs
0.0983825428	signal from
0.0983619024	but rather
0.0983565428	procedures under
0.0983100626	investigated by
0.0983091141	t distribution
0.0982842095	$ n = \ omega
0.0982777649	excess risk of
0.0982129936	$ u_n
0.0982084968	characterized as
0.0981788386	$ k = 2
0.0981605609	in spite of
0.0981596080	an analog
0.0981466159	the horseshoe
0.0981186411	a novel
0.0981059065	amount of
0.0980891272	used to determine
0.0980890183	sample test for
0.0980719184	possible applications
0.0980470805	first derive
0.0980340321	stationary processes with
0.0979860899	$ optimality
0.0979488878	an event
0.0978896115	implemented by
0.0978658839	$ penalization
0.0978449545	model based on
0.0978413693	distributed according to
0.0978197296	these measures
0.0978019556	various methods
0.0977878759	measured in terms of
0.0977782637	the noisy case
0.0977439346	the regression coefficients
0.0977396767	many times
0.0977377818	an intermediate
0.0977272813	$ p \ gg n
0.0977161859	robust estimator of
0.0976581409	sum of
0.0976514585	a new class of
0.0976155938	the non linear
0.0975769686	a discrete distribution
0.0975624581	further assumptions
0.0975383484	functions of
0.0975080527	to define
0.0974579034	other common
0.0974550654	the high dimensional
0.0974424916	the low degree
0.0974189898	methodology based on
0.0974108724	in survival analysis
0.0973917689	hundreds of
0.0973913185	the non parametric
0.0973896531	crossings of
0.0973891472	each hypothesis
0.0973797456	analogy with
0.0973419040	distributed according
0.0972712388	two datasets
0.0972558119	a recently developed
0.0972374204	mar \
0.0972105799	the long memory
0.0971901524	recent work on
0.0971849788	and nickl
0.0971601447	to produce
0.0971381137	to predict
0.0971104866	$ \ sf
0.0971007978	\ int_0 ^ 1
0.0970903320	an application to
0.0970229026	bootstrap procedure for
0.0970116352	no algorithm
0.0970096161	dimension p
0.0969896962	the conditional sampling
0.0969793697	\ alpha = 1
0.0969763107	$ z
0.0969728157	$ vector
0.0969632835	gaussian approximation of
0.0969118869	r = 1
0.0969049597	the use of
0.0969045483	theoretical study of
0.0969015841	large amount of
0.0968608103	a survey
0.0968554619	new methods
0.0968397912	a data adaptive
0.0968216883	subfamily of
0.0968199784	along with
0.0967960317	\ theta _
0.0967930471	robust estimators of
0.0967817450	rejoinder to
0.0967800245	provide useful
0.0967777198	$ n \ delta_n
0.0967746185	a finite time
0.0967667017	both simulated
0.0967447800	central limit theorem of
0.0967123511	x _n
0.0966969093	o \ left
0.0966933223	expansions for
0.0966686681	different levels
0.0966556004	$ h
0.0966554616	implemented using
0.0966441106	relevant to
0.0966430820	the geometry
0.0965971089	priors based on
0.0965919974	not at random
0.0965782562	a semiparametric model
0.0965674167	competitive with
0.0965614525	an overview
0.0965489192	density based on
0.0965383484	estimation for
0.0965292344	via convex
0.0965286813	an existing
0.0965031792	the optimal choice
0.0964994053	the prior distribution
0.0964755635	techniques based on
0.0964615033	general classes of
0.0964364373	this chapter
0.0964356989	conditioning on
0.0964226981	t distributions
0.0964155418	value function
0.0964138161	proof of
0.0963889729	the single index
0.0963841296	some unknown
0.0963785985	new family
0.0963721270	a quadratic functional
0.0963667632	the extreme value index
0.0963541660	the problem of
0.0963354392	particular examples
0.0963299621	then establish
0.0962975427	| \ sigma
0.0962914886	of extreme events
0.0962805704	by leveraging
0.0962778306	$ p_n
0.0962726458	many practical
0.0962721056	well suited to
0.0962693244	these test statistics
0.0962642607	the shape
0.0962498011	under fairly
0.0962472069	implications for
0.0962383821	this task
0.0962277423	independent but
0.0962218754	an agent
0.0962203536	several numerical
0.0962095461	an approximation
0.0962010634	linearly with
0.0961988361	nonparametric approach to
0.0961500525	a minimum distance
0.0961377862	dimension reduction for
0.0961065042	the log likelihood
0.0960982465	differ by
0.0960979257	delta =
0.0960963283	* \ in \ mathbb
0.0960832918	two major
0.0960468839	to characterize
0.0960371290	concentrates on
0.0960246441	parametric estimation for
0.0960098756	parametric families of
0.0960003072	studied through
0.0959841649	rates than
0.0959737443	than previous
0.0959404110	most existing
0.0959348306	approximation method for
0.0959202871	also analyze
0.0958929475	a more general result
0.0958549906	$ error
0.0958010364	$ bootstrap
0.0958000172	conditionally on
0.0957929809	$ p \ geq
0.0957845026	i \ leq n
0.0957748243	to pay
0.0957583313	further shown
0.0956821391	shared by
0.0956803359	to mitigate
0.0956728162	$ y_i
0.0956627259	the change points
0.0956433182	control over
0.0956268356	poisson process with
0.0956038567	$ \ hat \ beta
0.0955844738	many existing
0.0955565833	$ 2k
0.0955468101	proven to
0.0955428917	the case
0.0955400992	data generated by
0.0955332020	connections with
0.0955325760	$ \ textbf
0.0955030785	correlation structure of
0.0954854780	not required
0.0954730677	least squares approach
0.0954514153	d _
0.0954488149	with time dependent
0.0954363550	$ sparsity
0.0953822555	required for
0.0953523604	further analysis
0.0953468502	fitted to
0.0953011691	inference after
0.0952710294	complexity bounds for
0.0952596943	d_ \
0.0952087696	estimation using
0.0952077466	markov chain on
0.0951842213	posterior mean
0.0951807002	used to solve
0.0951721861	spectral statistics of
0.0951671421	to develop
0.0951521059	very high
0.0951283183	such designs
0.0951092516	these challenges
0.0950855598	i = 1 ^
0.0950834518	the riemannian
0.0950812493	known result
0.0950740786	$ n_
0.0950588080	the final
0.0950577876	algorithms based on
0.0950406212	distributions of
0.0950354864	expense of
0.0950335171	to treat
0.0950317425	signal detection in
0.0950293806	the graphical lasso
0.0950230718	a sufficient condition
0.0950201619	but different
0.0950129330	the problem of constructing
0.0949743775	the gaussian
0.0949490163	eigenvectors of
0.0949473987	markov chain with
0.0949442892	compared with other
0.0949330026	shrinkage estimators of
0.0949252782	\ hat \ lambda
0.0949020807	other settings
0.0948867314	further provide
0.0948847721	to assign
0.0948567086	projections of
0.0948146966	up to constant
0.0947961427	n \ log n
0.0947354969	mean integrated
0.0947332171	time intervals
0.0947205941	derive bounds on
0.0946953360	the regularization parameter
0.0946853563	the non asymptotic
0.0946531195	to tune
0.0946499061	union of
0.0946277607	novel approach
0.0946159256	a popular method
0.0945699217	the em
0.0945696563	results from
0.0945630088	a novel approach
0.0945591591	causal effects in
0.0945383484	function of
0.0945134981	the second order
0.0944732702	$ \ boldsymbol \ beta
0.0944725990	used to define
0.0944715898	1 n
0.0944290232	new insight
0.0944268191	the true regression
0.0944197554	log ^ 2
0.0944189067	takes into
0.0944037842	closed under
0.0943230047	regression with
0.0943155136	the model class
0.0943116303	$ y =
0.0942972674	the tail index
0.0942547890	a general theory
0.0942276767	$ d \ geq 1
0.0942111113	corresponding to
0.0942038782	assessed by
0.0941933612	the average treatment
0.0941795746	\ sum_ j =
0.0941793817	marginal distribution of
0.0941683082	test does not
0.0941371028	$ k_n
0.0941326465	estimates for
0.0941127075	mean regression
0.0940867202	two scenarios
0.0940717975	$ f_n
0.0940591021	test under
0.0940539952	with time varying
0.0940459378	+ \ alpha
0.0940436628	any type
0.0940404475	to simulate
0.0939963335	exact recovery of
0.0939904799	with non linear
0.0939876582	the error term
0.0939648542	an attempt
0.0939606932	a theoretical point of view
0.0939581820	to monitor
0.0939517169	the convergence rate
0.0939467273	do not depend
0.0939315315	unlikely to
0.0939081013	several existing
0.0939042989	bayes estimator for
0.0938969945	z ^ d
0.0938964840	the noise variance
0.0938817945	\ in \ r ^
0.0938563454	justifications for
0.0938518467	w ^
0.0938410173	both synthetic
0.0938059537	the optimal solution
0.0937834772	minimax rates of
0.0937748844	inequality for
0.0937656742	$ a_i
0.0937483737	realizations of
0.0937065270	several properties
0.0936824481	new notion
0.0936819729	used to compute
0.0936769953	an empirical likelihood
0.0936498773	a real data example
0.0936385490	approach provides
0.0936003560	efficient algorithm for
0.0935283217	representation for
0.0935278360	other existing
0.0935157988	a nonparametric test
0.0934841794	consistent estimator for
0.0934730648	improved by
0.0934704903	$ z_i
0.0934274127	n t
0.0934252818	by giving
0.0934249649	the same rate
0.0934093699	\ | y
0.0934041985	the spectral measure
0.0933882193	considered here
0.0933781233	any convex
0.0933438282	| \ cdot
0.0933329261	random graphs with
0.0933321399	studied via
0.0933260764	examination of
0.0933153080	$ consistency
0.0932961148	depend only on
0.0932698141	information between
0.0932209719	via simulation
0.0932107870	the population covariance
0.0932033653	detect changes in
0.0932003931	$ \ int
0.0931935432	new bounds
0.0931832142	goodness of fit testing for
0.0931809087	philosophy of
0.0931584775	on simulated and real data
0.0931563046	common use
0.0931454192	then estimate
0.0931453919	each class
0.0931385420	theta \ |
0.0931328043	= \ sum_ i =
0.0931022090	said to
0.0931001039	$ p = 1
0.0930953388	built on
0.0930944735	a goodness of fit test
0.0930878406	the coupling
0.0930851424	relates to
0.0930781461	the optimal
0.0930386965	limits of
0.0930291786	to circumvent
0.0930259796	bands for
0.0930202208	other parameters
0.0929491531	for kernel based
0.0929324410	and two sided
0.0929116818	case of
0.0929020285	first moment
0.0928926807	seems to
0.0928878657	$ \ rightarrow
0.0928836944	minimizer of
0.0928796553	present here
0.0928660898	x ^ *
0.0928212973	the minimax optimal rate of convergence
0.0927812173	probability bounds for
0.0927794031	hold under
0.0927629361	used to build
0.0927563720	first prove
0.0927542593	the number of predictors
0.0927461192	techniques from
0.0927330035	this connection
0.0926915511	identification of
0.0926915458	many examples
0.0926906100	tools for
0.0926861958	also include
0.0926845748	connection with
0.0926745293	random vectors with
0.0926725234	_ i =
0.0926404110	very important
0.0926155301	derived here
0.0925860856	taken into
0.0925750172	identical to
0.0925666060	two stage least
0.0925636876	gaussian process with
0.0925635429	the penalty term
0.0925347908	than previously
0.0925287426	accessible to
0.0925264743	literature on
0.0925175122	a weighted sum
0.0925142864	2 \ sqrt
0.0924962663	the problem of finding
0.0924892959	the expectation maximization
0.0924891134	a regularly varying
0.0924884086	a large scale
0.0924852512	the past
0.0924792301	= \ left
0.0924269651	k \
0.0924136224	these authors
0.0923705355	efficient than
0.0923622263	also conduct
0.0923606184	a simple method
0.0923585893	treatment effects in
0.0923223607	\ in \ theta
0.0923197791	classical problem of
0.0922865050	of detecting
0.0922652753	only depends
0.0922421168	need to
0.0922278530	very sparse
0.0921739626	used to derive
0.0921636868	$ \ mu_n
0.0921620879	p \ rightarrow
0.0921305186	by computing
0.0921265299	a neural network
0.0920838315	\ chi
0.0920482500	$ z_
0.0919920874	two part
0.0919873842	by product
0.0919699557	many modern
0.0919595359	continue to
0.0919224727	minors of
0.0919169340	by drawing
0.0919133484	results in
0.0919033430	an ideal
0.0918830933	covariance function of
0.0918822616	some situations
0.0918655846	behave as
0.0918631431	$ p \ geq 1
0.0918542692	the effect
0.0918512478	1 f
0.0918332893	measure based on
0.0918045291	difference between two
0.0918044642	discussion on
0.0917921055	in \ r ^
0.0917781217	adaptive estimator of
0.0917765232	y = x \ beta
0.0917745698	theory for
0.0917253670	the standard bayesian
0.0917000418	this condition
0.0916814646	superior to
0.0916767319	consistent with
0.0916129214	as quickly as
0.0915963452	restriction on
0.0915806409	this goal
0.0915583310	to prevent
0.0915475861	the law of large numbers
0.0915383484	problem of
0.0915302521	by imposing
0.0915127333	n \ to 0
0.0915115432	many fields
0.0914920037	independently from
0.0914738283	only partially
0.0914410797	other fields
0.0914343889	recipe for
0.0914208917	critical values of
0.0914204864	random field on
0.0913512799	observed over
0.0913441091	a probability measure
0.0913287871	propriety of
0.0913221056	to capture
0.0913158014	holds under
0.0913137684	the average degree
0.0912950569	0 \ le
0.0912909052	the quality
0.0912857260	hold even
0.0912690608	knowledge of
0.0912602821	the sub gaussian
0.0912566362	established for
0.0912489700	nu =
0.0912345775	oracle inequalities in
0.0911915206	evaluated using
0.0911896806	the log density
0.0911880393	with log concave
0.0911416313	models for
0.0911111486	a recently introduced
0.0911071677	working with
0.0910847976	identifiability of
0.0910432177	sequences of
0.0910406212	estimation in
0.0910342120	perform very
0.0910337768	upper bound of
0.0910097216	the case of
0.0909899696	developed for
0.0909855708	a linear process
0.0909663848	the low rank
0.0909599705	le p \
0.0909226187	derive novel
0.0909084951	performance compared to
0.0909032515	a statistical model
0.0908653098	these rules
0.0908127011	$ y_i =
0.0907966869	to take into account
0.0907936181	theta = \
0.0907786483	over besov
0.0907644766	a time varying
0.0907508437	primarily on
0.0907445240	result about
0.0907285809	preferable to
0.0907238704	minimizers of
0.0907105240	explicitly given
0.0907093496	n \ log
0.0907032576	type inequality for
0.0906902443	different tests
0.0906740239	the problem of high dimensional
0.0906668529	the link function
0.0906634830	all possible
0.0906495913	used to approximate
0.0906336322	extension to
0.0906228871	a finite number of
0.0906107237	the non gaussian
0.0906009675	the test
0.0905982101	the delta method
0.0905931615	cornerstone of
0.0905345911	a max
0.0905228256	this construction
0.0905142386	adaptation to
0.0904718683	confidence set for
0.0904682865	do not rely
0.0904664857	existence and uniqueness of
0.0904271670	recently introduced in
0.0904265106	^ m
0.0904081988	of order 2
0.0904008856	the sum of squares
0.0903713227	these classes
0.0903693586	a small
0.0903561041	the asymptotic covariance
0.0903501661	distribution based on
0.0903239120	the rank based
0.0903229070	decomposition of
0.0903143633	a separable hilbert
0.0903086399	not just
0.0902941437	distance between two
0.0902821177	framework allows
0.0902763120	the method
0.0902670900	grows at
0.0902530262	also holds
0.0902079249	appearance of
0.0901686648	relation to
0.0901640898	better results
0.0901629864	thousands of
0.0901534778	nonparametric inference for
0.0900951030	sampling without
0.0900859406	q \ leq
0.0900447058	\ mathbb l ^
0.0900146642	not applicable
0.0899683303	a random
0.0899683089	calculation of
0.0899164302	the number of
0.0899107829	rise to
0.0898970546	member of
0.0898798265	used to compare
0.0898625361	class of test
0.0898491522	$ 2
0.0898384440	latter case
0.0898164421	to combine
0.0898053966	on compact
0.0897820262	$ y_t
0.0897807588	a connection
0.0897797699	used to illustrate
0.0897765739	any smooth
0.0897586289	x ^
0.0897528951	$ 1 \ epsilon
0.0897402649	variants of
0.0897216740	the target
0.0897196416	regardless of whether
0.0897159799	matrices with
0.0897097813	the celebrated
0.0897048442	a statistical perspective
0.0897020303	$ s_
0.0896901932	a parametric family
0.0896897157	an arm
0.0896791640	t \ geq
0.0896744136	experiments with
0.0896742194	a general procedure
0.0896635776	two versions
0.0896233112	a non negative
0.0896187454	identified as
0.0895787029	plugging in
0.0895727445	answer to
0.0895712655	selection consistency of
0.0895525744	new result
0.0895097929	$ k \ times
0.0895097413	2 \ times 2
0.0894879336	a real data
0.0894827045	light on
0.0894723548	a general method
0.0894703196	the restricted isometry
0.0894682039	the optimal rate of convergence
0.0894627815	increasing interest in
0.0894507186	an isotropic
0.0894458668	the asymptotic power
0.0894342998	prior over
0.0894337121	linked to
0.0894137824	x ^ \ rm
0.0894075809	a sub gaussian
0.0894059770	first provide
0.0893852229	information from
0.0893772627	theory allows
0.0893587293	elements of
0.0893561195	the mediator
0.0893404327	$ p_
0.0893374245	$ \ gamma 0
0.0893292748	a detailed analysis
0.0892859121	a large number of
0.0892700036	efficient estimators for
0.0892289245	these settings
0.0891983019	mixture of
0.0891915511	optimality of
0.0891820695	the exact distribution
0.0891813454	heavily on
0.0891788807	efficient way
0.0891367656	to dominate
0.0891298483	$ \ infty
0.0890975393	by transforming
0.0890800654	the finite dimensional
0.0890796355	models based on
0.0890725955	studied in
0.0890683223	averages of
0.0890680364	method provides
0.0890674348	not limited
0.0890460052	used to evaluate
0.0890344633	approaches based on
0.0890261019	this document
0.0890198700	products of
0.0890069447	a non standard
0.0890058528	1 \ sqrt n
0.0889848223	distance from
0.0889817617	consistency results for
0.0889808778	subclasses of
0.0889782312	of block maxima
0.0889738740	to enhance
0.0889619431	trained on
0.0889455488	time series regression
0.0889442854	does not rely
0.0889189555	modes of
0.0888913266	$ \ hat \ theta
0.0888891192	| n
0.0888552917	the error process
0.0888551505	to interpret
0.0888436480	propose to use
0.0888414108	to unity
0.0888345959	new multivariate
0.0888259676	s \ log
0.0888137512	limited to
0.0887935376	the author
0.0887634517	for example
0.0887268436	the number of factors
0.0887201963	present several
0.0887166212	time series using
0.0886802128	to incorporate
0.0886061933	characterisation of
0.0886047907	implemented in
0.0885987834	$ t
0.0885127388	the small ball
0.0885048011	statistical methods for
0.0885000226	t \ leq
0.0884882563	the log concave
0.0884763882	the presence of
0.0884696173	certain types
0.0884172414	maxima of
0.0884113685	this characterization
0.0884013576	this bound
0.0883865756	over existing
0.0883824837	a finite state
0.0883696786	an algebraic
0.0883609015	estimated at
0.0883562542	the most important
0.0883552466	formulation of
0.0883527119	direction method of
0.0883494068	covariance matrices with
0.0883473866	these formulas
0.0883397760	c \ `
0.0883353988	encountered in
0.0883042518	such problems
0.0882908125	analogues of
0.0882878284	the goal
0.0882689022	$ n \ ll
0.0882344339	these equations
0.0882339134	a prototype
0.0882267816	two popular
0.0882177489	and computationally efficient
0.0881843008	the sample
0.0881816599	such approximations
0.0881707696	$ optimization
0.0881524133	unbiased estimator for
0.0881512006	analyzed using
0.0881252198	i = 1 ^ n
0.0881019142	by carefully
0.0880848814	all existing
0.0880727746	effect on
0.0880509644	$ \ theta_i
0.0880466132	the chi squared
0.0880206129	rates of
0.0879921815	n \ geq
0.0879871595	the extreme eigenvalues
0.0879800778	the recent literature
0.0879662349	other estimators
0.0879575125	proceed to
0.0879424682	$ fraction
0.0879208934	the problem of identifying
0.0878846166	square error of
0.0878695030	the former
0.0878620236	$ y_
0.0878556846	i_ \
0.0878433881	a piecewise constant
0.0878334975	the semi parametric
0.0878199539	for right censored
0.0877688607	\ int f
0.0877513225	from incomplete
0.0877502920	the new method
0.0877383642	$ x \ sim
0.0877358866	a careful
0.0877342907	magnitudes of
0.0877327447	conditions than
0.0877279196	the signal strength
0.0877274381	the problem
0.0876977574	better performance than
0.0876925334	$ s
0.0876782375	the gaussian white noise
0.0876777191	the sample complexity
0.0876465190	in order to obtain
0.0876427387	a closed form expression for
0.0876176315	thought to
0.0876134686	good results
0.0875969523	on manifolds
0.0875859918	marginal distributions of
0.0875699311	the signal to noise
0.0875390798	$ \ rho_
0.0875246578	advantages of
0.0875176212	same rate
0.0875122545	determination of
0.0875095701	but not
0.0874881110	the effective dimension
0.0874668353	more accurate than
0.0874622576	tools used
0.0874581129	measure of
0.0874495000	three types
0.0874328705	method gives
0.0874247211	\ sim \ mathcal
0.0874209915	the approximation error
0.0873983713	an extremely
0.0873932808	behaviour of
0.0873740073	of interest
0.0873349457	perturbations of
0.0873159780	learning with
0.0873139429	both synthetic and real
0.0872532908	f ^ *
0.0871853443	= p
0.0871323560	an introduction
0.0871244724	to tackle
0.0871114798	by defining
0.0870554013	the optimal convergence
0.0870550712	fixed value
0.0870350750	estimates based on
0.0870276399	= \ mathbb e
0.0870159803	\ v s
0.0870068036	no tuning
0.0869910270	an absolute
0.0869878636	m \ leq
0.0869864842	variations of
0.0869827025	an easy
0.0869798726	techniques such as
0.0869777877	the almost sure convergence
0.0869614844	derived for
0.0869536166	quantile regression with
0.0869422414	ratios of
0.0869389658	a probability distribution
0.0869387723	to verify
0.0869301826	also illustrated
0.0869188158	$ m \ geq
0.0869150296	couple of
0.0869132372	a central limit theorem for
0.0869036066	the out of sample
0.0868986963	derive bounds for
0.0868805600	information criterion for
0.0868748662	contribution to
0.0868640601	scales as
0.0868584834	a new technique
0.0868432489	the unit root
0.0868354258	complicated by
0.0868250972	\ max_ 1 \ leq
0.0868158358	used to select
0.0867519650	a finite set
0.0867518798	general family of
0.0867426426	results related to
0.0867099169	modelled as
0.0867081942	a small number of
0.0867042479	the problem of recovering
0.0866922598	also characterize
0.0866608098	\ mathcal x
0.0866447433	effectiveness of
0.0866279294	optimal rates of
0.0865819636	of independent interest
0.0865784411	\ ^ o processes
0.0865465443	two dimensions
0.0865453353	an analogous
0.0865404631	degrees of
0.0865346385	some regularity
0.0865250149	k \ geq 1
0.0865220200	calculated by
0.0865168699	weak law of
0.0865078009	motivation for
0.0864946005	a much smaller
0.0864911657	the rest
0.0864868829	also construct
0.0864850523	$ \ lim_
0.0864808274	$ k \ geq 1
0.0864635095	a new criterion
0.0864603982	consequence of
0.0864510307	the number
0.0864502300	to check
0.0864474801	taking into
0.0864438109	with immigration
0.0864411411	\ mathbb r ^ k
0.0864316157	an indirect
0.0864306236	by evaluating
0.0864165173	r _ +
0.0864158201	also give
0.0864103328	the singular vectors
0.0863963331	examples from
0.0863896355	an iid
0.0863738835	an r package
0.0863436869	an important class
0.0863237199	the data generating
0.0863115778	= x +
0.0863067722	the state space
0.0863037112	the optimal linear
0.0862909388	$ \ sum_
0.0862903412	to replace
0.0862590933	the joint distribution
0.0862428607	parameters of interest
0.0862347811	\ ln n
0.0862336738	from indirect
0.0862292109	computational efficiency of
0.0862136249	rather general
0.0862106476	sample performance of
0.0861977303	combinations of
0.0861834608	of least squares
0.0861732828	+ t
0.0861572831	a robust test
0.0861539946	$ independent samples
0.0861426025	$ \ mathcal o
0.0861405344	at level
0.0861169851	a general asymptotic
0.0861092582	probability at least
0.0860986539	under misspecification
0.0860893217	+ n
0.0860689612	analogy to
0.0860596365	in detail
0.0860524088	comparison with
0.0860512125	the data dimension
0.0860483408	power than
0.0860403675	a data dependent
0.0860069426	maximum value
0.0859982059	nonparametric method for
0.0859905346	k \ leq
0.0859897863	establish consistency of
0.0859859360	the odds ratio
0.0859632885	normality of
0.0859521890	two sources
0.0859498324	pieces of
0.0859388666	the long term
0.0859294988	to maximize
0.0859272373	estimate of
0.0859184929	recovery from
0.0858915473	any knowledge
0.0858598354	density at
0.0858478949	= \ sqrt
0.0858390402	minimax optimal up to
0.0858096563	the first hitting
0.0858067327	generating function of
0.0857935077	the reverse
0.0857765859	result for
0.0857440970	a linear space
0.0856958352	with sub gaussian
0.0856900503	arises in many
0.0856682882	\ log \ log n
0.0856531278	\ sqrt t
0.0856232465	also developed
0.0856210435	assumptions than
0.0856190326	$ a_
0.0856166764	an arbitrarily
0.0856150400	\ _n
0.0856095858	singular value decomposition of
0.0856088737	i \ geq 1
0.0855978251	special case of
0.0855811480	in advance
0.0855806555	to constant factors
0.0855776619	to create
0.0855773699	evaluations of
0.0855758605	$ regular
0.0855667658	observations per
0.0855660986	the original data
0.0855554683	$ p 1
0.0855540260	unknown number of
0.0855440231	amounts to
0.0855404264	tested on
0.0855396995	for detecting
0.0855197945	r ^ k
0.0855150600	a non gaussian
0.0855045857	variable selection with
0.0855000226	p \ le
0.0854916643	to collect
0.0854870759	traces of
0.0854765193	such situations
0.0854733911	a convex function
0.0854581512	a unique
0.0854464600	some typical
0.0854395726	the degree of smoothness
0.0854310636	considered in detail
0.0854195417	expression for
0.0854116851	in arbitrary dimension
0.0853641942	complexity of
0.0853304025	the truth
0.0853182616	to pick
0.0853148378	an unbiased
0.0853091331	algorithms such as
0.0852985438	a good approximation
0.0852817724	\ beta 0
0.0852810054	these tools
0.0852674772	a generic
0.0852629556	the square root
0.0852430549	a sequence of
0.0852216740	the minimum
0.0851967747	local time
0.0851420266	some popular
0.0851377443	a mean field
0.0851338183	a regression function
0.0851231811	n \ ge
0.0851204116	a prescribed
0.0851021005	and identically distributed
0.0850942368	then compared
0.0850792372	$ \ hat \ psi
0.0850541519	stationary distribution of
0.0850511423	two measures
0.0850406038	| \ mathbf
0.0849829621	\ log ^ 2 n
0.0849782445	1 + o
0.0849728363	the spectral gap
0.0849654638	dimension reduction in
0.0849569323	prior on
0.0849000098	1 \ leq
0.0848845890	variable of interest
0.0848826920	$ divergences
0.0848718575	$ p \ times
0.0848694922	nonstationary time
0.0848656774	_ 1 \ leq i
0.0848453547	robust estimators for
0.0848277065	noisy observations of
0.0848255033	the microergodic
0.0848067225	information on
0.0847785453	n \ leq
0.0847733499	to exist
0.0847328004	\ epsilon 0
0.0847316371	some recent
0.0847267993	$ d 1
0.0847258838	the number of nonzero
0.0847232789	the same size
0.0847148418	these techniques
0.0847144153	a linear combination
0.0847047343	content of
0.0846872115	examined by
0.0846856514	sigma =
0.0846604788	an image
0.0846603416	the number of components
0.0846571751	two types
0.0846566281	under reasonable
0.0846549862	of dimensionality
0.0846432968	this reason
0.0846424795	begin with
0.0846341064	sub class of
0.0846237879	for count data
0.0846192768	volumes of
0.0845939708	random matrices with
0.0845872045	between two random variables
0.0845795746	\ tilde o
0.0845359121	a general class of
0.0845348518	in essence
0.0845325494	several statistical
0.0845206129	detection of
0.0845165373	the same time
0.0845117161	arise as
0.0845006713	dependence structure of
0.0844965244	the null
0.0844938828	\ theta 0
0.0844805653	\ alpha 0
0.0844789413	experiments on
0.0844647438	of large numbers
0.0844589499	$ \ text
0.0844532985	this procedure
0.0844518498	do so
0.0844516604	graphs with
0.0844018170	\ v
0.0843760446	rules for
0.0843444126	uniform over
0.0843386982	unbiased estimators of
0.0843360083	the curse of dimensionality
0.0843059414	algorithm gives
0.0842961401	the most efficient
0.0842952353	procedure provides
0.0842855399	discuss several
0.0842793543	an estimation method
0.0842597007	hypothesis tests for
0.0842401471	likelihood based on
0.0842089966	finite mixture of
0.0841767627	\ partial
0.0841745865	graphical models with
0.0841664999	prediction based on
0.0841541413	not fully
0.0841482112	a special
0.0841430549	the aim of
0.0841398074	a near optimal
0.0841352644	to guide
0.0841095011	a new test
0.0841049235	the classical approach
0.0840707393	multivariate time
0.0840598824	the standard
0.0840122906	the cover
0.0840080754	the problem of model selection
0.0840070730	of time varying
0.0839899436	by choosing
0.0839629857	not sufficient
0.0839558710	duration of
0.0839547599	logarithm for
0.0839536097	guidelines for
0.0839535014	the sphere
0.0839503153	by simulation studies
0.0839359659	an asymptotic analysis
0.0839139092	an average
0.0839030639	best possible
0.0838633100	a random number
0.0838548866	and non convex
0.0838496324	a family
0.0838423076	by obtaining
0.0838394602	verification of
0.0838333987	in mind
0.0838228406	both low
0.0838181169	$ \ mathcal h
0.0838013463	two problems
0.0838000279	little work
0.0837885516	framework based on
0.0837814126	the upper bound
0.0837696432	an exchangeable
0.0837401630	to fit
0.0837342759	$ dx_t =
0.0837182502	tied to
0.0837099457	universality of
0.0837047584	autocovariances of
0.0836945021	sure consistency
0.0836866627	process with
0.0836847073	new criterion
0.0836728121	for ergodic diffusion
0.0836711285	also suggest
0.0836633459	n =
0.0836543031	integration by
0.0836492148	fundamental problem in
0.0836354121	the maximum
0.0836157651	constant over
0.0836137903	to clarify
0.0836126877	absolute value of
0.0836083000	n \ rightarrow
0.0835674372	a new perspective
0.0835621186	different types
0.0835514159	\ alpha 2
0.0835489084	needed for
0.0835460737	by maximizing
0.0835383998	the restricted eigenvalue
0.0835229909	parameter family of
0.0835084084	$ w
0.0834806385	similarly to
0.0834786735	limitation of
0.0834593738	with jumps
0.0834512582	sets based on
0.0834458341	ability to
0.0834033206	a goodness of fit
0.0834001697	new type
0.0833779392	approximations for
0.0833758571	criterion based on
0.0833629515	the posterior
0.0833572029	\ cdot \ log
0.0833387452	this scenario
0.0833289223	\ in \ mathbb n
0.0833157399	above results
0.0833132598	also briefly
0.0832886504	fisher information in
0.0832849654	also valid
0.0832724029	applicability of
0.0832396840	independent but not
0.0832275887	the optimal number
0.0832266605	not exceed
0.0832112574	the joint
0.0831762101	convergence results for
0.0831719895	proved under
0.0831714056	n \ delta
0.0831557933	sort of
0.0831400559	error bounds on
0.0831387185	expressed by
0.0831325904	the number of particles
0.0830734179	sample behavior of
0.0830545100	theory of
0.0830455330	the main result
0.0830430702	a broad
0.0830276399	\ beta ^ *
0.0830116745	the standard approach
0.0829978154	a tutorial
0.0829895038	size n
0.0829748487	a well defined
0.0829468234	closure of
0.0829387248	estimator proposed in
0.0829170674	the aforementioned
0.0829047441	and higher order
0.0829046428	a kernel type
0.0828964928	a second order
0.0828658396	only if
0.0828482514	a statistician
0.0828413090	the information theoretic
0.0828265398	the power law
0.0828124695	several new
0.0828102866	in such cases
0.0828065262	= \ mathbb
0.0828002017	representations for
0.0827888920	\ log m
0.0827741366	this contribution
0.0827726768	a statistical test
0.0827192965	this topic
0.0827167402	the continuous case
0.0827098595	this conjecture
0.0826938962	the sense
0.0826936832	a plug in estimator
0.0826637887	the goodness of fit
0.0826600605	distributions based on
0.0826294331	methods such as
0.0826135112	the mean field
0.0825977304	improve on
0.0825919559	a class of nonlinear
0.0825910612	a central limit
0.0825596221	the large sample properties
0.0825341611	for computing
0.0825215385	sensitivity analysis of
0.0825188423	selection based on
0.0825001275	the method of maximum
0.0824943069	an automatic
0.0824870759	refinements of
0.0824749415	highly non
0.0824664797	two algorithms
0.0824648807	a finite mixture
0.0824606129	examples of
0.0824592893	different classes
0.0824388073	the joint probability
0.0824382392	some important
0.0824202407	already known
0.0824173169	an illustrative
0.0824104757	$ rate
0.0824053401	a useful tool
0.0823999046	the problem of choosing
0.0823642052	the full data
0.0823502166	utilized to
0.0823360716	by contrast
0.0823340025	consistency under
0.0823125653	and sun
0.0823109279	equality of
0.0822901898	with regard to
0.0822888549	m \ times
0.0822753132	\ mathbb r ^
0.0822569635	not affected
0.0822565337	\ 0
0.0822449385	these intervals
0.0822443722	designs with
0.0822365209	the operator norm
0.0822292520	two simple
0.0822255397	an independent
0.0822230596	model driven by
0.0822057331	analogue of
0.0822035531	mean function
0.0821832056	among other
0.0821800076	quantification of
0.0821677907	established by
0.0821670877	in order to achieve
0.0821498521	this challenge
0.0821418444	\ hat \ mu
0.0821359360	the particle filter
0.0821225377	tendency of
0.0821069264	an asymptotic theory
0.0820848375	some assumptions
0.0820482059	the local
0.0820416461	new approximation
0.0820411593	the discrete case
0.0820401011	a multivariate
0.0820264772	$ \ min
0.0820254408	computational cost of
0.0820033521	with diverging
0.0819991551	aim to
0.0819966363	to calibrate
0.0819754219	for longitudinal data
0.0819694951	empirical measure of
0.0819647492	+ k
0.0819545589	not require
0.0819461667	earlier work on
0.0819409803	statistical performance of
0.0819397658	not satisfy
0.0819360819	improves on
0.0819302357	the latter case
0.0819129904	for non stationary
0.0819107232	new light on
0.0818824321	an easily
0.0818766264	limit distribution of
0.0818749706	theoretical framework for
0.0818542620	one dimension
0.0818534176	games with
0.0818517283	inverse problems in
0.0818465615	to simplify
0.0818318790	three types of
0.0818268942	much better than
0.0818086237	normal approximation of
0.0818000892	a simple algorithm
0.0817945536	$ r
0.0817917810	the first order
0.0817907373	by averaging
0.0817509612	a slight
0.0817270569	error rate in
0.0817209454	the lasso
0.0817172595	to meet
0.0816788420	first hitting
0.0816764056	different distributions
0.0816741551	modification of
0.0816741551	usefulness of
0.0816659077	a sufficiently large
0.0816433157	an improvement
0.0816197838	definite functions on
0.0816163848	the infinite dimensional
0.0816089340	$ \ 0,1
0.0816051118	\ to \ gamma
0.0815942908	and lower
0.0815769111	derivatives of
0.0815509050	the accuracy
0.0815303571	to extend
0.0815248540	vary with
0.0815200431	type estimators for
0.0815113109	explanation of
0.0814811981	on synthetic
0.0814763882	a set of
0.0814661237	= \ mu
0.0814659638	for analyzing
0.0814518369	obtained as
0.0814325303	these criteria
0.0814267994	substantially more
0.0814016060	hold for
0.0813986807	for high dimensional time
0.0813961180	the most fundamental
0.0813897218	analog of
0.0813879390	_ i \ in
0.0813879015	the frequency domain
0.0813857668	_k \
0.0813646214	to enable
0.0813596614	a broad class of
0.0813443916	by parts
0.0813396374	$ x =
0.0813372501	an explicit formula for
0.0813291734	by reducing
0.0813289577	to accommodate
0.0813079208	modifications of
0.0813069867	these metrics
0.0812372152	gradient descent in
0.0812330338	an integrated
0.0812329117	a striking
0.0811973790	asymptotic variance of
0.0811857895	many settings
0.0811798885	these functionals
0.0811613816	the most common
0.0811596957	comparisons with
0.0811494397	in contrast to previous
0.0811447433	fraction of
0.0811430549	the purpose of
0.0811418978	a new methodology
0.0811193655	statistical inference on
0.0811190159	determined from
0.0811154493	justification for
0.0810681949	both methods
0.0810624355	n \ ll
0.0810606767	alternative to
0.0810534679	\ hat \ boldsymbol
0.0810522322	lambda =
0.0810497073	\ gamma 0
0.0810496041	development of
0.0810485793	estimation procedure for
0.0810372923	the multiplier bootstrap
0.0810040890	adapting to
0.0809730489	parameters based on
0.0809618683	an interior
0.0809454419	signal of interest
0.0809234354	also demonstrated
0.0809077560	a bivariate
0.0808880440	connection to
0.0808696424	described in terms
0.0808542005	a subclass
0.0808026640	\ alpha \ leq
0.0808011209	| y
0.0807954134	three different
0.0807594638	k th
0.0807464765	the bivariate normal
0.0807414415	not identically
0.0807291592	of fit
0.0807183645	appears as
0.0807130464	the noise distribution
0.0807109220	to summarize
0.0807059414	algorithm uses
0.0806866288	x \ sim
0.0806759362	asymptotic efficiency of
0.0806510010	a detailed
0.0806491486	to adjust
0.0806490375	| t
0.0805946991	first propose
0.0805938199	an intractable
0.0805916656	the respective
0.0805816166	number of non zero
0.0805694381	extreme values of
0.0805454033	a major
0.0805368073	change point in
0.0805348407	suitability of
0.0805137429	verified by
0.0804847026	an inequality
0.0804831424	this work studies
0.0804821143	the generality
0.0804709541	rates for
0.0804612962	th moment
0.0803746088	suitable for
0.0803729825	exponentially with
0.0803628547	using simulations
0.0803582177	approximations of
0.0803572964	proportion of
0.0803515780	both settings
0.0803402243	rate of
0.0803318009	a method based
0.0803208431	1 \ le
0.0803150133	the scale parameter
0.0802808738	occurrence of
0.0802787388	an asymptotically optimal
0.0802772303	\ | \ sigma
0.0802731609	possible model
0.0802679066	a target distribution
0.0802657195	a new method
0.0802638103	performed on
0.0802560190	between two
0.0802558592	an analogue
0.0802508662	problems such as
0.0802493738	the seed
0.0802430951	underlying distribution of
0.0802358190	$ l ^ p
0.0802249064	this setup
0.0802114844	apply to
0.0802032276	with regard
0.0801816018	consistent estimation in
0.0801621888	amount of information
0.0801535854	an array
0.0801503475	given by
0.0801216740	the maximal
0.0801090208	the earth
0.0801036942	replaced with
0.0801030932	this limitation
0.0800810782	the choice
0.0800750849	study estimation of
0.0800682422	uniqueness of
0.0800593414	increases with
0.0800403576	an autoregressive
0.0800395845	across different
0.0800310718	and vice
0.0800225226	an infinitely
0.0800080713	provide conditions for
0.0799894124	model selection in
0.0799501172	$ \ mathbf \ sigma
0.0799371499	an intrinsic
0.0799295100	parameters of
0.0799277571	the block maxima
0.0799108934	the p values
0.0798914776	away from zero
0.0798834871	$ matrix
0.0798802573	used for
0.0798787475	^ * \ in \ mathbb
0.0798561288	selection consistency for
0.0798423593	linear processes with
0.0798395175	causal effect of
0.0798110339	new concept
0.0798104906	allowed to grow with
0.0798067225	problems with
0.0797982439	constructed under
0.0797949270	to reconstruct
0.0797829981	+ \
0.0797819947	high dimensional time
0.0797691575	weak convergence to
0.0797626153	features such as
0.0797457376	a result
0.0797403491	procedure for
0.0797378071	s _n
0.0797344339	these approximations
0.0797322756	availability of
0.0797151342	also hold
0.0796953730	arises in
0.0796893063	\ beta ^ 0
0.0796853461	the actual
0.0796811273	exp \
0.0796761269	requirement for
0.0796759872	an equivalent
0.0796697181	for nonlinear models
0.0796266308	a much larger
0.0795936123	n \ delta_n
0.0795924889	over time
0.0795798026	feasibility of
0.0795651131	generalized method of
0.0795640461	the number of clusters
0.0795454382	\ mathbb z _
0.0795400571	main purpose of
0.0795273384	and wu
0.0795237864	the unknown smoothness
0.0795234312	the analyst
0.0795227081	the upper tail
0.0795150821	to remove
0.0795146178	this kind
0.0795037528	unknown mean
0.0795030976	x_0 \ in
0.0794838438	the k th
0.0794762067	up to order
0.0794715987	opposed to
0.0794683184	hypothesis testing with
0.0794470675	convolutions of
0.0794270395	$ \ mathbb h
0.0794132990	widely used as
0.0794132342	in terms of estimation
0.0793949067	violation of
0.0793897089	\ mathcal p
0.0793867799	the mean integrated squared error
0.0793716426	$ v
0.0793715871	a metric space
0.0793567329	hard to
0.0793515780	both approaches
0.0793509675	the unknown
0.0793489467	the total
0.0793443076	in many areas
0.0793364242	hat f
0.0793358268	obtained at
0.0793279686	the exponent
0.0793258507	\ in \
0.0793121098	the likelihood principle
0.0793065067	amounts of
0.0793062807	the empirical covariance
0.0792876027	designs for
0.0792842676	kernel methods for
0.0792833996	testing procedures for
0.0792405579	the strength
0.0792342784	to increase
0.0792309016	the non convex
0.0792215454	the joint density
0.0792098344	$ term
0.0792091253	mean independence
0.0791902022	$ 1 \ leq
0.0791901169	some simulation
0.0791806528	an objective
0.0791507118	and forward
0.0791422594	in large samples
0.0791271940	tending to one
0.0791131843	each sample
0.0791123860	the main contribution
0.0791123437	the special case
0.0791029692	parametric family of
0.0790949388	the empirical likelihood
0.0790775486	merits of
0.0790516845	\ leq i \ leq n
0.0790373400	n \ cdot
0.0790218261	category of
0.0789812691	+ e
0.0789496026	likelihood estimators for
0.0789298405	hypothesis testing on
0.0789239839	at zero
0.0789060702	to answer
0.0788853772	the time dependent
0.0788830147	the asymptotic regime
0.0788721234	analysis based on
0.0788664086	features of
0.0788567403	\ theta ^ \ star
0.0788557881	new observation
0.0788527805	the reconstruction error
0.0788310414	the growth rate
0.0788237397	laws of
0.0788073135	x_i \ in
0.0788059611	a model based
0.0787755170	the empirical
0.0787602984	d \
0.0787527319	the detection boundary
0.0787463717	helps to
0.0787410348	the same asymptotic
0.0787194113	^ 1 \
0.0787099433	faces of
0.0786761052	non stationary time
0.0786578284	the key
0.0786230404	with random design
0.0786230328	a tractable
0.0786212120	density estimation under
0.0785900796	to discover
0.0785854905	efficiency of
0.0785805100	some simple
0.0785591663	causal inference in
0.0785500845	convolution of
0.0785088050	a surprising
0.0785063536	the input data
0.0784891420	y_i \
0.0784860825	a coordinate
0.0784777326	for selecting
0.0784743053	an improper
0.0784535533	also perform
0.0784472478	\ sqrt \ log n
0.0784466464	the data points
0.0784040786	the asymptotic efficiency
0.0784040786	the optimal design
0.0783956261	tables with
0.0783705546	the presence of noise
0.0783653352	asymptotic bounds on
0.0783600446	regression problems with
0.0783489522	one factor
0.0783449761	far from
0.0783364242	omega =
0.0783335162	x \ in \ mathbb
0.0782799933	measures based on
0.0782611129	validity of
0.0782517812	also address
0.0782504612	used to detect
0.0782400707	the plug in estimator
0.0782373998	the invariant measure
0.0782161656	a theoretical framework
0.0781584391	a machine
0.0781457369	the number of false
0.0781342456	\ x_
0.0781277941	a comprehensive
0.0781181190	rate than
0.0781067503	a continuous
0.0780545100	applications of
0.0780519143	the presence
0.0780412923	the trade off
0.0780396664	the moderate deviations
0.0780081786	^ th
0.0779914669	components of
0.0779513202	\ gg n
0.0779408817	formulae for
0.0779328306	levels of
0.0779094740	eigenfunctions of
0.0779058520	the likelihood ratio
0.0778740339	step by
0.0778437728	to preserve
0.0778398574	the theoretical findings
0.0778385272	a new approach
0.0778335587	a first order
0.0777842575	by extending
0.0777569818	a very simple
0.0777328306	aggregation of
0.0777283526	two random variables
0.0777084910	y given x
0.0777023931	a nonparametric estimator
0.0776995876	to exploit
0.0776760803	the normal distribution
0.0776601079	a non convex
0.0775903785	\ widetilde o
0.0775899835	type estimator for
0.0775885110	the global minimum
0.0775860159	an unbounded
0.0775805609	the problem of approximating
0.0775492172	performances of
0.0775393558	in many scientific
0.0775296344	beta =
0.0775211289	large family of
0.0775108747	attempts to
0.0774932502	favorably with
0.0774798977	a novel framework
0.0774737378	the number of hidden
0.0774647473	an experimental
0.0774640317	to aggregate
0.0774617473	markov models with
0.0774562304	to optimize
0.0774522373	model for
0.0774421850	and bidirected
0.0774394665	the sample covariance
0.0774357043	the gaussian white
0.0774226220	f \ _
0.0774047405	$ n \ ge
0.0773818912	spectral norm of
0.0773694608	a principled
0.0773577937	two specific
0.0773395996	widely used for
0.0773217816	survival function of
0.0773153785	grow with
0.0773086226	the prior
0.0772775182	the response
0.0772649123	a standard normal
0.0772512249	enumeration of
0.0772477822	main goal of
0.0772443521	behaviors of
0.0772432340	^ h
0.0772426796	two moments
0.0772377331	to serve
0.0772311838	$ independent observations
0.0772182502	suffice for
0.0772026086	approach uses
0.0771498277	\ times \ mathbb
0.0771490921	the asymptotic normality
0.0771340415	the euclidean distance
0.0771266958	this quantity
0.0771113282	a clear
0.0770984137	the proportional hazards
0.0770932880	justification of
0.0770873293	method of
0.0770782445	y = x
0.0770636466	n \
0.0770470424	the conditional expectation
0.0770409739	parametric inference for
0.0770331550	criterion for
0.0770222425	limit theorems in
0.0770219766	ratio tests for
0.0770200004	some standard
0.0770163976	practical applications of
0.0770098506	show empirically
0.0769932452	walks on
0.0769909005	the heart of
0.0769813731	under independence
0.0769789375	a final
0.0769737106	differences in
0.0769718920	the regression parameter
0.0769694049	to prove
0.0769260887	the hazard rate
0.0769158613	large numbers for
0.0768783915	a particular case
0.0768688864	the signal
0.0768547108	a gaussian
0.0768382191	to demonstrate
0.0768195353	a non central
0.0768141189	a corollary
0.0767913546	constraint on
0.0767668748	increasing interest
0.0767658736	by making
0.0767533010	supremum of
0.0767519407	a gaussian distribution
0.0767352821	the problem of selecting
0.0767246042	residuals from
0.0766936840	used to design
0.0766914395	complete characterization of
0.0766677849	general theory for
0.0766631723	the detection delay
0.0766501981	such estimators
0.0766260725	a purely
0.0766185629	implementation of
0.0765832359	with vanishing
0.0765694158	the benefit
0.0765590252	for finite samples
0.0765271248	m \ geq
0.0765146636	ubiquitous in
0.0765073724	characteristic function of
0.0764898072	covariance estimation for
0.0764880536	to reach
0.0764834667	ease of
0.0764797412	uniform distribution on
0.0764743497	improvements in
0.0764466503	accuracy of
0.0764306632	of fit tests
0.0763949163	this direction
0.0763940368	a systematic
0.0763690203	null hypothesis of
0.0763499526	tools such as
0.0762646661	with existing methods
0.0762557658	scheme for
0.0762457038	an orthogonal
0.0762290673	by selecting
0.0762001924	a lot
0.0761891696	the whole
0.0761614170	for sample quantiles
0.0761450663	to gain
0.0761432144	m \ times n
0.0761431622	the sample data
0.0761430549	a family of
0.0761426525	+ o
0.0761290571	a strong law of large
0.0761264968	the large sample
0.0761242339	the same order as
0.0761192286	the noise
0.0761191786	a small set
0.0761106902	the number of groups
0.0761097347	$ p 2
0.0761079892	$ \ sum
0.0761046568	a scalar
0.0761039252	\ mathcal q
0.0760979955	the author's
0.0760952662	reasons for
0.0760945396	$ p_i
0.0760769568	the ising model
0.0760615630	line of
0.0760566406	to facilitate
0.0760541426	the number of points
0.0760511106	accurate than
0.0760474869	$ 4
0.0760465240	most cases
0.0760386632	blocks of
0.0760268540	b |
0.0760162697	to carry
0.0760068910	applications in
0.0760052080	many classical
0.0760049264	start with
0.0760012212	an advantage
0.0760003954	concept of
0.0759997321	this equivalence
0.0759734307	a convenient
0.0759653072	the unknown sparsity
0.0759447998	the mutual information
0.0759262812	the empirical measure
0.0759254417	also conducted
0.0759210610	the intrinsic dimension
0.0759175970	the corresponding
0.0759062435	part of
0.0758960101	a standard gaussian
0.0758653701	the model's
0.0758639842	lines of
0.0758612230	x _
0.0758551131	a consistent estimate
0.0758400535	such tests
0.0758184112	a recently proposed
0.0758008266	derived based on
0.0758000052	some practical
0.0757858043	included in
0.0757846133	asymptotics of
0.0757588556	advances in
0.0757353536	$ p \ gg
0.0757332910	made about
0.0757216740	the initial
0.0757081990	using tools
0.0756957356	the performance of
0.0756747908	adaptive estimation for
0.0756745819	the standard deviation
0.0756082579	to explain
0.0755780430	distributed as
0.0755727044	to balance
0.0755503544	the ambient
0.0755443313	log likelihood of
0.0755392140	= g
0.0755348847	empirical application to
0.0755155352	convergence rate under
0.0755122870	two quantities
0.0755036268	certain regularity
0.0754952621	for simulating
0.0754912085	composed of
0.0754768126	b ^
0.0754766954	the asymptotic minimax
0.0754688864	the population
0.0754572564	solution of
0.0754557950	technique for
0.0754492821	this study
0.0754475556	this review
0.0754329364	to analyse
0.0754136466	the upper and lower
0.0754112813	$ \ sqrt n
0.0753883427	paper aims to
0.0753808574	a linear
0.0753705919	\ int_ \ mathbb r
0.0753697398	realization of
0.0753660512	the asymptotic distributions
0.0753620623	list of
0.0753570584	| u
0.0753524895	normal distribution with
0.0753217017	both classical
0.0753083029	the number of non zero
0.0752987091	$ \ tilde \ mathcal o
0.0752875635	= 1 ^ m
0.0752874769	a universal
0.0752852213	the drift
0.0752822675	new model selection
0.0752573269	suited to
0.0752365312	consequences of
0.0752171136	the bias variance
0.0752054240	a modified
0.0752036574	two classes
0.0751877162	a sufficient statistic
0.0751760122	a flexible
0.0751720148	considered by
0.0751512913	an appropriately
0.0751430549	the existence of
0.0751368860	effect of
0.0751341160	this survey
0.0751198366	\ leq \ infty
0.0751192286	the dimension
0.0751090290	then proposed
0.0751024908	$ \ mathcal c
0.0750960140	discretization of
0.0750739290	an integer
0.0750600528	$ \ mathbb r ^ m
0.0750581976	the mean function
0.0750572564	control of
0.0750521907	algorithm provides
0.0750361102	the finite sample performance of
0.0750115782	optimal rate of
0.0750109192	numbers of
0.0750024560	lower bound of
0.0749973472	the matrix variate
0.0749964693	presentation of
0.0749820469	a great
0.0749786097	suffice to
0.0749609678	demonstrated using
0.0749447522	$ \ x_
0.0749177970	likelihood estimator for
0.0749140893	\ mathbb r ^ 2
0.0748806544	p n \ rightarrow
0.0748693226	a trade off
0.0748633358	general theory of
0.0748613244	2 5
0.0748561951	the problem of parameter
0.0748442552	to find
0.0748293464	to attain
0.0748233565	$ \ | \ hat
0.0748179835	two real
0.0748045226	to classify
0.0747990584	this idea
0.0747927349	asymptotic mean
0.0747915305	$ \ x_t
0.0747803298	two nodes
0.0747740080	the minimax
0.0747618826	some existing
0.0747556102	an analytical
0.0747537854	k \ geq
0.0747535667	the problem of statistical
0.0747466716	based approach for
0.0747372288	both theoretically
0.0747277489	to distinguish
0.0747219718	fluctuations of
0.0747037935	approach does not
0.0746997622	a formal
0.0746996541	this formula
0.0746978753	and shephard
0.0746957960	the mean square
0.0746952526	n \ rightarrow \ infty
0.0746631366	proved by
0.0746553663	instead of
0.0746490080	the conditional
0.0746459941	a delicate
0.0746379219	to cluster
0.0746376900	divergence from
0.0746255965	in depth
0.0746255077	| \
0.0745438501	a large sample
0.0745377115	previous work on
0.0744913435	these features
0.0744659638	a reasonable
0.0744623392	some common
0.0744435875	in such situations
0.0744385733	some new
0.0744359140	then prove
0.0744193492	an adjusted
0.0744180098	added to
0.0744146067	both discrete
0.0743967895	the conditional mean estimator
0.0743734603	efficient estimation in
0.0743351293	to hold
0.0743240160	different from
0.0743170164	an ergodic
0.0742844158	an asymptotically
0.0742807241	lifetimes of
0.0742667500	to investigate
0.0742613989	novel theoretical
0.0742485978	\ mathcal m
0.0742409284	$ \ ell ^
0.0742373321	very sensitive to
0.0742368488	the spectral density
0.0742325080	comparable with
0.0742033747	some natural
0.0742006661	the time varying
0.0741920887	networks via
0.0741809093	distribution function of
0.0741792864	a fast
0.0741712190	power of
0.0741625067	by generalizing
0.0741192286	the observed
0.0741136109	the asymptotic analysis
0.0741050357	vicinity of
0.0740979955	the integrand
0.0740969047	uniform convergence of
0.0740853425	bandits with
0.0740844406	well as
0.0740810972	included to
0.0740785578	novelty of
0.0740584651	the original model
0.0740382555	a bootstrap procedure
0.0740315678	a compact
0.0740163179	model selection by
0.0740102984	m \
0.0740027243	measures of
0.0739963365	relationship with
0.0739847811	\ mathbf s
0.0739819929	function based on
0.0739703926	d \ times
0.0739670595	statistic under
0.0739663355	with prescribed
0.0739620787	extrema of
0.0739531370	sample from
0.0739522099	to resolve
0.0739512799	recovery of
0.0739468315	trees from
0.0739432991	test statistic for
0.0739399997	optimal design for
0.0739214064	as input
0.0739174065	to approximate
0.0739173870	the explanatory variables
0.0739093972	signals from
0.0739078512	the hardness
0.0738780762	studied using
0.0738679403	to separate
0.0738465441	nonparametric estimation in
0.0738413405	to modify
0.0738204808	the problem of optimal
0.0738059796	zeros of
0.0738053576	earlier by
0.0738047051	new generalization
0.0738012056	to draw
0.0737958192	x \ beta
0.0737919594	starting with
0.0737877816	conditional expectation of
0.0737649217	operator norm of
0.0737503556	sensitivity analysis for
0.0737445703	available data
0.0737345347	regression model for
0.0737343523	a non stationary
0.0737295180	principal components of
0.0737246350	to vary
0.0737098258	statistical test for
0.0737024508	used for inference
0.0736960424	the mean squared
0.0736747670	computational complexity of
0.0736631360	roles of
0.0736526882	derive rates of
0.0736508802	a random graph
0.0736427719	minimax rate of
0.0736224910	variable selection for
0.0736086089	with probability one
0.0735986522	the sampling rate
0.0735766902	of attraction
0.0735537864	not available
0.0735241380	the extremogram
0.0734953908	roles in
0.0734858938	limits on
0.0734797595	the title
0.0734572564	means of
0.0734466503	degree of
0.0734419324	a combination
0.0734339293	the continuous time
0.0734277243	type of
0.0734189598	adjust for
0.0734175877	a real
0.0733969890	an increasingly
0.0733928982	lying in
0.0733239144	2 \ log
0.0732871819	for studying
0.0732522195	details of
0.0732436796	superiority of
0.0732411617	the basic
0.0732326468	valid for
0.0732304234	the statistics literature
0.0732236516	capability of
0.0732130302	used as
0.0732089583	a very general
0.0732013781	\ 1
0.0731726788	\ mathbf r ^
0.0731672972	inference from
0.0731615650	f \ in
0.0731549429	the estimated
0.0731282822	\ al
0.0731088315	max \
0.0730989652	the problem of adaptive
0.0730939423	feature of
0.0730867591	pair of
0.0730675537	an affine
0.0730563448	theoretical results on
0.0730284658	associated to
0.0730227196	to formulate
0.0729918913	to bring
0.0729814020	^ p \ times
0.0729799973	zeros in
0.0729778023	$ c
0.0729720544	in order to estimate
0.0729650897	to control
0.0729414477	the false alarm
0.0729398031	introduced in
0.0729287056	a robust version
0.0729265684	covariance structure of
0.0729163976	a pair
0.0728989302	sides of
0.0728729957	strategies for
0.0728624542	seek to
0.0728591614	descriptions of
0.0728531974	to enjoy
0.0728359587	derivative of
0.0728310529	available methods
0.0728299774	a non linear
0.0728155199	the transition density
0.0728147613	\ mathbf t
0.0728026317	insights from
0.0727894640	numerical results on
0.0727874420	large variety of
0.0727825234	on synthetic and real
0.0727728720	a large range
0.0727713976	the circle
0.0727647227	correctness of
0.0727579132	follows from
0.0727538059	properties such as
0.0727318201	bayesian framework for
0.0727241751	used to test
0.0727119596	roughness of
0.0726964804	eta \
0.0726918357	a prominent
0.0726778682	the famous
0.0726712414	probability distribution on
0.0726681189	inversion of
0.0726650296	a variety of applications
0.0726399065	p \ times p
0.0726269593	to maintain
0.0726237412	superposition of
0.0726057349	error rates of
0.0725995941	the negative log
0.0725911469	demonstrated with
0.0725618738	the bulk
0.0725315678	a basic
0.0725278363	parameterization of
0.0725206784	\ mathbb z ^
0.0725200360	tail index of
0.0725132293	dual to
0.0725122522	also show
0.0725092628	a proxy
0.0724681728	density estimation with
0.0724590225	the problem of reconstructing
0.0724575911	an extension
0.0724534245	present work
0.0724318875	period of
0.0724226394	specialized to
0.0723967998	in many situations
0.0723887272	fixed number of
0.0723624809	the asymptotic bias
0.0723624022	a number of
0.0723570230	any finite
0.0723561951	the number of data
0.0723524895	a rich
0.0723245179	the diameter
0.0723123355	free from
0.0723107406	a new estimation
0.0723092352	consequences for
0.0722843860	to conduct
0.0722514407	\ &
0.0722438634	to get
0.0722406267	this methodology
0.0722346717	the theory developed
0.0722305653	history of
0.0722261098	the step size
0.0722113986	confidence sets in
0.0722055436	conditional distributions of
0.0721919809	a refined
0.0721854024	the problem of variable
0.0721824571	the resultant
0.0721776462	a proper
0.0721426909	$ e ^ \
0.0721366338	the false
0.0721364379	probability distribution of
0.0721274791	this notion
0.0721160114	p *
0.0721127898	\ alpha \ in 0,1
0.0721096233	the proportion
0.0721077409	both simulated and real
0.0721061410	do not need
0.0720882911	a spherically
0.0720734472	finiteness of
0.0720494234	a preliminary
0.0720355432	to decompose
0.0720343538	general case of
0.0719794919	a frequentist
0.0719776820	the interplay
0.0719772903	non asymptotic bounds for
0.0719746799	the metric entropy
0.0719622256	the new algorithm
0.0719470387	the breakdown point
0.0719357956	a convex set
0.0719357877	to construct confidence
0.0719259092	this relationship
0.0719257340	change in
0.0718943954	benefits of
0.0718929166	$ factor
0.0718911617	a similar
0.0718894446	an active
0.0718893957	suite of
0.0718834112	analogs of
0.0718738430	density estimation for
0.0718626991	study of
0.0718624461	to reject
0.0718615010	\ xi ^
0.0718415543	the main purpose
0.0718384020	the variance
0.0718246924	p \ times
0.0718143441	p =
0.0718006833	x ^ t
0.0717912837	optimal up to
0.0717897363	extended by
0.0717780769	distributions on
0.0717723579	extends to
0.0717662167	a prior distribution
0.0717568910	method to
0.0717471232	parametrization of
0.0717200975	estimation methods for
0.0717103326	a counterexample
0.0716914721	gg \
0.0716910996	error rates for
0.0716877820	optimal rate of convergence for
0.0716675472	m _
0.0716345227	the well known
0.0716314277	tests under
0.0716304405	the relevance
0.0716288742	applied to various
0.0716284437	performs well in
0.0716101259	at different
0.0715997390	optimal value
0.0715941413	to exceed
0.0715871365	the conditional variance
0.0715471115	squares estimators of
0.0715316909	a sharp
0.0715305409	constructed as
0.0715250328	general framework of
0.0715230895	the adjacency matrix
0.0715207228	to adapt
0.0715093378	or not
0.0714907393	article provides
0.0714790577	law of
0.0714609396	| b
0.0714474279	k ^
0.0714381726	based estimator of
0.0714212844	connected with
0.0714073142	probability distributions on
0.0713970673	the prediction risk
0.0713929337	in contrast
0.0713806057	minimax risk for
0.0713715794	$ h 1
0.0713682138	$ 0,1
0.0713489467	the proof
0.0713435138	variance of
0.0713320746	minimisation of
0.0713302577	between two random
0.0713201604	employed in
0.0713069850	reason for
0.0713014284	same problem
0.0712996333	defined using
0.0712897170	drawback of
0.0712719604	prior for
0.0712716604	to express
0.0712664847	the support
0.0712597286	the regression parameters
0.0712549965	inconsistency of
0.0712436813	procedures for
0.0712272552	an asymptotically efficient
0.0712269752	true even
0.0712239111	involved in
0.0712152243	probability of
0.0711774946	to apply
0.0711715844	proved for
0.0711680081	a sequence of random variables
0.0711555774	a standard
0.0711548078	the number of training
0.0711515071	transition from
0.0711383676	$ n \ rightarrow
0.0711382116	t_ \
0.0710962241	sources of
0.0710936469	a nonparametric regression
0.0710924131	ingredient in
0.0710783235	then use
0.0710745021	$ \ hat \ sigma
0.0710739143	$ \ mathbb e
0.0710681198	distribution theory for
0.0710669128	a broad range of
0.0710657712	martingales with
0.0710638243	result from
0.0710610801	an input
0.0710576820	an aggregation
0.0710217175	a wide
0.0710177113	to relate
0.0709997496	relaxation of
0.0709793951	direction of
0.0709764728	do not make
0.0709729562	groups of
0.0709500178	different parameters
0.0709230427	ergodicity of
0.0709079895	a likelihood ratio
0.0708681120	very well
0.0708567011	information geometry of
0.0708507678	guarantees on
0.0708209019	$ 3
0.0708183533	mass at
0.0708041590	the spectral distribution
0.0707750546	connected by
0.0707749131	as special
0.0707385790	a parametrized
0.0707305653	positions of
0.0707297374	submatrices of
0.0707155455	the new estimator
0.0706975051	fisher information of
0.0706926358	e ^ \
0.0706881264	$ \ textit
0.0706744890	priors on
0.0706686774	very different
0.0706683005	the block bootstrap
0.0706510028	the proportion of true
0.0706314080	concavity of
0.0706161153	demonstrated in
0.0706133136	to explore
0.0706084501	one observation
0.0706083879	contaminated with
0.0705995546	limit distributions of
0.0705990725	based estimation of
0.0705983274	the occurrence
0.0705755824	to devise
0.0705685699	g \
0.0705641459	used to analyze
0.0705625836	this new class
0.0705417948	asymptotic normality for
0.0705371007	n \ geq 1
0.0705157210	used in applications
0.0705092496	and empirically
0.0705068884	p_n \
0.0704997158	insights on
0.0704937241	the bias
0.0704813472	crucial to
0.0704711270	a symbolic
0.0704337059	z _
0.0704164842	used to prove
0.0704075137	a certain threshold
0.0704062831	mean value
0.0703888688	estimation procedures for
0.0703866921	while still
0.0703860149	order statistics of
0.0703706851	peaks over
0.0703639182	average number of
0.0703469365	scope of
0.0703445198	demonstrated on
0.0703318094	$ x_t
0.0703228472	given to illustrate
0.0703178098	an undirected
0.0702954898	techniques for
0.0702934854	the remainder
0.0702788519	not impose
0.0702483767	statistical inference in
0.0702422388	not converge
0.0702348810	an upper
0.0702237916	random number of
0.0702070892	a comparison
0.0702044516	a normal distribution
0.0701814468	impact of
0.0701676442	the number of mixture
0.0701628819	conjunction with
0.0701565937	a link
0.0701550796	in statistics and machine
0.0701383692	unbiased estimate of
0.0701214249	achieved under
0.0701210654	1 \
0.0700757116	illusion of
0.0700716037	under sparsity
0.0700660845	possible to obtain
0.0700496110	some previous
0.0700338697	the case of gaussian
0.0700332232	the linear model
0.0700309484	$ y \ in \ mathbb
0.0700198505	permutations of
0.0700163439	to examine
0.0700093659	scalability of
0.0699958110	random vector with
0.0699808856	$ x_j
0.0699790444	seem to
0.0699618860	context of
0.0699560567	search for
0.0699339325	p_ \
0.0699244635	improvement on
0.0699177757	the lack
0.0699002147	volume of
0.0698908687	likelihood estimators of
0.0698878625	rates at
0.0698868758	jumps in
0.0698808525	inherent to
0.0698700235	the optimal minimax
0.0698646371	the practitioner
0.0698562558	the optimal rates
0.0698460354	architecture of
0.0698272654	a mixture of
0.0697964867	t 0
0.0697850180	the most widely
0.0697815414	\ mathbf v
0.0697788722	the conditional quantile
0.0697589054	1 d
0.0697508418	a sparse
0.0697215340	= e
0.0696913225	$ \ al
0.0696781244	the large deviation
0.0696770863	even for small
0.0696662018	the asymptotic performance
0.0696637700	a metamodel
0.0696580948	inference procedures for
0.0696491727	the problem of estimation
0.0696472516	results obtained in
0.0696258222	very broad
0.0696046759	the most natural
0.0696002283	statistical theory for
0.0695976940	\ sqrt 1
0.0695961591	the average
0.0695866937	points from
0.0695832451	\ hat \ alpha
0.0695746052	\ mathbf \ sigma
0.0695610948	used to demonstrate
0.0695521030	exploration of
0.0695463587	covariance operator of
0.0695413456	tests against
0.0695392431	the boundary
0.0695343971	partitions of
0.0695069672	institute of
0.0694951900	to conclude
0.0694833911	the lse
0.0694741131	to check whether
0.0694635474	deconvolution with
0.0694572564	level of
0.0694570793	0 \ alpha
0.0694477169	the notion
0.0694381020	an increase
0.0694339740	quantile regression in
0.0694158311	a trend
0.0694139930	limited by
0.0694084541	adaptive to
0.0694019257	$ \ mathcal m
0.0693985838	i \ in \ mathbb
0.0693983340	the current
0.0693901779	neighborhood of
0.0693764294	prevalence of
0.0693726723	superior performance of
0.0693670849	body of
0.0693650602	time observations
0.0693517603	the sum of squared
0.0693443128	a precise
0.0693417488	arbitrary number of
0.0693375046	the minimizer
0.0693310972	interpretations of
0.0693233367	the data matrix
0.0693204276	non parametric estimation of
0.0693122928	generators of
0.0693073406	used in
0.0692927581	the oracle property
0.0692828454	specification of
0.0692822154	possible to estimate
0.0692623539	the loss function
0.0692595540	p \ to \ infty
0.0692533170	various assumptions
0.0692531003	product of two
0.0692409840	the error rates
0.0692356892	the tail
0.0692073406	an upper bound on
0.0692024855	increase with
0.0692008838	compare different
0.0691915206	understood as
0.0691859725	many methods
0.0691780606	\ boldsymbol x
0.0691746897	the target density
0.0691673304	the number of measurements
0.0691559924	a hidden markov
0.0691542575	distribution with
0.0691299266	to impose
0.0691279561	goodness of fit of
0.0691235776	the moment generating
0.0691192286	the theoretical
0.0691170575	investigated using
0.0691106336	long as
0.0691067503	a discrete
0.0691013256	observations at
0.0690817800	a new algorithm
0.0690699668	expansion of
0.0690549542	posterior distributions of
0.0690499843	minimax rate for
0.0690431076	reduced by
0.0690350793	to decide
0.0690349396	foundation of
0.0690158046	distribution over
0.0690029617	this extension
0.0689848043	a well known
0.0689686352	a by product of
0.0689632325	the situation
0.0689422460	statistical model for
0.0689181760	some classical
0.0689063635	two well known
0.0689060072	empirical process of
0.0688949474	improving on
0.0688840417	of categories
0.0688710793	two different
0.0688659230	the existence
0.0688585324	problem in
0.0688296289	this difficulty
0.0687951235	new estimators
0.0687907983	hypothesis testing in
0.0687831381	lie on
0.0687721260	prediction error of
0.0687637744	efficient estimator of
0.0687596750	methods like
0.0687582903	statistical models for
0.0687529052	a pivotal
0.0687523794	insight on
0.0687520414	for predicting
0.0687396359	inverse problems with
0.0687387221	under very general
0.0687374462	more than one
0.0687314831	influence on
0.0687301834	problem arises in
0.0687300042	_ t \ in \
0.0686883049	a vast
0.0686867814	models under
0.0686732930	an expectation
0.0686695273	generation of
0.0686671312	the function class
0.0686666347	the familywise error
0.0686615780	detecting changes
0.0686587233	a proof
0.0686426548	mu =
0.0685957653	clt for
0.0685876207	methodology to
0.0685822981	compared to other
0.0685745179	of concordance
0.0685596172	to validate
0.0685567661	the estimated parameters
0.0685331894	different choices
0.0685306794	in \ cite
0.0685275114	as fast as
0.0685102984	$ n ^
0.0685054898	considered in
0.0684540816	the sharpness
0.0684513890	the solution
0.0684459612	the number of iterations
0.0684305983	this formulation
0.0684221911	t \ to \ infty
0.0684046181	build on
0.0683946474	the intermediate
0.0683874947	covariance matrix with
0.0683797095	the random walk
0.0683793054	more detail
0.0683786369	$ \ x_i
0.0683704560	this finding
0.0683700018	bayesian inference with
0.0683672525	likelihood estimate of
0.0683641039	many other
0.0683558651	\ leq n
0.0683428017	the sum
0.0683419799	\ times \ mathbb r
0.0683411736	parameter space of
0.0683111919	this perspective
0.0683072462	an inverse
0.0682893843	the directional
0.0682846271	\ in 1
0.0682796596	most commonly used
0.0682610188	the second method
0.0682462009	any design
0.0682414909	also introduced
0.0682302133	on simulated
0.0682150285	minimax rates in
0.0682046403	occurrences of
0.0681978211	a sample of size
0.0681930453	general method for
0.0681848239	recovery via
0.0681715002	posterior probability of
0.0681713306	the \ textit
0.0681639435	arises as
0.0681638096	research on
0.0681587435	the average number
0.0681515844	under additional
0.0681511847	this research
0.0681430549	the role of
0.0681421452	the receiver
0.0681183288	designs with respect to
0.0681053191	the size of
0.0680936558	analysis via
0.0680813356	generalisation of
0.0680417156	to cover
0.0680412037	the marginal likelihood
0.0680354120	admissibility of
0.0680124896	the joint asymptotic
0.0680002022	nonlinear least
0.0679767423	= m
0.0679644626	$ l
0.0679615412	\ sqrt 2
0.0679613793	carlo methods for
0.0679168765	to justify
0.0678965737	a stationary gaussian
0.0678956131	the observation times
0.0678931607	to decide whether
0.0678931597	perspective on
0.0678832230	these coefficients
0.0678691085	the boundedness
0.0678518811	developments in
0.0678430549	the space of
0.0678307141	the sum of independent
0.0678282589	further show
0.0678194040	and easy to implement
0.0678155245	evidence for
0.0678017053	some other
0.0677997215	general approach for
0.0677818971	an ordinary
0.0677599439	statistics under
0.0677532421	law of large numbers for
0.0677322612	likelihood approach for
0.0677271164	in genomics
0.0677192140	problem of nonparametric estimation of
0.0677156266	chosen from
0.0677053347	done by
0.0676959911	a sum of independent
0.0676932349	asymptotic properties for
0.0676871137	condition for
0.0676860695	a new measure
0.0676817901	metrics on
0.0676803862	other state of
0.0676791315	a sequence of independent
0.0676712747	a given threshold
0.0676664531	likelihood function of
0.0676585790	a remarkable
0.0676075014	the square loss
0.0675983188	the fitness
0.0675819800	this technique
0.0675325307	a new proof
0.0675255343	principles for
0.0675003122	satisfied for
0.0674488701	proposed for
0.0674467870	and asymptotically efficient
0.0674121553	the asymptotic expansion
0.0674100204	element of
0.0674082107	a conjecture
0.0674015797	likelihood estimates of
0.0673975869	first part
0.0673948983	$ q \ in
0.0673861659	propose two new
0.0673821802	a margin
0.0673758173	proposed estimators of
0.0673642180	lie in
0.0673475135	a promising
0.0673345866	procedures such as
0.0673310757	to unify
0.0673292038	$ boosting
0.0673110660	$ m =
0.0672819906	log p
0.0672807332	journal of
0.0672704734	generalized least
0.0672492474	new proof
0.0672475636	the difference
0.0672351451	criteria for
0.0672260349	a large set
0.0672215205	a functional
0.0672069789	prior distributions for
0.0672030707	the present
0.0672013093	inherent in
0.0672010943	d +
0.0672001239	for testing
0.0671948288	the target function
0.0671839827	$ d =
0.0671785941	only few
0.0671660311	stochastic processes with
0.0671602168	the divide and conquer
0.0671572568	a toric
0.0671430549	a function of
0.0671259913	squared error of
0.0671167036	developed in
0.0671121808	the limit theory
0.0670791878	k \ times
0.0670690400	discussed in
0.0670620929	based inference for
0.0670619026	by using
0.0670447273	\ mathbf e
0.0670429570	some theoretical
0.0670197414	picture of
0.0670192684	$ p n
0.0670121156	data set of
0.0670089524	by product of
0.0670028831	a white noise
0.0669989001	recent results in
0.0669840764	alternative approach to
0.0669613544	the relative entropy
0.0669471123	curvature of
0.0669419143	adaptive with respect to
0.0669415280	straightforward to
0.0669387880	a novel method
0.0669374500	the missing data
0.0669263625	\ mathcal n
0.0669196608	a direct
0.0669039094	the transition probability
0.0668977704	^ o
0.0668944690	$ b
0.0668857727	$ x_n
0.0668721901	t |
0.0668528089	lo \
0.0668343601	the hidden markov
0.0668116078	selected from
0.0668049525	trials with
0.0667644373	grows with
0.0667449020	the unknown parameters
0.0667193511	to guarantee
0.0667145641	distribution function for
0.0667143924	violations of
0.0666879852	existing methods for
0.0666873424	some aspects
0.0666769316	illustrated in
0.0666729562	concentration of
0.0666660380	the ultra high
0.0666548834	the scale parameters
0.0666475344	an extreme value
0.0666243008	the help of
0.0666239220	a regression model
0.0666202011	of order two
0.0666136346	system of linear
0.0666071183	w =
0.0666004255	a substantial
0.0665942155	contrast to most
0.0665924692	discrete observations of
0.0665824459	likelihood estimation in
0.0665795772	a new notion
0.0665736954	2 +
0.0665697270	the asymptotic behaviour
0.0665569177	in various settings
0.0665481911	improvement of
0.0665197979	p values of
0.0665041668	establish consistency and
0.0664915577	the interpolation
0.0664868305	best estimator
0.0664867558	not known
0.0664864379	likelihood estimator of
0.0664774073	a new data
0.0664548360	new theoretical
0.0664472106	$ exponential
0.0664416516	to make inference
0.0664389830	known procedures
0.0664309237	the classic
0.0664279372	for implementing
0.0664133340	regularization by
0.0664114117	a uniform
0.0663953971	the context
0.0663776319	relevance to
0.0663741766	a kernel
0.0663722342	convergence rates in
0.0663705688	the training data
0.0663632075	standard deviation of
0.0663421264	eigenvector of
0.0663408527	new method
0.0663352409	as particular cases
0.0663310972	pool of
0.0663267738	fast rates of
0.0663154865	identified by
0.0663141405	testing problem for
0.0663088966	an identifiable
0.0662936684	an issue
0.0662797626	distribution on
0.0662777243	problems in
0.0662554593	empirical likelihood for
0.0662325120	a brief
0.0662291452	\ frac 2
0.0662165933	between two probability
0.0662017712	the wavelet coefficients
0.0662006359	attention in
0.0661942257	the standard normal
0.0661840745	log d
0.0661780227	features from
0.0661640260	no polynomial
0.0661549429	the assumption
0.0661459348	a new concept
0.0661430549	a generalization of
0.0661278407	difficulty in
0.0661255243	a powerful
0.0661202592	of freedom
0.0661180394	used to establish
0.0660919559	the number of latent
0.0660903686	estimation with
0.0660861183	the empirical risk
0.0660824278	the uniform distribution
0.0660699668	minimization of
0.0660695307	the quadratic variation
0.0660681707	to use
0.0660606328	the equality
0.0660558824	estimation problem of
0.0660515357	p _
0.0660364218	$ h \
0.0660203366	performance over
0.0660079953	true value of
0.0660027403	often used
0.0659992989	for evaluating
0.0659969571	the main theorem
0.0659916532	paper uses
0.0659750713	the maximum entropy
0.0659454217	\ _ t \ in \
0.0659299777	two related
0.0659070287	t =
0.0659032022	a bit
0.0658965863	novel procedure
0.0658920973	methodology for
0.0658903347	the theoretical properties
0.0658785288	a strong
0.0658730091	paper gives
0.0658639942	the sample size goes to infinity
0.0658629948	the well studied
0.0658492454	a black
0.0658459530	a popular
0.0658406959	for proving
0.0658399672	rate of convergence of
0.0658247085	the ipw
0.0658198379	$ \ mathcal p
0.0658106265	fall in
0.0658048786	the supremum
0.0657962396	the fundamental limits
0.0657879332	the new procedure
0.0657876635	the inverse
0.0657814494	x_0 \
0.0657723296	detection problem in
0.0657652757	the strong law of large numbers
0.0657538707	2 ^ k
0.0657296174	several classes
0.0657259626	a closed
0.0657254255	a crucial
0.0657130222	pattern of
0.0657066352	in many practical
0.0656739711	minimax risk in
0.0656611183	the population size
0.0656410947	solutions of
0.0656239836	popularity of
0.0656236034	a probability density
0.0656165089	the same set
0.0656113144	the necessity
0.0656089444	$ n ^ \
0.0656029686	the marginal
0.0655853988	the most commonly
0.0655564204	with drift
0.0655429138	some covariates
0.0655365687	the minimax rates
0.0655274084	datasets from
0.0655244110	minima of
0.0655210507	introduction of
0.0655192151	evaluated on
0.0655132787	c ^
0.0655117541	regressions with
0.0655081071	the score test
0.0655041436	a hierarchical
0.0654991064	some real
0.0654940751	the small sample
0.0654776126	segments of
0.0654758655	well in practice
0.0654735387	only depend
0.0654686466	embeddings of
0.0654558100	than usual
0.0654556008	a relatively small
0.0654377656	a function
0.0654347051	the empirical spectral
0.0654214613	$ distance between
0.0653923842	\ log d
0.0653857192	the construction of confidence
0.0653636699	equations with
0.0653546134	met in
0.0653404292	$ \ theta ^ *
0.0653382566	conducted on
0.0653323746	the mean residual life
0.0653265827	a notion
0.0653223452	the asymptotic behavior
0.0653168281	n \ times
0.0653103157	$ confidence
0.0653090467	a sensor
0.0653079911	implication of
0.0653074227	appropriate choice
0.0653040608	a continuum
0.0653037420	asymptotically optimal for
0.0652755107	incorporated in
0.0652746833	fluctuations in
0.0652728015	regression function in
0.0652670911	the vast
0.0652505253	observed with
0.0652427704	principle for
0.0652377858	correlated with
0.0652328351	classification using
0.0652276304	any assumption
0.0652273493	explanation for
0.0652074546	second approach
0.0651902009	to leverage
0.0651787692	a collection of
0.0651523559	a robust
0.0651512089	to grow
0.0651508418	a stochastic
0.0651389141	as follows
0.0651346083	then provide
0.0651123406	adopted to
0.0651096986	several simulation
0.0651016995	of magnitude
0.0651001012	posterior distribution of
0.0650926548	epsilon =
0.0650849050	the angular
0.0650642165	under dependence
0.0650475849	gaussian processes with
0.0650413814	bayesian inference in
0.0650369775	a realization
0.0650217291	empirical processes of
0.0650182904	main contribution of
0.0650041193	an expression
0.0649965447	difference of
0.0649671109	simulation results for
0.0649576609	the tendency
0.0649562733	the conditional distribution
0.0649502277	the consistency and asymptotic normality
0.0649495921	an identity
0.0649404894	a weighted average
0.0649401178	the results obtained
0.0649313335	in econometrics
0.0649053027	optimal designs in
0.0648811762	differ in
0.0648685546	a smooth
0.0648591674	propose here
0.0648581672	matrix of
0.0648452929	empirical performance of
0.0648342202	two independent
0.0648134552	information matrix of
0.0648107623	impossible to
0.0647942717	$ constraint
0.0647915214	this yields
0.0647747136	unified way
0.0647539637	eigenvalues and eigenvectors of
0.0647376328	a directed
0.0647363597	instances of
0.0647285808	the division
0.0647121743	a companion
0.0647089230	value copulas
0.0647034160	2 \ times
0.0646940980	the inductive
0.0646747143	an ensemble
0.0646724579	in many problems
0.0646633074	important in many
0.0646586405	the degree distribution
0.0646537961	of samples required
0.0646525894	the power
0.0646375966	for choosing
0.0646010086	other than
0.0645903293	the asymptotic validity
0.0645867545	grows as
0.0645765427	possibility of
0.0645733301	configurations of
0.0645705859	for designing
0.0645699977	in terms of power
0.0645596477	\ leq k
0.0645586226	the design
0.0645509605	with errors in variables
0.0645277243	inference in
0.0645251991	estimators in
0.0645011152	the excess
0.0644936233	a uniform distribution
0.0644918153	the problem of multiple
0.0644898578	the conventional
0.0644848862	requirements for
0.0644830011	value distribution
0.0644811203	matrices via
0.0644797277	a convolution
0.0644638525	\ lambda 0
0.0644589876	an invariance
0.0644473709	the problem of nonparametric
0.0644398682	transformations of
0.0644275013	the first result
0.0644120776	the singular values
0.0643986705	transformation of
0.0643834100	appears in
0.0643711457	i \ leq
0.0643551903	for contingency
0.0643400677	$ dependent
0.0643199668	the tail dependence
0.0643161736	a recent
0.0642562645	$ m \ times
0.0642380553	expensive to
0.0642379570	proposals for
0.0642361102	scales with
0.0642225670	\ cal x
0.0642186613	the mean squared error
0.0642186068	statistical theory of
0.0642161164	found to
0.0642079652	the nonparametric maximum
0.0642016751	stable under
0.0641994281	enough to
0.0641972867	alpha =
0.0641941599	in favor of
0.0641832810	a large range of
0.0641616028	discussed by
0.0641546237	occurring in
0.0641527492	the efficacy
0.0641422797	$ z =
0.0641274030	the asymptotic theory
0.0641085675	investigated under
0.0641075663	relative error of
0.0640969023	also proposed
0.0640795455	each pair of
0.0640480002	a rectangular
0.0640389652	the validity
0.0640361665	$ \ mathbf m
0.0640123919	the result holds
0.0640049542	unknown parameters of
0.0640014281	t +
0.0639897738	computation of
0.0639872081	not rely
0.0639861543	in designing
0.0639800907	a novel bayesian
0.0639642028	modulus of
0.0639406812	in favor
0.0639308546	not possible
0.0639286931	some new results
0.0638995741	obtained in
0.0638955187	diffusions with
0.0638888232	mixture model for
0.0638856951	new robust
0.0638824918	testing procedure for
0.0638808747	likely to
0.0638540608	a nontrivial
0.0638514493	a sequence
0.0638397365	the space of probability
0.0638372464	a central
0.0638245717	all stationary
0.0638198375	cases such as
0.0638061988	estimator under
0.0637915608	the primal
0.0637850529	the second approach
0.0637783958	to possess
0.0637683805	usage of
0.0637623786	reduce to
0.0637530386	the contrary
0.0637343675	a possibility
0.0637153814	two procedures
0.0637038217	the finite population
0.0636940225	a polynomial
0.0636854804	change detection in
0.0636784940	a significance test
0.0636471382	theoretical results with
0.0636282500	intersection of
0.0636230512	for solving
0.0636220493	the new model
0.0636185138	dimension of
0.0636181656	regression via
0.0636083643	all parameters
0.0635831791	of large random
0.0635782304	the covariance
0.0635705596	the primary
0.0635591845	not assumed
0.0635553420	testing problem of
0.0635514515	consideration of
0.0635440995	on simulated and real
0.0635308722	computed on
0.0635281226	such dependence
0.0635251991	parameters in
0.0635190525	second method
0.0635140008	a multidimensional
0.0635031942	emergence of
0.0635014997	the total variation distance between
0.0634980005	$ _
0.0634935114	\ sum
0.0634873554	the scope
0.0634525306	a union
0.0634409762	observed in
0.0634084218	problem at
0.0634028831	such as consistency
0.0633961702	the empirical performance
0.0633862796	areas of
0.0633611183	the design points
0.0633610740	several methods
0.0633530510	spectral density of
0.0633523237	in many settings
0.0633404292	$ \ mathcal q
0.0633397144	$ var
0.0633388685	extensively in
0.0633386629	$ value
0.0633227146	examples such as
0.0633157078	many different
0.0632957126	arrays of
0.0632944475	i \ le
0.0632931285	theories of
0.0632879728	squared error in
0.0632840958	parametric rate of
0.0632772358	a neighborhood
0.0632710091	some numerical
0.0632700750	the excursion
0.0632558890	the holonomic
0.0632534401	becomes more
0.0632504190	$ \ | \ cdot \
0.0632212472	used to model
0.0632021674	same limit
0.0631532782	the objective
0.0631464083	gamma \ in
0.0631420107	the opposite
0.0631357254	$ k =
0.0631146733	for investigating
0.0631146502	a new framework
0.0631102137	presented to
0.0631053191	the support of
0.0630979189	the absence
0.0630930513	a new result
0.0630716648	\ bar x
0.0630683931	the volume
0.0630660284	area of
0.0630625748	vectors from
0.0630454999	just one
0.0630454146	posterior distribution on
0.0630451121	the nuisance parameter
0.0630380643	a concrete
0.0630275785	estimation error of
0.0630225759	associated random
0.0630154918	goodness of fit for
0.0630135421	the idea
0.0630053475	the distribution of
0.0629808988	$ vertices
0.0629775109	n \ sqrt
0.0629735596	the most general
0.0629661349	the french
0.0629637927	the input
0.0629389505	to reveal
0.0629373355	gains in
0.0629279800	difficulties in
0.0629272654	the sum of
0.0629180271	this regime
0.0629168477	the form
0.0629146229	stability of
0.0629142303	the expectation
0.0629003425	a sequence of random
0.0628953250	r ^
0.0628885586	to construct estimators
0.0628841840	$ p \ in
0.0628807618	each pair
0.0628742178	embedded in
0.0628705876	a reference
0.0628668025	pi \
0.0628651401	a random field
0.0628433679	| ^
0.0628401862	applied to other
0.0628394709	the first
0.0628309453	the sparsity level
0.0628264032	value statistics
0.0627948343	the null and alternative
0.0627903551	gap by
0.0627881341	means of two
0.0627521128	a semimartingale
0.0627506244	a gaussian mixture
0.0627377775	such algorithms
0.0627089623	likelihood estimator in
0.0627062831	chains with
0.0626931621	the covariance kernel
0.0626741413	known as
0.0626711867	= f
0.0626587233	the definition
0.0626561762	function over
0.0626449278	the parametric rate
0.0626438647	expansions of
0.0626381073	population mean in
0.0626377597	\ ell ^ 2
0.0626217511	under uncertainty
0.0626106262	projections for
0.0626083879	lies on
0.0625730941	a probabilistic
0.0625602790	vectors with
0.0625517906	the availability
0.0625433767	vector based on
0.0625378124	to test
0.0625292355	function from
0.0625269641	shifts in
0.0624896964	different values
0.0624896054	for quantifying
0.0624820038	robustness of
0.0624760517	by \ cite
0.0624754894	a subgraph
0.0624683235	different estimators
0.0624560975	a joint distribution
0.0624345074	segmentation of
0.0624229404	effort to
0.0624128260	adapted for
0.0624108659	runs in
0.0623965055	n \ right
0.0623866116	the outcome
0.0623795859	a parametric rate
0.0623725765	a weighted
0.0623653412	$ l ^ q
0.0623629894	the mesh
0.0623614169	the mixture components
0.0623421264	homogeneity of
0.0623338573	also provides
0.0623029062	likelihood estimation with
0.0622779032	points in
0.0622713079	choices for
0.0622649574	of experts
0.0622507033	method over
0.0622490019	posterior distributions for
0.0622365173	the beginning
0.0622343508	the seminal
0.0622331382	a very broad
0.0622238386	s 0
0.0622236763	the minimax optimality
0.0622215962	the rate of convergence
0.0622207882	estimator with
0.0622180794	the data distribution
0.0622056076	a nice
0.0621896886	to deal
0.0621894699	the asymptotic behavior of
0.0621818592	the incidence
0.0621738054	a fully data
0.0621573989	populations with
0.0621430549	the effect of
0.0621352383	the computational cost
0.0621257246	limits for
0.0621159656	growing with
0.0621091752	addressed in
0.0620868176	regression coefficients in
0.0620833860	refinement of
0.0620627448	stratification of
0.0620623517	converges almost
0.0620551423	investigation of
0.0620349852	the differential entropy
0.0620333175	one class
0.0620286136	not depend
0.0620202215	directly to
0.0620127667	a microarray
0.0620109460	separability of
0.0620060224	decompositions of
0.0619938466	the irrepresentable
0.0619865441	estimation error for
0.0619836365	changes in
0.0619789215	the knockoff
0.0619753417	allows to obtain
0.0619711284	or even
0.0619652446	many commonly
0.0619625459	estimated with
0.0619602425	method through
0.0619527463	continuous with respect to
0.0619218887	n ^
0.0619178402	non asymptotic bounds on
0.0619084389	convergence rate for
0.0618954007	the dependent variable
0.0618864279	in various fields
0.0618853414	all variables
0.0618708048	breaks in
0.0618703060	the saddlepoint
0.0618537621	a parametric model
0.0618511461	then study
0.0618478166	the score function
0.0618417890	a mixture model
0.0618353032	1 t
0.0618328166	the pdf
0.0618302106	the observed variables
0.0618018762	the quadratic loss
0.0617920191	an optimization
0.0617794128	expressed in
0.0617736299	the input variables
0.0617711760	a large collection of
0.0617494397	crucial for
0.0617397069	distributions with
0.0617257807	the fr
0.0617238266	allow for
0.0617119562	chosen to
0.0617107117	to highlight
0.0617078912	only one
0.0617051538	the same convergence
0.0617049581	the minimax lower
0.0617048662	error bound of
0.0617046738	at providing
0.0616817334	to update
0.0616489815	positivity of
0.0616473965	the number of observed
0.0616325131	desirable to
0.0616181253	density of
0.0616103115	the asymptotic properties
0.0615979784	benefit of
0.0615865920	\ gamma 1
0.0615682919	submatrix of
0.0615354400	widely used to
0.0615187829	design under
0.0615173994	a suitably
0.0615111172	in time and space
0.0614958395	and many others
0.0614892109	among variables
0.0614829611	a class of multivariate
0.0614518634	element in
0.0614386762	the number of blocks
0.0614373355	degeneracy of
0.0614327490	challenge in
0.0614253270	the heritability
0.0614065433	estimator over
0.0614004203	the posterior density
0.0613974821	a user
0.0613954496	those results
0.0613896803	the posterior probability
0.0613893674	a directed acyclic
0.0613531614	the heat
0.0613473861	any estimator
0.0613431492	a fine
0.0613157256	practical performance of
0.0613043089	a meaningful
0.0612815633	models with many
0.0612592451	implementations of
0.0612583558	efficacy of
0.0612530050	some properties
0.0612514483	reconstruction of
0.0612479562	smoothness of
0.0612289252	\ sum_ k =
0.0612282982	majority of
0.0612256896	a straightforward
0.0612255699	amount of data
0.0612236243	a new characterization
0.0612201100	investigated in
0.0612134068	the correctness
0.0612119076	unified approach to
0.0612114964	proposed in
0.0612099050	the instantaneous
0.0612055368	for assessing
0.0611916729	of change points in
0.0611905517	further extended
0.0611850007	these theoretical
0.0611779532	estimation problem for
0.0611777685	formulation for
0.0611728176	same asymptotic
0.0611690542	not follow
0.0611684293	a deterministic
0.0611449171	the corresponding posterior
0.0611428601	limit theorem with
0.0611423829	specified by
0.0611359628	constrained least
0.0611315336	possibility to
0.0611196347	elements in
0.0611098854	existing methods in
0.0611053191	the dimension of
0.0611005859	a new family
0.0611003869	$ \ x_t \
0.0610957119	performed to
0.0610918290	n +
0.0610809320	turn to
0.0610659424	ranges of
0.0610644764	essential to
0.0610516136	\ min \
0.0610495925	interplay of
0.0610465421	functions with
0.0610355704	consistency and asymptotic normality for
0.0610352197	estimators with
0.0610274588	s ^
0.0610145406	procedures do
0.0610109359	running time of
0.0609990171	to deal with
0.0609974436	2 \ beta
0.0609820278	to construct confidence intervals for
0.0609795168	the frequentist coverage
0.0609681018	$ p =
0.0609580487	all other
0.0609387309	the causal effect
0.0609367814	distribution under
0.0609243350	a rescaled
0.0608927862	the degrees of freedom
0.0608809769	equality of two
0.0608745593	\ times m
0.0608741180	a combinatorial
0.0608731912	a critical
0.0608685952	the first time
0.0608621983	a significant
0.0608273918	the error rate
0.0608272654	the impact of
0.0608160208	estimators such as
0.0608159868	applied in
0.0607817296	enables to
0.0607710989	a statistical
0.0607704486	an entropy
0.0607652262	the inner product
0.0607588220	space into
0.0607533736	proxy for
0.0607415297	success in
0.0607305322	cumulants of
0.0606790426	at least one
0.0606735611	in conjunction with
0.0606693977	for maximizing
0.0606666579	trajectory of
0.0606558381	a large deviation
0.0606465261	an immediate
0.0606397247	evolution of
0.0606385573	ij \
0.0606165280	singularity of
0.0606084083	the survival function
0.0606066649	to confirm
0.0606013737	mixtures of two
0.0605954564	^ n \ times
0.0605936239	new class
0.0605888763	to employ
0.0605836416	test does
0.0605826301	linearity of
0.0605611673	based on continuous time
0.0605595270	hypotheses on
0.0605515502	$ ^
0.0605431319	the concept
0.0605265716	the sandwich
0.0605121808	the cumulative distribution
0.0605069509	approach for
0.0604939191	concepts of
0.0604713914	a new statistical
0.0604572956	more general result
0.0604038631	reported in
0.0603776319	beginning of
0.0603591206	stated in
0.0603587411	attraction of
0.0603509977	x ^ \
0.0603507524	estimations of
0.0603232620	gaussians with
0.0603069521	main result of
0.0602959465	for inferring
0.0602940451	also lead
0.0602856097	guarantees under
0.0602786039	theoretical results by
0.0602738366	to match
0.0602362953	the number of communities
0.0602299675	published in
0.0602061349	distribution functions of
0.0601958876	x \
0.0601924454	d =
0.0601814257	$ drawn
0.0601652446	via extensive
0.0601225874	a subset
0.0601207523	robust with respect to
0.0601173658	the novelty
0.0601169622	increments of
0.0600924704	function with respect to
0.0600907343	a recursive
0.0600692109	problems over
0.0600563467	neighborhoods of
0.0600537350	contrast to
0.0600471886	the periodogram
0.0600436318	^ \
0.0600412640	optimal way
0.0600383060	for calculating
0.0600251274	defined in
0.0600207003	directly on
0.0600136806	asymptotic distribution as
0.0600022285	corresponding estimators
0.0599828403	in terms
0.0599712575	to make
0.0599711741	even in high
0.0599497996	measured with
0.0599405661	the lasso path
0.0599371774	densities under
0.0599269086	this feature
0.0599149658	the decay rate
0.0599031278	\ sqrt m
0.0598692933	estimation of mean
0.0598524572	l ^ q
0.0598513069	the construction
0.0598405734	via monte
0.0598273068	the regressor
0.0598272654	a subset of
0.0598149189	hardness of
0.0598063914	converge in
0.0597683305	$ n =
0.0597630260	available at
0.0597603928	contrast with
0.0597511579	more power
0.0597490010	the impact
0.0597239863	new concentration
0.0597167890	the local linear
0.0597107774	mean measure
0.0597041691	construction of such
0.0597011698	the curse
0.0596941536	one important
0.0596931286	the limit of large
0.0596929133	the auction
0.0596783085	an index
0.0596711423	the mean residual
0.0596639170	fails for
0.0596506681	metrics for
0.0596409739	the spiked covariance
0.0596309853	vertices in
0.0596209296	stated for
0.0596147766	an independence
0.0596140665	a theoretical study
0.0596094383	a rational
0.0595891442	capacity of
0.0595653653	a permutation
0.0595650553	b \
0.0595648642	known algorithms
0.0595470752	in doing so
0.0595445846	the corresponding estimators
0.0595153714	a circular
0.0595000560	^ v
0.0594937809	for exploring
0.0594850961	used for estimation
0.0594784743	composition of
0.0594706963	expansion for
0.0594459397	a given set
0.0594345062	error rate of
0.0594237471	counterpart of
0.0594143934	the same asymptotic distribution
0.0594089032	this new distribution
0.0594066877	logarithm of
0.0594006286	to support
0.0593894080	the inverse problem
0.0593670910	a model selection
0.0593656038	formulations of
0.0593483709	exploited in
0.0593343106	$ 1 \ leq p \
0.0593320627	minimaxity of
0.0593301841	the replica
0.0593286116	or complex
0.0593282354	a test statistic
0.0593248294	the generalized pareto
0.0593231601	$ \ sim
0.0593167212	favorably to
0.0593091709	projection on
0.0593001546	e _
0.0592863764	difficulty of
0.0592793161	a wavelet
0.0592715555	succeeds with
0.0592560224	span of
0.0592559352	array of
0.0592548932	factorization of
0.0592432569	shown by
0.0592391985	$ 0,1 ^ d
0.0591975109	basis for
0.0591781244	the influence function
0.0591422301	varieties of
0.0591218426	coefficients of
0.0591152647	some smoothness
0.0590976646	the exponential distribution
0.0590882714	a duality
0.0590841705	note on
0.0590744824	to offer
0.0590271561	rho \
0.0590238288	\ \ frac
0.0590164485	axioms of
0.0590067076	taken at
0.0590025627	second algorithm
0.0589989513	this observation
0.0589973001	parallel to
0.0589945128	in many real
0.0589882642	two new
0.0589859227	the performance
0.0589766623	sample complexity of
0.0589751567	general theory to
0.0589696629	an empirical example
0.0589637927	the output
0.0589544467	\ rrr ^ d
0.0589516495	log m
0.0589484793	experiments show
0.0589464390	the endpoints
0.0589411563	built in
0.0589364484	contribution of
0.0589161490	more important than
0.0589152644	\ mathcal d
0.0589128383	^ \ top \
0.0588994290	a meta
0.0588825959	system of stochastic
0.0588764322	conjectured to
0.0588486492	the exposure
0.0588467279	also describe
0.0588456106	the propensity
0.0588445370	translation of
0.0588295252	a multivariate normal
0.0588258688	the student
0.0588231524	decay of
0.0588220874	progress in
0.0588160223	a nonparametric bayesian
0.0588112869	bayesian approach for
0.0587951346	a general approach
0.0587894682	density function of
0.0587889930	written in
0.0587671055	the error probability
0.0587655209	model without
0.0587409349	$ c ^
0.0587408495	bayesian inference on
0.0587285449	an invariant
0.0587106232	columns of
0.0587060306	examined in
0.0586961919	specified models
0.0586816225	\ mathcal t
0.0586806470	proposed to
0.0586806303	from i.i.d
0.0586787577	the unknown distribution
0.0586746897	a random design
0.0586716048	a greedy
0.0586615322	implications of
0.0586538979	c \
0.0586517014	not imply
0.0586486987	a review
0.0586440056	best model
0.0586427607	random vectors in
0.0586373007	definiteness of
0.0586296185	first result
0.0586043353	flexibility to
0.0585995021	the mean integrated
0.0585975953	novel technique
0.0585575639	the reciprocal
0.0585482957	$ y = f
0.0585402469	condition number of
0.0585307289	with increasing
0.0585300703	a multiplicative
0.0585190044	a number of applications
0.0585126755	naturally to
0.0584890718	allows to
0.0584870324	vector x
0.0584847568	a shift
0.0584701135	provide necessary
0.0584574027	space of
0.0584470931	records in
0.0584285651	polynomially in
0.0584185664	distribution function in
0.0584064938	x ^ n
0.0583927141	of estimating
0.0583819263	same conditions
0.0583801463	essential for
0.0583664345	foundations of
0.0583626608	a second step
0.0583597811	\ hat f
0.0583399567	in two steps
0.0583308531	different assumptions
0.0583119618	measure on
0.0583071558	$ optimal designs for
0.0582941174	increase in
0.0582794056	provided to
0.0582790444	none of
0.0582790273	patterns in
0.0582509564	over graphs
0.0582432144	_ 1 \
0.0582196473	the kernel estimator
0.0582120190	the spot
0.0582099970	each time
0.0582076599	the most powerful
0.0582035446	a variety
0.0581967066	errors in
0.0581835694	the drift parameters
0.0581795640	asymptotic bounds for
0.0581758517	the multivariate normal
0.0581579874	the variance function
0.0581565686	geometry of
0.0581545566	the role
0.0581542803	to measure
0.0581437026	the latent process
0.0581196374	generalization error of
0.0581109955	integration with
0.0581041885	the framework of
0.0581039922	corresponding posterior
0.0581026730	the disorder
0.0580890966	employed for
0.0580749338	the empirical process
0.0580601875	a new estimator
0.0580581649	statistics for
0.0580416487	the amplitude
0.0580399992	comparing with
0.0580278628	an adaptation
0.0580209461	set of possible
0.0580190648	detection in
0.0580175085	the estimation procedure
0.0579765838	a variant
0.0579720464	mean time to
0.0579683963	invariant to
0.0579648358	algorithm to
0.0579644569	connectivity of
0.0579558476	in economics
0.0579463338	the aim
0.0579389322	underestimation of
0.0579287809	\ mathcal w
0.0579245659	the cube
0.0579088424	the tail behavior
0.0578985787	this class of models
0.0578860555	a modification
0.0578830305	the isotonic regression
0.0578776167	$ s ^ *
0.0578702463	the unit
0.0578683162	real example
0.0578674604	the error density
0.0578558651	\ le n
0.0577978765	to decrease
0.0577908254	quantiles under
0.0577790836	a graphical model
0.0577785651	topic in
0.0577698761	under various
0.0577605953	rates of convergence of
0.0577550075	expected value of
0.0577415297	lengths of
0.0577205337	only through
0.0577064723	the unobserved
0.0577018413	functional of interest
0.0577010319	the \ emph
0.0576975573	probability measures in
0.0576920098	novel bayesian
0.0576900377	random variable with
0.0576482264	an operator
0.0576428881	magnitude of
0.0576367660	missing at
0.0575943742	a conjugate
0.0575913488	to exhibit
0.0575903686	problem with
0.0575842756	a strong law
0.0575824006	not involve
0.0575813564	the conditional density
0.0575722830	the error terms
0.0575711633	the minimax optimal
0.0575693717	parameter at
0.0575648642	various statistical
0.0575610394	the mean and variance
0.0575475465	that purpose
0.0575463617	hierarchy of
0.0575442797	a diffusion process
0.0575132778	function with
0.0575096497	a multi
0.0575066201	commonly used to
0.0574980766	a summary
0.0574975765	a positive
0.0574968772	the marginal distribution
0.0574742671	the characteristic function
0.0574730049	to converge
0.0574722350	commonly used in
0.0574620843	a double
0.0574462850	statistical point of
0.0574455540	relevance of
0.0574345495	speed of
0.0574334592	a projection
0.0574177106	in probability theory
0.0574165823	function of interest
0.0574114117	a practical
0.0573975483	the false discovery
0.0573739321	for bounding
0.0573562827	influence of
0.0573555960	loss functions for
0.0573391788	both finite
0.0573343106	k \ in \ mathbb n
0.0573317229	the system's
0.0573303623	the optimal sample
0.0573198343	\ mathcal h
0.0573150382	improvement in
0.0572925656	2 ^ n
0.0572913463	a game
0.0572892461	a set
0.0572821303	the transition matrix
0.0572785448	mixture of two
0.0572738007	an almost sure
0.0572723196	success of
0.0572428945	possible rate
0.0572386733	property for
0.0572061349	estimation problem in
0.0572044217	+ +
0.0572015814	adopted in
0.0571818962	of normals
0.0571686011	true mean
0.0571531712	$ n \ times n
0.0571503251	the mean and covariance
0.0571414099	_ n \ in \
0.0571365281	propose to
0.0571134433	p values for
0.0570997277	functions over
0.0570945848	variable x
0.0570772525	calibration of
0.0570674609	the forward
0.0570562998	e y
0.0570532043	variability in
0.0570243766	corollary of
0.0570207309	processes via
0.0570169564	balls in
0.0570052403	the local asymptotic
0.0569975765	a convex
0.0569957134	a heuristic
0.0569723681	attention on
0.0569502277	the uniform convergence
0.0569471626	some extensions
0.0569468952	occur in
0.0569461051	work well
0.0569395346	this short
0.0569348899	for conducting
0.0569309068	the inherent
0.0568913985	the subcritical
0.0568782595	density with respect to
0.0568640966	a piecewise
0.0568532782	the slope
0.0568519248	the presence of outliers
0.0568508129	not necessary
0.0568272654	the validity of
0.0568192623	working in
0.0568192212	occurs in
0.0568127364	popularity in
0.0568026289	naturally from
0.0567962217	this constraint
0.0567918192	both theoretical
0.0567866711	to follow
0.0567699872	performs as well
0.0567647575	presented in
0.0567565210	derived as
0.0567557886	a ball
0.0567517987	$ independent random
0.0567471496	the non zero
0.0567423326	the anomaly
0.0567420053	insight to
0.0567236043	a kernel density
0.0567235107	variables with
0.0567149100	constructed to
0.0567142488	testing problems in
0.0567068781	challenging to
0.0567048979	to yield
0.0566938180	transforms of
0.0566930830	\ _ i = 1 ^
0.0566911376	the same order
0.0566905245	continuity of
0.0566568325	the shape parameter
0.0566468754	the ordinary
0.0566273946	both algorithms
0.0566182253	a degenerate
0.0565997905	a certain
0.0565966591	the prediction error
0.0565656388	for approximating
0.0565642455	a residual
0.0565564872	spread of
0.0565478751	the fiducial
0.0565467437	to outperform
0.0565431150	regularity of
0.0565430512	a typical
0.0565316369	diverge to
0.0565255316	a fully
0.0565174317	a class of estimators
0.0564833131	a gaussian random
0.0564774440	a limited
0.0564769655	as possible
0.0564747981	the finite sample properties of
0.0564727484	= k
0.0564558476	a simplex
0.0564442865	$ \ pmb
0.0564080539	\ real
0.0563875135	a multinomial
0.0563820733	z =
0.0563778864	the expense
0.0563709029	non asymptotic analysis of
0.0563579660	sample complexity for
0.0563570353	the random forest
0.0563488244	to include
0.0563224167	performance than
0.0563199699	the book
0.0563158710	performance via
0.0563021629	also applies
0.0562790662	setting with
0.0562572852	spectrum of
0.0562296761	general approach to
0.0562152679	y = f
0.0562016487	the rotation
0.0561857095	motivated by applications in
0.0561825192	a new class
0.0561677228	a strict
0.0561564872	constructions of
0.0561536295	by conditioning
0.0561507936	most general
0.0561435219	error in
0.0561299357	\ to \
0.0561290201	the oracle properties
0.0561114577	the parameter vector
0.0561034450	\ in r
0.0560847450	this work provides
0.0560220141	results shed
0.0560142112	expected to
0.0560099287	regression under
0.0560088769	the variance of
0.0560070163	the union
0.0560046822	but still
0.0560032165	back to
0.0559934268	the adjacency
0.0559729688	naturally in
0.0559492745	estimator does not
0.0559409070	testing if
0.0559367112	the context of functional
0.0559310385	assessed in
0.0559154699	estimator among
0.0559123440	this type
0.0559029321	cardinality of
0.0558841690	the minimax estimation
0.0558817557	a proposal
0.0558783388	the superiority
0.0558717338	a new procedure
0.0558665481	for recovering
0.0558660818	a countable
0.0558624916	empirical best
0.0558587880	used to study
0.0558584455	j =
0.0558499238	the jackknife
0.0558488334	at risk
0.0558470698	^ 2 n
0.0558431163	the normal approximation
0.0558387468	bounded from
0.0558338645	the mean integrated squared
0.0558337767	a necessary and sufficient condition
0.0558231244	the computational complexity
0.0558158058	a novel algorithm
0.0558107860	well known in
0.0558039609	squares estimator for
0.0557962372	risk under
0.0557796486	methods used in
0.0557746765	the spectral
0.0557730941	meaning of
0.0557568781	suggested to
0.0557533690	for reducing
0.0557532474	continuum of
0.0557482109	with missing
0.0557033032	the asymptotical
0.0557019802	the weak convergence
0.0556828551	1 \ right
0.0556788098	the same conditions
0.0556756541	the calculation
0.0556737744	the extent
0.0556699939	the sieve
0.0556630596	the domination
0.0556497452	data into
0.0556161800	several results
0.0556041823	monotonicity of
0.0556014613	the discrepancy
0.0555976747	$ \ bf r
0.0555966014	far more
0.0555804594	a semiparametric
0.0555785634	amplitude of
0.0555766153	out of
0.0555612304	in learning theory
0.0555437728	the particular case
0.0555335528	a unified way
0.0554896817	the projected
0.0554831528	covariation of
0.0554807485	posterior distribution in
0.0554687980	the intercept
0.0554661816	without using
0.0554599448	converges in
0.0554492961	by means
0.0554360440	lens of
0.0554315466	addition to
0.0554257535	process at
0.0554008973	the question
0.0553892525	in various applications
0.0553530331	examples of such
0.0553504985	a consistent
0.0553420910	a high
0.0553319142	studied from
0.0553279492	log n n
0.0553024240	to induce
0.0553017693	corresponding estimator
0.0553008141	a hybrid
0.0552766255	0,1 \
0.0552689208	0 q
0.0552406921	to construct asymptotically
0.0552334989	= z
0.0552320037	an estimate of
0.0552273268	works on
0.0552260925	the necessary and sufficient
0.0552239718	a continuous time
0.0552124177	the interior
0.0552115975	the new class
0.0552099188	a gaussian approximation
0.0552051051	based tests for
0.0551891851	matrices from
0.0551614117	the traditional
0.0551364468	for measuring
0.0551357806	the geometric structure
0.0551317979	the additive model
0.0551119039	a partition
0.0551068519	linear functional of
0.0551038784	then obtained
0.0551032992	\ mathbb h
0.0550932445	a feasible
0.0550744424	topology of
0.0550706559	a lack
0.0550692623	perturbations in
0.0550493241	this strategy
0.0550404587	both types
0.0550393966	number of components in
0.0550304824	prediction under
0.0550191255	^ +
0.0550183895	the law of large
0.0550004466	the trace
0.0549998187	flexibility of
0.0549975553	matrix with
0.0549491048	the estimator's
0.0549428767	even better
0.0549249692	width of
0.0549101071	kernels with
0.0549081990	a dictionary
0.0548752722	asymptotic distribution for
0.0548643762	permits to
0.0548603063	density functions of
0.0548471382	work provides
0.0548465382	^ 2 \
0.0548075232	trajectories of
0.0547951869	the increment
0.0547849224	contributions of
0.0547806928	the second moment
0.0547735394	corresponding results
0.0547670822	strength of
0.0547516622	$ \ mathbb s ^
0.0547360787	coefficient of
0.0547325600	strong law of
0.0547259242	the baseline
0.0547217826	a local linear
0.0547129438	equation with
0.0547090832	some general
0.0547056334	applies for
0.0547051025	a naive
0.0546924431	tool to
0.0546909381	two sets
0.0546838643	the ability
0.0546650879	e f
0.0546636023	optimal with respect to
0.0546581015	the realization
0.0546469705	taken from
0.0546390163	a convex optimization
0.0546383592	a kernel estimator
0.0546370647	error of
0.0546324475	the unconstrained
0.0546303827	degrees of freedom of
0.0546224068	estimates to
0.0546182002	an upper bound for
0.0546138952	determinant of
0.0545879811	b =
0.0545804052	to do so
0.0545801725	the essential
0.0545413019	families with
0.0545407215	metric on
0.0545395097	to link
0.0545309829	a dynamic
0.0545288590	product of
0.0545270003	m ^
0.0545032268	for such problems
0.0545004427	errors under
0.0544915045	making use
0.0544796631	works for
0.0544780699	any algorithm
0.0544617658	$ consistency of
0.0544469177	\ hat m
0.0544302881	minimax risk of
0.0544274544	the difficulty
0.0544105377	well even
0.0544103456	recently by
0.0543972353	to go
0.0543932214	\ 0,1
0.0543886412	by taking into
0.0543854495	fast as
0.0543819254	$ denote
0.0543707866	a bridge
0.0543501274	dynamics of
0.0543442715	the new distribution
0.0543436206	under certain
0.0543422601	the binomial distribution
0.0543375554	rate under
0.0543271962	the same number
0.0543266377	p value for
0.0543171634	the type i error
0.0543148089	individuals in
0.0543128180	several estimators
0.0543017463	in many statistical
0.0542915870	developed under
0.0542864543	$ satisfying
0.0542852980	the geodesic
0.0542811864	measured in
0.0542683324	a benchmark
0.0542640188	v ^
0.0542542932	from observational
0.0542507057	provides more
0.0542289252	\ mathcal l
0.0542261846	\ mathcal u
0.0542247559	the measurement matrix
0.0542151675	a separate
0.0542059020	the computational efficiency
0.0541865255	the class of functions
0.0541808778	developed to
0.0541792690	$ q =
0.0541601818	obtained by using
0.0541569198	$ p n \ to \
0.0541471720	the covariance structure
0.0541317090	generator of
0.0541179537	necessity of
0.0541063167	new lower
0.0541059538	guarantee for
0.0541042753	the enumeration
0.0541041885	the concept of
0.0540972027	a grid
0.0540877835	the full likelihood
0.0540504887	provided under
0.0540381326	method does not
0.0540328890	\ sigma ^
0.0540169277	testing via
0.0540098158	the raw
0.0539900462	performance in terms of
0.0539801300	risk of
0.0539756506	the response variables
0.0539751734	an assumption
0.0539670056	particularly interested in
0.0539592360	the tangent
0.0539583965	an approach
0.0539301076	the infinitesimal
0.0539257154	several other
0.0539237744	the l1
0.0539184743	perform well in
0.0539152116	the general theory
0.0539123357	tool in
0.0539006335	rate over
0.0538951828	certain number
0.0538881245	models such as
0.0538816273	view on
0.0538591921	regret in
0.0538287413	implemented to
0.0538259519	posterior distribution for
0.0538173542	a necessary and sufficient
0.0538101534	theoretical computer
0.0537997151	a quantity
0.0537691478	interpreted in
0.0537609161	necessary and sufficient conditions for
0.0537598321	a theoretical
0.0537443173	probabilities of
0.0537152149	between different
0.0537031839	a new distribution
0.0536689011	a testing procedure
0.0536649928	s &
0.0536479595	the random effects
0.0536398553	of tuning parameters
0.0536077822	to zero
0.0536023931	a simulation
0.0535985308	illustrations of
0.0535693354	a new nonparametric
0.0535652568	the notion of
0.0535529657	presented for
0.0535463323	novel class
0.0535447442	penalty on
0.0535417806	challenge for
0.0535286415	also applied
0.0535253581	ball of
0.0535127658	$ \ mathbf x
0.0534968426	effects in
0.0534961645	\ subset \ mathbb r
0.0534831370	inequality under
0.0534700298	alignment of
0.0534688276	\ sum_ i =
0.0534625172	spectra of
0.0534542892	the centralized
0.0534187281	1 \ log
0.0534144257	the mean of
0.0533931302	with existing
0.0533447132	tests with
0.0533406717	propagation of
0.0533406717	requirements of
0.0533003322	$ \ beta ^ *
0.0532902765	the mean square error
0.0532687562	compare to
0.0532664379	ingredient of
0.0532538413	ways of
0.0532275189	sets for
0.0532216916	such cases
0.0532197695	techniques used
0.0532155814	particular interest
0.0532070667	a complicated
0.0531992671	the dependence structure
0.0531897084	the price
0.0531873534	the estimation accuracy
0.0531789584	article by
0.0531783205	variability of
0.0531695808	\ mathcal c
0.0531663364	certain assumptions
0.0531518731	$ e
0.0531423331	also given
0.0531226627	provided for
0.0531121436	the strong law
0.0531010361	the singular value decomposition
0.0530956753	new efficient
0.0530702051	knowledge on
0.0530672283	some prior
0.0530466128	the accuracy of
0.0530396603	the targeted
0.0530393966	estimation of parameters in
0.0530321245	consists of two
0.0530308480	the environment
0.0530179212	the fluctuation
0.0530067825	also consider
0.0529957231	setting of
0.0529831649	important to
0.0529794719	\ in \ mathcal p
0.0529445088	a quantitative
0.0529265188	modeled in
0.0529209464	to \ infty
0.0529129233	measures on
0.0529057131	an elliptical
0.0529044143	\ log n n
0.0528659252	studied for
0.0528651162	two novel
0.0528596128	after model
0.0528373818	$ \ mathbb r ^
0.0528328890	\ mathbb x
0.0528205493	models of interest
0.0528069877	simplicity of
0.0528065458	the intensity function
0.0528051952	the intersection
0.0528032228	the covariance function
0.0527971747	classification with
0.0527970638	any other
0.0527929531	rates over
0.0527908907	distributions via
0.0527868622	a global
0.0527796822	successful in
0.0527464551	a semidefinite
0.0527462264	m estimators of
0.0527396182	control under
0.0527379599	^ p \
0.0527319222	performance of such
0.0527192077	the covariance operator
0.0527152464	under appropriate
0.0527044194	vector from
0.0526864758	new ones
0.0526853154	suboptimal in
0.0526818078	a new central limit
0.0526697171	estimator with respect to
0.0526577802	but do not
0.0526463896	quickly as
0.0526417608	appear in
0.0526410670	an introduction to
0.0526377498	requirement of
0.0526176122	considered for
0.0526167392	univariate time
0.0526152644	\ mathcal s
0.0526120411	\ ell =
0.0526092054	calculus for
0.0526075737	entries with
0.0526040786	result of
0.0525990408	the estimation of
0.0525920098	many real
0.0525772263	the logarithm
0.0525735939	now well
0.0525652568	the choice of
0.0525556566	also asymptotically
0.0525509782	vectors to
0.0525485230	vector of
0.0525391376	a collection
0.0525372107	commonly used for
0.0525249701	presented by
0.0525246266	intervals for
0.0525108859	\ sqrt p
0.0525001558	inference using
0.0524953525	importance in
0.0524701658	to satisfy
0.0524618238	adaptivity of
0.0524450834	d ^
0.0524437517	for handling
0.0524386884	optimal up
0.0524349500	the first and second order
0.0524331238	possible to
0.0524274566	learning from
0.0524130740	a mixture
0.0523839452	a surrogate
0.0523521162	designs under
0.0523468492	the landscape
0.0523158895	under regularity
0.0522954513	x = x
0.0522861922	$ independent and identically
0.0522836212	proportions of
0.0522726148	then used
0.0522713739	goes to
0.0522668030	\ sum_ i
0.0522469815	various numerical
0.0522392412	the reason
0.0522333366	often not
0.0522277214	equivalence of
0.0522270952	the main purpose of
0.0522269144	for checking
0.0522207538	signals with
0.0522170442	this scheme
0.0521929252	a confidence interval
0.0521777327	$ \ mathbf p
0.0521365516	obtained with
0.0521321305	goodness of
0.0521202582	multiple time
0.0521160511	convergence for
0.0521019266	the discretized
0.0520897735	\ boldsymbol x ^ \
0.0520896400	the ground
0.0520804188	a joint
0.0520785288	a geometric
0.0520717870	this fundamental
0.0520683449	expression of
0.0520283025	convergence under
0.0520281389	a generative
0.0520167736	x =
0.0520160962	schemes for
0.0520090588	focus on two
0.0519816976	an analysis
0.0519705291	a sensitivity analysis
0.0519668066	a nonconvex
0.0519617525	$ \ mathbf y
0.0519461170	second part
0.0519444670	u =
0.0519442427	with varying
0.0519412870	consistency for
0.0519407862	transition density of
0.0519036761	random sample from
0.0519025417	works with
0.0519024151	a periodic
0.0518988753	order one
0.0518898055	constrained to
0.0518705179	log s
0.0518603678	m estimators with
0.0518549355	flexibility in
0.0518394588	not limited to
0.0518383675	sampler for
0.0518147638	root mean
0.0517890314	the minimax rate of convergence
0.0517851506	optimal rate in
0.0517748534	the quantile function
0.0517713806	even without
0.0517417587	size tends to
0.0517325100	procedure to
0.0517229336	weighted by
0.0517108727	makes use
0.0517081140	the asymptotic distribution of
0.0516952963	uncertainty in
0.0516877841	entry of
0.0516796249	size of
0.0516711051	problem of estimation of
0.0516696784	includes as
0.0516462518	c +
0.0516278647	an estimate
0.0516243132	$ \ mathcal l
0.0515967742	the rapid
0.0515940065	the tail probability
0.0515783804	\ sim n
0.0515679212	the intuition
0.0515652568	the construction of
0.0515492519	given threshold
0.0515474697	of probability densities
0.0515456968	$ \ hat f
0.0515429531	inference through
0.0515397613	a discrete time
0.0515218172	no such
0.0515132943	$ fraction of
0.0514906231	\ beta _ \
0.0514836228	extend to
0.0514698894	the general results
0.0514537048	localization of
0.0514373153	the convolution
0.0514371515	an error
0.0514370179	introduced as
0.0514211047	the bias and variance
0.0514181995	a compound
0.0514181263	the nominal
0.0514137035	the inverse covariance
0.0514051464	in developing
0.0514050180	the frame
0.0513993265	entries of
0.0513907443	\ right \
0.0513851713	the gaussian sequence
0.0513724737	a considerable
0.0513503069	issue of
0.0513441815	models via
0.0513126092	phenomena in
0.0512983141	x_1 \
0.0512968771	the predictive distribution
0.0512926991	priors for
0.0512918685	procedure allows
0.0512858950	the new tests
0.0512784952	a nonnegative
0.0512674933	$ \ mathbb z
0.0512642277	networks from
0.0512568283	the fractal
0.0512554135	values under
0.0512529379	the existing results
0.0512505262	g ^
0.0512430955	any statistical
0.0512170763	a class
0.0512116734	s ^ *
0.0511909980	the relationship
0.0511843772	the power function
0.0511808791	variances of
0.0511680532	for describing
0.0511460419	the driving
0.0511304805	simple way
0.0511260597	a nonasymptotic
0.0511225579	for deriving
0.0511168094	$ close to
0.0511065877	o s
0.0511038965	of such methods
0.0511007928	the autoregression
0.0510883635	the generalization error
0.0510829362	region for
0.0510754770	$ \ mathbb r ^ n
0.0510744672	allocation in
0.0510551076	the pool
0.0510514087	a newly
0.0510430578	| | x
0.0510360465	$ \ mathcal f
0.0510283384	vertices of
0.0510140924	new statistical
0.0510039065	for incorporating
0.0510011282	or more
0.0509651290	the plug in
0.0509451619	a sieve
0.0509365015	l ^
0.0509185368	useful tool for
0.0509125279	a batch
0.0508994633	the problem of sampling
0.0508899851	the critical values
0.0508889974	the predictor variables
0.0508805055	motion with
0.0508797424	posed in
0.0508637851	a stochastic differential
0.0508609123	view of
0.0508593359	randomness in
0.0508516531	goal of
0.0508449967	spirit of
0.0508406717	orders of
0.0508333974	a necessary condition
0.0508223509	a coherent
0.0508179373	$ 2 ^
0.0508149482	computed for
0.0508030251	mechanism for
0.0507984020	presented as
0.0507836868	\ mathcal g
0.0507784913	rate does
0.0507736213	the first two moments
0.0507596110	a candidate
0.0507534976	node in
0.0507501110	established in
0.0507322765	\ tilde \ mathcal o
0.0507304430	i \ le n
0.0507205681	represented in
0.0507158895	an importance
0.0507151996	$ j
0.0506990421	the graphon
0.0506906864	grid of
0.0506580702	result in
0.0506494475	for comparing
0.0506487597	result on
0.0506448158	$ s =
0.0506394682	rate for
0.0506295531	^ * +
0.0506278592	$ \ hat p
0.0506243853	\ leq t
0.0506239868	remains to
0.0506121506	many others
0.0505967742	the dominant
0.0505754997	even more
0.0505694569	domain of attraction of
0.0505681263	the core
0.0505468469	trace of
0.0505261147	a copula
0.0505174602	any assumptions
0.0505169623	several different
0.0505095201	a fractional
0.0505002132	\ ll n
0.0504927430	applications to
0.0504873532	key to
0.0504813804	the number of classes
0.0504590455	the usefulness
0.0504508678	an order
0.0504415201	the cost function
0.0504317397	to take into
0.0504244232	a generalisation
0.0504090197	idea of
0.0503933476	the parent
0.0503645783	introduced for
0.0503599347	rates of convergence under
0.0503512918	also find
0.0503468245	the plane
0.0503258235	distributed under
0.0502956545	particularly well
0.0502888352	various estimators
0.0502825900	a plug in
0.0502795293	by making use
0.0502740464	large range of
0.0502651303	the limit distribution
0.0502642672	\ max \
0.0502540287	problems under
0.0502031946	the innovation
0.0501896775	a stationary time series
0.0501856724	of mixture components
0.0501791934	z ^
0.0501611389	position of
0.0501607596	allows for
0.0501402242	the strong law of large
0.0501247968	$ \ boldsymbol x
0.0501162354	demonstrated to
0.0501124787	law from
0.0501105579	the rate function
0.0501058186	than ever
0.0500932565	the probability distribution
0.0500632897	the coverage probability
0.0500529568	^ * =
0.0500499878	extent to
0.0500321072	the usage
0.0500305049	loss over
0.0500250013	quantities such
0.0500166337	margins of
0.0500029455	the p value
0.0500018519	program for
0.0500011286	the advantage
0.0499868787	an equivalence
0.0499821049	the ordinary least squares
0.0499599011	a coupling
0.0499506441	q ^
0.0499471222	only provide
0.0499376216	to fail
0.0499228779	a low
0.0499048392	action of
0.0498961610	recent work in
0.0498936711	$ 1 n
0.0498923836	= c
0.0498645452	the square root of
0.0498637777	a pure
0.0498508121	a hierarchy
0.0498458372	a nuclear
0.0498385830	this new method
0.0498254888	comparison to
0.0498251604	singular value of
0.0498232746	the stationary distribution
0.0498230062	not even
0.0498198921	random sample of
0.0498174412	a minimal
0.0497882011	values in
0.0497880916	the out of
0.0497830103	then show
0.0497829368	byproduct of
0.0497739912	graphs under
0.0497690151	error bounds in
0.0497617766	the class of
0.0497548720	estimates under
0.0497548482	2 d
0.0497462902	the sure screening
0.0496905413	the proximity
0.0496864894	$ \ mathcal r
0.0496849499	the success
0.0496848333	satisfied in
0.0496699633	various types of
0.0496674975	\ mathbb z
0.0496570552	all probability
0.0496503864	only available
0.0496460841	selection for
0.0496389227	the marginal distributions
0.0496053173	u statistics of
0.0495933183	the general problem of
0.0495870235	settings with
0.0495836164	copulas with
0.0495650165	studies show
0.0495480653	usually not
0.0495338810	an important role in
0.0495272435	studied as
0.0495205848	the fourth
0.0495186211	k =
0.0495126614	formalism of
0.0495110799	and lower bounds on
0.0494985453	the extra
0.0494886526	bootstrap for
0.0494681814	some statistical
0.0494550025	a new general
0.0494375086	j \
0.0494245841	n \ log p
0.0493888365	the existing
0.0493879276	m \ times m
0.0493836273	summary of
0.0493632219	the development
0.0493628759	value of
0.0493493385	$ m \ times m
0.0493413860	the implied
0.0493353136	the strong consistency
0.0493343106	y \ in \ mathbb r
0.0493278443	question by
0.0493099778	$ m = o
0.0492829362	situations with
0.0492814798	a pseudo
0.0492778901	purpose of
0.0492385857	that end
0.0492372951	the first exit time
0.0492218236	the general setting
0.0491809744	i +
0.0491800376	field on
0.0491795409	useful for
0.0491780368	this paper focuses on
0.0491695808	\ mathcal y
0.0491675281	^ 3 \
0.0491632288	a manifold
0.0491507751	$ \ mathbb c
0.0491496723	the distance correlation
0.0491439817	any time
0.0491297979	most widely used
0.0491210238	inferences for
0.0491193175	empirical example
0.0490670458	the following
0.0490569496	or nearly
0.0490361596	\ times 2
0.0490320703	specification for
0.0490266001	a framework
0.0489768148	g =
0.0489710659	a multiscale
0.0489298500	locations of
0.0489236578	the same data
0.0489201364	allowing to
0.0489150459	possible if
0.0489084086	a certain class
0.0488836715	$ g =
0.0488493230	the large dimensional
0.0488440059	and more general
0.0488412690	the rescaled
0.0488342591	constructed with
0.0488307561	for performing
0.0488174602	any set
0.0488052310	a class of functions
0.0487616689	communities in
0.0487470695	the mean vector
0.0487390443	number of available
0.0487369719	generalized version of
0.0486931820	much attention in
0.0486783222	take values in
0.0486045974	minimum mean
0.0485972491	$ 1 \ sqrt
0.0485566773	rates under
0.0485277051	a monotone
0.0485060405	known to
0.0484991445	and two real
0.0484731610	technique to
0.0484547146	a variational
0.0484521780	functions under
0.0484307653	zero components
0.0484272864	matrices under
0.0484256634	1 \ leq p
0.0484188898	the theoretical analysis
0.0484135986	used in statistics
0.0484034289	gain in
0.0483883554	first give
0.0483637212	\ tau ^
0.0483415182	series based on
0.0483349449	a new family of
0.0483172043	the arrival
0.0483019882	s +
0.0482948349	do not rely on
0.0482728829	| x =
0.0482587497	hold with
0.0482523346	dependence in
0.0482495476	the basis of
0.0482456607	i =
0.0482207624	$ \ mathbf v
0.0482036730	sum of two
0.0482036130	a conservative
0.0482032367	a complementary
0.0482014387	adaptation in
0.0481976397	place in
0.0481779488	constructed for
0.0481529796	autoregressive time
0.0481231991	m = o
0.0481222740	\ r
0.0481130608	diverges to
0.0481060339	the emission
0.0480952710	a stream
0.0480866886	the new approach
0.0480517590	the time domain
0.0480515037	efficient algorithm to
0.0480466128	the risk of
0.0480433400	except for
0.0480259668	to model misspecification
0.0480254263	and subsequently
0.0480107019	and practically
0.0479899658	ratio test for
0.0479886593	the distribution function
0.0479541144	datasets with
0.0479440164	the problem of nonparametric estimation
0.0479405209	* n
0.0479260737	the probability density
0.0479252540	an expansion
0.0479135156	light of
0.0479119786	observed on
0.0478968245	the compatibility
0.0478704645	reciprocal of
0.0478629797	the usefulness of
0.0478592019	derived in
0.0478559955	diffusion with
0.0478377438	models without
0.0477988279	rule for
0.0477975143	the logit
0.0477959842	1 \ epsilon ^
0.0477858841	a desirable
0.0477775755	as much
0.0477691906	collected in
0.0477642304	to lie
0.0477521043	basis of
0.0477276403	most natural
0.0477256192	reduction in
0.0477127277	\ | \ sigma \ |
0.0476969732	to play
0.0476940882	$ d = o
0.0476888427	sequences with
0.0476828647	grow as
0.0476744241	framework of
0.0476651807	mode of
0.0476244422	grows to
0.0476083933	considered to
0.0475897052	a latent
0.0475861814	the mean
0.0475797074	2 ^
0.0475652568	the sense of
0.0475404396	the amount of data
0.0475208758	applied to two
0.0475146691	this new
0.0475143868	the goodness of fit of
0.0475025111	the sampling distribution
0.0474971549	ability of
0.0474865010	1 \ leq i
0.0474728927	new estimator
0.0474545669	process over
0.0474520235	very close to
0.0474148661	the correlation structure
0.0474147250	convergence in
0.0473985280	f ^
0.0473973826	m =
0.0473769722	the error bound
0.0473591266	the area
0.0473349449	a new method for
0.0473342591	analyzed for
0.0473334094	tomography with
0.0473150878	to deduce
0.0473080426	distributions such as
0.0472930074	the estimation problem
0.0472784952	a perfect
0.0472671571	screening for
0.0472391530	n = o
0.0472281182	only known
0.0472276279	testing under
0.0472234237	time algorithms
0.0472108814	a minimax lower
0.0471971820	first study
0.0471845708	structure from
0.0471643902	a new type of
0.0471250798	\ frac s
0.0471130608	answers to
0.0471067579	take into
0.0470882424	vector with
0.0470545942	\ mathbb l
0.0470435901	a very large
0.0470151730	independent given
0.0470130302	median of
0.0470118811	necessary condition for
0.0470095469	challenges in
0.0469946130	$ x_ i
0.0469781722	shapes of
0.0469770563	p = o
0.0469572562	$ \ r ^ d
0.0469565793	of two independent
0.0469530997	radius of
0.0469523941	estimation from
0.0469267793	norm as
0.0469124356	class of models for
0.0469053749	2 \
0.0468861871	= b
0.0468790302	$ \ mathcal s
0.0468340730	some asymptotic
0.0468316616	small set of
0.0468251202	first introduced
0.0467980469	assumption of
0.0467914951	$ \ widetilde o
0.0467899326	n ^ *
0.0467803593	to take
0.0467789984	f =
0.0467578405	$ norm of
0.0467495828	solved in
0.0467469952	work studies
0.0467401714	z |
0.0467388502	the new methodology
0.0467272939	the parameters of
0.0467117401	manifolds with
0.0466592742	the eigen
0.0466499363	_ n \
0.0466105974	predictor with
0.0466035797	the intensity
0.0466010371	for modeling
0.0465993293	r =
0.0465794786	methodology with
0.0465652568	the study of
0.0465421437	$ \ mathcal n
0.0465250621	with finite second
0.0465240211	the same distribution
0.0465107350	_ k \ in \
0.0465007708	significance of
0.0464570733	= |
0.0464542238	the majority
0.0464534442	first show
0.0464445786	introduced to
0.0464388522	a realistic
0.0464149939	d n
0.0463950367	a goodness of fit test for
0.0463892927	bayesian point of
0.0463841327	recent work of
0.0463618517	$ 1 \
0.0463539492	different sets
0.0463475060	also allow
0.0463382227	$ f ^ *
0.0463379271	this article provides
0.0462722103	\ _ n
0.0462544105	considered under
0.0462451902	researchers in
0.0462378597	requires to
0.0461882495	in line with
0.0461407264	gaussianity of
0.0461324373	cdf of
0.0461141709	this way
0.0461054218	convexity of
0.0461041885	an estimator of
0.0460969789	inclusion of
0.0460758170	statistics such as
0.0460468036	time series with
0.0460280485	over h \
0.0459810667	efficiency under
0.0459759466	issue in
0.0459683032	= \ sum_ i
0.0459469815	a logarithmic
0.0459369225	a large set of
0.0459334871	filter for
0.0459295487	$ \ | \
0.0459291207	the state of
0.0459283644	frequently in
0.0459245383	scheme with
0.0459183009	function at
0.0459151899	linearly in
0.0459071788	same time
0.0458996274	in machine
0.0458940573	schemes with
0.0458903252	validation for
0.0458892500	the heart
0.0458736698	regard to
0.0458732477	$ x ^ *
0.0458694508	and also discuss
0.0458488885	rate up to
0.0458321216	the derivation
0.0458026331	regions with
0.0457884477	variable given
0.0457844080	$ x ^
0.0457692725	statistic for
0.0457627104	norm of
0.0457607095	the discrete time
0.0457540584	simultaneously with
0.0457519691	conditional least
0.0457483819	problem over
0.0457412055	\ _ i
0.0457382624	a member
0.0457379531	the debiased
0.0457292072	nearly as
0.0457138564	length of
0.0456794784	$ x = \
0.0456678948	a good
0.0456401996	$ being
0.0456383451	situation in
0.0456288396	$ \ mathcal x
0.0456221638	a composite
0.0456053230	to correct
0.0455725156	to state of
0.0455262203	lot of
0.0455174421	to occur
0.0454807247	densities with
0.0454456673	n ^ 1 \
0.0454422919	then give
0.0454135268	\ hat s
0.0454104659	formulated in
0.0453486020	grow to
0.0453276403	good finite
0.0453164682	a tight
0.0453157655	a multiplier
0.0453055541	to generalize
0.0452776074	novel framework
0.0452691554	the shape of
0.0452677694	not restricted
0.0452617261	proved in
0.0452588935	the possibility
0.0452568542	i error
0.0452491981	delay in
0.0452182263	transform of
0.0451882310	landscape of
0.0451652039	\ mathbb c
0.0451346383	the statistical performance
0.0451334293	holds with
0.0450792654	to admit
0.0450644925	as usual
0.0450287354	the utility
0.0450261926	u \
0.0450134556	questions in
0.0450066597	extent of
0.0450055320	the maximum likelihood estimator in
0.0449757115	the condition number
0.0449671340	no other
0.0449638887	suggested for
0.0449558447	the applicability
0.0449462899	$ \ bf x
0.0449287217	the regression functions
0.0448946556	function in terms of
0.0448674881	the second
0.0448573471	cases of
0.0448471525	to belong
0.0448424071	the first to
0.0448309903	assumptions such as
0.0448305321	root of
0.0447705710	t \
0.0447652174	convergence over
0.0447638545	more than two
0.0447532638	the available data
0.0447495828	dependencies in
0.0447476766	nonlinear time
0.0447439305	studied with
0.0447426961	heart of
0.0447283484	n \ to \
0.0447272939	the form of
0.0447185728	the domain of attraction
0.0447068644	experiment with
0.0447023775	the full
0.0446902568	the theory of
0.0446490410	x |
0.0446452162	a challenge
0.0446391025	rest of
0.0446381690	appropriate choice of
0.0446333470	error between
0.0446048344	mixtures with
0.0446038971	regions for
0.0446019163	a new model
0.0445648307	appear to
0.0445357807	than other
0.0445029016	suggested in
0.0444791646	$ \ sqrt \ log
0.0444778788	computed in
0.0444641294	\ arg \
0.0444321809	illustration of
0.0444036092	a general framework for
0.0443841472	the good performance
0.0443827684	directions for
0.0443019380	coordinates of
0.0442964984	improved to
0.0442950123	required in
0.0442715961	characterized in
0.0442480584	point of
0.0442448349	not affected by
0.0442235189	estimates from
0.0442041144	arguments for
0.0441970705	the ubiquitous
0.0441938857	objects in
0.0441832810	a large family of
0.0441518866	of producing
0.0441317663	$ \ mathbb r
0.0441184074	interval with
0.0441007154	impacts of
0.0440987077	order to
0.0440755733	graph with
0.0440711441	to fill
0.0440466128	the setting of
0.0440446784	setup with
0.0439893814	used to make
0.0439871815	the statistical problem
0.0439746733	by fitting
0.0439602904	problem under
0.0439574328	seen to
0.0439510439	a dataset
0.0439462720	class of non
0.0439447648	place of
0.0439335073	made by
0.0439251176	the second one
0.0439092852	optimal rate for
0.0439040112	a number
0.0438853029	observed time
0.0438680596	fill in
0.0438288000	laws for
0.0438173304	paradigm for
0.0438107548	a second part
0.0438079246	$ \ mathbb l
0.0438074321	a comparative
0.0437617766	the behavior of
0.0437608222	done using
0.0437353872	almost surely to
0.0437311867	order to make
0.0437186045	origin of
0.0437028355	a variant of
0.0436883605	simpler and
0.0436836321	a reliable
0.0436407074	the consistency of
0.0436224206	a separable
0.0435837985	consider here
0.0435763951	do not need to
0.0435698030	\ mu =
0.0435652568	the power of
0.0435421304	$ n \ times p
0.0435017521	new measure
0.0434873023	trees with
0.0434703984	= r
0.0434681564	_ n \ in
0.0434601539	heterogeneity in
0.0434540872	phenomenon in
0.0434471730	the first one
0.0434457333	and more generally
0.0434124556	thresholds in
0.0434007943	analyzed in
0.0433903604	signs of
0.0433776898	this paper provides
0.0433466128	the quality of
0.0433385857	sets from
0.0433377954	$ \ beta \ in
0.0433333253	row of
0.0433331614	expectation of
0.0433315359	to introduce
0.0433208053	for finding
0.0433085721	field of
0.0432860021	a generalization
0.0432778685	the effectiveness
0.0432521796	a rank one
0.0432397362	result by
0.0431621758	the npmle
0.0431620157	used to describe
0.0431358548	different levels of
0.0431271972	with state of
0.0431270691	role of
0.0431070147	the value of
0.0431021028	to search
0.0430974326	\ bf r
0.0430894899	policy for
0.0430893623	these new
0.0430786068	sure convergence of
0.0430682638	a polynomial time
0.0430582172	the last
0.0430535351	dimensional mean
0.0430138608	a very
0.0429690204	an overview of
0.0429428104	= 0 ^
0.0429396369	with application to
0.0429395941	achieved for
0.0428809563	\ to c
0.0428690356	\ mathbb r ^ m
0.0428621435	domain of
0.0428490858	large set of
0.0428346247	\ leq m
0.0428068397	theorem under
0.0428026105	an information
0.0427675105	a mathematical
0.0427617766	the set of
0.0427617766	the probability of
0.0427321263	rate at
0.0427008646	probability measure on
0.0426891258	holds in
0.0426706774	selection in
0.0426515545	weakly to
0.0426187629	combination with
0.0425564918	robust version of
0.0425534433	the analysis of
0.0425274149	any pair of
0.0424801577	finite second
0.0424666482	n \ times p
0.0424590011	interior of
0.0424525095	\ delta \
0.0424394394	numbers for
0.0424228779	a quadratic
0.0424154673	set from
0.0424034533	especially in
0.0423974443	constructed on
0.0423956765	the claim
0.0423469211	= n ^
0.0423275251	exist for
0.0422761202	$ u =
0.0422357300	stream of
0.0422142218	into two
0.0421710507	p \ times n
0.0421417247	make use
0.0421050839	generality of
0.0420948967	at least two
0.0420917843	of particular interest
0.0420746968	error over
0.0420613878	$ g ^
0.0420543241	\ big \
0.0420161274	z \
0.0420151730	test if
0.0420017925	task in
0.0419509741	certain types of
0.0419409193	filters for
0.0419244893	\ eta ^
0.0418829404	$ \ mathcal u
0.0418780466	inference with
0.0418663599	only depends on
0.0418639692	a useful tool for
0.0418531430	to describe
0.0418437618	series with
0.0418237012	even in
0.0418160641	same as
0.0417850005	^ j
0.0417720290	the pc
0.0417488300	not assume
0.0417175571	the art in
0.0416936375	the new
0.0416761017	overfitting in
0.0416458904	t \ |
0.0416339804	a semi
0.0416075784	under mild assumptions on
0.0416027496	= n
0.0415895420	law for
0.0415893653	\ mathbf r
0.0415651228	$ n n
0.0415310405	sample mean of
0.0415275210	the density of
0.0415033520	$ r =
0.0414597558	allow to
0.0414588103	$ \ mathbb p
0.0414558996	line with
0.0414121715	utility in
0.0413828405	$ error of
0.0413156423	reliability of
0.0413134940	normality for
0.0413093601	interval for
0.0413044313	with i.i.d
0.0412966128	the effectiveness of
0.0412888476	for identifying
0.0412238341	the familiar
0.0412180285	adequacy of
0.0411818166	the limit distributions
0.0411778592	$ \ mathbb r ^ p
0.0411678852	and hence
0.0411381439	\ | x
0.0411314631	minimax rate in
0.0410953843	review of
0.0410890000	in light of
0.0410890000	a lot of
0.0410466128	the assumption of
0.0410231332	the noiseless
0.0410124919	of great interest
0.0409811965	some known
0.0409198228	\ mathbb n
0.0408868768	| =
0.0408807834	spaces with
0.0408672189	a fraction
0.0407981395	findings with
0.0407921437	$ 1 \ sqrt n
0.0407744451	necessary to
0.0407540849	eigenvalue of
0.0407471147	performed in
0.0407365582	this means
0.0406946207	$ l \
0.0406934912	samples with
0.0406788396	$ m \ times n
0.0406633121	the lens
0.0406401730	graphs from
0.0406356604	for obtaining
0.0406275424	t n
0.0406080396	the consistency and asymptotic
0.0406061710	fit to
0.0406040140	bounds in terms of
0.0405226464	$ \ |
0.0405034384	novel method for
0.0405024051	$ 0 p
0.0404886215	\ alpha |
0.0404663249	optimal in terms of
0.0404631344	\ times p
0.0404377921	field with
0.0404365821	likelihood estimator with
0.0403964783	found by
0.0403961166	for modelling
0.0403899028	in addition to
0.0403788286	rates of convergence in
0.0403729362	a clinical
0.0403635233	well known to
0.0403189086	bound under
0.0403135391	for establishing
0.0403107084	p n \ to
0.0402935704	center of
0.0402935053	mean estimator
0.0402818381	p \ |
0.0402811578	works in
0.0402691554	the utility of
0.0402187151	evaluated in
0.0402090037	le \
0.0402019907	and thus
0.0402018956	the language
0.0401426227	the amount
0.0400466128	a measure of
0.0400209176	recovery in
0.0400204497	the first method
0.0400096139	this latter
0.0400034384	novel class of
0.0399853458	\ beta +
0.0399794174	aim of
0.0399704808	estimation and inference for
0.0399693141	optimal number of
0.0399619524	a fundamental problem in
0.0399406250	ignored in
0.0399069339	the main contribution of
0.0398846030	potential to
0.0398629290	below by
0.0398481022	of view
0.0398390331	error than
0.0398296502	the above
0.0398216072	\ left \
0.0398129629	the same way
0.0398015428	$ t ^
0.0398003815	for such models
0.0397998075	the classical problem
0.0397992940	case of non
0.0397825859	code for
0.0397631476	cost of
0.0397474366	time setting
0.0397271146	a new non
0.0397069479	freedom of
0.0396984178	y \ in
0.0396959358	some particular
0.0396827828	not well
0.0396784433	the structure of
0.0396609825	models used in
0.0396582513	mean squared error for
0.0396458904	x \ |
0.0396172225	a great deal of
0.0396094101	in more detail
0.0396059023	both continuous
0.0396048486	\ in \ z
0.0395971020	1 ^ n
0.0395936362	estimator does
0.0395919557	only depend on
0.0395657832	^ t \
0.0395399063	constants for
0.0395281389	the divide
0.0395018933	\ _ t
0.0394808452	to shed
0.0394643979	value at
0.0394551615	\ ll p
0.0394318030	$ +
0.0394135268	$ i_ \
0.0394035681	as measured by
0.0393564296	the finite sample behavior of
0.0393524063	adjustment for
0.0393049560	treated in
0.0392882274	then applied to
0.0392860223	this last
0.0392632062	the tail index of
0.0392420000	the new estimators
0.0392387515	approaches to
0.0392236705	recovery with
0.0392063902	the corresponding estimator
0.0392032930	tested in
0.0391963407	benchmark for
0.0391823639	the best possible
0.0391803117	the model for
0.0391600526	to observe
0.0391348001	rate of convergence in
0.0391175276	the second part
0.0390470503	importance of
0.0390451067	fields with
0.0390325358	the sup
0.0390212698	t ^
0.0390117959	of such estimators
0.0389986772	a simple way
0.0389951631	aid of
0.0389747948	the fundamental problem
0.0389741428	in such models
0.0389709142	\ delta =
0.0389645124	\ frac k
0.0389502313	any such
0.0389479980	for determining
0.0389361936	a challenging
0.0389268230	\ mathbf p
0.0389173993	_ \
0.0388761777	each such
0.0388630735	the theoretical side
0.0388365649	to +
0.0388213004	the asymptotic normality of
0.0388209103	the other
0.0388179748	a unified framework for
0.0387940653	a given set of
0.0387884794	the best linear
0.0387700653	for linear spectral statistics of
0.0387568387	with probability at least
0.0386849348	$ \ theta =
0.0386784802	$ l ^
0.0386233564	\ in
0.0386092813	the literature to
0.0386004091	a new type
0.0385988651	first time
0.0385711436	using tools from
0.0385474974	$ i
0.0385280544	$ \ | x \ |
0.0385206385	not much
0.0385191554	a new approach to
0.0385010654	\ times d
0.0384769475	0 \
0.0383777646	$ x \ in
0.0383419997	a measurable
0.0383329948	\ subset \
0.0383291212	a method for estimating
0.0382782744	$ \ theta ^
0.0382653516	issues in
0.0382501879	the extent to
0.0382192735	\ le i
0.0381720212	not rely on
0.0381567974	from below
0.0381282226	just as
0.0380791904	\ lambda ^
0.0380367288	a numerical example
0.0380295425	a particular
0.0380091347	x +
0.0379932732	the existence and uniqueness
0.0379893530	p ^
0.0379838202	an attempt to
0.0379562905	\ emph et
0.0378677157	| x \
0.0378633358	matrix estimation for
0.0378628260	to account for
0.0378497276	no assumptions on
0.0378381327	utility of
0.0378321814	even for
0.0378161834	exists for
0.0378068397	detection under
0.0377981297	squares estimator in
0.0377907458	chain with
0.0377907458	fields on
0.0377712263	to contain
0.0377574495	points to
0.0377558262	distribution of interest
0.0377209453	needed in
0.0377170343	certain threshold
0.0376981276	hold in
0.0376936375	the most
0.0376681587	\ | ^
0.0376439605	the efficiency of
0.0376439605	the solution of
0.0375732047	as measured
0.0375555196	task of
0.0375519475	$ t =
0.0375384476	the new methods
0.0375278348	a triangular
0.0375254261	this paper gives
0.0375214539	the help
0.0374878108	a thorough
0.0374759681	support of
0.0374621548	| p
0.0374315968	$ \ mathbf s
0.0374153805	some useful
0.0373994830	\ times n
0.0373593008	i \ in \
0.0373592305	$ p n \ to
0.0373350164	$ \ mathbb z ^
0.0373271645	then extended to
0.0373174915	the maximum likelihood estimator of
0.0373038450	often used to
0.0372535289	a large variety of
0.0372401458	especially for
0.0372251649	almost sure convergence of
0.0372133528	very useful in
0.0372079246	$ \ delta =
0.0372063047	$ \ alpha =
0.0371924688	$ m n
0.0371036688	two possible
0.0370993048	* \
0.0370857023	$ p \ times p
0.0370742766	e \ |
0.0370732624	\ varepsilon ^
0.0370697224	most efficient
0.0370466128	the goal of
0.0370443938	convergence than
0.0370312397	also use
0.0370282855	going to
0.0370262480	described as
0.0370041528	p \ gg n
0.0370038790	well studied in
0.0369717203	\ eta \
0.0369608014	1 \ le i
0.0369535319	v \
0.0369415250	go to
0.0369358221	a system of
0.0369354115	a dynamical system
0.0369290907	available from
0.0368975080	a whole
0.0368898400	d \ to \
0.0368781963	q \
0.0368478731	to cope with
0.0368388495	the difference between
0.0368306923	sense of
0.0368061789	need for
0.0367893573	$ f =
0.0367543151	further extended to
0.0367501804	the most commonly used
0.0367234178	s \ in
0.0367168270	help of
0.0366882030	$ h \ in
0.0366870480	structure between
0.0366709582	f \
0.0366634271	\ to
0.0366405707	the need of
0.0366402336	the problem by
0.0366261415	whether two
0.0366226161	| | \
0.0366162531	quantification for
0.0366129961	not suffer from
0.0366010002	the method of moments
0.0365968483	y = \
0.0365823885	modified to
0.0365784809	comes with
0.0365622653	$ \ mathbf z
0.0365594772	second one
0.0365585914	\ delta_ \
0.0365072506	the importance of
0.0365072506	the question of
0.0364911701	novel estimator
0.0364896589	values to
0.0364435306	$ 1 \ leq p
0.0363934461	the practical performance
0.0363780855	to do
0.0363621399	x \ in
0.0363301209	appear as
0.0363172692	\ frac |
0.0363110309	the relationship between
0.0362894454	some logarithmic
0.0362851272	than or equal to
0.0362501307	infinity with
0.0362364859	work on
0.0362095725	\ lambda =
0.0362005713	question of
0.0361953515	$ x_0 \ in
0.0361758253	to distinguish between
0.0361674813	often used for
0.0360923220	into three
0.0360909356	same distribution
0.0360412881	taken as
0.0360385385	some sufficient
0.0359353922	\ mu \
0.0358646791	\ epsilon ^
0.0358411497	$ \ mathbf r
0.0358283813	n |
0.0358152568	a range of
0.0358147753	interest in
0.0357884595	a specified
0.0357775463	interest in many
0.0357618667	\ b
0.0357610839	first consider
0.0357258041	a change in
0.0356727930	then used to
0.0356709818	more general than
0.0356517315	a robust version of
0.0356420536	to put
0.0356407074	the rate of
0.0356401730	effects from
0.0356381228	in place of
0.0356287721	\ ensuremath \
0.0356018485	the test of
0.0355867412	the number of change
0.0355429649	a pair of
0.0355396904	even under
0.0355324989	not depend on
0.0355015313	the development of
0.0355003378	intensity of
0.0354953449	$ \ x_i \
0.0354931998	^ i
0.0354686164	both theoretically and
0.0354378455	\ subseteq \
0.0353728481	to ask
0.0353484178	v \ in
0.0353399635	$ | \
0.0353349476	then consider
0.0353188084	the most widely used
0.0352988937	a complete characterization of
0.0352947106	\ leq j
0.0352882912	= q
0.0352480206	second part of
0.0352195939	$ \ gamma =
0.0352120125	a finite set of
0.0352111974	give sufficient conditions for
0.0352083910	z \ in
0.0351902385	$ j =
0.0351729732	a strong law of
0.0351515593	also applies to
0.0351450017	and then
0.0351268639	2 \ log n
0.0351058109	\ sigma_n \
0.0351011090	a system
0.0350995532	given samples from
0.0350315207	the inner
0.0350298795	the present work
0.0350278257	a way to
0.0350012236	as well as under
0.0349468733	a sum of
0.0348647860	\ theta =
0.0348531797	$ \ lambda ^
0.0348415713	\ top
0.0348366233	\ mu ^
0.0348298795	the relevance of
0.0348238995	made on
0.0348213004	the asymptotic properties of
0.0348205614	the overall
0.0348162531	forecast of
0.0348128052	\ _ n \
0.0347929186	\ boldsymbol u
0.0347780841	need not
0.0347693327	any assumptions on
0.0347681557	a simulation study for
0.0347585771	$ y = x
0.0347528354	to specify
0.0347133156	but do
0.0347015211	k \ in \ mathbb z
0.0347000916	a theoretical point of
0.0346870480	bounds over
0.0346867618	as if
0.0346660046	same way
0.0346639407	$ n +
0.0346443885	the conditional distribution of
0.0346381228	the adequacy of
0.0346228775	under mild conditions on
0.0346208793	new approach to
0.0345979673	\ leq p
0.0345676684	1 ^
0.0345563265	understood in
0.0345178814	the first part of
0.0345123593	a linear combination of
0.0345072506	the cost of
0.0344965462	the posterior mean
0.0344637955	the bias of
0.0344634312	$ w \
0.0344604148	a significance test for
0.0344301770	come with
0.0344281665	put on
0.0344148185	w \
0.0344083985	problem of testing for
0.0344058107	also known
0.0344019349	the absence of
0.0343750341	or equal to
0.0343202486	an overall
0.0342699870	viewpoint of
0.0342332915	all such
0.0342159687	of y given x
0.0342090766	a linear regression model with
0.0342063303	the minimax optimal rate of
0.0341980211	to look
0.0341803470	\ cdot n
0.0341757739	many areas of
0.0341709219	$ r \
0.0341650648	normality under
0.0341551889	rate of convergence for
0.0341551517	$ \ gamma ^
0.0341045637	\ 0,1 \
0.0340881293	the second part of
0.0340703360	to help
0.0340655308	new type of
0.0340610591	not based on
0.0339971730	the need for
0.0339828866	give conditions under
0.0339788616	\ theta +
0.0339763493	a real example
0.0339498918	a natural way
0.0339355200	the test for
0.0339268314	done with
0.0339058032	\ beta ^
0.0338410398	done in
0.0338239061	6 \
0.0338081873	help to
0.0338061045	\ x_t \
0.0337994830	$ \ hat m
0.0337927895	both synthetic and
0.0337921166	favor of
0.0337909463	measures such as
0.0337815653	a necessary
0.0337799756	and lower bounds for
0.0337756577	good performance of
0.0337702295	i \
0.0337564836	a small set of
0.0337491901	with probability tending to
0.0337368546	not asymptotically
0.0337294221	\ x
0.0336859984	both real and
0.0336659042	no more
0.0336548452	in terms of mean
0.0336147963	even with
0.0336063512	in order to make
0.0336059901	the special case of
0.0335848647	the rate of convergence of
0.0335785763	taken to
0.0335557723	$ \ mathcal e
0.0335334320	a list
0.0334685904	hull of
0.0334656525	way to
0.0334640859	\ mapsto \
0.0334637955	the smoothness of
0.0334358221	the total number of
0.0333841362	\ beta =
0.0333807668	a fixed number of
0.0333411466	several classes of
0.0333313458	$ \ x_i \ _ i
0.0333065892	the method in
0.0333037852	to lead to
0.0332875162	point of view of
0.0332732338	the almost sure
0.0332706142	$ o \
0.0331553362	\ cdots \
0.0331342300	\ leq i
0.0331092874	to show
0.0331058109	\ exp \
0.0330768212	k = \
0.0330311563	the literature in
0.0330186016	the equality of
0.0330067335	\ nu \
0.0329935306	$ \ sigma =
0.0329897304	the joint distribution of
0.0329828873	the length of
0.0329809818	the next
0.0329787324	a generalized version of
0.0329660421	^ m \
0.0329601973	$ \ lambda =
0.0329267662	order to show
0.0329191518	\ e
0.0328846050	to give
0.0328393023	the halfspace
0.0328323878	c \ in
0.0327883608	$ b ^
0.0327817512	^ * \ in
0.0326964012	to account
0.0326716731	necessary conditions for
0.0326694682	the volume of
0.0326435484	a non
0.0326380519	p ^ *
0.0326216109	the model of
0.0326176044	with unknown mean
0.0325911497	$ \ mu =
0.0325484405	r ^ d \
0.0325361840	the interplay between
0.0325318870	the problem of nonparametric estimation of
0.0325026080	\ theta ^
0.0325015313	the influence of
0.0324926439	x \ in \ mathbb r
0.0324905956	* \ in
0.0324426208	use of
0.0324317512	\ ^ n
0.0324257444	the sample complexity of
0.0323926341	$ y \ in \
0.0323725413	well as for
0.0323535070	new notion of
0.0323501527	a certain class of
0.0323458573	\ h
0.0323179615	a new concept of
0.0323147753	useful in
0.0323145396	\ frac p
0.0323110028	q =
0.0323100627	a side
0.0323020003	\ r ^ d
0.0322671483	\ rho =
0.0322509740	with emphasis on
0.0322403741	to see
0.0321739173	this type of
0.0321642413	in combination with
0.0321491926	$ f ^
0.0321265655	t = \
0.0321219762	new classes of
0.0321198494	$ d ^
0.0320936785	an associated
0.0320321605	the proofs of
0.0320020425	well as other
0.0319994767	first work
0.0319499793	\ frac n
0.0319429528	the estimate of
0.0319259936	0 ^
0.0318855355	the true mean
0.0318765455	\ alpha ^
0.0318612418	course of
0.0318509711	an application of
0.0318508888	new approach for
0.0318468733	the issue of
0.0318416307	a small subset of
0.0318164206	new family of
0.0318091374	the inverse of
0.0318089713	u ^
0.0317992542	the possibility of
0.0317652514	1 n ^
0.0317539047	of such models
0.0317417440	certain class of
0.0317399473	the large sample properties of
0.0317318503	least squares estimators of
0.0317101973	\ hat \
0.0317055981	the course of
0.0316766352	mean square error of
0.0316609746	2 + \
0.0315635399	the intensity of
0.0315536697	\ widehat \
0.0315431307	to infinity at
0.0315015313	the geometry of
0.0314615883	and consequently
0.0314555981	\ in e
0.0314411205	1 + \
0.0314320641	two kinds of
0.0314278203	$ r ^
0.0314186646	an extension to
0.0314177979	to appear
0.0314107073	described in terms of
0.0314093106	t \ in \ mathbb r
0.0314068496	$ k \ in \
0.0314028613	\ log ^
0.0313849102	s =
0.0313844918	the mean or
0.0313420658	an important class of
0.0313381114	no assumption on
0.0312896096	the same as
0.0312894454	an answer
0.0312590475	$ n p
0.0312492489	different values of
0.0312385503	the measure of
0.0312101973	\ geq \
0.0312082674	the name
0.0312012224	\ | \ cdot \ |
0.0311766128	necessary and sufficient condition for
0.0311740134	a bayesian approach to
0.0311632129	the spirit of
0.0311188611	to know
0.0310931037	$ z \
0.0310761773	the difficulty of
0.0310717524	found in
0.0310551097	show in particular
0.0310079106	3 \
0.0310071902	y ^
0.0310041102	to derive new
0.0309764256	$ t \ in
0.0309636666	and therefore
0.0309634941	with zero mean and
0.0309278641	a crucial role in
0.0309173118	the applications of
0.0309119494	a full
0.0309101600	the expectation of
0.0309086983	h \ in
0.0308912753	as well as with
0.0308307359	by conditioning on
0.0308298795	new results on
0.0307966720	the model to
0.0307889795	$ y \
0.0307817469	these results by
0.0307287753	a procedure to
0.0307099929	by making use of
0.0306739685	the convex hull of
0.0306635684	the computation of
0.0306205672	any assumption on
0.0306001450	$ \ hat \
0.0305947505	\ mathbf m
0.0305793141	example from
0.0305527677	happens to
0.0305347369	^ 2 =
0.0305203764	j \ in
0.0304596316	the supremum of
0.0304406847	given set of
0.0304320641	different choices of
0.0303793468	any non
0.0303755416	$ |
0.0303484178	$ p n \
0.0303416307	the main goal of
0.0303297107	\ beta \ |
0.0303293882	without loss of
0.0303272608	2 \ log p
0.0302991492	$ s ^
0.0302828873	an analysis of
0.0302798795	the efficacy of
0.0302705703	t \ in
0.0302596316	the logarithm of
0.0302189034	a central role in
0.0301925570	and widely used
0.0301871158	a useful
0.0301782700	$ \ sigma ^
0.0301670415	under weak assumptions on
0.0301045122	$ s_0 \
0.0301020399	same rate as
0.0300968733	the idea of
0.0300814853	new methods for
0.0300689898	often used in
0.0300657701	to grow with
0.0300613756	with at most
0.0300396682	$ u \
0.0300159248	a way
0.0300010490	^ * + \
0.0299429528	the subset of
0.0299304843	as well as other
0.0299248199	$ \ sqrt t
0.0299234354	\ rightarrow \
0.0299101600	the task of
0.0298967021	certain classes of
0.0298857166	of large numbers for
0.0298836757	p +
0.0298790640	\ theta = \
0.0298468733	the boundary of
0.0298081576	an adaptation of
0.0297552785	in polynomial time
0.0296807160	the convergence of
0.0296635684	the degree of
0.0296595579	the domain of attraction of
0.0295592816	value decomposition of
0.0295419587	language of
0.0294795122	\ widetilde \
0.0294645184	the magnitude of
0.0294640517	n p
0.0294605353	show through
0.0294395998	both simulated and
0.0294223339	\ phi \
0.0294222017	a serious
0.0294219918	k \ in
0.0293842520	the estimators in
0.0293632129	in comparison to
0.0293609636	\ u
0.0293526660	between pairs of
0.0293393100	new class of
0.0293072506	a new approach for
0.0292787669	\ hat p
0.0292773548	system with
0.0292520934	an analogue of
0.0292391442	| _ \
0.0292391442	\ int_ \
0.0292331115	to increase with
0.0292269738	show here
0.0292179084	a new way
0.0292002351	the mode of
0.0291670288	^ n \
0.0291621086	the convergence in
0.0290966325	of parameters in
0.0290707786	^ 2 + \
0.0290404630	the strength of
0.0290347663	the ability to
0.0290169085	work well in
0.0290001168	d \ in
0.0289969854	the best
0.0289963914	sense over
0.0289922398	$ 0 \
0.0289684303	u \ in
0.0289201628	$ y = x \
0.0288628260	an alternative to
0.0288428198	object of
0.0288253239	the complexity of
0.0288008507	$ m ^
0.0287990233	for changes in
0.0287946886	as far
0.0287875880	the maximum of
0.0287735205	the expected value of
0.0287697180	both types of
0.0287689625	a fundamental role in
0.0287661222	the scope of
0.0287635399	a vector of
0.0287478884	the posterior of
0.0287440493	$ z ^
0.0287079308	a neighborhood of
0.0287066657	the classical one
0.0286889625	a key role in
0.0286636574	of practical interest
0.0286563894	this paper aims to
0.0286561413	the relation between
0.0286464362	g ^ \
0.0286288041	the product of
0.0286195022	a modification of
0.0286073755	the asymptotic behaviour of
0.0285891851	i = 1 ^ n \
0.0285827061	the point of
0.0285610071	y = x \
0.0285463694	as few
0.0285386577	the test statistic under
0.0285150845	$ s = \
0.0284898289	or near
0.0284834943	m +
0.0284771544	the errors in
0.0284614593	for mixtures of
0.0284588927	the model in
0.0284580059	the type i
0.0284481642	a tradeoff
0.0284212439	a unified approach to
0.0284102213	over classes of
0.0283462687	$ e \
0.0283226242	$ \ boldsymbol \
0.0283140272	$ c \
0.0283058346	$ f \
0.0282904630	the field of
0.0282771303	derived to
0.0282627818	not make
0.0282538953	the amount of
0.0282326856	so as
0.0282123328	\ xi \
0.0282053095	the diameter of
0.0281951567	$ t \
0.0281892254	used in many
0.0281641013	x \ in \
0.0281281797	$ \ mathbb n
0.0281244767	least one
0.0281189661	some conditions on
0.0281135368	the ordinary least
0.0280903794	\ lambda \
0.0280895998	give conditions for
0.0280713072	\ star \
0.0280463694	above by
0.0280425049	new concept of
0.0280323159	$ k ^
0.0280291388	new proof of
0.0280017163	$ \ sum_ i
0.0280001168	m \ in
0.0279919905	the method of
0.0279912122	^ * \ in \
0.0279599404	\ rho \
0.0279553097	an optimal rate of
0.0279247161	$ e ^
0.0279226433	a new proof of
0.0279075823	both theoretical and
0.0279011533	degree at
0.0278992581	a second
0.0278979814	$ t_ \
0.0278614903	n = \
0.0278484178	= 1 ^ n \
0.0278406801	and asymptotic normality for
0.0278338598	to come
0.0277742581	system of
0.0277619232	\ log \
0.0277439564	transitions in
0.0277424765	$ \ ell_ \
0.0277309348	$ 0,1 ^
0.0277287753	of solutions of
0.0277233186	the associated
0.0276749606	$ i =
0.0276288041	the proportion of
0.0276265699	described in
0.0276243728	the lasso in
0.0276068272	only on
0.0275963084	$ x_i \
0.0275246499	done for
0.0274800264	a recent work
0.0274255411	both parametric and
0.0274232768	the divide and
0.0274214957	made for
0.0274065050	the significance of
0.0273997540	the same rate as
0.0273644896	the lasso for
0.0273437684	the core of
0.0272928770	new characterization of
0.0272790437	a connection between
0.0272669166	the regression function in
0.0272641679	$ d n
0.0272295586	r ^ n \
0.0272083910	1 2 \
0.0271551523	to allow
0.0271162651	$ \ theta \ in
0.0270591400	\ frac \
0.0270529442	p \ in
0.0270501432	increase to
0.0270478142	the empirical distribution of
0.0270426111	a weighted sum of
0.0270176369	to improve on
0.0270051920	mean squared error of
0.0269665827	the topology of
0.0269505925	the aid of
0.0269323942	* \ in \ mathbb r
0.0269178658	\ in n
0.0269124223	the first non
0.0269043099	quantification in
0.0269042386	infinity as
0.0268952803	made to
0.0268836622	a small fraction of
0.0268820018	\ alpha =
0.0268459914	the minimax rates of
0.0268262246	two sets of
0.0267819499	in particular to
0.0267735205	the ability of
0.0267701651	an example of
0.0267619232	$ \ epsilon \
0.0267600482	two classes of
0.0267368057	$ \ theta_ \
0.0267264883	y \ in \
0.0267230130	new estimator for
0.0267175509	$ g \
0.0266967544	$ s \
0.0266782455	the practical performance of
0.0266110810	2 =
0.0266031152	not assumed to
0.0266024057	$ c ^ \
0.0265795060	the cone of
0.0265791165	the companion
0.0265686016	a combination of
0.0265593491	\ l
0.0265203551	^ * \
0.0264599461	to test whether
0.0264577748	as part of
0.0264563471	least one of
0.0264455075	this estimator in
0.0264428529	and then in
0.0264276468	the sample size goes to
0.0264198838	an unbiased estimator of
0.0264169966	the optimal value
0.0264141645	the sample size n
0.0264082333	y \
0.0264025869	almost as
0.0264013396	the dependence structure of
0.0263997540	a continuum of
0.0263582189	the determinant of
0.0263267538	$ rate of
0.0262930610	the necessary and
0.0262724033	$ v \
0.0262686016	an algorithm for
0.0262533545	$ \ m
0.0262430940	\ le \
0.0262226940	$ \ mathbb l ^
0.0262176462	a random sample from
0.0261721585	not need to
0.0261048850	f \ in \
0.0260897648	an empirical application to
0.0260524701	the model with
0.0260399562	the third
0.0260210848	the method to
0.0259902850	n ^ \
0.0259833202	the main result of
0.0259492556	\ theta \ in \
0.0259477470	the maximum likelihood estimator for
0.0259398953	$ \ log n
0.0259033763	a subclass of
0.0259030080	\ sqrt n \
0.0258951941	\ kappa \
0.0258799103	an expression for
0.0258365457	a consistent estimator of
0.0258233065	an array of
0.0258082189	the signs of
0.0257912764	value problem
0.0257908411	the law of
0.0257841223	the transition density of
0.0257822831	$ \ frac \
0.0257765893	both continuous and
0.0257278308	given to
0.0257006107	\ leq p \
0.0256907740	\ in \ r
0.0256565250	known results for
0.0256513401	of communities in
0.0256425312	the empirical performance of
0.0256306633	the limit distribution of
0.0256201640	a necessary and sufficient condition for
0.0255867198	the last two
0.0255830455	cone of
0.0255787368	necessary and sufficient conditions on
0.0255721836	made in
0.0255573579	k +
0.0254628960	i n
0.0254471951	the other two
0.0254366489	the condition number of
0.0253969943	4 \
0.0253764533	the empirical mean
0.0253757662	the superior performance of
0.0253707684	some properties of
0.0253681311	an order of
0.0253058346	$ m \
0.0252879738	\ theta \ |
0.0252742118	of distributions with
0.0252596316	the introduction of
0.0252584716	\ beta \
0.0252580863	time algorithm for
0.0252205620	of interest in
0.0252010760	the causal effect of
0.0251791928	using data from
0.0251738343	^ k \
0.0251731667	an arbitrary number of
0.0251569745	many applications in
0.0251531797	$ \ mathbb e \
0.0251202514	new results for
0.0250918176	a general family of
0.0250862561	\ gamma \
0.0250752736	any knowledge of
0.0250661420	t \ in t
0.0250615487	investigated to
0.0250222136	some form of
0.0250196759	to adapt to
0.0249863250	\ lim_ n \ to
0.0249681810	the covariance matrix of
0.0249614718	$ \ tilde \
0.0249599404	$ \ mathcal d
0.0249567788	the trace of
0.0249534973	this kind of
0.0249292224	two versions of
0.0249162229	\ log p \
0.0249095579	a novel approach to
0.0249064593	estimator as well as
0.0248850616	a new generalization of
0.0248788041	an estimator for
0.0248654158	$ y \ in
0.0248536622	a rich class of
0.0248212650	for example in
0.0248201567	$ x \
0.0248065084	m \ in \
0.0247918176	a statistical test for
0.0247908411	the advantage of
0.0247908411	a test for
0.0247543031	to zero at
0.0247526633	a comparison with
0.0247493022	the problem in
0.0247478884	a construction of
0.0247465305	or less
0.0247422044	the average number of
0.0247290484	the signal to
0.0247171056	with errors in
0.0247115131	a member of
0.0246944465	an efficient algorithm for
0.0246922193	the reliability of
0.0246618415	e \
0.0246429087	the central limit theorem for
0.0246243728	a law of
0.0246229331	some extensions of
0.0246025290	particular case of
0.0245933430	the decomposition of
0.0245872188	this gap by
0.0245832328	\ mathbb e \
0.0245787931	this problem with
0.0245768629	the availability of
0.0245661388	the characteristic function of
0.0245171313	the description of
0.0244992489	the interior of
0.0244968552	the unknown mean
0.0244611713	\ ge \
0.0244610999	\ mathbb p \
0.0244562902	\ sqrt \
0.0243828734	+ 2 \
0.0243790015	the extreme value
0.0243594589	the maximum mean
0.0243404869	$ \ alpha \
0.0243344524	the covariance matrix in
0.0243144510	known from
0.0242899452	also used to
0.0242865357	\ varepsilon \
0.0242277798	a natural extension of
0.0242226242	\ times \
0.0242165827	a review of
0.0242081475	infinity at
0.0241918151	also apply to
0.0241818350	not lead to
0.0241778203	to zero as
0.0241453731	$ \ mathbf \
0.0241194040	time algorithms for
0.0241111438	a general approach for
0.0240787937	in comparison with
0.0240762246	an approximation to
0.0240573755	a special case of
0.0240393760	the proof relies on
0.0239922193	the success of
0.0239887665	$ \ nu \
0.0239666675	for sampling from
0.0239367908	$ l ^ \
0.0239133521	the mean square error of
0.0239131529	$ \ gamma \
0.0239086687	$ \ lambda \
0.0238850616	a new notion of
0.0238719762	to test if
0.0238358493	$ q \
0.0238342500	\ | _ \
0.0238325823	a generalisation of
0.0238082189	the inclusion of
0.0238037278	\ ell \
0.0237993320	an optimal choice of
0.0237815422	$ k \
0.0237770267	the emergence of
0.0237686243	the true value
0.0237574593	used to show
0.0237531797	$ \ mu \ in
0.0237309350	$ \ delta \
0.0236998788	to allow for
0.0236866489	a general approach to
0.0236767446	s \
0.0236753184	the main advantage of
0.0236649043	to converge to
0.0236431204	new generalization of
0.0236288041	a method of
0.0236212359	$ r ^ d
0.0236128580	a data example
0.0236111085	mean time
0.0236000101	new method for
0.0235933430	the means of
0.0235928926	an answer to
0.0235825823	the cardinality of
0.0235639216	the exact distribution of
0.0235623343	the first two moments of
0.0235515283	^ d \
0.0235492489	the impacts of
0.0235367622	new method to
0.0235270267	a survey of
0.0235062137	to depend on
0.0234637230	a stationary time
0.0234544267	to infinity with
0.0234297799	first two moments of
0.0234239951	the direction of
0.0234198464	of order k
0.0234141645	the singular values of
0.0234024042	the literature as
0.0233862776	a \ in
0.0233683223	least squares estimators for
0.0233325711	to lie in
0.0233108413	known results on
0.0233064564	performs as
0.0232584824	a prior on
0.0232559766	with values in
0.0232539488	$ y = \
0.0232492489	the equality of two
0.0232419905	the detection of
0.0232309021	$ p \
0.0232049227	an ensemble of
0.0231870539	the computational complexity of
0.0231590339	the control of
0.0231421061	a probability measure on
0.0231219762	different sets of
0.0231143606	$ \ chi ^
0.0230639216	a general theory of
0.0230628397	any number of
0.0230582189	the usage of
0.0230540265	the true number of
0.0230492489	the language of
0.0230467586	but also for
0.0230424430	not possible to
0.0230349559	the l \
0.0230249286	the variance in
0.0230123343	a new framework for
0.0229871927	the change in
0.0229765928	of attention in
0.0229754394	an important problem in
0.0229681810	the convergence rate of
0.0229608634	the variability of
0.0229535801	i \ in
0.0229442835	least squares estimator in
0.0229162616	and sometimes
0.0229101896	least squares estimator for
0.0229012452	$ d \
0.0228882007	of attraction of
0.0228843228	n \ in \
0.0228694772	a general method for
0.0228325823	the lens of
0.0228085326	$ \ sigma \
0.0227774123	many well
0.0227522466	a comparison between
0.0227143749	this result for
0.0227003239	the application of
0.0226925661	the first part
0.0226819958	new algorithm for
0.0226291388	also shown to
0.0226285652	* where
0.0226091001	$ \ beta =
0.0225908411	the design of
0.0225908411	a result of
0.0225879093	of decay of
0.0225834450	\ omega \
0.0225307222	a sub
0.0225204665	the prediction error of
0.0225168963	\ gamma \ in
0.0224992489	two families of
0.0224897502	the case for
0.0224794310	the main interest
0.0224727593	well as under
0.0224242264	a number of different
0.0223912147	the asymptotic theory for
0.0223796341	+ \ sigma \
0.0223690791	the standard deviation of
0.0223621616	\ gamma ^
0.0223405657	\ sigma =
0.0223268629	the benefit of
0.0222802170	\ beta \ in
0.0222703731	\ log n \
0.0222703731	$ \ sqrt n \
0.0222510760	the fundamental limits of
0.0222490492	$ \ rho \
0.0222215458	\ tilde \
0.0221975430	$ i \
0.0221804673	the marginal distribution of
0.0221671660	to depend
0.0221363868	the excess risk of
0.0221157946	some results on
0.0220900683	the representation of
0.0220864987	an oracle inequality for
0.0220855501	the asymptotic variance of
0.0220709914	of distributions on
0.0220526633	a realization of
0.0220519446	$ \ r ^
0.0220311563	of view of
0.0220291347	$ k \ in
0.0220256751	$ n \
0.0220098324	the same set of
0.0219919905	the behaviour of
0.0219862120	more robust to
0.0219622188	different approaches to
0.0219549227	a stream of
0.0219348477	the posterior distribution of
0.0219234017	the interpretation of
0.0218995971	a new method to
0.0218951651	a l \
0.0218757034	in order to show
0.0218292547	the sequence of
0.0218045096	this problem by
0.0217908411	a notion of
0.0217864312	the tradeoff between
0.0217774123	new way
0.0217559616	of independence between
0.0217395770	first part of
0.0217209007	the vertices of
0.0217181894	$ n \ to
0.0216915952	the coefficient of
0.0216888338	the extension of
0.0216710141	$ \ mu \
0.0216573832	given in terms of
0.0216553043	the first two
0.0216490943	of size n
0.0215803233	q \ in
0.0215796064	\ sim \
0.0215768629	in relation to
0.0215574485	the results from
0.0215513873	one way to
0.0215022567	a new algorithm for
0.0214992489	the reciprocal of
0.0214992489	the rest of
0.0214992489	the viewpoint of
0.0214748296	as compared to
0.0214607188	\ in t
0.0214541232	$ \ theta \
0.0214455205	a sufficient condition for
0.0214193957	least squares estimator of
0.0214150242	the degrees of
0.0214065050	an approximation of
0.0213754551	d \ to
0.0213611438	the optimal number of
0.0213582189	the generality of
0.0212982234	the case of non
0.0212955467	the extent of
0.0212648013	\ cdot \
0.0212445027	of goodness of
0.0211682823	the same order of
0.0211681899	\ alpha \
0.0211421061	a parametric family of
0.0211363868	the conditional expectation of
0.0211334766	analyzed to
0.0211157946	a hierarchy of
0.0210982376	in applications such as
0.0210868588	this result to
0.0209919905	the eigenvalues of
0.0209919905	the level of
0.0209766200	the point of view of
0.0209406980	mean zero and
0.0209348477	the statistical properties of
0.0209169905	the components of
0.0209137579	the error rate of
0.0209051915	the generalization error of
0.0209035443	a random sample of
0.0208951287	the algorithm to
0.0208943417	of convergence as
0.0208932867	the mle for
0.0208757629	the local time
0.0208657946	a partition of
0.0208637579	the spectral density of
0.0208616916	$ \ theta \ in \
0.0208482684	in \ r
0.0208338805	the interaction between
0.0208338600	of probability distributions on
0.0208325823	in many areas of
0.0208277048	the sample mean
0.0208218581	a finite mixture of
0.0207964014	the center of
0.0207932221	a consequence of
0.0207919905	the literature on
0.0207908411	a framework for
0.0207629709	the speed of
0.0207575078	the entries of
0.0207575078	the regularity of
0.0207459007	the sum of two
0.0207439564	diameter of
0.0207325595	to infinity as
0.0207274938	the increments of
0.0207226198	$ \ mathbb x
0.0207108137	mean function and
0.0206574485	the target of
0.0206313140	new framework for
0.0206291388	also applied to
0.0206218581	a general theory for
0.0206194772	a random number of
0.0205661388	the strong consistency and
0.0205580016	to perform well
0.0205361438	the problem of parameter estimation for
0.0205123619	$ n = \
0.0205121265	the majority of
0.0204992489	the necessity of
0.0204823646	the best known
0.0204748140	$ out of
0.0204573928	the expansion of
0.0204251491	the objective of
0.0204251491	the output of
0.0203863868	the existing literature on
0.0203812762	the need to
0.0203763131	the geometric mean
0.0203402203	and only if
0.0203393137	show consistency of
0.0203031533	^ \ infty \
0.0202984238	the computational cost of
0.0202876102	the particular case of
0.0202860983	the general framework of
0.0202709605	as special cases of
0.0202578055	the uniform distribution on
0.0202438138	the asymptotic mean
0.0202277298	of products of
0.0201931484	the superiority of
0.0201533150	\ sigma \
0.0201393342	the goodness of
0.0201363868	the tail behavior of
0.0201363868	the operator norm of
0.0201214335	$ t \ to
0.0201144446	a kind of
0.0201114352	the bootstrap for
0.0200992098	the case with
0.0200739445	\ theta \
0.0200693562	the statistical performance of
0.0200603556	the cdf of
0.0200582189	in contrast with
0.0200582189	in connection with
0.0200582189	a list of
0.0200464014	the rate at
0.0200419905	the proof of
0.0200329093	the light of
0.0200079149	the mean value
0.0199919905	a characterization of
0.0199919905	the advantages of
0.0199797939	$ k = \
0.0199687191	the same number of
0.0199594622	the search for
0.0199290010	the object of
0.0199251491	a sample from
0.0198843273	$ x_0 \
0.0198450723	the data into
0.0198388716	the action of
0.0198273822	this results in
0.0197686236	a new characterization of
0.0197566150	the coordinates of
0.0197344508	the null hypothesis of
0.0197209007	a question of
0.0197194827	a class of non
0.0196976908	$ x \ in \
0.0196976908	$ i \ in
0.0196870380	this problem in
0.0196479527	the distance between
0.0196432867	the ratio of two
0.0196066031	\ sigma ^ 2 \
0.0195888716	an estimate for
0.0195825823	the vicinity of
0.0195768629	the feasibility of
0.0195606474	a h \
0.0195468096	$ 2 \
0.0195304245	the classical problem of
0.0195088496	an estimator based on
0.0194390997	$ n \ in \
0.0194153452	the key to
0.0194150242	a property of
0.0194026896	a nonparametric estimator of
0.0193888716	a novel method for
0.0193856376	the convergence rates of
0.0193698007	the test under
0.0193582189	particular cases of
0.0193568965	the estimator of
0.0193268629	the occurrence of
0.0193237711	to converge at
0.0193043343	not only on
0.0192904364	a way of
0.0192465341	the hessian of
0.0192169070	the strong consistency of
0.0191986142	for equality of
0.0191824154	a conjecture of
0.0191744722	by use of
0.0191403492	\ boldsymbol \
0.0190926171	the case in
0.0190855129	the mean squared error of
0.0190739445	\ infty \
0.0190186236	the discrepancy of
0.0189819773	\ mathbf y \
0.0189684659	for model selection and
0.0188823711	$ n \ in
0.0188589356	on simulated and
0.0188558857	a discussion of
0.0188434659	the optimal rates of
0.0188361438	an asymptotic analysis of
0.0188347932	\ sigma = \
0.0188241291	the norm of
0.0187919905	the dynamics of
0.0187209007	a new estimator of
0.0187149308	of convergence under
0.0186831649	the median of
0.0186713888	the asymptotic distributions of
0.0186434789	second moment of
0.0186404939	$ n p \
0.0186229004	the benefits of
0.0186161388	an adaptive estimator of
0.0186149308	for sequences of
0.0186062725	the powers of
0.0186036200	a necessary and
0.0185871861	the domain of
0.0185785672	the lasso to
0.0185768629	a long time
0.0185768629	the intersection of
0.0185768629	a corollary of
0.0185705582	a representation of
0.0185638864	at zero and
0.0185304245	the inverse problem of
0.0185304245	the spectral distribution of
0.0185173325	the link between
0.0185138879	for inference in
0.0185097449	of convergence for
0.0184748140	t \ to
0.0184608634	an approach to
0.0184333444	the population mean
0.0184239951	the difference of
0.0183922754	in cases of
0.0183183216	of interest for
0.0182659346	\ mu \ in
0.0182423462	the nonparametric estimation of
0.0182208930	and uniqueness of
0.0181989445	$ \ omega \
0.0181771950	of points in
0.0181533582	$ f \ in
0.0181169905	the family of
0.0180765205	the dependence between
0.0180720672	of fit for
0.0180682090	\ theta \ in
0.0180429798	a byproduct of
0.0180108281	or not to
0.0180066150	a basis for
0.0180042547	the error of
0.0179546852	the r \
0.0179397178	the moments of
0.0179290010	to sample from
0.0178831110	n \ to
0.0178273822	the outcome of
0.0177919905	the applicability of
0.0177811643	for inference on
0.0177006087	the expression of
0.0176494645	the value at
0.0176366152	a bound for
0.0176366152	the ratios of
0.0176229004	the evolution of
0.0175952019	the problem of estimation of
0.0175888716	the position of
0.0175871861	the implications of
0.0175494503	the tail of
0.0175397613	the conditional mean
0.0175210848	the problem to
0.0175101326	the asymptotic efficiency of
0.0175050919	not only for
0.0174871265	the union of
0.0174465512	and many other
0.0174259504	the property of
0.0174259504	the literature for
0.0174252087	$ d \ in
0.0173963074	a lack of
0.0173418304	to hold in
0.0173058794	the parameter of interest
0.0172907946	to search for
0.0172372249	the solutions of
0.0172329093	a new estimator for
0.0172247613	of convergence in
0.0172149308	of groups of
0.0171624838	\ leq \
0.0171425774	a flexible and
0.0170926171	the dependence on
0.0170926171	the type of
0.0170418786	the convexity of
0.0170319126	the fr \
0.0170186236	the price of
0.0169919905	a method for
0.0169919905	the definition of
0.0169709007	in support of
0.0169186521	the good performance of
0.0169169905	the optimality of
0.0168811643	the rate of convergence in
0.0168618650	the equivalence of
0.0168434659	the loss function and
0.0168434285	the decay of
0.0168168786	a technique for
0.0168114673	this approach to
0.0168022661	to belong to
0.0167788916	the uncertainty in
0.0167566150	an approach for
0.0167459007	the mean and variance of
0.0167085453	the columns of
0.0166989445	\ epsilon \
0.0166959243	for detection of
0.0166387781	a confidence interval for
0.0166261138	the data in
0.0166127682	the matrix of
0.0165705582	the combination of
0.0165638864	but also on
0.0165501491	a solution to
0.0165304245	for model selection in
0.0165180691	the asymptotic expansion of
0.0164871265	this question in
0.0164835453	the concepts of
0.0164608682	the spectral norm of
0.0164448115	with applications in
0.0163834462	as functions of
0.0163800821	the posterior distribution in
0.0163672754	a space of
0.0161095469	\ mathbb r ^ d \
0.0161036770	the singular value
0.0160777048	the derivation of
0.0160537932	several examples of
0.0159374074	a concept of
0.0159318214	the vector of
0.0159217487	a regression model with
0.0159174205	the contribution of
0.0158717487	the consistency and asymptotic normality of
0.0158618650	the area of
0.0158459007	a product of
0.0157722099	the density function of
0.0157434659	the theoretical analysis of
0.0157286843	the asymptotic validity of
0.0156961998	$ \ log p
0.0156722099	a method based on
0.0155728310	this method to
0.0155558794	a form of
0.0155478310	the bias in
0.0154835453	and stability of
0.0154705582	the elements of
0.0154616647	the notions of
0.0154299256	the hardness of
0.0154032231	the numbers of
0.0153716689	this class of
0.0153591282	the spectral properties of
0.0152713967	a bound on
0.0152372249	a choice of
0.0152144976	a distribution with
0.0152125998	two estimators of
0.0150926171	the limits of
0.0150926171	the identification of
0.0149786843	the first and second
0.0149168786	the neighborhood of
0.0149060652	the recent work of
0.0148829378	the problem of testing for
0.0148811643	a functional of
0.0148618650	the variances of
0.0148263153	the connection between
0.0148256087	mean and variance of
0.0148168786	a definition of
0.0147969008	the distribution function of
0.0147566150	in view of
0.0147104218	the approximation of
0.0146924616	the probability distribution of
0.0146924616	the posterior probability of
0.0145634335	a data set of
0.0145233827	the almost sure convergence of
0.0144714259	the gap between
0.0144678272	the minimizer of
0.0144536843	of interest to
0.0144259504	the recovery of
0.0144232817	a dataset of
0.0143983868	the case of two
0.0143752119	the flexibility of
0.0143716689	a proof of
0.0142287790	an estimation of
0.0141957103	a model for
0.0141144976	the parameters of interest
0.0141122249	the sample mean and
0.0140926171	the derivatives of
0.0139531348	the investigation of
0.0139531348	the curse of
0.0138796847	the drift of
0.0138716689	the stability of
0.0138716689	the performances of
0.0138716689	the robustness of
0.0138716689	the identifiability of
0.0138618650	the average of
0.0138618650	the spectrum of
0.0138317946	the way to
0.0137641644	on synthetic and
0.0137466689	the coefficients of
0.0137286843	the minimax risk for
0.0137155890	a part of
0.0136572967	a new method of
0.0135139000	the degrees of freedom of
0.0134923397	an algorithm to
0.0134695134	the lack of
0.0134678272	a tool for
0.0134644084	the merits of
0.0134644084	the existence and uniqueness of
0.0134543934	the mle in
0.0134251539	a theoretical analysis of
0.0134068553	the modulus of
0.0134001128	the minimum of
0.0133936110	the estimation error of
0.0133716689	the minimization of
0.0133661492	the order statistics of
0.0133346366	the minimax rate for
0.0132492817	the covariance of
0.0131900494	the determination of
0.0131353149	an illustration of
0.0130845553	a portion of
0.0130830455	increases to
0.0130210279	the knowledge of
0.0129657071	a formula for
0.0129644084	the foundations of
0.0129001128	the concentration of
0.0127269443	the minimax rate of
0.0126811927	the theoretical properties of
0.0126650670	the width of
0.0125667795	the rates of convergence of
0.0124923397	a methodology for
0.0124644084	a fraction of
0.0124536067	a version of
0.0124388765	the asymptotic normality for
0.0123672845	the comparison of
0.0123591282	the covariance structure of
0.0123220090	the probabilities of
0.0121192687	the weak convergence of
0.0120264115	the eigenvectors of
0.0119695573	a rate of
0.0119174205	a comparison of
0.0119073832	the fraction of
0.0118716689	the result of
0.0118716689	a study of
0.0118542445	the minimax risk of
0.0118445573	a theory of
0.0117269443	the optimal rate of
0.0117096366	the statistical analysis of
0.0116929700	the unknown parameters of
0.0116917795	the rate of convergence for
0.0115251128	a solution of
0.0113716689	the cases of
0.0113597449	the basis for
0.0113597449	and robustness of
0.0113317337	the radius of
0.0113220090	the derivative of
0.0112125778	the convergence properties of
0.0111679700	the asymptotic theory of
0.0111353149	the history of
0.0110608271	the specification of
0.0110608271	the fluctuations of
0.0110264115	the reconstruction of
0.0109001128	the error in
0.0108975793	the calculation of
0.0107466689	the asymptotics of
0.0105608271	the consequences of
0.0104477319	the inversion of
0.0104477319	the uniqueness of
0.0104470090	a matrix of
0.0103941605	for sums of
0.0103097449	the evaluation of
0.0102870176	the implementation of
0.0102334462	a type of
0.0102104218	the nature of
0.0100608271	the locations of
0.0098584462	a method to
0.0098584462	the difference in
0.0098584462	to test for
0.0097466689	the solution to
0.0092870176	a procedure for
0.0087466689	the collection of
