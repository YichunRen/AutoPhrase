0.9775678543	markov decision process
0.9721983391	artificial intelligence
0.9708133078	discrete cosine transform
0.9703808910	support vector machine
0.9699745902	light field
0.9650535510	ip telephony
0.9643085153	cultural heritage
0.9633344814	base station
0.9583713822	vector quantization
0.9570783272	optical flow
0.9557071004	haar wavelet
0.9548907122	fourier transform
0.9533921620	virtual reality
0.9525239302	augmented reality
0.9520109372	sentiment analysis
0.9513922168	resource allocation
0.9506976311	sign language
0.9502099879	reinforcement learning
0.9493935747	compressed sensing
0.9470677266	feature extraction
0.9464577778	facial expression
0.9455391840	spread spectrum
0.9440781786	neural networks
0.9433962546	machine translation
0.9425410862	natural language
0.9416041597	head mounted display
0.9394636476	neural network
0.9393629452	social media
0.9391062422	hidden markov model
0.9389306891	discrete wavelet transform
0.9383425997	point cloud
0.9377786853	wavelet transform
0.9363793478	remote sensing
0.9361927766	motion compensation
0.9358976702	admission control
0.9354715781	qr codes
0.9327332707	contrast enhancement
0.9322604507	intellectual property
0.9321049032	bit rate
0.9303465618	deep learning
0.9303269747	sheet music
0.9299800421	high efficiency video coding
0.9285491485	wireless networks
0.9257995396	congestion control
0.9248642740	action recognition
0.9242103610	nearest neighbor search
0.9236976676	frame rate
0.9225376323	compressive sensing
0.9218730760	weakly labeled
0.9201273842	information hiding
0.9196077740	arithmetic coding
0.9194866172	older adults
0.9194132249	human perception
0.9182801829	copyright infringement
0.9175847875	nearest neighbor
0.9174755628	compression ratio
0.9174662368	ad hoc
0.9173655094	closed form
0.9173163497	packet loss
0.9160179529	copyright protection
0.9154510100	principal component analysis
0.9154393673	wi fi
0.9154347528	user experience
0.9138382175	point clouds
0.9135592646	question answering
0.9131264338	signal processing
0.9125354297	tv series
0.9122867125	color space
0.9108942388	secret messages
0.9098754290	fake news
0.9094365352	high fidelity
0.9090498243	energy compaction
0.9088043211	variational autoencoder
0.9086212584	euclidean distance
0.9080530477	linear programming
0.9078676332	social networking
0.9073652999	reversible data hiding
0.9072696344	content delivery
0.9065020921	ms coco
0.9052872615	machine learning
0.9050920346	service providers
0.9044745959	recommender systems
0.9038151415	hash codes
0.9022557054	rate adaptation
0.9016333382	convex optimization
0.9013303805	dynamic programming
0.9011571900	source separation
0.9011313978	content based image retrieval
0.9008194049	crowdsourced live streaming
0.9006216979	weakly supervised
0.8991429832	image compression
0.8991376542	correlation coefficient
0.8970515797	long short term memory
0.8968757606	chosen plaintext
0.8958255797	cloud computing
0.8956531942	singing voice separation
0.8954562139	adversarial examples
0.8951135985	big data
0.8949371222	visual question answering
0.8944854838	gray scale
0.8941367525	mel frequency
0.8940782403	generative adversarial
0.8914480570	random access
0.8914247738	error correction
0.8913013939	singing voice
0.8912363770	rate allocation
0.8910691117	frequency domain
0.8910479966	late fusion
0.8909006064	motion estimation
0.8906350897	head mounted
0.8897675205	recurrent neural networks
0.8893214276	emotion recognition
0.8885105155	facial expressions
0.8881358313	maximum likelihood
0.8875892413	convolutional neural networks
0.8875586684	social networks
0.8874542081	spatial domain
0.8864833551	speaker diarization
0.8849788513	style transfer
0.8849757493	long term
0.8846222222	generative adversarial networks
0.8844519598	fully connected
0.8838386116	interactive multiview
0.8837727792	recent advances
0.8835253385	cover song
0.8831366168	bandwidth allocation
0.8822533832	bit allocation
0.8818861217	adversarial training
0.8818030216	principal component
0.8813902228	loss function
0.8810265575	user generated
0.8804070759	natural language processing
0.8798520276	discrete cosine
0.8793863423	packet scheduling
0.8789473126	http adaptive streaming
0.8789129633	convolutional neural network
0.8783401922	domain adaptation
0.8778890880	error concealment
0.8745757992	live streaming
0.8743833775	quality assessment
0.8739909242	search engines
0.8738966201	cloud gaming
0.8735283994	digital watermarking
0.8725627361	jpeg compression
0.8720134445	image processing
0.8710893306	computational complexity
0.8702763406	bit plane
0.8678442074	rate control
0.8676796453	digital image
0.8674081978	secret message
0.8672886686	high definition
0.8672553134	web browser
0.8671446879	explainable recommendation
0.8659689852	bounding box
0.8659574299	energy consumption
0.8654317741	huffman coding
0.8647465166	rain streaks
0.8644013528	street view
0.8640739393	digital media
0.8639466442	hit ratio
0.8631779142	object tracking
0.8627679936	bd rate
0.8617456877	deep neural networks
0.8612178659	cellular networks
0.8610964982	low rank
0.8603698765	open source
0.8599460945	real valued
0.8598931471	low complexity
0.8598789089	singular value decomposition
0.8593631667	optimization problem
0.8593304316	peer cdn
0.8592347437	pseudo analog
0.8582273068	f1 score
0.8581750913	high dynamic range
0.8580686510	super resolution
0.8576203510	recurrent neural network
0.8576162544	bit planes
0.8572581504	motion capture
0.8572295670	proxy servers
0.8569150080	aesthetic qr
0.8568944995	dct coefficients
0.8568706196	generative adversarial network
0.8564246069	double jpeg
0.8561185030	structural similarity
0.8556216190	gaussian mixture
0.8555467912	convolutional neural
0.8550591490	mobile device
0.8543024601	transfer learning
0.8541989866	physical layer
0.8533116101	opinion scores
0.8530155479	multimedia conferencing
0.8522708367	video codec
0.8517730486	source code
0.8516889307	tone mapped
0.8507164142	video streaming
0.8505379168	data hiding
0.8500848459	forgery detection
0.8500485343	watermarking scheme
0.8498042790	large margin
0.8481816991	chaotic maps
0.8474716698	multi view
0.8463410380	low delay
0.8457151495	spatio temporal
0.8456116086	base stations
0.8452909146	social network
0.8451970078	boundary matching
0.8448085048	comprehensive review
0.8446929359	red packets
0.8445842921	application layer
0.8438650057	knowledge transfer
0.8421340771	comprehensive survey
0.8414474655	fine tune
0.8410314829	intra prediction
0.8401367487	semantic segmentation
0.8399350114	content analysis
0.8391807899	versatile video coding
0.8380777560	secret key
0.8380346343	reversible watermarking
0.8378660526	deep convolutional neural network
0.8378224875	power consumption
0.8374717943	multi user
0.8372030553	deep convolutional neural networks
0.8371617025	large scale
0.8367133602	cross layer
0.8363498687	high resolution
0.8362568162	speaker recognition
0.8360567934	high speed
0.8358475847	mobile devices
0.8350078675	fixed point
0.8349727108	statistically significant
0.8343964040	mode selection
0.8342322618	low latency
0.8340906046	attention mechanism
0.8339111550	data compression
0.8338555149	video coding
0.8330524945	search engine
0.8320366907	gray level
0.8319393427	black box
0.8319344550	data augmentation
0.8317453743	dynamic range
0.8306034382	digital cameras
0.8301973559	auto encoder
0.8298047676	human eye
0.8278533109	post processing
0.8271601790	multi modal
0.8270887421	object detection
0.8267101837	fragile watermarking
0.8265972249	mid level
0.8264491433	multi level
0.8261253268	speech separation
0.8255285798	statistical analysis
0.8254916377	consecutive frames
0.8254765898	user generated content
0.8249645904	representation learning
0.8244139081	supervised learning
0.8243222162	bit rates
0.8233437710	key agreement
0.8231425607	semi supervised
0.8223602442	sparse representation
0.8221463973	multiple instance learning
0.8217918623	latent space
0.8217410254	cosine transform
0.8214606646	prediction error
0.8201381220	variable length
0.8199301656	user satisfaction
0.8193553667	video processing
0.8191445497	short term
0.8190631393	information processing
0.8189532214	hand crafted
0.8187892743	image quality assessment
0.8183821389	human action recognition
0.8178556698	fine grained
0.8177089647	discrete wavelet
0.8175584911	previous works
0.8174939800	multi label
0.8172459832	free viewpoint
0.8161184952	great success
0.8157460864	itu t
0.8152128863	secret information
0.8152118328	deep convolutional
0.8149235109	adaptive streaming
0.8142420803	multiple description
0.8138845181	average precision
0.8136607139	energy efficient
0.8136014488	cloud based
0.8134561017	similarity measurement
0.8134241939	embedding capacity
0.8129014515	adaptive bitrate
0.8128880541	dynamic point clouds
0.8126952315	multi scale
0.8125658973	sound events
0.8120099196	human computer interaction
0.8118665947	quality metric
0.8114902155	audio visual
0.8111900377	ground truth
0.8103382498	multi task
0.8100105796	energy efficiency
0.8097813352	meta data
0.8090883114	virtual environment
0.8090795907	coarse grained
0.8088058720	feature maps
0.8083133014	real life
0.8081942428	processing operations
0.8075340075	immersive media
0.8074362512	user engagement
0.8070761660	deep neural network
0.8069488582	lossy compression
0.8066167465	discrete fourier
0.8065754394	entropy coding
0.8059084905	recommendation systems
0.8055674385	file size
0.8055613857	low cost
0.8050475545	coding efficiency
0.8043447542	gaussian mixture model
0.8041599721	generalization ability
0.8038223481	image steganography
0.8035232284	computation complexity
0.8032097804	user interface
0.8029754709	event detection
0.8026649202	pre trained
0.8020413355	iptv services
0.8015122635	audio signal
0.8008476845	modulus method
0.8007860704	visual perception
0.8006977267	user preferences
0.8005697675	step size
0.8004573134	robust watermarking
0.7999683603	audio source separation
0.7999649488	uncompressed video
0.7999043370	auto tagging
0.7997090807	spatial temporal
0.7995844948	video sharing
0.7981123643	acoustic scene
0.7979159213	video conferencing
0.7964318977	bandwidth utilization
0.7961094142	significantly improved
0.7960966423	human actions
0.7959346665	video streams
0.7955436417	cross modal
0.7955042542	high dimensional
0.7955041988	benchmark datasets
0.7953435123	generative models
0.7952327342	recent years
0.7950010252	subjective quality
0.7942055885	virtual environments
0.7939029477	information security
0.7937929846	rate distortion
0.7934950040	steganographic method
0.7932163985	trade offs
0.7929366260	signal to noise ratio
0.7925444622	extensive experiments
0.7921403229	modality specific
0.7919326301	wireless network
0.7909248636	optimal solution
0.7908872569	deep neural
0.7906280847	short term memory
0.7905607096	significant improvements
0.7903943261	recurrent neural
0.7900255396	target domain
0.7899395652	compression standards
0.7898903658	quantization parameter
0.7898769123	paper discusses
0.7895752580	image watermarking
0.7895397166	content based video retrieval
0.7889310512	moment retrieval
0.7886826528	face recognition
0.7883223470	cross modal retrieval
0.7878600389	blind watermarking
0.7877933087	power allocation
0.7876920915	random linear
0.7872743090	multi exposure
0.7864023282	result shows
0.7863131174	similarity measures
0.7856812287	data set
0.7856577587	contextual information
0.7853190645	intra coding
0.7849147478	long range
0.7847530011	research topic
0.7846762711	` `
0.7843895473	media types
0.7842780854	fine tuning
0.7840153889	recent studies
0.7838312463	video transmission
0.7838197946	adversarial attacks
0.7838056934	prediction errors
0.7833011515	depth map
0.7829178644	frame level
0.7826782022	pre processing
0.7824805686	manually annotated
0.7824445576	temporal pooling
0.7820363703	peer to peer
0.7818381417	delay sensitive
0.7813341234	brute force
0.7813271044	digital image watermarking
0.7811889187	depth estimation
0.7810496343	evaluation metrics
0.7801994465	single modal
0.7800319580	test set
0.7792217052	copy move forgery
0.7786020631	real world
0.7779068151	image retrieval
0.7775106887	transport layer
0.7770277829	edge computing
0.7769400623	rate distortion optimization
0.7754921084	cost effective
0.7754850819	binary codes
0.7745959633	audio clips
0.7735198843	low resolution
0.7734068274	data analysis
0.7733001552	visual cues
0.7731119837	speech recognition
0.7726900633	compression artifacts
0.7725350476	viewing experience
0.7722290670	rdh schemes
0.7716893125	significantly outperforms
0.7716419804	computational cost
0.7714827095	significant improvement
0.7713020573	main idea
0.7710148388	multimodal information
0.7707215407	underwater images
0.7705893760	inter frame
0.7705855073	end users
0.7705420907	speech enhancement
0.7704383546	mobile video
0.7697034916	web based
0.7691140191	word level
0.7686346294	cross media
0.7685862047	research area
0.7677558475	subjective ratings
0.7673990663	trace driven
0.7669366070	test sequences
0.7663450466	recent works
0.7661776619	packet losses
0.7653819860	performance improvement
0.7645615298	future directions
0.7645323826	video editing
0.7644877119	intra frame
0.7642585369	video quality
0.7641865080	music generation
0.7635576214	multimedia applications
0.7633254630	data driven
0.7632549315	single view
0.7630704125	natural images
0.7630205167	sound source
0.7627736047	feature vectors
0.7627697683	human subjects
0.7625678240	increasing demand
0.7618613049	storage cost
0.7616629340	pixel wise
0.7610632427	road network
0.7607713284	context aware
0.7606913155	deep learning based
0.7604943425	video sequences
0.7602012102	visual search
0.7601075414	cross domain
0.7596889369	low level
0.7582700662	encoder decoder
0.7569572851	decision making
0.7562064229	compressed video
0.7560854638	computational power
0.7553571674	content aware
0.7553157310	significantly improves
0.7551729957	tile based
0.7548799794	image editing
0.7545487394	joint optimization
0.7545454562	high quality
0.7544048776	image denoising
0.7542485539	information retrieval
0.7533905411	payload capacity
0.7531274922	sparse coding
0.7529023596	existing works
0.7526646574	fully exploit
0.7526235773	web images
0.7523415661	image based rendering
0.7523043124	coding standards
0.7519056581	lossless coding
0.7518263816	edge detection
0.7513695589	public datasets
0.7512777528	audio features
0.7512627414	image search
0.7511478633	audio watermarking
0.7508421239	online hashing
0.7507647965	low bit rate
0.7505247698	meta learning
0.7497299089	image steganalysis
0.7492008077	image collection
0.7489725831	previous studies
0.7485019576	jnd based
0.7483252997	image fusion
0.7481165547	distance metric
0.7471560546	experimental results
0.7470964866	content providers
0.7470525793	superior performance
0.7467046006	video search
0.7463164101	medical images
0.7461584359	convolution neural network
0.7458723696	video retrieval
0.7457932581	transform coefficients
0.7456540697	compression efficiency
0.7455252190	image coding
0.7452893555	utility function
0.7452253274	simulation results
0.7452143627	prior knowledge
0.7451103001	bd rate reduction
0.7450967386	video indexing
0.7447028302	high level
0.7436392191	results suggest
0.7435041885	domain specific
0.7430902511	http adaptive
0.7430750783	free viewpoint video
0.7427052369	multi resolution
0.7426438342	peak signal to noise ratio
0.7423947050	control protocol
0.7420678677	reference software
0.7416729807	word embedding
0.7416503105	cross media retrieval
0.7413676565	video watermarking
0.7404553742	music video
0.7404165777	significantly improve
0.7400172882	web video
0.7396628496	encryption scheme
0.7388964923	stego image
0.7388948194	color images
0.7385523274	cover image
0.7379070085	extensive simulations
0.7373613131	audio signals
0.7362720395	weak labels
0.7359458702	sample level
0.7350572205	multi layer
0.7337735812	jpeg images
0.7332266577	image captioning
0.7331344554	cnn based
0.7325485726	multiview video
0.7324275273	hand crafted features
0.7320706727	image enhancement
0.7320251113	low dimensional
0.7316575212	visual sentiment
0.7315793899	multi dimensional
0.7311631983	predictive coding
0.7304418382	multi modality
0.7302682173	quality adaptation
0.7301973371	multimedia streaming
0.7299958493	comparative analysis
0.7283926438	multimedia content
0.7282109560	multimedia systems
0.7279358023	scene recognition
0.7279011373	user generated videos
0.7278672673	media streaming
0.7274885085	high frequency
0.7274428599	comprehensive experiments
0.7274059592	network steganography
0.7267108555	ontology based
0.7262739472	audio event
0.7258839060	information technology
0.7256888497	video summarization
0.7255572415	unified framework
0.7252714026	scalable video coding
0.7252354370	semi supervised learning
0.7242214278	image super resolution
0.7231768993	audio steganalysis
0.7230056287	network coding
0.7227520153	single image
0.7226483320	music recommendation
0.7216801258	key idea
0.7214436412	sketch based
0.7209752594	theoretical analysis
0.7204711559	internet of things
0.7202628219	jointly optimized
0.7196641040	video clips
0.7195359526	training set
0.7181947637	stego images
0.7179732968	multimedia services
0.7169558560	experimental evaluation
0.7161777355	video analysis
0.7155489804	reversible data hiding in encrypted
0.7155091938	existing methods
0.7154476034	single frame
0.7153507891	image classification
0.7152003430	photo realistic
0.7149527299	cross modal hashing
0.7148492002	experimental results demonstrate
0.7146925757	activity recognition
0.7146064805	dynamic adaptive streaming over http
0.7137479652	mean opinion score
0.7135260382	video delivery
0.7124091660	inter modality
0.7122955674	streaming video
0.7121001082	music information retrieval
0.7119576384	dance videos
0.7118687065	communication systems
0.7117236308	video classification
0.7114975345	image text
0.7110493468	embedding space
0.7106301220	http based
0.7099445401	video quality assessment
0.7088982217	wireless video
0.7082861218	e commerce
0.7081762623	graph based
0.7078346776	cross modal similarity
0.7077813553	feature learning
0.7068713797	quality metrics
0.7065679019	social media platforms
0.7058171054	video stream
0.7057937384	visual semantic
0.7047020451	motion vector
0.7039568680	error rate
0.7028536139	significant bit
0.7026774096	multimedia data
0.7025255535	user preference
0.7020989996	deep reinforcement learning
0.7018031826	subspace learning
0.7015943003	manipulation detection
0.7015462017	cross layer design
0.7011531089	watermark extraction
0.7010734396	future research
0.7007792874	streaming services
0.7007570005	rate distortion performance
0.7007403563	mean square error
0.7005186759	watermarking technique
0.7003147610	multi stream
0.6985385868	hiding information
0.6976151388	automatically generated
0.6972866730	audio event detection
0.6969502713	metric learning
0.6965712834	taking into account
0.6958982006	scheduling algorithm
0.6949296715	semantic space
0.6943692402	low frequency
0.6942138651	digital images
0.6936434036	least significant bit
0.6932565712	video services
0.6928630933	stereoscopic image
0.6928437571	dct domain
0.6927550396	audio content
0.6919244531	mean squared error
0.6918714762	quality perception
0.6916004231	image inpainting
0.6914733215	steganography algorithm
0.6914627000	previous methods
0.6913973068	watermarking schemes
0.6907830492	multi channel
0.6906258531	digital video
0.6904761522	image forensics
0.6902899633	performance evaluation
0.6900869203	pixel domain
0.6900505233	increasingly important
0.6893250622	feature vector
0.6877553680	recently proposed
0.6870035600	self similarity
0.6867882418	rgb d
0.6867705884	qoe prediction
0.6847170851	face generation
0.6845480564	support vector
0.6844278817	video captioning
0.6827758188	speech signals
0.6825404038	steganographic scheme
0.6823548096	transform domain
0.6821803167	svd based
0.6817120589	visual emotion
0.6817089551	quality model
0.6813413288	quality degradation
0.6813402697	feature matching
0.6813391882	perceived quality
0.6810753195	object recognition
0.6805982855	visual sentiment analysis
0.6804129738	steganography technique
0.6799379575	omnidirectional images
0.6796301064	secret image
0.6795963546	training samples
0.6792642939	plaintext attack
0.6792020218	comparative study
0.6789906720	speech signal
0.6783613408	video compression
0.6770016395	speech quality
0.6768600156	video summaries
0.6767064545	spatial resolution
0.6764392167	quality scores
0.6762484629	real world scenarios
0.6759678968	visual tracking
0.6757413918	content based
0.6757355710	high capacity
0.6753973561	block level
0.6746252101	device to device
0.6741823258	qoe metrics
0.6738331574	audio classification
0.6733570555	watermarking algorithms
0.6721509441	attention network
0.6720327000	emotion analysis
0.6717682173	image annotation
0.6714371587	block based
0.6714167987	network conditions
0.6707737669	existing approaches
0.6706260276	visual concepts
0.6699076389	similarity search
0.6695817415	face images
0.6687141707	image translation
0.6685336364	compressed image
0.6681809722	high performance
0.6681540715	deep networks
0.6677374096	latent semantic
0.6671785625	dance video
0.6669691871	paper proposes
0.6668279070	adaptation algorithm
0.6665529124	visual recognition
0.6665285389	client side
0.6665238033	mobile multimedia
0.6664080861	previously proposed
0.6659364552	mobile networks
0.6649021082	subjective experiments
0.6646071804	source domain
0.6642712368	encryption algorithm
0.6642597582	joint embedding
0.6641673590	visual content
0.6634063000	music classification
0.6633288246	extracted features
0.6631773466	end to end trainable
0.6631193407	multimodal fusion
0.6630304405	secret data
0.6619200412	multi frame
0.6611135327	cross modal hashing methods
0.6609070288	u net
0.6592977908	field of view
0.6590932332	method achieves
0.6588907395	results demonstrate
0.6583625936	attention based
0.6581699500	just noticeable
0.6579632344	squared error
0.6571689298	coarse to fine
0.6568018360	steganographic techniques
0.6566361511	adaptive video streaming
0.6566136830	video popularity
0.6565569769	high efficiency
0.6561429830	color image
0.6544495412	video clip
0.6538284828	image transmission
0.6535670166	residual network
0.6530665916	cover images
0.6518903731	high bit
0.6517367200	image quality
0.6503496053	key frames
0.6496216367	feature representation
0.6494262805	long short term
0.6484345994	convolutional network
0.6473357244	higher level
0.6461309827	extensive experimental results
0.6461232467	scalable video
0.6456037183	based watermarking
0.6451335970	discriminative features
0.6450550668	lecture video
0.6448162007	retrieval systems
0.6447297841	video understanding
0.6444087391	medical image
0.6443050514	image encryption
0.6442407136	noise ratio
0.6438345477	multimedia communication
0.6434526784	volumetric video
0.6432179028	end user
0.6431650809	deep network
0.6426302472	grayscale images
0.6424515974	copy move
0.6423830699	vision based
0.6414253173	competitive performance
0.6410193643	zero shot learning
0.6408961451	watermarking techniques
0.6408256752	generative model
0.6395463774	video frames
0.6391697669	mpeg 7
0.6383051311	opinion score
0.6379279478	source camera
0.6377683672	benchmark dataset
0.6370553221	video representation
0.6362514697	video on demand
0.6360702978	image patches
0.6357440414	multiple modalities
0.6354408578	compressed images
0.6353170504	image restoration
0.6324762231	quality enhancement
0.6314374159	common representation
0.6299672975	baseline methods
0.6297908682	hiding data
0.6295636695	steganographic methods
0.6291584067	reversible data
0.6284243775	point cloud compression
0.6281219220	youtube videos
0.6276502611	video annotation
0.6275428558	region based
0.6274178573	end to end
0.6263893133	numerical results
0.6261773742	video surveillance
0.6259429644	adversarial networks
0.6258949885	pixel level
0.6258561621	times faster
0.6258286623	user behavior
0.6253948288	takes into account
0.6252026433	simulation results demonstrate
0.6238960088	image dataset
0.6235168065	audio track
0.6225107509	promising results
0.6224226327	texture features
0.6221535734	playback rate
0.6212251293	visual features
0.6210419541	cover media
0.6209570240	higher quality
0.6206056649	existing algorithms
0.6203920703	higher accuracy
0.6202183239	human action
0.6191645074	temporal video
0.6191010828	computer aided
0.6186210742	convolutional networks
0.6184002501	sensor networks
0.6179774436	subjective test
0.6176820753	transform coding
0.6173715900	multimedia databases
0.6166082575	labeled data
0.6160813925	performance analysis
0.6140794387	challenging problem
0.6135217655	challenging task
0.6133678471	deep learning framework
0.6131285361	image to image
0.6128397772	high level semantic
0.6122482986	near duplicate
0.6113717798	audio based
0.6111868367	video communication
0.6106911013	trade off
0.6106267851	domain knowledge
0.6093544879	performance gain
0.6074746272	audio video
0.6074153753	data sets
0.6072944439	prediction accuracy
0.6071200992	paper describes
0.6067052597	rapid development
0.6066659084	proposed method
0.6052822196	no reference
0.6046527330	significant bits
0.6032476153	streaming over http
0.6026057619	training data
0.6001234992	deepfake videos
0.5995706855	human visual system
0.5993257723	quality of experience
0.5982211805	steganographic bandwidth
0.5971906351	mobile edge
0.5968395246	compression method
0.5962846727	secret images
0.5953757545	markov decision
0.5952651961	quantitative and qualitative
0.5952640913	practical applications
0.5951871388	indexing and retrieval
0.5948324412	feature based
0.5940863268	mobile applications
0.5938333828	research community
0.5934299045	adaptive steganography
0.5933160475	visual information
0.5931334620	hidden data
0.5922816818	full reference
0.5921695044	automatic music
0.5920729159	perceptual quality
0.5914552705	increasing attention
0.5912426494	deep multimodal
0.5909651961	qualitative and quantitative
0.5907561333	light field image
0.5901641850	large scale video
0.5886825259	transmission rate
0.5879151561	proposed method achieves
0.5872447978	global features
0.5863618725	server side
0.5855029302	video streaming services
0.5845294945	streaming systems
0.5843547472	hidden information
0.5837719805	compression methods
0.5834374084	video moment
0.5828665377	neural network based
0.5824397460	competitive results
0.5809204777	retrieval task
0.5808914266	video chunks
0.5800648191	zero shot
0.5793876872	optimization framework
0.5789575075	coding scheme
0.5774794246	multimedia event
0.5769143284	video codecs
0.5738807527	image and video
0.5738182066	convolutional neural network based
0.5736990443	video segment
0.5729478229	person re
0.5719717897	low quality
0.5717576084	recognition accuracy
0.5702070881	peak signal to noise
0.5701647491	quality of service
0.5698417698	few shot
0.5698112583	video text
0.5688067450	depth images
0.5686052929	video content
0.5678657648	least squares
0.5662830681	next generation
0.5662021971	based method
0.5653667604	automatic image
0.5633600354	classification tasks
0.5612849771	learning framework
0.5610156211	previous approaches
0.5601788425	subjective and objective
0.5601030677	self supervised
0.5596061000	high accuracy
0.5588948725	extensive experimental
0.5580876011	classification accuracy
0.5573470925	retrieval tasks
0.5571788425	objective and subjective
0.5568696851	based image retrieval
0.5568066849	watermarking methods
0.5561437320	synthetic and real
0.5544659077	image collections
0.5542111048	local and global
0.5508379404	local features
0.5507627412	media platforms
0.5506413470	performance metrics
0.5503115501	watermarking algorithm
0.5498217332	deep recurrent
0.5476104765	dynamic adaptive streaming
0.5471707392	network architecture
0.5471121767	deep convolutional neural
0.5456949291	paper explores
0.5456461794	mobile users
0.5452748884	learning based
0.5445627807	previous research
0.5432229697	point of view
0.5427750472	digital content
0.5427367726	visual contents
0.5415494925	video encoding
0.5396623158	temporal graph
0.5395599245	deep models
0.5395014037	video frame
0.5381045672	efficiency video coding
0.5375587607	automatic video
0.5368974305	image pixels
0.5361489915	deep feature
0.5357678929	instance learning
0.5343680783	co occurrence
0.5325640211	proposed scheme
0.5313772023	textual and visual
0.5311947335	network architectures
0.5289205134	proposed transform
0.5286227488	image recognition
0.5266890876	video traffic
0.5260415348	markov model
0.5259591253	reference image
0.5256978786	semantic information
0.5255081054	visual question
0.5242991605	datasets demonstrate
0.5240001316	audio and visual
0.5233913251	spatial and temporal
0.5216587395	rapid growth of
0.5214922023	visual and textual
0.5213533444	audio data
0.5207501940	temporal information
0.5207199820	p2p iptv
0.5199641173	results showed
0.5195985455	component analysis
0.5191251316	audio and video
0.5183580018	crucial role
0.5164170391	dynamic adaptive
0.5157056439	depth image
0.5149564319	generated images
0.5136483742	$ d_ \ text ssim
0.5121595587	visual quality
0.5105525940	fast algorithm
0.5099228956	real time
0.5098401316	images and videos
0.5085554282	image pairs
0.5075632903	sensor data
0.5065780414	prediction based
0.5057094293	adversarial network
0.5052250737	video dataset
0.5050401316	image and text
0.5030733968	case study
0.5023647358	experiments demonstrate
0.5021998083	additional data
0.5012840672	front end
0.5011451052	video data
0.5007530352	existing schemes
0.5003687750	deep features
0.4995460719	multimedia retrieval
0.4991215670	hashing methods
0.4977430161	complex event
0.4976705944	mixture model
0.4961288034	deep learning approach
0.4958753067	reconstruction quality
0.4949747449	trade off between
0.4927713668	visual signals
0.4914699784	results confirm
0.4909653126	proposed approach
0.4901557341	proposed algorithm
0.4887094821	adversarial example
0.4871101493	online video
0.4870633903	compression technique
0.4865879577	news detection
0.4862172652	large dataset
0.4859056987	voice over
0.4849815516	data points
0.4831572783	state of art
0.4825779363	image and video coding
0.4819992698	watermark image
0.4819622328	coding method
0.4817165733	feature space
0.4805675006	sub pixel
0.4801192238	deep learning methods
0.4795124416	paper aims
0.4787854436	deep learning techniques
0.4783949278	semantic image
0.4766654176	video level
0.4763517995	visual analysis
0.4757458447	compression scheme
0.4746899066	watermarking framework
0.4739945543	versatile video
0.4729982112	music information
0.4718075162	real world dataset
0.4715401120	generated music
0.4706477805	research directions
0.4691895420	attention in recent
0.4690158735	vr 360
0.4686832586	steganography methods
0.4681750854	model based
0.4678722370	multi view video
0.4663340197	the past decade
0.4662375388	multimedia information
0.4662142715	network resources
0.4654478909	content based image
0.4647051225	query image
0.4646298516	singular value
0.4638421178	quality dataset
0.4632437268	learning approach
0.4628910182	built upon
0.4627077650	computer science
0.4619928003	quality estimation
0.4616448596	adaptive video
0.4604611073	wide range
0.4589785595	back propagation
0.4584605164	image datasets
0.4556193227	spatial information
0.4553020627	semantic embedding
0.4545264615	digital data
0.4534126365	publicly available
0.4533864673	non linear
0.4533564900	360 degree videos
0.4528523131	computer vision
0.4519989675	commonly used
0.4501929704	a case study
0.4500518371	fake images
0.4499514594	feature representations
0.4490581038	model parameters
0.4485922265	simulation results show
0.4479792389	deep learning models
0.4470569618	360 degree
0.4469016289	re ranking
0.4466439387	cnn model
0.4465575378	video contents
0.4462191901	well established
0.4454775560	non uniform
0.4448069219	time consuming
0.4445995004	8 point
0.4442034866	semantic concepts
0.4431052379	based adaptive
0.4428427059	shot learning
0.4428272169	video file
0.4425351229	content based video
0.4422497367	based methods
0.4415294023	widely used
0.4404408786	three dimensional
0.4402656912	traditional methods
0.4386166783	image features
0.4379948996	decision process
0.4377818856	mean opinion
0.4373644025	detection methods
0.4357975564	image content
0.4346208602	detection accuracy
0.4344886886	video service
0.4340155213	high efficiency video
0.4327900010	detection performance
0.4325284327	hiding in encrypted
0.4312889208	based algorithm
0.4312462574	large amounts of
0.4294289935	deep learning model
0.4284272524	steganography method
0.4282722736	method outperforms
0.4280702584	high bandwidth
0.4272099669	this paper proposes
0.4271661756	experimental results show
0.4264576504	query by example
0.4263309470	8 bit
0.4261844815	layer optimization
0.4257709640	achieves state of
0.4251746277	training dataset
0.4250278028	near optimal
0.4244489327	prediction model
0.4241449686	re id
0.4237003429	user study
0.4235317446	deep reinforcement
0.4234137995	effective method
0.4233385871	proposed method outperforms
0.4227459220	dynamic point
0.4220805907	neural network architecture
0.4206753774	image blocks
0.4203206100	model achieves
0.4199244516	point dct
0.4199004230	visual attention
0.4191468830	network structure
0.4191020063	objective quality
0.4188714445	neighbor search
0.4188675367	input video
0.4186212998	crafted features
0.4184908939	waiting time
0.4177350618	crowdsourced live
0.4176280022	numerical results show
0.4174026703	classification task
0.4171666421	visual data
0.4162964525	\ text ssim
0.4157784383	approach achieves
0.4149346473	up sampling
0.4138436022	video based
0.4135025549	retrieval performance
0.4110478518	robustness against
0.4110156255	multimodal data
0.4105701480	quality level
0.4096609613	data streams
0.4096533912	360 degree video streaming
0.4080860494	data rate
0.4080427904	approach outperforms
0.4068827101	input images
0.4066088267	based rendering
0.4061056064	well defined
0.4028136973	video segments
0.4028093239	264 avc
0.4027285667	watermarked image
0.4025372781	proposed model
0.4017272240	paper introduces
0.4010465185	this paper presents
0.4007726321	et al
0.4005953803	the general public
0.4004510377	signal to noise
0.4004261788	compression performance
0.3990341913	simple yet
0.3988583289	well suited
0.3981903589	vision tasks
0.3974125395	method called
0.3970271035	\ emph
0.3953961727	image data
0.3950710912	de la
0.3940004871	world datasets
0.3930275646	term memory
0.3926241962	hevc reference
0.3925391467	network based
0.3921835910	360 degree video
0.3905833734	text based
0.3897978676	time varying
0.3887927624	based music
0.3887390258	variety of applications
0.3886960855	peak signal
0.3880827505	perceptual video
0.3854781163	human computer
0.3854433783	experiments conducted on
0.3853981487	existing techniques
0.3850597309	original image
0.3848089138	outperforms state of
0.3847811464	video sequence
0.3846902001	media retrieval
0.3839374153	computer graphics
0.3835267185	360 \ deg
0.3831823127	compression algorithms
0.3828704744	image database
0.3817638124	3 d
0.3813877996	varying network
0.3804590363	faster than
0.3786517045	self attention
0.3784581733	network bandwidth
0.3783426254	experiments conducted
0.3775581286	language processing
0.3775434287	original data
0.3772975136	long short
0.3770367861	a comparative study
0.3761676861	art results on
0.3758601432	host image
0.3755483046	input image
0.3751060593	extensive experiments on
0.3742896269	becoming increasingly
0.3723898830	coding standard
0.3722859682	short time
0.3718057650	\ textit
0.3709795297	encryption scheme based on
0.3706675253	convolution neural
0.3699389637	important role
0.3696506502	$ \ ell_1
0.3689043879	proposed technique
0.3688697388	image based
0.3685593881	the art methods
0.3683643083	watermarking method
0.3678631401	high dynamic
0.3673785274	paper investigates
0.3661095507	divided into
0.3657340613	media data
0.3656784781	semantic gap
0.3646995702	image regions
0.3645913172	recommender system
0.3644258826	data embedding
0.3639465190	allocation problem
0.3629967876	robust against
0.3621032248	k means
0.3620221956	based image
0.3620116388	cloud compression
0.3609955814	based approaches
0.3609836882	multiple users
0.3605848366	hiding secret
0.3604566577	small number
0.3603899185	wireless sensor
0.3597973168	$ \ lambda
0.3595562745	rate reduction
0.3592178842	paper presents
0.3578547589	data hiding scheme
0.3577408780	steganography based on
0.3566442093	2 d
0.3560566427	p2p streaming
0.3545795202	achieve high
0.3543576845	multimodal learning
0.3540670433	recent advances in
0.3531582708	mean squared
0.3528188652	an open source
0.3527580859	decomposed into
0.3520687653	video applications
0.3510239428	results obtained
0.3497901324	\ mathbf
0.3494491654	relationships among
0.3489944136	space time
0.3486360163	based multi
0.3481511378	proposed framework
0.3475421812	evaluation results
0.3473119706	based approach
0.3472315464	two stream
0.3469299495	in recent years
0.3469136240	trained models
0.3454123742	\ times
0.3439491707	360 vr
0.3435643218	based video
0.3434009429	based video retrieval
0.3424815551	encrypted images
0.3420163183	method based
0.3408691194	a markov decision
0.3407670924	image compression using
0.3405108385	tradeoff between
0.3397336957	fed into
0.3395086451	on demand
0.3385923094	learning process
0.3383508356	input data
0.3374611633	time series
0.3372191372	computer generated
0.3367908122	no longer
0.3362411567	time frequency
0.3353663603	processing techniques
0.3350373533	learning algorithms
0.3349972419	previous state of
0.3348344564	3d point cloud
0.3340987518	based approach for
0.3334842431	proposed methods
0.3333773318	this paper introduces
0.3330370186	1 d
0.3328401853	visual modalities
0.3321404405	\ `
0.3316223647	least significant
0.3308892710	large scale dataset
0.3300880423	based algorithms
0.3298902783	self training
0.3295417912	original images
0.3294923633	$ \ mathcal
0.3284574780	two dimensional
0.3277050188	jpeg image
0.3274216492	learning algorithm
0.3271068312	so far
0.3270592458	music audio
0.3266659829	art performance
0.3261955880	correspondence between
0.3261692221	small number of
0.3254973168	$ ^ \ circ
0.3236253566	user based
0.3232807733	taken into account
0.3227426227	^ o
0.3223423287	\ em
0.3218022170	still remains
0.3211629362	framework for video
0.3210586448	outperforms existing
0.3210292780	streaming applications
0.3194857162	significant performance
0.3192650718	converted into
0.3174209483	online social
0.3173126553	while maintaining
0.3167455222	a wide variety
0.3163568263	adaptive streaming over http
0.3159035122	paper studies
0.3146514213	traditional image
0.3146464290	well known
0.3144697153	important role in
0.3139275339	neural network models
0.3134351559	^ \ circ
0.3132726712	results reveal
0.3131351084	video datasets
0.3127126040	the proposed method
0.3124627617	low computational
0.3120664871	$ d_ \ text
0.3114651746	real time applications
0.3111286480	correlations between
0.3108558192	does not require
0.3101400232	recognition systems
0.3092803892	lossy image
0.3092789283	experimental results on
0.3091658282	relationship between
0.3086310151	compression techniques
0.3084115410	last decade
0.3070941652	prior work
0.3054909493	differences between
0.3046073841	vod system
0.3033417799	experiment results
0.3022212569	real time video
0.3008552103	obtained results
0.3007338563	balance between
0.3000363196	features extracted
0.2991996810	across modalities
0.2991670883	quantitative results
0.2983341707	\ mathcal
0.2979684325	previous state
0.2978261296	an efficient
0.2971084679	while keeping
0.2943450531	based on deep learning
0.2942571775	compared to existing
0.2935972294	achieve state of
0.2922426437	based retrieval
0.2922042289	large scale image
0.2909770997	previous work
0.2903573594	proposed architecture
0.2879647290	allocation scheme
0.2874458321	perform well
0.2872455392	ranging from
0.2871430669	based models
0.2870432220	+ +
0.2866522706	referred to as
0.2865896537	scale datasets
0.2862539387	trained model
0.2855573572	aims at
0.2839632074	generated videos
0.2831528305	large number of
0.2830640731	insight into
0.2829069450	\ pi ^ *
0.2827533002	available at https
0.2827400456	hiding techniques
0.2826756611	based learning
0.2816580894	into account
0.2810465240	current state
0.2806144815	aiming at
0.2804194062	important task
0.2804163616	while preserving
0.2801863664	rather than
0.2800449440	embedding data
0.2783735813	processing applications
0.2776803891	relationships between
0.2774875370	computation time
0.2774436077	state of
0.2765811677	model outperforms
0.2763909933	this paper investigates
0.2761351161	two step
0.2760672822	even though
0.2752569591	interactions between
0.2731895966	^ *
0.2728333209	improvements over
0.2720366169	network model
0.2717093177	higher than
0.2712570393	more importantly
0.2712063674	this paper describes
0.2708214123	scheme based
0.2698337352	results indicate
0.2692923820	achieves better
0.2691254738	without requiring
0.2691135102	this paper addresses
0.2690968220	method significantly
0.2683236685	non local
0.2679725698	art methods
0.2675946833	relying on
0.2664491504	art results
0.2662709193	the past few years
0.2657681024	first attempt
0.2656831851	most popular
0.2648193172	long time
0.2626741735	dynamic time
0.2615273733	features extracted from
0.2613369632	difference between
0.2597353057	the proposed algorithm
0.2597017970	learning approaches
0.2593907305	the original image
0.2582202836	per second
0.2549919359	$ \ pi ^ *
0.2540687147	scale images
0.2537499197	learning method
0.2534177716	control algorithm
0.2530437556	algorithm outperforms
0.2529617833	algorithm based
0.2528569311	suffers from
0.2527911270	peak signal to
0.2525728852	suffer from
0.2525202248	^ 2
0.2524724127	significantly better
0.2512936178	proposed solution
0.2511149527	two stage
0.2501933416	transmitted over
0.2500149123	scale image
0.2484606880	effective way
0.2482364135	few years
0.2479850475	coming from
0.2477102945	the art performance
0.2473629434	dynamic adaptive streaming over
0.2471644623	the art approaches
0.2469397950	modal data
0.2468984750	yet effective
0.2462311741	a large scale
0.2454428419	comparison between
0.2440123441	a large scale dataset
0.2438909706	focuses on
0.2435418279	the proposed framework
0.2421209671	wide range of
0.2419720242	affected by
0.2400076567	learning methods
0.2395639627	real data
0.2389057414	based framework
0.2386826415	order to reduce
0.2385456702	more precise
0.2384428593	a convolutional neural network
0.2384274073	serve as
0.2380596910	focus on
0.2374724855	features based
0.2371116976	value decomposition
0.2370670893	gap between
0.2366502595	improvement over
0.2363423925	characterized by
0.2355625859	the last few years
0.2348504323	method based on
0.2344304980	motivated by
0.2335100625	level image
0.2331923357	live video
0.2316150360	two parts
0.2314696209	more accurate
0.2308098462	caused by
0.2306247576	emphasis on
0.2303135632	focused on
0.2302236306	serves as
0.2293438131	current state of
0.2288761563	learning model
0.2287693764	does not
0.2283618196	approach based on
0.2281120264	aim at
0.2280760035	deals with
0.2271905096	integrated into
0.2270223462	re identification
0.2267123885	conjunction with
0.2260367574	the proposed scheme
0.2258135632	rely on
0.2255421968	reversible data hiding in
0.2245619532	performance compared
0.2239985325	depend on
0.2227328313	this paper explores
0.2226311806	an ensemble
0.2226289434	the proposed approach
0.2224516452	a data driven
0.2222653049	less than
0.2222423352	based steganography
0.2221578385	the art
0.2210018814	cope with
0.2208198811	experiments show
0.2205694411	distortion performance
0.2202060048	based model
0.2194258132	distance between
0.2189746194	relies on
0.2185689915	different modalities
0.2182881581	an important role
0.2182247071	dealing with
0.2177932034	focusing on
0.2172874786	a high quality
0.2165453401	depends on
0.2150349178	equipped with
0.2149952694	the semantic gap
0.2149559522	the host image
0.2143049264	take advantage
0.2141984952	streaming system
0.2139084325	existing state of
0.2127372691	based on
0.2123141096	scheme based on
0.2121800489	millions of
0.2117655359	the proposed model
0.2112830473	formed by
0.2111869577	one dimensional
0.2103573453	results show
0.2102758147	algorithm based on
0.2098509219	an end to end
0.2094239988	human visual
0.2092146461	scale dataset
0.2091357025	$ ^
0.2082644613	vr video
0.2075916772	search system
0.2073891139	proposed algorithms
0.2070856262	this paper
0.2064038602	insights into
0.2053206334	side information
0.2051555829	the shelf
0.2049865227	the paper presents
0.2049576471	sub networks
0.2046731339	generated content
0.2046370817	$ p
0.2039948510	mapping between
0.2036411921	represented by
0.2028215986	do not
0.2019899002	extracted from
0.2011851935	inspired by
0.2011747868	emerged as
0.2007372805	existing video
0.2005225361	starting from
0.1990992616	proposed watermarking
0.1990939842	derived from
0.1986714376	much attention
0.1981471762	formulated as
0.1977577910	$ k
0.1976294826	large amount of
0.1961378028	even if
0.1961181525	refers to
0.1957534056	the discrete cosine transform
0.1951636438	360 \ deg video
0.1946769177	responsible for
0.1937673122	lead to
0.1931004267	level semantic
0.1928594833	generated by
0.1926247138	supported by
0.1924725994	aims to
0.1922159810	this paper aims
0.1920001982	proof of
0.1914604758	to date
0.1906157244	compared with
0.1898887305	learning models
0.1895754595	an innovative
0.1893359103	based on multi
0.1883228662	for cross modal retrieval
0.1878527360	video streaming over
0.1877272829	produced by
0.1872570716	an alternative
0.1865356501	images using
0.1864704322	this chapter
0.1859944121	order to achieve
0.1859401271	at least
0.1854604146	by proposing
0.1854108894	data hiding in
0.1846752970	learning techniques
0.1843965829	embedded into
0.1841209217	watermarking based on
0.1840933541	viewed as
0.1838021488	on line
0.1836964088	range of applications
0.1825334514	an optimization problem
0.1822896085	an enhanced
0.1820212658	depending on
0.1819050312	order to improve
0.1817777441	a deep neural network
0.1802799031	proliferation of
0.1799954408	into consideration
0.1799334124	perceptual quality of
0.1796824437	the cover image
0.1793968995	bag of
0.1792460321	absence of
0.1791799914	technique using
0.1789058638	the proposed technique
0.1782389813	images taken
0.1781752937	information about
0.1781227520	compared to
0.1762874563	first step
0.1747021422	over http
0.1747015869	fields such as
0.1746186101	made available
0.1745793462	a user study
0.1744848524	control over
0.1744581629	better understanding
0.1738893202	opposed to
0.1738069723	achieve better
0.1737413915	taking into
0.1736490593	audio source
0.1723834013	for image compression
0.1719153293	very popular
0.1713984657	rapid development of
0.1712907352	induced by
0.1705603650	some cases
0.1704726680	recent work
0.1704467089	a coarse to fine
0.1704026088	very large
0.1703238686	similarity between
0.1700441728	an improved
0.1700252126	an effective
0.1690812312	correlation between
0.1687226438	a low complexity
0.1680893425	on social media
0.1661463173	easy to
0.1658783183	impact on
0.1647970904	videos based on
0.1647543718	$ n
0.1645095899	$ \
0.1642822643	this article
0.1639896045	network models
0.1632291137	consists of
0.1629500753	the watermarked image
0.1628941844	analysis using
0.1628500785	unable to
0.1625624156	an iterative
0.1618262813	most important
0.1610776906	a priori
0.1608937937	leads to
0.1602986662	tend to
0.1601736896	refer to
0.1598027814	the best performance
0.1590205696	retrieval system
0.1589583841	^ \
0.1579472946	based on deep neural
0.1575591504	a new paradigm
0.1572727860	outperforms other
0.1569220377	determined by
0.1559394354	time domain
0.1556319995	led to
0.1556261355	owing to
0.1553142145	not always
0.1552386473	a pre trained
0.1543283820	better than
0.1530732117	deal with
0.1529381852	in conjunction
0.1523740451	able to achieve
0.1520899975	an overview
0.1520071393	streaming over
0.1519041247	to further improve
0.1517972058	modeled as
0.1516756566	transmission over
0.1516484474	this end
0.1515320177	the art models
0.1510335953	interact with
0.1510095734	the input image
0.1504896541	neural networks for
0.1502010477	an important
0.1495472727	obtained by
0.1486838544	the proposed method outperforms
0.1479050429	classification using
0.1475885600	the art algorithms
0.1469351806	hundreds of
0.1468326350	closer to
0.1468249840	applied to
0.1468167687	an adaptive
0.1460126879	number of
0.1459551644	experiments on three
0.1456723905	conditioned on
0.1451015482	propose to use
0.1440343730	detection using
0.1439626123	framework based on
0.1439453543	methods based on
0.1426038475	to noise ratio
0.1424700767	based approach to
0.1421325097	in accordance
0.1416945353	an image
0.1414976183	a systematic
0.1413311923	collected from
0.1411770587	consists of two
0.1410365925	an extensive
0.1406161108	conducted on
0.1402579977	existing work
0.1402051151	coupled with
0.1400514559	query by
0.1395489891	performance compared to
0.1391961644	paper focuses on
0.1391899809	the stego image
0.1390957667	the rate distortion
0.1388955530	various fields
0.1388622029	the secret message
0.1385460551	the secret data
0.1375285070	the perceived quality
0.1371238300	last few
0.1365019628	a secret message
0.1361787128	of digital data
0.1361684732	a challenging task
0.1360849283	a survey
0.1359725326	datasets show
0.1357936857	watermarking based
0.1356062740	as opposed to
0.1352237246	obtained from
0.1351563496	for cross modal
0.1351371733	a new approach
0.1350935635	adaptive streaming over
0.1348648776	a modified
0.1344615516	as much as
0.1344434245	compared to other
0.1341350485	level visual
0.1338754014	corresponds to
0.1335946015	very effective
0.1332242596	good performance
0.1330610051	lots of
0.1327244423	proposed network
0.1326703586	the art techniques
0.1324460690	benefit from
0.1323748806	the complexity of
0.1323406741	experiments on two
0.1323330131	also discuss
0.1323239553	followed by
0.1321125743	the compressive sensing
0.1320550595	this problem
0.1320415472	the detection of
0.1318810934	to cope
0.1318483636	provided by
0.1317323055	over ip
0.1315240280	3d scene
0.1314483473	leading to
0.1311543294	encoding time
0.1310481656	coding based
0.1309590515	fraction of
0.1305490982	takes into
0.1303571347	the discrete cosine
0.1302320234	the generation of
0.1301949612	steganography based
0.1300843263	a cover image
0.1300535672	the art performance on
0.1300458346	compatible with
0.1300415472	a dataset of
0.1297030839	a secure
0.1295071275	scale video
0.1292654937	on mobile devices
0.1291310401	as well as
0.1290415472	a method to
0.1289719986	an automatic
0.1289590515	advent of
0.1287944375	of multimedia content
0.1287879614	a video sequence
0.1287846720	better performance than
0.1284997857	a new image
0.1282086617	quality assessment of
0.1273096648	the absence
0.1272849248	more than
0.1272794433	the art results
0.1272111159	detection system
0.1270509801	adoption of
0.1270415472	the benefits of
0.1264252145	retrieval using
0.1260415472	the application of
0.1258986901	the content of
0.1255937594	not only
0.1253263614	recommendation system
0.1252574563	due to
0.1250415472	the security of
0.1250415472	the task of
0.1244310401	a pilot
0.1243918367	these issues
0.1242713536	various attacks
0.1238986901	the optimization of
0.1237489642	the perceptual quality
0.1234167706	during training
0.1232211880	an immersive
0.1230415472	the context of
0.1228282040	an evaluation
0.1227519618	the ground truth
0.1225364952	achieved by
0.1225009351	model based on
0.1223126569	to ensure
0.1220895358	validated on
0.1220415472	the design of
0.1219080303	tested on
0.1218237903	visual system
0.1212071907	two steps
0.1210415472	the level of
0.1206643200	close to
0.1205488337	to promote
0.1205042952	challenging due to
0.1204507067	the video content
0.1203313976	to solve
0.1200376565	this paper studies
0.1199109128	features based on
0.1199095321	attempt to
0.1198986901	the extraction of
0.1197507802	concepts from
0.1197404691	the second stage
0.1193740276	by introducing
0.1192771142	the proposed solution
0.1188352188	all possible
0.1187082139	the dynamics of
0.1186699380	by utilizing
0.1185992026	the audio visual
0.1184441807	capable of
0.1184082139	and retrieval of
0.1183953386	the video quality
0.1180415472	the process of
0.1180153187	quality of video
0.1179806141	two major
0.1177082139	the objective of
0.1176324563	more and more
0.1175714109	an important role in
0.1174986151	much more
0.1174082139	the spatial and
0.1171867853	and so on
0.1171092233	for future research
0.1170398771	the art method
0.1169552680	the audio and
0.1167082139	a method of
0.1166562025	represented as
0.1164478177	compression using
0.1160328133	in addition
0.1157403748	a crucial role
0.1157082139	a function of
0.1156254360	to learn
0.1154526723	the proposed architecture
0.1151262650	the fly
0.1149010710	the result of
0.1148289149	each modality
0.1147957346	very important
0.1147539892	at https
0.1146866040	experiments on
0.1142136052	a hybrid
0.1140415472	the help of
0.1139761047	portion of
0.1138390467	videos using
0.1135215594	samples from
0.1134672658	a crucial role in
0.1132653139	different classes
0.1124354381	a convolutional neural
0.1124271515	interested in
0.1122895040	video streaming with
0.1122668055	a comparative
0.1120872435	with respect to
0.1120415472	the effects of
0.1118795730	frame by
0.1117122093	to achieve
0.1116105914	three tasks
0.1113692476	this purpose
0.1112213711	the proposed
0.1107327269	evaluated on
0.1105731036	on top of
0.1099511253	mapping from
0.1097353978	correlated with
0.1096616041	the research community
0.1096177349	consisting of
0.1094261825	this issue
0.1093106943	by leveraging
0.1090860908	resulted in
0.1089071358	the long term
0.1087043014	suitable for
0.1083919688	prone to
0.1083472485	taken into
0.1078624687	such as
0.1075313710	very low
0.1073997093	to improve
0.1073673392	driven by
0.1072973044	captured by
0.1070953133	to detect
0.1070127715	other hand
0.1069504764	adapted to
0.1069122435	this work
0.1067698145	first stage
0.1067198589	to adapt
0.1067082139	the need of
0.1066884376	a deep convolutional neural
0.1065664280	the experimental results
0.1064893903	considered as
0.1063282697	consist of
0.1060752107	to address
0.1058902840	kinds of
0.1057578847	attacks such as
0.1054070927	but also
0.1052082139	in comparison to
0.1051033221	system using
0.1048970857	high quality of
0.1048219795	to avoid
0.1042812727	overall performance
0.1038061272	better performance
0.1037535753	a wide variety of
0.1036938129	a survey on
0.1036879394	a challenging problem
0.1036254360	to generate
0.1034119795	to protect
0.1033483523	vulnerable to
0.1033260515	recognition using
0.1032082139	the cost of
0.1031084379	directly from
0.1030997857	the compression ratio
0.1029768857	more robust
0.1029503298	a large number
0.1029478306	widely used in
0.1027997186	one or more
0.1027082139	the performances of
0.1025757967	according to
0.1025509943	a game
0.1024566432	set of
0.1024109764	composed of
0.1023341814	of multimedia data
0.1022161451	difficult to
0.1021448192	an overview of
0.1019230862	the image quality
0.1018320139	a real world
0.1018131776	combined with
0.1016647621	fail to
0.1015397779	amounts of
0.1014848876	able to
0.1012588253	an improvement
0.1012427639	a multi modal
0.1011865788	a study
0.1011426775	to achieve high
0.1009582139	a total of
0.1009075077	a graph based
0.1008210143	neural network for
0.1007280259	effect on
0.1006760663	second stage
0.1006673126	trained on
0.1006183076	the art video
0.1004556775	3d space
0.1003754661	several state of
0.1000133582	performed on
0.0999782398	the state of
0.0999425750	a wide range
0.0998359805	available bandwidth
0.0994732027	a two stage
0.0992919063	improved by
0.0992402341	so as to
0.0992330131	two modalities
0.0989240937	take advantage of
0.0987764555	a single
0.0987124225	tool for
0.0986045595	a wide range of
0.0981426230	make use of
0.0980808540	each block
0.0978529758	in order to
0.0976071321	allows users
0.0973576018	images based on
0.0971669659	evaluated using
0.0969543268	the real world
0.0968512512	visual quality of
0.0966888112	detected by
0.0963529758	in terms of
0.0961351357	under various
0.0961058029	over wireless
0.0959737252	lies in
0.0959201721	to extract
0.0958078528	suited for
0.0955280622	and visual modalities
0.0955269489	in order to reduce
0.0953366621	approaches based on
0.0952629652	tasks such as
0.0948933547	an analysis
0.0948921056	music from
0.0948465958	watermarking using
0.0947212447	image into
0.0945550449	to eliminate
0.0944414010	an open
0.0942804881	of user generated
0.0942172868	most existing
0.0938332246	than previous
0.0934575260	related to
0.0932953384	dependent on
0.0932324575	applications such as
0.0930821777	to overcome
0.0929992210	created by
0.0919201721	to reduce
0.0919061920	evaluated by
0.0912302600	comparing with
0.0907525131	contained in
0.0906540449	this study
0.0905656680	the art deep
0.0903446425	a novel
0.0900008175	to retrieve
0.0899473893	by means of
0.0899224513	different aspects
0.0898218928	variety of
0.0895908028	proposed method on
0.0894806309	tends to
0.0893686633	more efficient
0.0889181658	paper provides
0.0888137062	to facilitate
0.0886053624	computer interaction
0.0875081932	each pixel
0.0873300115	other state of
0.0872591767	the proposed network
0.0865391449	introduction to
0.0863789732	features from
0.0863028990	by adding
0.0862668312	to create
0.0862535054	to obtain
0.0861137285	proven to
0.0857981316	scheme using
0.0855400094	new paradigm
0.0854316663	to predict
0.0851621075	mapped to
0.0850210909	contribute to
0.0849520004	results on two
0.0845648067	each frame
0.0842676581	the last decade
0.0842548691	the source code
0.0841907150	an unsupervised
0.0841900094	various types
0.0840132367	versions of
0.0835843011	an optimal
0.0835591416	along with
0.0834803900	learning framework for
0.0832809891	dataset show
0.0831222989	perceived by
0.0830258055	approach using
0.0829041838	for image steganography
0.0824016441	the quality of
0.0823101647	a machine learning
0.0822344224	an average
0.0818840999	a blind
0.0818046239	learning to
0.0818029194	further research
0.0816653968	a general
0.0816639875	the first stage
0.0816495279	techniques such as
0.0815073817	by applying
0.0814999740	emergence of
0.0813798589	to optimize
0.0812916186	an extremely
0.0805383925	framework for
0.0805121436	by exploiting
0.0804571425	a series of
0.0804123384	the art image
0.0802858465	family of
0.0801907655	each other
0.0800585302	to understand
0.0799472997	characteristic of
0.0796264707	new data
0.0796119893	sum of
0.0795632512	the other hand
0.0795185868	to provide
0.0793125318	information from
0.0792352620	the original
0.0791394821	implementations of
0.0790820592	information into
0.0790465255	to hide
0.0789537465	more complex
0.0786472975	try to
0.0784155591	two main
0.0783915089	method using
0.0783671615	majority of
0.0783416186	an essential
0.0782348997	feasibility of
0.0778256739	an emerging
0.0776936447	extracted using
0.0775999115	a high level
0.0775160259	performance on
0.0774369348	the computational complexity
0.0771196597	nature of
0.0770620195	steganography using
0.0768270616	hours of
0.0767791974	proposed system
0.0767198589	to maximize
0.0766581608	a lot of
0.0763472144	characterization of
0.0762301357	these problems
0.0759777123	by analyzing
0.0757754207	a class
0.0756440795	more effective
0.0755500700	good results
0.0755219647	comparable to
0.0754209390	analysis of
0.0752683007	by employing
0.0750405748	probability of
0.0749860362	hard to
0.0749468192	an arbitrary
0.0748187379	by combining
0.0747758807	an additional
0.0746983007	by incorporating
0.0745644457	applied on
0.0743984063	applicable to
0.0743865255	to tackle
0.0743510534	equivalent to
0.0742530687	not possible
0.0741495299	an example
0.0741247046	to enhance
0.0740021095	this limitation
0.0739585304	by solving
0.0739054999	to embed
0.0738358708	introduced by
0.0736553890	more specifically
0.0735805683	included in
0.0732892213	problem as
0.0732606734	uploaded to
0.0731968431	degree of
0.0731556171	definition of
0.0731232243	learned from
0.0729190255	advantage of
0.0727922721	the video frames
0.0721225375	performed by
0.0720435616	generated from
0.0720193598	extracted by
0.0719289552	to infer
0.0718710058	this goal
0.0715337073	a neural network
0.0714915723	a new
0.0714611679	the performance of
0.0713829315	available datasets
0.0713115756	groups of
0.0712352620	the main
0.0711700320	against various
0.0710430900	regardless of
0.0709929411	adapt to
0.0706423517	to train
0.0700953512	results on
0.0697231789	these challenges
0.0688249844	the wild
0.0688025784	different types of
0.0684912101	by integrating
0.0684571912	to track
0.0684253461	a deep learning
0.0683740379	these methods
0.0683573841	account for
0.0682601056	platform for
0.0682104201	efficacy of
0.0680399483	to support
0.0680081917	in contrast to
0.0675972690	kind of
0.0673145309	advances in
0.0671787517	the existing methods
0.0670805865	attention for
0.0669398090	patterns from
0.0668889558	method for
0.0668760489	role in
0.0668723738	introduction of
0.0667238949	a deep convolutional
0.0666156372	respect to
0.0664687436	the same time
0.0664611679	a set of
0.0664611679	the problem of
0.0663505096	identification of
0.0659624943	the same
0.0658049124	an application
0.0655351596	by comparing
0.0654954753	problem by
0.0653943536	different types
0.0653666581	piece of
0.0650809826	video at
0.0648280839	protection of
0.0648081883	to decide
0.0648006502	over time
0.0647071586	obtained using
0.0646585466	aspects of
0.0641830933	the simulation results
0.0641813361	to bridge
0.0641534859	as inputs
0.0641069262	to deal with
0.0640653345	a variety of
0.0640020481	consistent with
0.0638447885	this task
0.0634708880	research on
0.0634611679	the effectiveness of
0.0634584055	types of
0.0633709533	associated with
0.0633566142	region of
0.0632893185	existence of
0.0630150821	by minimizing
0.0628705719	the visual content
0.0628587082	consists in
0.0627705783	learned by
0.0624591542	aspect of
0.0621544766	not available
0.0621269078	also introduce
0.0621190512	very well
0.0619347333	a tool
0.0617528176	paradigm of
0.0615769578	essential for
0.0615593384	amount of
0.0615531992	amount of data
0.0615332180	subset of
0.0613637572	a brief
0.0612665246	across different
0.0608888197	two problems
0.0607528176	length of
0.0604937917	type of
0.0604032415	performance of
0.0603897105	in loop
0.0603402517	terms of
0.0602891461	to enable
0.0601061312	knowledge from
0.0599047072	gain of
0.0598131982	approach to
0.0597890325	function for
0.0597881680	the art methods on
0.0596202852	to identify
0.0595774835	an appropriate
0.0595728793	model for
0.0595127155	a comparison
0.0591815367	representation of
0.0591680017	the model to
0.0590342320	list of
0.0588633772	in order to improve
0.0587232848	to assess
0.0585592748	most significant
0.0583756506	each layer
0.0579617961	works on
0.0579005210	together with
0.0578996503	to build
0.0577670158	two key
0.0577035824	further improve
0.0574340871	interactions with
0.0573956604	range of
0.0573041239	different layers
0.0570994722	to perform
0.0570342320	variant of
0.0568830332	exploited to
0.0567888077	to preserve
0.0564543122	a reliable
0.0564493550	the past few
0.0563696824	the aim of
0.0560832553	combinations of
0.0560105143	on average
0.0559577009	availability of
0.0559083051	a new method for
0.0557336158	of things
0.0557055458	by providing
0.0556776966	to deliver
0.0553194492	to determine
0.0553003716	need to
0.0552891793	to prevent
0.0551461682	various types of
0.0548916553	to recommend
0.0545860299	to recover
0.0545443633	to reconstruct
0.0543973818	available at
0.0542364738	reduction in
0.0542184522	quality of
0.0539122855	image without
0.0538716083	assessment of
0.0538273112	to end
0.0537347872	scheme with
0.0535061268	used to generate
0.0534769434	a deep
0.0534489885	overview of
0.0531647329	different levels
0.0531319429	as input
0.0530168725	effectiveness of
0.0529654122	a large
0.0527179049	the watermark
0.0525924442	approach for
0.0523908697	to locate
0.0523266707	the quality of experience
0.0523218296	different kinds of
0.0520773228	designed for
0.0519716357	the current state of
0.0516821824	the superiority of
0.0515803982	this method
0.0512412428	to minimize
0.0509609513	seen as
0.0509125125	consumption of
0.0508053288	similar to
0.0507980755	added to
0.0507794861	signal to
0.0507784478	the rapid development of
0.0507336286	a subset
0.0505593061	extended to
0.0505259257	novel algorithm
0.0504794141	instead of
0.0504409908	the forged
0.0503656486	to evaluate
0.0503003535	version of
0.0501656933	dedicated to
0.0501623271	form of
0.0500927409	the host
0.0498575364	to realize
0.0497844240	well as
0.0497200364	to assist
0.0496393710	the secret
0.0495042661	peer to
0.0494843670	to compensate
0.0494537071	the ultimate
0.0492462790	forms of
0.0492370962	to estimate
0.0491529110	performance than
0.0490195673	trained with
0.0488540113	in conjunction with
0.0488322779	features such as
0.0488172111	in order to achieve
0.0488167458	accuracy on
0.0486732913	values of
0.0485467622	to remove
0.0483143440	location of
0.0481332322	the switch
0.0481014522	to break
0.0480763285	or even
0.0480526144	by taking
0.0480514464	a large number of
0.0479230042	this aim
0.0478934861	the number of
0.0478398386	usefulness of
0.0477258188	not well
0.0477147307	to mitigate
0.0476184833	easier to
0.0474282727	to produce
0.0474040731	summary of
0.0472946839	this approach
0.0472120123	to capture
0.0471986125	basis for
0.0471745594	learn from
0.0470516262	the internet
0.0470187569	dataset with
0.0470016903	combination of
0.0469972168	a well known
0.0469584804	in turn
0.0468873801	designed to
0.0468346410	to maintain
0.0467863490	the use of
0.0466821824	the basis of
0.0465900255	a sequence of
0.0465506725	factor of
0.0464011805	between music
0.0463665836	a group
0.0463114059	methodology for
0.0463067299	algorithm for
0.0461097387	the fact
0.0460798135	to fuse
0.0459730915	the notion of
0.0458926590	evaluation of
0.0454778638	comparing to
0.0454133283	integrity of
0.0453193094	very high
0.0452701152	a baseline
0.0452395353	also provides
0.0452321824	the goal of
0.0452288386	popularity of
0.0451289776	visualization of
0.0449107331	architecture for
0.0448720044	the carrier
0.0448685141	an attention
0.0446120907	more challenging
0.0445989072	stored in
0.0445125655	same time
0.0444986318	aiming to
0.0444634674	methods in terms of
0.0444100618	a person
0.0443864239	an experiment
0.0443264178	as well
0.0442821824	the first time
0.0442805017	the size of
0.0442441170	a simple
0.0442306369	known as
0.0442085838	propose to
0.0441517816	to get
0.0441393634	even more
0.0441200364	to satisfy
0.0440780144	impacts of
0.0440593061	subject to
0.0439497644	used to
0.0438540113	to cope with
0.0437961542	by example
0.0436611796	two types
0.0435687144	the human visual
0.0435393443	a universal
0.0433323104	survey on
0.0432016025	these two
0.0431671178	information at
0.0429697317	to classify
0.0428954082	more attention
0.0428776317	embedded in
0.0428558893	of interest
0.0428387432	attempts to
0.0428069072	used for
0.0427710506	deployment of
0.0425020129	a framework
0.0424674154	a sequence
0.0423520390	each user
0.0423093550	improvement in
0.0422024122	utilization of
0.0421333642	by considering
0.0420529682	overall quality
0.0420303312	this research
0.0420213186	tries to
0.0419636191	an extension
0.0419179859	the end to end
0.0418809136	distribution of
0.0418022464	allocation for
0.0417674505	possibility to
0.0417181001	studies on
0.0416960471	properties of
0.0416570870	shown to
0.0414908194	important to
0.0414821248	for indexing
0.0414214813	the cover
0.0413748730	volume of
0.0411183044	implemented in
0.0410617362	notion of
0.0409202417	this area
0.0407508268	technique for
0.0407305463	understanding of
0.0406437080	study on
0.0406176198	three different
0.0405218296	different levels of
0.0404755571	for selecting
0.0404345562	a result
0.0403220761	characteristics of
0.0400500127	other existing
0.0400385384	steganography with
0.0398582677	impact of
0.0398287606	implementation of
0.0397558253	interpretation of
0.0396991269	superiority of
0.0396899312	to manage
0.0395650503	to recognize
0.0394873619	a lot
0.0394318935	two novel
0.0394285556	for improving
0.0393807294	increase in
0.0393673889	reliability of
0.0392250821	by reducing
0.0392215218	validation of
0.0391430202	the input
0.0390842363	such systems
0.0389696641	a new technique
0.0389599502	reduction of
0.0388275442	levels of
0.0388190416	alternative to
0.0387969624	quality than
0.0387579306	success of
0.0385332492	to reach
0.0384518163	superior to
0.0384400754	the art in
0.0383841883	the corrupted
0.0383455969	experiment with
0.0383400255	the impact of
0.0383149106	solution for
0.0382721745	both spatial and
0.0381204329	attention from
0.0381147850	a cloud
0.0380554421	this way
0.0380061204	employed in
0.0379517816	for example
0.0378676191	to represent
0.0378236978	data into
0.0378048037	choice of
0.0377622635	comparison with
0.0377399670	development of
0.0374516377	resulting in
0.0373117989	an accurate
0.0373047380	investigation of
0.0371938645	a significant
0.0371899312	to alleviate
0.0371607375	consideration of
0.0370777098	problem using
0.0370769891	a new dataset
0.0369342506	a specific
0.0369314360	two types of
0.0368740078	important for
0.0367303311	series of
0.0367245299	involved in
0.0366842612	result in
0.0363965398	an interactive
0.0363573482	aim to
0.0362331021	structure of
0.0362164120	a semi
0.0361463531	likely to
0.0360223451	an extension of
0.0359949315	a set
0.0359625239	the well known
0.0359609513	done by
0.0358476880	model with
0.0357974480	watermarking system
0.0356713225	the default
0.0356420628	trained by
0.0355640003	lot of
0.0355345309	a comprehensive
0.0354843172	360 video
0.0354292035	presence of
0.0353769942	transmitted to
0.0352058257	robust to
0.0351964735	this report
0.0351675152	ability to
0.0351540276	an approach to
0.0351252892	the sum of
0.0350349367	applied in
0.0350299791	with state of
0.0350295374	a block
0.0349833920	generalization of
0.0349242711	in many applications
0.0348010966	an implementation
0.0347551191	to construct
0.0346852763	performance over
0.0346154769	mixture of
0.0345876990	an audio
0.0345476013	the first work
0.0345235588	new method for
0.0344999502	perception of
0.0344366106	to discover
0.0344223013	required for
0.0343735283	strategies for
0.0343609976	capability of
0.0343400255	the development of
0.0342092001	demand for
0.0341258277	a convolutional
0.0341216934	this idea
0.0340689776	exploration of
0.0340141339	3d model
0.0339554062	conducted to
0.0339080022	variation of
0.0337963824	sensitive to
0.0337185787	many applications
0.0336292164	scheme for
0.0335105111	learns to
0.0335095562	a common
0.0334163460	needed to
0.0333973607	an end
0.0333400255	the robustness of
0.0333165305	the last few
0.0331026030	a real time
0.0330920094	a user's
0.0330461600	quantization for
0.0329917501	to validate
0.0329863268	developed to
0.0329636701	an online
0.0329425361	evaluation on
0.0328656734	success in
0.0328309066	efficiency of
0.0327917501	to leverage
0.0327398552	a fundamental
0.0326539606	crucial to
0.0325679591	to calculate
0.0324865188	network for
0.0324737395	importance of
0.0323551313	the literature
0.0323367413	presentation of
0.0323364749	an input
0.0323345309	to select
0.0322933888	to store
0.0322831267	this context
0.0322359972	the state
0.0321896608	concept of
0.0321773160	the receiver
0.0321539004	two different
0.0319001829	introduced in
0.0318525392	ability of
0.0317862565	a practical
0.0317793838	to measure
0.0317749502	collection of
0.0317691289	the final
0.0317061985	by jointly
0.0316973017	with respect
0.0315689776	pair of
0.0315121888	class of
0.0315090739	in computer vision
0.0315016763	advantages of
0.0314772357	a novel approach
0.0314345562	to explore
0.0314309346	the efficacy of
0.0313608588	a number of
0.0313547194	to find
0.0313404062	approximation of
0.0313400255	the field of
0.0313291222	addressed in
0.0313137569	lack of
0.0312996135	but not
0.0312779127	developed for
0.0312732316	to implement
0.0312504654	in order
0.0312356443	contribution of
0.0312356443	composition of
0.0312134540	possibility of
0.0310239018	extension of
0.0310173209	want to
0.0309832479	used as
0.0309479408	improvement of
0.0308735283	potential for
0.0308557004	extraction from
0.0308091427	robustness of
0.0307459123	presented in
0.0307126395	the choice of
0.0306233438	variations in
0.0306108588	the proposed system
0.0305097346	interaction with
0.0304621426	a unified
0.0304129622	to exploit
0.0303657681	description of
0.0303647400	a strong
0.0303608588	the accuracy of
0.0303259786	the length of
0.0303150503	to handle
0.0302919346	prior to
0.0302396740	the problem
0.0301311644	role of
0.0301308679	case of
0.0300677191	problem of
0.0299851013	this type of
0.0299319541	part of
0.0299095164	introduced to
0.0298740439	still images
0.0298076353	architecture with
0.0298006468	size of
0.0297716485	goal of
0.0297356443	degradation of
0.0296626274	to deal
0.0294833920	purpose of
0.0293776297	studied in
0.0293711375	idea of
0.0293400255	the lack of
0.0293400255	the advantages of
0.0293217605	the entire
0.0292953084	novel framework
0.0291761659	the performance
0.0291168328	field of
0.0290863578	representation for
0.0290755312	to develop
0.0290570015	expected to
0.0290379742	a novel framework
0.0290308973	to encode
0.0290176824	addition to
0.0289708428	2d image
0.0289441922	the efficiency of
0.0288546919	construction of
0.0287683551	adopted to
0.0287386653	growth of
0.0287323975	investigated in
0.0287123788	to combine
0.0286970030	the usefulness of
0.0285035059	an approach
0.0283400255	the concept of
0.0283400255	the case of
0.0282737207	a novel method
0.0282542350	survey of
0.0281469800	paradigm for
0.0280740556	evolution of
0.0280689776	integration of
0.0280173209	to keep
0.0280104457	mechanism for
0.0279787702	to compare
0.0279730795	a state of
0.0279082328	means to
0.0278018859	of interest in
0.0276798861	to transmit
0.0276311353	evaluated in
0.0275214572	the amount of
0.0274754162	benefit of
0.0274621480	means of
0.0274512146	classifier for
0.0274273967	issue of
0.0273827887	by using
0.0273437790	critical to
0.0273400255	in addition to
0.0272600152	the emergence of
0.0272345562	to increase
0.0272194054	in practice
0.0271632348	accuracy of
0.0271536826	to decrease
0.0270423702	up to
0.0270246547	to peer
0.0270080060	relevant to
0.0269240733	hidden in
0.0268967703	a hierarchical
0.0268714417	considered in
0.0268447944	a complete
0.0268384979	to yield
0.0268117639	an edge
0.0266429267	contrast to
0.0266201489	the gap between
0.0266038437	to fill
0.0265880869	influence of
0.0264868308	for solving
0.0264066922	a collection of
0.0263566332	potential of
0.0262625626	to make
0.0262273906	imperceptibility of
0.0262246125	helps to
0.0261655445	a small
0.0260618349	3d video
0.0260613155	an experimental
0.0259334817	achieved with
0.0259288846	a clear
0.0258482034	a new method
0.0258406222	to examine
0.0258243857	optimized for
0.0258134223	a novel algorithm
0.0258072804	utilized to
0.0257812864	to compute
0.0257658942	the relationship between
0.0256988256	area of
0.0256618543	the whole
0.0256315934	progress in
0.0255398753	essential to
0.0254297646	strategy for
0.0254084769	the visual quality of
0.0253493426	order to
0.0253400255	the need for
0.0253400255	the presence of
0.0252976013	by up to
0.0252493427	a proper
0.0251871620	novel approach
0.0251308583	sense of
0.0251054854	an optimization
0.0250176824	aim of
0.0249233588	the importance of
0.0249137732	to integrate
0.0248866992	different from
0.0248731069	the probability of
0.0247905503	an adversarial
0.0247677774	for estimating
0.0247607875	attributes of
0.0247400255	the role of
0.0247400255	in case of
0.0247319541	a few
0.0246833309	a low
0.0246711303	discussed in
0.0246586566	a variety
0.0246515617	a unique
0.0245466263	to answer
0.0245020265	a series
0.0244238541	an algorithm
0.0243191404	a novel deep
0.0242941613	in comparison with
0.0242471280	for image and video
0.0242347127	the upper
0.0241830650	the structure of
0.0241226149	the correlation between
0.0240116183	modification of
0.0240105517	the notion
0.0239416169	property of
0.0239195931	effect of
0.0238764678	the learned
0.0238664695	the sender
0.0238098215	collected in
0.0237660208	to analyze
0.0237594506	critical for
0.0236880223	an algorithm for
0.0236515617	a major
0.0235590317	for extracting
0.0234976013	a subset of
0.0234721521	an object
0.0234171961	for detecting
0.0232442541	the properties of
0.0231850502	to boost
0.0231850502	to share
0.0231616712	performed in
0.0231220044	the desired
0.0230349442	a generative
0.0230105022	usage of
0.0229876533	corpus of
0.0229872648	a large amount of
0.0229054190	review of
0.0229045502	the form of
0.0228963823	new approach
0.0228737026	required to
0.0228038776	other methods
0.0226675539	new method
0.0226542601	used in
0.0226084728	the creation of
0.0225461851	each time
0.0224544478	creation of
0.0224108142	diversity of
0.0223233588	the purpose of
0.0223209268	to use
0.0223185862	the reliability of
0.0223118427	a prototype
0.0222482701	a novel approach to
0.0222066922	the idea of
0.0221970980	to guide
0.0221970030	as part of
0.0221458384	an analysis of
0.0220293485	a convex
0.0220169026	the superiority
0.0219873252	a benchmark
0.0219775255	a novel approach for
0.0219394667	then used to
0.0219119298	novel approach to
0.0218963823	new dataset
0.0217624841	further propose
0.0217621188	a graph
0.0217467771	effective in
0.0216963557	the benefit of
0.0216870937	a preliminary
0.0215899653	to incorporate
0.0215538224	for instance
0.0215185862	the sense of
0.0214811954	a wide
0.0214422624	a whole
0.0214066922	a combination of
0.0213508442	a class of
0.0213233588	the ability to
0.0211970980	to characterize
0.0211192912	employed to
0.0211136529	this type
0.0210047624	the latter
0.0208893447	the predicted
0.0207823608	independent of
0.0207375051	a survey of
0.0207293824	a detailed
0.0206954811	the rapid
0.0206471684	the success of
0.0205741720	the presence
0.0205400255	the evolution of
0.0205400255	the possibility of
0.0205298472	novel method
0.0205107818	sent to
0.0205037160	a novel method for
0.0204882156	to form
0.0204762238	metric for
0.0204375051	a lack of
0.0204048043	the feasibility
0.0204006676	the evaluation of
0.0203766320	to quantify
0.0203419009	the effectiveness
0.0203244875	the experimental results show
0.0202807875	means for
0.0202721105	this problem by
0.0201891829	the absence of
0.0201624053	to derive
0.0200881567	the effect of
0.0200177490	a given
0.0199680476	to meet
0.0199659838	to guarantee
0.0199626395	the availability of
0.0199434533	or not
0.0199311353	topic in
0.0198809346	the feasibility of
0.0198720904	a carrier
0.0197886763	the former
0.0197290708	the number
0.0197050109	the diversity of
0.0195124004	to verify
0.0194626395	of up to
0.0193080652	the usage of
0.0192920158	this paper provides
0.0192801590	to define
0.0192778976	a coarse
0.0192692276	a review
0.0191772010	available on
0.0191316161	a special
0.0191080652	the area of
0.0191056421	a crucial
0.0190560256	basis of
0.0190547905	a method for
0.0189805017	the influence of
0.0189490275	adopted in
0.0189390742	the output
0.0189004177	to balance
0.0188984576	the analysis of
0.0188232864	a framework for
0.0186758629	a robust
0.0186626395	as compared to
0.0186340757	the past
0.0186273812	to compress
0.0186259242	both spatial
0.0186173304	a huge
0.0185849102	to establish
0.0185361230	a multimodal
0.0184626395	the issue of
0.0184297452	the simulation results show
0.0183000129	the emergence
0.0180952254	a great
0.0180030504	different media
0.0179214572	the advantage of
0.0178111796	the actual
0.0177652956	new framework
0.0177327367	the first
0.0176825808	the existence of
0.0176676217	a flexible
0.0175293824	a probabilistic
0.0174790329	the potential of
0.0174094914	in terms
0.0173081410	to noise
0.0172853401	a multi
0.0172273404	to separate
0.0171568693	to approximate
0.0171273812	to illustrate
0.0171038322	the audio and visual
0.0170030211	the watermarked
0.0169651165	enables to
0.0169373444	especially on
0.0169358489	a generic
0.0169245253	an encoder
0.0168328291	the first to
0.0167916718	the integration of
0.0167216085	to reveal
0.0166361704	or more
0.0164314045	the possibility
0.0161478621	in contrast
0.0160909838	to match
0.0160697462	a distributed
0.0159928088	to allow
0.0159286296	the usefulness
0.0159064001	a fast
0.0157220286	given by
0.0155704218	even with
0.0155214043	the growth of
0.0153406934	to investigate
0.0152120475	useful for
0.0152112484	to utilize
0.0151594034	use of
0.0150909838	to collect
0.0149838228	the combination of
0.0148914700	a shared
0.0148874763	to consider
0.0148794226	a powerful
0.0147080422	a rich
0.0144977863	the goal
0.0142450009	to apply
0.0142421033	the characteristics of
0.0142068980	a combination
0.0138821499	a joint
0.0137690747	the human visual system
0.0137649802	the overall
0.0137004995	described in
0.0136074392	a number
0.0135925387	to focus on
0.0134608807	to give
0.0134070404	enough to
0.0133381684	a challenging
0.0133373708	to do
0.0133348245	the popularity of
0.0133100502	to take
0.0132809515	the distribution of
0.0130987711	a self
0.0130496291	a full
0.0129227200	a fixed
0.0128446814	a certain
0.0124144033	the definition of
0.0123986038	the similarity between
0.0123807841	the majority of
0.0120273189	the need to
0.0115518403	the above
0.0113120972	the implementation of
0.0112413896	allows for
0.0112136860	possible to
0.0109925686	the right
0.0109314740	way to
0.0108498698	the last
0.0108446814	necessary to
0.0105067090	a good
0.0104898750	the ability of
0.0104359956	especially for
0.0103261629	need for
0.0102136860	corresponding to
0.0099925686	done in
0.0099314740	allows to
0.0098077110	the type of
0.0097599081	to describe
0.0094069443	thanks to
0.0089715069	to help
0.0087943166	allow for
0.0087860304	interest in
0.0067882551	needs to
