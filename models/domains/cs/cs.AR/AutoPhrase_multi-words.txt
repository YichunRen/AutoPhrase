0.9711941452	artificial intelligence
0.9704837290	von neumann
0.9702583354	moore's law
0.9648650567	message passing
0.9592568348	monte carlo
0.9573144524	machine learning
0.9569109299	deep learning
0.9565173702	fault tolerant
0.9553035473	intellectual property
0.9520122499	floating point
0.9518367897	fault tolerance
0.9514428156	field programmable gate array
0.9505495063	register transfer level
0.9484348890	signal processing
0.9484075357	instruction set
0.9483154194	ad hoc
0.9482986458	big data
0.9459559944	content addressable memory
0.9455419456	wear leveling
0.9437095208	sequence alignment
0.9432077695	digital signal processing
0.9429260821	fast fourier transform
0.9415594512	sparse matrix
0.9403840616	hardware description language
0.9398299893	neural networks
0.9395189563	random access memory
0.9382447105	reinforcement learning
0.9381052630	speculative execution
0.9379154428	dynamic range
0.9352147038	matrix multiplication
0.9342448321	linear algebra
0.9330466534	field programmable gate arrays
0.9301952778	virtual memory
0.9299075259	memory hierarchy
0.9272998492	register file
0.9270306726	speech recognition
0.9267970080	linear programming
0.9260665878	flash memory
0.9253888243	feature extraction
0.9248772336	neural network
0.9243105708	short term memory
0.9203417264	integrated circuits
0.9199509867	flip flops
0.9192917216	cache coherence
0.9167782421	open source
0.9165251117	formal verification
0.9147122671	successive cancellation
0.9137473826	power management
0.9116973300	quantum computers
0.9106060145	embedded systems
0.9083552290	input output
0.9075393762	spin transfer torque
0.9065493910	phase change
0.9063798629	systolic array
0.9056226918	quantum computing
0.9051836092	page table
0.9047656772	design space exploration
0.9047444362	fourier transform
0.9046550826	space exploration
0.9029865047	partial sums
0.9008431519	multi core
0.9006415261	data acquisition
0.8989803640	load balancing
0.8966387912	sequential circuits
0.8965018607	data center
0.8960146915	random number generator
0.8955237040	domain specific
0.8939294027	resource management
0.8918468456	row buffer
0.8917222866	reconfigurable computing
0.8905443997	threshold voltage
0.8896209919	wireless communication
0.8886363418	buffer insertion
0.8885324466	coherence protocol
0.8882175074	model checking
0.8879470810	data centers
0.8875646618	image processing
0.8875192321	deep neural networks
0.8856585911	shared memory
0.8855922156	data corruption
0.8845933722	parity check
0.8843297563	encryption decryption
0.8842226347	field programmable gate
0.8836040560	general purpose
0.8833122376	memristor crossbar
0.8833009495	processing units
0.8821143260	modular redundancy
0.8814831329	convolutional neural networks
0.8813111551	level parallelism
0.8802343170	hardware acceleration
0.8797858984	soft error
0.8797580102	polar decoder
0.8789867205	graphics processing units
0.8779656007	deep neural network
0.8766735340	hardware trojans
0.8750498323	power grid
0.8742898361	pattern recognition
0.8733180256	cache hierarchy
0.8728450142	source code
0.8725122875	coarse grained
0.8714271601	clock cycle
0.8684755450	address space
0.8678118393	integrated circuit
0.8666065860	programmable gate arrays
0.8664968677	compression ratio
0.8656803970	meander segments
0.8636154757	partial reconfiguration
0.8614571802	asynchronous early output
0.8613391242	fine grain
0.8611011670	logic synthesis
0.8606216881	natural language
0.8601998487	reversible logic
0.8599305708	parity preserving
0.8593466987	dram chips
0.8588411632	xilinx zynq
0.8585554915	processing element
0.8581864988	convolutional neural network
0.8580838378	cycle accurate
0.8577456964	ripple carry adder
0.8573982058	error correction
0.8566344649	timing analysis
0.8563131794	control flow
0.8541775467	upper bound
0.8536252206	process variations
0.8535781281	soft errors
0.8528831021	memory controller
0.8512054255	analytical model
0.8511963905	bit error rate
0.8509709831	thread level parallelism
0.8508591583	high level synthesis
0.8502139830	majority voter
0.8493074858	turbo decoder
0.8491800624	xilinx virtex
0.8486594436	convolutional neural
0.8481463205	case study
0.8481353475	chip multiprocessors
0.8479711922	polar codes
0.8473265700	nand flash memory
0.8469547100	coarse grained reconfigurable
0.8462257022	carry skip
0.8444880175	scientific computing
0.8441147610	fd soi
0.8431639081	large scale
0.8424431941	carry lookahead
0.8419736380	supply voltage
0.8415921074	basic block
0.8410909855	high speed
0.8404987284	flip flop
0.8398477388	cloud computing
0.8397956385	fault injection
0.8391732049	frequency scaling
0.8390129494	massively parallel
0.8380087102	computational complexity
0.8373981789	low cost
0.8363040657	high performance computing
0.8343445630	graph processing
0.8337368301	instruction set architecture
0.8335393866	threshold logic
0.8322269128	reversible gates
0.8320951072	application specific
0.8316771699	leakage power
0.8302575149	field effect
0.8289263173	data movement
0.8282290422	early output
0.8278878525	solid state
0.8273683494	garbage outputs
0.8273309003	benchmark suite
0.8248095327	miss rates
0.8240330568	processing elements
0.8217810750	worst case
0.8205666495	bcd adder
0.8198137089	mixed signal
0.8195317699	fine grained
0.8195231407	carry lookahead adder
0.8172805718	soft processor
0.8164971356	address translation
0.8161697661	replacement policies
0.8154456312	hybrid memory
0.8153599378	clock gating
0.8151050252	stochastic computing
0.8147221644	large list size
0.8136449913	programmable gate array
0.8132478440	dual rail
0.8128841463	qc ldpc
0.8123939219	replacement policy
0.8122700835	computationally intensive
0.8113217881	high throughput
0.8105698213	crossbar array
0.8096462924	main memory
0.8096408834	energy saving
0.8095398162	access patterns
0.8094315450	low latency
0.8088462770	mixed precision
0.8084246365	processing unit
0.8081895458	nand flash
0.8076437293	phase change memory
0.8072741651	single event
0.8071539800	deep convolutional neural networks
0.8069425698	deep neural
0.8067287343	parity preserving reversible
0.8059837831	baugh wooley
0.8044042943	research directions
0.8043624989	data analytics
0.8031591647	triple modular
0.8026392400	process variation
0.8024717015	vlsi implementation
0.8023643157	polar code
0.8008663776	data movements
0.8006249369	transaction level
0.8003744916	delay insensitive
0.7996160957	data flow
0.7994652040	computing platform
0.7988960749	die stacked dram
0.7977228749	load store
0.7958272297	transistor count
0.7951181932	low complexity
0.7944238167	information processing
0.7941774538	persistent memory
0.7930552112	low power
0.7925332709	trade offs
0.7923938430	spiking neural
0.7923823561	logic gate
0.7906340429	non volatile memory
0.7903786194	application specific integrated
0.7901868215	stt ram
0.7891531391	clock tree
0.7887738094	standard cell
0.7886963818	performance improvement
0.7886863489	experimental characterization
0.7882195923	real world
0.7878056560	neuromorphic computing
0.7870097361	fault tolerant reversible
0.7863845983	cell library
0.7863590879	memory footprint
0.7859282918	parallel processing
0.7853071934	fully connected
0.7848041868	relative timed
0.7846277262	critical path delay
0.7839037914	cnn accelerator
0.7835602723	random access
0.7830720330	critical path
0.7823446073	stt mram
0.7818894713	fixed point
0.7807120636	operating systems
0.7801834593	fast fourier
0.7794219535	memory wall
0.7779618652	image classification
0.7772230692	error correcting
0.7767586249	hit rate
0.7754356635	multiply accumulate
0.7736806556	ultra low
0.7733711738	end nodes
0.7731415581	cmos technology
0.7717596353	parallel computing
0.7716862327	access latency
0.7715891400	ripple carry
0.7696008103	resource usage
0.7692265299	voltage scaling
0.7688627120	power dissipation
0.7659321418	data reuse
0.7659130823	ultra low power
0.7656264537	energy efficient
0.7640742772	dnn accelerator
0.7633658373	significant improvements
0.7627628914	neural network inference
0.7625829877	programmable logic
0.7620753310	65nm cmos
0.7617367135	object detection
0.7609112942	high bandwidth
0.7583488429	intensive workloads
0.7576666470	previous works
0.7572734558	safety critical
0.7558631777	energy efficiency
0.7554431775	delay product
0.7545511803	gate array
0.7545136316	carry look ahead
0.7543477686	cache misses
0.7537821811	case studies
0.7530448083	cnn inference
0.7526914730	high level
0.7522750444	design flow
0.7516879562	nm cmos technology
0.7506069659	operating frequency
0.7503976789	cross layer
0.7496897592	experimental results
0.7496608644	low overhead
0.7475330769	massive parallelism
0.7472411074	approximate computing
0.7448464070	hardware description
0.7447180254	high quality
0.7446188025	bit width
0.7441730383	digital circuits
0.7424243415	quantum cost
0.7417048886	performance degradation
0.7415949419	energy savings
0.7415589359	gate count
0.7402957076	weak indication
0.7391814159	post silicon
0.7389712455	memory accesses
0.7385997999	pre alignment
0.7370070486	real life
0.7370007094	content addressable
0.7350577099	hardware resources
0.7348720728	recent years
0.7339255324	silicon area
0.7335208772	heterogeneous systems
0.7334337938	evaluation shows
0.7328057695	clock frequency
0.7325702744	bit serial
0.7318831473	custom instruction
0.7318399321	dnn accelerators
0.7311917866	paper describes
0.7310433051	access pattern
0.7309540276	nm cmos
0.7305428297	high density
0.7294593453	flow control
0.7274274062	convolutional layers
0.7269894266	matrix vector multiplication
0.7249311085	28nm cmos
0.7240314588	shared cache
0.7238423193	l2 cache
0.7237001256	building block
0.7223925421	x86 64
0.7216123010	memory management
0.7216021358	ip cores
0.7187217630	multi threaded
0.7173247914	hardware trojan
0.7169970723	design methodology
0.7159485281	digital signal
0.7148059311	resource utilization
0.7135946282	building blocks
0.7124570924	memristor based
0.7123130713	edge computing
0.7110982822	design space
0.7104404041	thread blocks
0.7095808658	mobile devices
0.7080236261	high performance
0.7068493243	compute intensive
0.7059908482	experimental results demonstrate
0.7057978913	pipeline stages
0.7052071417	low voltage
0.7037372384	processor cores
0.7032794866	redundant logic
0.7031869383	area overhead
0.7029202156	read write
0.7021016218	die stacked
0.7014778599	error rate
0.7012155943	recently proposed
0.7011648092	last level cache
0.7010829851	standard cells
0.7005663852	taking into account
0.6987434257	field programmable
0.6987161685	quantum circuits
0.6984285445	image recognition
0.6961099716	al dram
0.6959354222	high precision
0.6936647694	clock cycles
0.6931172207	level cell
0.6925902308	miss rate
0.6914417926	bit flips
0.6912619983	encryption standard
0.6912003575	proof of concept
0.6906691907	process technology
0.6905569113	strong indication
0.6903380581	internet of things
0.6896028927	energy consumption
0.6894507200	reconfigurable hardware
0.6884466542	bitwise operations
0.6883961727	accuracy loss
0.6883346450	application domains
0.6882168212	data structures
0.6878121780	feature size
0.6873043658	classification accuracy
0.6863525033	deep convolutional
0.6861837574	power consumption
0.6861089729	energy delay product
0.6853287800	multi port
0.6851496265	optical computing
0.6850310487	network architecture
0.6847018965	fault coverage
0.6835881434	paper proposes
0.6822636759	results demonstrate
0.6820502979	data processing
0.6818295742	resource constrained
0.6815648510	cmos process
0.6812214007	power budget
0.6809831400	micro architectural
0.6806551664	cache lines
0.6804674578	register transfer
0.6791584147	sram cell
0.6772954016	address mapping
0.6772490114	high computational
0.6772349702	last level caches
0.6763601775	precision floating point
0.6748666809	multi operand
0.6747295058	write endurance
0.6718744468	sram based
0.6701835826	high resolution
0.6679160204	risc v isa
0.6665506429	data path
0.6660055320	paper presents
0.6654576971	quality of service
0.6651783591	code length
0.6625558542	recently accessed
0.6623852238	high end
0.6616702125	evaluation results
0.6612897653	embedded applications
0.6607058473	proposed methodology
0.6605980214	synthesis results
0.6595050626	compute units
0.6576315463	random number
0.6575570600	design metrics
0.6558989355	modern dram
0.6558519585	simulation results
0.6558355435	memory subsystem
0.6543069360	computing paradigm
0.6536981267	computing systems
0.6532362686	cancellation decoding
0.6526959980	l1 cache
0.6509746873	post layout
0.6503747934	recurrent neural
0.6503621555	overlay architectures
0.6496982598	memory access patterns
0.6496228948	recent research
0.6492373366	matrix vector
0.6484668901	technology scaling
0.6469964391	neuromorphic hardware
0.6468190709	orders of magnitude
0.6462082228	place and route
0.6458509102	hardware accelerators
0.6455609655	inference accelerator
0.6451896410	cost effective
0.6444752764	neural network architectures
0.6440944367	programming model
0.6424586848	heterogeneous computing
0.6418584907	decoding algorithm
0.6416884131	power saving
0.6405159688	proposed solution
0.6394388008	highly efficient
0.6382802143	fpga based
0.6378196732	multicore processors
0.6341235168	memory interface
0.6340353455	description language
0.6338858942	arithmetic operations
0.6316701449	times faster
0.6313299178	transfer torque
0.6312712427	logic gates
0.6286320454	pre processing
0.6285040199	performance impact
0.6283582326	multi gpu
0.6264757046	memory requests
0.6262884677	neural network accelerator
0.6260445692	pareto optimal
0.6259629259	technology node
0.6250765573	c + +
0.6249445364	bit errors
0.6245770789	inference accelerators
0.6242750477	processing tasks
0.6241031141	timing parameters
0.6237086305	hardware software co
0.6232170142	small number
0.6231170142	paper introduces
0.6230411010	virtex 6
0.6225242769	routing algorithm
0.6214749390	reversible full adder
0.6197528005	bit error
0.6197105541	vlsi design
0.6165393612	static power
0.6158101502	modern processors
0.6146862641	significantly improve
0.6137796899	adder circuits
0.6129821667	memory access
0.6123883312	lookahead adder
0.6118716854	data transfer
0.6113169972	significantly reduces
0.6103147323	optimization techniques
0.6101048767	network on chip
0.6100288446	decoder architecture
0.6095519262	cycle level
0.6091535664	number generator
0.6079828228	single precision
0.6078183268	area cost
0.6077460161	timing model
0.6077006807	highly parallel
0.6072414370	logic circuits
0.6069128522	embedded processors
0.6061069696	current state
0.6021569867	risc v core
0.6021446487	dram bandwidth
0.6017473730	multi layer
0.6013570553	hardware software
0.6005297697	area efficiency
0.5994540892	analysis shows
0.5994392601	memory bandwidth
0.5991206420	specialized hardware
0.5973326264	latency dram
0.5967023313	dual bit full
0.5952125428	data copy
0.5929219677	hardware implementations
0.5917291824	order of magnitude
0.5907643139	on die ecc
0.5902361356	leakage energy
0.5889988370	circuit synthesis
0.5887529205	graph algorithms
0.5878818093	list size
0.5868736571	dram caches
0.5868186018	hardware security
0.5861671337	cache replacement
0.5859705634	gate level
0.5859683614	reconfigurable architectures
0.5857213931	memory capacity
0.5852299672	performance bottleneck
0.5850624298	artificial neural
0.5845355472	reduced precision
0.5836155977	dram modules
0.5831600442	multi core systems
0.5829977753	reduce power consumption
0.5827629428	peak performance
0.5824541692	execution model
0.5817603147	management techniques
0.5813597883	point of view
0.5806472660	high accuracy
0.5800151783	level simulations
0.5797967853	instruction level
0.5794146247	decoding algorithms
0.5786553819	energy reduction
0.5784325808	micro architecture
0.5779139922	program execution
0.5768435107	high frequency
0.5754068501	recent advances
0.5732707718	routing algorithms
0.5726919654	enable efficient
0.5725171618	write latency
0.5724133397	benchmark circuits
0.5700618758	low level
0.5697069762	decoding latency
0.5696192120	analog to digital
0.5689135866	low precision
0.5678874648	look ahead
0.5643704736	single bit
0.5642543399	performance overhead
0.5635611097	area overheads
0.5631314975	data intensive applications
0.5629841578	computing platforms
0.5624026543	learning models
0.5622970655	processor architectures
0.5615286536	an open source
0.5613121019	fpga accelerator
0.5607953806	low power consumption
0.5598138117	cache line
0.5595961433	circuit design
0.5592282166	bit precision
0.5581541651	multi channel
0.5577876678	results obtained
0.5577690796	read and write
0.5573979736	proposed technique
0.5555285654	data sharing
0.5552450859	proposed multiplier
0.5544441625	performance loss
0.5541691755	fpga device
0.5540325906	general purpose processor
0.5537750351	memory controllers
0.5536213718	near data processing
0.5525222335	circuit level
0.5518334191	processing in memory
0.5512813586	end to end
0.5512434711	deep convolutional neural
0.5512243155	delay insensitive data
0.5509383098	error correction performance
0.5501339253	data centric
0.5498935989	proposed method
0.5487197663	hardware accelerator
0.5481986117	critical applications
0.5468432798	improves performance
0.5464306881	i o
0.5437098912	cifar 10
0.5432243815	computational power
0.5411841126	memory intensive
0.5409629094	data storage
0.5356069336	asic design
0.5355709674	decoding of polar
0.5354600501	level caches
0.5350076146	nm technology
0.5338142543	cache size
0.5337784320	power supply
0.5330701717	tops w
0.5327735994	average power
0.5323255850	fpga board
0.5322191271	level design
0.5285406597	key idea
0.5282011468	reversible gate
0.5280444579	high capacity
0.5278529861	chip area
0.5270802577	fpga platforms
0.5269580587	data intensive
0.5255440387	work's significance and
0.5252397152	fpga resources
0.5250076747	energy constrained
0.5248353618	dram access
0.5237404021	write energy
0.5235908135	performance improvements
0.5230250755	dram latency
0.5214445614	side channel attacks
0.5214260197	timing models
0.5200422337	power savings
0.5195235918	bit parallel
0.5191288398	single core
0.5183631305	risc v
0.5183203248	model compression
0.5176464855	energy cost
0.5169966120	65 nm cmos
0.5169066698	efficiency improvement
0.5167718041	multi application
0.5164963178	reversible circuit
0.5145804849	hardware resource
0.5132638280	multi bit
0.5108619355	power reduction
0.5103613033	hardware implementation
0.5098333795	data dependent
0.5091162826	implementation results
0.5088379747	emerging non volatile
0.5078049529	multi level
0.5047262047	the work's significance
0.5045046388	memory channels
0.5042518064	hardware cost
0.5034584400	processor core
0.5026357957	memory bound
0.5023083840	short term
0.5010814166	hardware overhead
0.4999254285	intensive applications
0.4951947727	power efficiency
0.4948817257	fpga devices
0.4943641474	path delay
0.4924212464	carry adder
0.4912320236	data encoding
0.4905697952	level synthesis
0.4892240265	a 4
0.4874256840	memory encryption
0.4872258328	hardware support
0.4858232373	dynamic power
0.4857497201	dram cache
0.4848167373	tree based
0.4841454991	memory modules
0.4835000308	low area
0.4824271224	promising solution
0.4822092007	et al
0.4819910015	accelerator architecture
0.4795661810	stacked dram
0.4795165248	tolerant reversible
0.4792102044	multi core processors
0.4786228265	monolithic 3d
0.4784704712	non volatile
0.4784028640	physical design
0.4780595661	dram chip
0.4769452962	input and output
0.4760791776	trade off
0.4759392717	memory systems
0.4758667858	performance and energy efficiency
0.4735208049	modern systems
0.4732193166	bit level
0.4721101285	dram cells
0.4708593429	network accelerators
0.4708376157	fast and accurate
0.4707494621	memory technologies
0.4704688724	achieve high
0.4701414263	data encryption
0.4693680505	cpu and gpu
0.4690112260	resnet 50
0.4689219934	physical memory
0.4684792079	full adder
0.4676109982	memory safety
0.4666424832	training and inference
0.4664067971	side channel
0.4661915918	flash based
0.4641913418	hardware designs
0.4636992270	hardware architecture
0.4634365606	large number
0.4618401715	data rate
0.4617521877	dynamic energy
0.4612203034	large list
0.4609904120	thread level
0.4571098849	improve performance
0.4563668961	logic unit
0.4548297234	performance analysis
0.4534853901	hardware complexity
0.4521723620	computing architectures
0.4519526995	many core systems
0.4519404476	design parameters
0.4515496412	transfer level
0.4513071842	an area efficient
0.4512445201	data driven
0.4510830512	graphics processing
0.4510262226	power efficient
0.4503955658	hardware platform
0.4482894810	low energy
0.4458064431	fpga accelerators
0.4427775293	application level
0.4427312864	high energy
0.4424493806	28 nm
0.4419158356	network inference
0.4417640919	high latency
0.4412002929	front end
0.4410311295	performance and energy
0.4404776743	hardware and software
0.4368204379	hardware design
0.4353180365	specific hardware
0.4314993491	logic circuit
0.4300565967	65 nm
0.4289478966	paper addresses
0.4253663184	latency and energy
0.4241087909	memory model
0.4224644772	power and energy
0.4223957293	memory models
0.4219208439	reconfigurable architecture
0.4204549941	3d stacked
0.4198629734	area and power
0.4192873810	networks on chip
0.4189727512	performance and power
0.4180129718	real time
0.4176899985	recent advances in
0.4151080404	accelerator design
0.4150613870	performance computing
0.4147771387	software hardware
0.4139291225	software and hardware
0.4138243874	memory requirements
0.4135376256	area efficient
0.4132438430	fpga based accelerators
0.4126803614	experimental results show
0.4120114576	hardware architectures
0.4112103975	higher performance
0.4101977760	cache miss
0.4092819495	45 nm
0.4089935216	ultrascale +
0.4086129734	power and area
0.4031842079	commercially available
0.3981987319	this paper summarizes
0.3980390450	design and implementation
0.3974765017	fan out
0.3953755786	input data
0.3947678345	32 28nm cmos
0.3934275928	in recent years
0.3927293583	cache energy
0.3902982071	memory computing
0.3902154923	gpu memory
0.3888358293	processor architecture
0.3856381101	hardware co design
0.3853446672	d dct
0.3834429807	cache memory
0.3832292921	cmos based
0.3829484541	near memory computing
0.3828755837	fpga implementation
0.3799551501	significant performance
0.3795909920	this paper describes
0.3795298749	dram power
0.3794862869	memory latency
0.3793168572	computer vision
0.3777656817	near threshold
0.3774841295	efficient hardware
0.3774561885	single chip
0.3767356137	fpga architecture
0.3762196579	based accelerator
0.3746842854	this paper presents
0.3731757481	computing architecture
0.3727128562	change memory
0.3721776270	based approach
0.3719381438	next generation
0.3716877892	hardware level
0.3691360171	t count
0.3689774657	large memory
0.3682640067	in memory computing
0.3680442069	performance model
0.3677914316	number of bits
0.3636457666	cache design
0.3636027288	well suited
0.3628792883	proposed approach
0.3616133045	data communication
0.3614753187	high degree
0.3611831219	compared to existing
0.3607111132	low power cmos
0.3582163390	hardware based
0.3574939874	data access
0.3572231243	learning applications
0.3567612724	logic design
0.3562848830	built in self
0.3560141598	access memory
0.3554930588	dual bit
0.3548361069	gb s
0.3535179672	core processor
0.3516517373	high degree of
0.3516006920	correction performance
0.3512420485	this paper proposes
0.3509995095	based designs
0.3509684454	algorithm architecture
0.3502114111	multiple bit
0.3496892055	memory architecture
0.3468084394	proposed scheme
0.3456096382	memory technology
0.3445366276	scale out
0.3425996247	architecture research
0.3418179046	3d nand flash
0.3413403996	network architectures
0.3411938369	quantum computer
0.3408107090	computing in memory
0.3407568816	core architecture
0.3403274641	non uniform
0.3399243797	core processors
0.3394773847	design process
0.3385154367	computing applications
0.3382387414	processor design
0.3373107274	high power
0.3363563058	chip communication
0.3361738375	software based
0.3352077569	bandwidth memory
0.3322197334	near sensor
0.3277059361	single fpga
0.3265200255	operating system
0.3252808134	\ textit
0.3252592448	run time
0.3246771793	proposed architecture
0.3244359825	radix 2
0.3223258115	architecture level
0.3216278710	processor based
0.3213870013	$ \ times
0.3211524366	an energy efficient
0.3205069023	set architecture
0.3192728978	self interference
0.3190318876	based systems
0.3176653762	out of order
0.3174446033	average performance
0.3169230057	8 bit
0.3165112410	32 bit
0.3153904068	based hardware
0.3146521800	fpga design
0.3139535081	communication systems
0.3138141164	off chip memory
0.3125729137	simulation results show
0.3099619030	near zero
0.3088378152	dram based
0.3083458323	a case study
0.3081354062	proposed framework
0.3074313629	non blocking
0.3059490266	4 phase return to zero
0.3036632835	range of applications
0.3025787694	computer architecture
0.3011702608	memory performance
0.2990579534	based architecture
0.2990116019	^ 2
0.2983105413	wide range of
0.2977638987	model based
0.2973489626	reduce energy
0.2966867413	based data
0.2963213238	core architectures
0.2960606319	architecture design
0.2960594422	system on chips
0.2940862299	based implementations
0.2925462318	a 3
0.2924339797	learning based
0.2921356763	this paper introduces
0.2919226093	$ \ mu
0.2914961200	level cache
0.2911865690	last level
0.2899183012	based memory
0.2894192971	becoming increasingly
0.2877753715	2 ^ n
0.2871659043	efficient implementation
0.2837508255	reduce power
0.2834485575	proposed design
0.2830222130	frames per
0.2822590699	ever increasing
0.2816324796	core systems
0.2813118932	systems on chip
0.2812108250	dealing with
0.2784109916	a promising solution
0.2769625263	the key idea
0.2743200584	non linear
0.2725070455	off chip
0.2716585158	a wide range
0.2680903431	based accelerators
0.2675088071	does not
0.2656009718	near memory
0.2647524140	co design
0.2634172164	return to zero
0.2629320706	trade off between
0.2626497352	processing applications
0.2595997897	key value
0.2567510921	per bank
0.2539535196	higher energy
0.2531788409	\ times
0.2529871497	\ mu
0.2523568727	without compromising
0.2523281186	per cycle
0.2501860973	speed up
0.2497440264	commonly used
0.2491962861	well known
0.2489163346	\ em
0.2477482625	widely used
0.2474070921	$ ^ 2
0.2472911772	power delay
0.2469247313	$ 10 ^
0.2453730943	cmos design
0.2442877018	based design
0.2440161228	4 phase return to
0.2398244041	more and more
0.2377102187	more energy efficient
0.2372697183	3 d
0.2357222232	prior work
0.2346278548	do not
0.2337529029	a 32 28nm
0.2333506915	hardware implementation of
0.2332933041	per watt
0.2311381360	on chip network
0.2264856777	faster than
0.2259836820	for polar codes
0.2259001403	3d nand
0.2245358911	while maintaining
0.2229584468	into account
0.2227112913	ranging from
0.2224724531	retention time
0.2198358561	in low power cmos
0.2185334036	clock frequency of
0.2172252906	s w
0.2150639284	\ log
0.2139720471	10 ^
0.2137733951	large number of
0.2136797269	suffer from
0.2130963803	a single chip
0.2129533320	this paper
0.2113061459	64 bit
0.2110631092	space time
0.2095351963	greater than
0.2095220304	on chip
0.2094666725	time consuming
0.2083898299	fpga implementation of
0.2079860639	co designed
0.2077027821	even though
0.2073397319	three major
0.2062744802	so far
0.2050406977	experimental results on
0.2049681996	an efficient
0.2032877481	+ 1
0.2029523190	does not require
0.2016179300	execution time
0.2010726139	evaluations show
0.2009294213	time domain
0.2007700661	this dissertation
0.2004199293	depending on
0.2002726807	the shelf
0.2001531735	this article
0.2000790870	embedded system
0.1997187486	results indicate
0.1974382084	a graph
0.1973108523	full adders
0.1970502770	the other hand
0.1939104998	peak performance of
0.1937605739	at design time
0.1929661117	at low cost
0.1927639875	rather than
0.1922194165	referred to as
0.1916403594	rely on
0.1909928697	a 32
0.1904001290	previous work
0.1900777375	efficient implementation of
0.1899893493	$ \
0.1892191227	the proposed architecture
0.1889224617	an fpga based
0.1875403766	hardware accelerator for
0.1874120606	connections between
0.1871862925	the art
0.1868956184	1 byte
0.1868584091	a 32 28nm cmos
0.1864250119	into consideration
0.1863779783	the accuracy of
0.1851335148	caused by
0.1847136990	millions of
0.1840803380	4 bit
0.1828779783	the speed of
0.1827521962	in memory processing
0.1824997811	of polar codes
0.1819406422	system on chip
0.1796177283	balance between
0.1793779783	the area of
0.1791739348	gap between
0.1786107142	refer to
0.1785047331	many core
0.1772671300	a 3d
0.1766225026	while keeping
0.1765345382	n ^
0.1757139895	the critical path
0.1756361264	phase return to zero
0.1753149131	for use in
0.1745653344	system level
0.1745028532	focused on
0.1741883438	focuses on
0.1740442068	cycle time
0.1733550105	depends on
0.1731972710	a large number
0.1730497061	susceptible to
0.1728834361	a wide variety of
0.1726677560	continues to
0.1725665750	focus on
0.1724418733	resource utilization and
0.1723594986	emerged as
0.1706875744	energy consumption by
0.1693779783	the architecture and
0.1693779783	the order of
0.1690513797	16 bit
0.1682328360	response time
0.1678779783	the level of
0.1673577902	an improved
0.1669033016	an energy efficiency
0.1663779783	a method to
0.1660902196	key idea of
0.1653779783	and simulation of
0.1637070196	take advantage
0.1636790819	a shared
0.1633779783	the advantages of
0.1618926960	absence of
0.1613679517	to achieve high
0.1605619432	as well as
0.1604449796	relies on
0.1599989190	energy efficiency by
0.1598721243	the proposed scheme
0.1598030454	a quantum
0.1597943793	amounts of
0.1597224841	improvement over
0.1594796537	two dimensional
0.1590366364	on chip memory
0.1588779783	the execution of
0.1586266879	a lot
0.1558478944	less than
0.1555291185	use cases
0.1554502223	power consumption by
0.1544753557	^ n
0.1540010542	of power consumption
0.1538779783	the problem of
0.1536677467	per second
0.1534559233	a low complexity
0.1533970645	a general purpose
0.1525496736	consisting of
0.1525098743	an ultra
0.1517542764	$ 2 \
0.1517536152	results show
0.1513328735	the effects of
0.1504233164	a binary
0.1501948987	affected by
0.1499224311	equipped with
0.1495860857	followed by
0.1489634633	test time
0.1489510025	depend on
0.1486662068	the field of
0.1482503892	a custom
0.1480500718	3d integration
0.1471277670	the proposed approach
0.1463472779	to test
0.1454630395	on average
0.1449231246	the proposed design
0.1446662068	the latency of
0.1445090896	per bit
0.1444487716	experiments show
0.1441894053	full system
0.1441742446	compared to
0.1438176501	derived from
0.1432674404	$ 10
0.1431662068	the benefits of
0.1426509741	conjunction with
0.1420487516	near data
0.1416150547	4 phase
0.1411146957	an 8
0.1408831452	an important
0.1404006215	the supply voltage
0.1402988806	the proposed method
0.1401065896	at runtime
0.1397419226	a multi core
0.1396211174	motivated by
0.1394627903	due to
0.1391281251	the open source
0.1390844867	power consumption of
0.1390307112	an end to end
0.1388810906	for large scale
0.1373957735	based on
0.1369793832	as much as
0.1367544421	the characteristics of
0.1362407453	two orders of magnitude
0.1357961571	communication between
0.1357544421	the limitations of
0.1355182862	design based on
0.1354015361	architecture based on
0.1351662068	the security of
0.1348849423	a clock
0.1341662068	the process of
0.1332646917	the lifetime of
0.1330198097	while consuming
0.1324899368	the memory hierarchy
0.1312272364	energy consumption of
0.1309555099	by up to
0.1307175476	offered by
0.1306398387	time steps
0.1302646917	a speedup of
0.1301608125	state of
0.1299294208	a novel method
0.1299030008	only on
0.1296408871	an area
0.1293799226	lead to
0.1288220756	to become
0.1283454333	by exploiting
0.1282758679	benefit from
0.1279814798	take advantage of
0.1278625575	even if
0.1277192875	carry look
0.1262943852	to compute
0.1262542397	full chip
0.1255317671	during training
0.1249515763	communication system
0.1247997398	energy efficiency of
0.1247593548	focusing on
0.1243745056	$ 2
0.1222737482	existing work
0.1221871291	large amount of
0.1221071613	a low cost
0.1219311010	n +
0.1218290556	to predict
0.1214089523	less than 1
0.1213724864	higher than
0.1211137779	speedup over
0.1206523390	$ 8
0.1203411406	power consumption and
0.1202446105	leads to
0.1196005461	and energy efficiency
0.1190405782	$ m
0.1186886322	obtained from
0.1185945909	to lower
0.1182562729	the experimental results
0.1181028056	processor based on
0.1180515448	compared with
0.1180087889	scale up
0.1178632297	impact on
0.1175117822	a distributed
0.1173685432	2 ^
0.1173493779	+ +
0.1167871789	a methodology
0.1165227288	and power efficiency
0.1162531593	the spatial
0.1162226343	more than
0.1154328735	in terms of
0.1152873459	2 d
0.1151887722	work proposes
0.1150705926	number of
0.1149136897	across multiple
0.1148457083	a d
0.1133793200	of deep neural networks
0.1132199298	by proposing
0.1124070359	a high speed
0.1123858953	the energy efficiency
0.1123216062	the distributed
0.1116999080	novel approach
0.1113771153	a low power
0.1110353700	the hardware implementation
0.1109843685	the memory controller
0.1108110227	this work
0.1106743182	computer systems
0.1105314975	a network on chip
0.1101792197	significantly less
0.1101649000	very large
0.1101608093	along with
0.1098530859	implemented using
0.1095504874	time data
0.1093751181	supported by
0.1088566962	efficiency compared to
0.1083188471	a wide range of
0.1082006429	the given
0.1077688863	an energy
0.1075751120	a fully
0.1072289863	lower than
0.1068365658	close to
0.1068047957	design and implementation of
0.1066403004	a non
0.1065173599	the 4 phase
0.1061121155	each node
0.1057091988	out of
0.1054328735	in order to
0.1054206398	better than
0.1047471897	to improve
0.1041672436	able to
0.1040755817	tend to
0.1039276240	$ n
0.1038178972	on top of
0.1034644671	a field
0.1030868847	such as
0.1028021500	an attractive
0.1027043121	system on
0.1025297265	correspond to
0.1020402522	provided by
0.1019696009	at least
0.1019463882	energy per
0.1014152878	novel architecture
0.1013249451	to process
0.1009506770	two major
0.1006947383	achieved by
0.1003804377	deal with
0.0999249116	a novel
0.0999231905	the early
0.0997324953	this survey
0.0996406007	$ ^
0.0995638087	and even
0.0992298798	two key
0.0991092632	the way
0.0990989841	time by
0.0985380215	a unified
0.0983912941	to overcome
0.0982415954	adapted to
0.0980049532	the need
0.0979360493	the main memory
0.0979289773	the memristor
0.0979175257	to solve
0.0977784071	the partial
0.0973473674	capable of
0.0967077007	the common
0.0966268690	to reduce
0.0964646566	the scalability
0.0962399598	used to implement
0.0960856119	$ s
0.0959046949	the advantage
0.0954730693	a high performance
0.0952208294	realized using
0.0950591836	an average
0.0940287675	the target
0.0938679677	with respect to
0.0937620027	very low
0.0937251781	composed of
0.0935266832	very high
0.0930165832	the energy consumption
0.0926940882	operating at
0.0924789542	a self
0.0924253179	a survey
0.0917776500	a heterogeneous
0.0916572532	suitable for
0.0913986313	the challenge
0.0912746645	so as to
0.0904374297	this report
0.0901051588	at run time
0.0900704656	the compiler
0.0900673089	proportional to
0.0900530372	a multi
0.0899978851	a very
0.0897861103	a case
0.0896990864	generated by
0.0895443347	2 \
0.0893063460	combined with
0.0890932485	each layer
0.0890031770	the design space
0.0889701124	the recent
0.0889408288	the simulation results
0.0886613105	more complex
0.0884155845	leading to
0.0880636590	according to
0.0880061088	to build
0.0879193357	novel hardware
0.0873674561	a set
0.0870896564	consists of
0.0870551284	to minimize
0.0867634817	the overlay
0.0864645527	both single
0.0860801850	this end
0.0860170488	the work's significance and
0.0860165832	the power consumption
0.0859750993	of n
0.0858861821	a high throughput
0.0857302598	within dram
0.0857251432	these problems
0.0854536728	not only
0.0853425617	but also
0.0853328885	a systolic
0.0850151617	an alternative
0.0848612779	the high level
0.0843084965	the die
0.0841054182	a modern
0.0839511964	system design
0.0839046457	2 bit
0.0835321047	this work presents
0.0834008766	while achieving
0.0833904279	these issues
0.0830194586	two orders
0.0828723650	a large amount
0.0827964019	an overview
0.0826043721	a soft
0.0825221161	while reducing
0.0824978254	a high level
0.0822029172	constructed using
0.0821427199	the internet
0.0820729924	thousands of
0.0819317719	reduction in
0.0815231393	obtained by
0.0813292689	aims to
0.0812765967	simulation time
0.0812682149	most important
0.0811106804	generated from
0.0809713205	further reduce
0.0809504328	new design
0.0805968150	the sequential
0.0805344745	implemented on
0.0805104920	1 bit
0.0804586808	the off chip
0.0803600481	much as
0.0803292373	a limited
0.0802280424	to scale
0.0800374187	using xilinx
0.0793909786	the effectiveness
0.0793813284	to implement
0.0793556551	to address
0.0786705767	parameters such as
0.0786462518	associated with
0.0786281770	and energy consumption
0.0786063227	subset of
0.0785530372	a technique
0.0783387916	adapt to
0.0782411521	of on chip
0.0781876325	to alleviate
0.0779816208	more accurate
0.0778662084	the quality
0.0775736224	a low
0.0775506981	an extension
0.0775293902	other hand
0.0774608133	an automated
0.0774058933	memory system
0.0769973138	the same
0.0769431315	the resulting
0.0766520576	to enable
0.0765100395	the entire
0.0760399817	a near
0.0757462082	a single
0.0757128482	a threshold
0.0755926859	as low as
0.0753437380	an order
0.0751147225	these challenges
0.0750253383	the proposed
0.0747982207	to accelerate
0.0747808455	to perform
0.0745721247	computing system
0.0745512622	and therefore
0.0744582838	return to
0.0743133343	to avoid
0.0742782902	taking into
0.0740248153	developed in
0.0738880961	the amount
0.0736932594	benefits from
0.0732072894	more efficient
0.0728626959	different types
0.0727925302	vulnerable to
0.0727767798	difficult to
0.0725696223	an analytical
0.0724194303	thanks to
0.0724168796	part of
0.0723767631	led to
0.0723483768	applicable to
0.0720754239	by means of
0.0718997579	inspired by
0.0718307776	the flexibility
0.0716724102	in memory
0.0714387213	in addition
0.0714002929	to protect
0.0711376954	possibility of
0.0711019701	a reversible
0.0708582064	two level
0.0708236834	to handle
0.0705096455	system stack
0.0704757000	by introducing
0.0702257532	a variety
0.0698367200	running on
0.0696484872	the following
0.0693805765	to study
0.0693739216	amount of data
0.0691769053	in most
0.0691473277	an industrial
0.0690764172	consist of
0.0688386048	an approach
0.0687939549	this context
0.0685601334	work presents
0.0685417691	the purpose
0.0681778906	overall performance
0.0681408675	a linear
0.0681238688	system performance
0.0680336224	a framework
0.0680167676	to mitigate
0.0679401309	the performance of
0.0678514808	these devices
0.0677452776	paper provides
0.0677151803	to meet
0.0676599171	to achieve
0.0676169403	an accelerator
0.0675926859	the context of
0.0674734642	the design of
0.0674227095	a variety of
0.0673359817	applied to
0.0672389166	of computer
0.0669625902	to optimize
0.0669287527	performance per
0.0667598765	to maximize
0.0666839118	with minimal
0.0665047411	the thermal
0.0664847095	none of
0.0664734642	the number of
0.0660454467	considered as
0.0658784572	widely used in
0.0658655757	to support
0.0658122894	reductions in
0.0658031692	in order
0.0657890759	a 32 bit
0.0657011548	to zero
0.0656592361	performed by
0.0656141722	portion of
0.0653965649	an adaptive
0.0653891181	a promising
0.0653544295	compared to state of
0.0651861599	the use of
0.0648529361	on die
0.0648322791	the user
0.0645181967	different levels of
0.0642551416	designed using
0.0640230639	an effective
0.0640197892	by applying
0.0636600143	this problem
0.0636218986	the baseline
0.0636165387	to work
0.0635021697	to maintain
0.0631054792	coupled with
0.0629292909	a new
0.0628985183	a factor
0.0628238142	allows to
0.0625947062	suited for
0.0624836288	for solving
0.0622038647	an application
0.0620343575	the design
0.0617738099	compatible with
0.0617523142	a function
0.0617273902	by allowing
0.0616672875	become more
0.0615161070	less power
0.0613286124	these techniques
0.0613111608	the next
0.0611417621	a range
0.0611309562	this approach
0.0609408563	a flexible
0.0608570034	found in
0.0607085323	attempts to
0.0607041000	available in
0.0606871912	a solution
0.0603098474	important to
0.0602725372	a result
0.0602629068	an open
0.0598254937	an embedded
0.0592025565	to show
0.0591642075	the available
0.0587784425	implementation of
0.0587155819	the need for
0.0585440896	by implementing
0.0585236136	a configurable
0.0582748755	low as
0.0582057581	a major
0.0581972428	the required
0.0580548439	different levels
0.0579326188	well as
0.0579191988	a mechanism
0.0578981167	by dynamically
0.0577939868	the second
0.0577583774	the previous
0.0576985761	a new approach
0.0575610861	devices such as
0.0575039626	with negligible
0.0574768991	of magnitude
0.0574445973	the fly
0.0574286603	the arm
0.0572566158	in comparison to
0.0572506511	and up to
0.0568366653	a proof of
0.0568200677	all possible
0.0567580768	this method
0.0566589961	new approach
0.0566423313	needs of
0.0566060564	attempt to
0.0565668029	the extra
0.0563072293	two different
0.0562565250	on line
0.0559862769	of service
0.0556926700	problem for
0.0556442245	amount of
0.0556204617	across different
0.0555651994	by taking
0.0554253911	respect to
0.0551970174	this project
0.0551939707	network on
0.0550315024	the maximum
0.0549252617	a secure
0.0547772091	an optimized
0.0547563970	the context
0.0547252153	reduced by
0.0546632702	fraction of
0.0546211952	realization of
0.0546184554	the experimental results show
0.0541614641	role in
0.0541117791	continue to
0.0539982473	applications such as
0.0538307581	the idea
0.0537886456	the world
0.0537860320	advantage of
0.0537429692	a long
0.0536359976	the help of
0.0535468051	the state of
0.0535366379	a broad
0.0534603932	to ensure
0.0532556452	compared to other
0.0531729526	the open
0.0530400018	a lot of
0.0530121733	the algorithmic
0.0528349073	tailored to
0.0526793263	a pipeline
0.0526704611	a hardware
0.0525549413	the original
0.0524688805	for on chip
0.0524239458	the fundamental
0.0523179146	evaluated on
0.0522507648	even more
0.0520951050	to verify
0.0520681765	the run time
0.0520637071	this issue
0.0520255519	an architecture
0.0519550271	up to
0.0519248923	need for
0.0519218498	a hybrid
0.0518850862	to deal with
0.0518778055	of up
0.0518542969	to calculate
0.0517906125	the obtained
0.0513002357	efficiency by
0.0512705904	processing in
0.0512660207	this gap
0.0511867194	by leveraging
0.0511372234	easy to
0.0510110941	design of
0.0509916383	comparison with
0.0509628800	intended to
0.0509628516	the latter
0.0505838048	in practice
0.0504111529	executed on
0.0503667093	types of
0.0501891833	a set of
0.0501660707	to increase
0.0501004512	code for
0.0499581065	much more
0.0497573219	an arbitrary
0.0494111693	synthesis for
0.0493955462	to enhance
0.0493758786	a full
0.0493333520	on field
0.0492483705	dependent on
0.0490604402	increase in
0.0489769482	fabricated in
0.0489021486	with state of
0.0487676542	the minimum
0.0485391639	by providing
0.0482093318	comparable to
0.0482085233	an overview of
0.0482084487	each other
0.0480861004	hundreds of
0.0480635266	accesses to
0.0480260195	performance of
0.0479426839	or even
0.0479134597	collection of
0.0478976757	to generate
0.0478599613	required by
0.0478280227	to add
0.0476767899	or not
0.0475920900	tailored for
0.0475423178	the need to
0.0474538720	a reconfigurable
0.0474478858	an asynchronous
0.0473945340	the complete
0.0473570837	for image
0.0472465676	the same time
0.0469892160	purpose of
0.0468667163	the corresponding
0.0466383263	group of
0.0466346633	the number
0.0466144603	of up to
0.0465820905	and in particular
0.0464858574	processor with
0.0464834696	the inherent
0.0464530612	a dynamic
0.0463164627	as well
0.0462941316	to introduce
0.0462887041	means of
0.0462568138	the whole
0.0462539878	to detect
0.0462240111	the potential
0.0461818380	advances in
0.0461139849	the purpose of
0.0460775416	a simple
0.0460383951	a well
0.0456041930	suited to
0.0455838714	structure for
0.0454907115	to understand
0.0454612131	hardware co
0.0454134570	set of
0.0453580087	a small
0.0453456835	the ability
0.0450633321	improvement in
0.0450536850	variety of
0.0449976230	orders of
0.0448948180	availability of
0.0447641672	a multicore
0.0446783903	to select
0.0446278619	two orders of
0.0445037017	the network on
0.0443514371	different from
0.0442457425	to construct
0.0442457425	to realize
0.0440242913	choice for
0.0439745500	in contrast to
0.0439414507	a highly
0.0437624462	and then
0.0437418525	nature of
0.0436552870	seen as
0.0436537133	overview of
0.0436336216	to manage
0.0435217562	the os
0.0434196144	published in
0.0433370580	the basic
0.0431931926	an energy efficiency of
0.0430628730	presence of
0.0430314137	degree of
0.0430279660	possible to
0.0429996121	the past
0.0427167332	the set of
0.0426946370	aspect of
0.0426331786	a fast
0.0425544727	integrated with
0.0424278232	stored in
0.0424258363	limited by
0.0423698094	to take
0.0421309241	a viable
0.0419779905	a particular
0.0419634976	to provide
0.0418883594	decrease in
0.0418864077	internet of
0.0418827254	resulting in
0.0417745526	by up
0.0417345403	the possibility
0.0416624171	faster and
0.0416364086	an example
0.0415783686	progress in
0.0415298626	to deliver
0.0415137528	an order of
0.0412877987	growth of
0.0412508578	an algorithm
0.0411946669	this purpose
0.0411891833	the impact of
0.0411723890	the overall
0.0411331131	on chips
0.0409701786	used to
0.0409472675	implemented in
0.0409286237	by means
0.0409124715	throughput by
0.0408984348	feasibility of
0.0408837652	the last
0.0408792573	the total
0.0408523782	mapped to
0.0408462568	an optimal
0.0408156062	to guarantee
0.0406490055	an end
0.0405616165	used in
0.0404963835	a large
0.0404518227	a series of
0.0403567083	a first
0.0403341684	a methodology to
0.0400434425	to replace
0.0400434425	to satisfy
0.0399926624	to tackle
0.0399261893	the literature
0.0399078419	cost by
0.0397734666	location of
0.0397303387	the design and
0.0396820212	accuracy for
0.0396810186	help of
0.0396095098	family of
0.0395414226	architecture for
0.0395218983	written in
0.0395004739	to represent
0.0394319914	a programmable
0.0394224939	even in
0.0394175703	to synthesize
0.0394046019	the feasibility
0.0393681017	need to
0.0393343148	to keep
0.0393339844	the amount of
0.0392977125	different types of
0.0390717582	the host
0.0389925381	a basic
0.0389647589	the final
0.0388888436	in terms
0.0385475520	a systematic
0.0384928272	a similar
0.0384564259	adoption of
0.0383713826	in particular
0.0382303387	the implementation of
0.0381899910	analysis of
0.0381669777	so as
0.0380593237	to exploit
0.0380317290	to evaluate
0.0379192289	an accurate
0.0378335631	in contrast
0.0377906280	used for
0.0376915837	the main
0.0376759325	to prevent
0.0376752421	deployed in
0.0376611878	accelerator with
0.0375339671	to extract
0.0374663589	a user
0.0373690045	accelerator for
0.0372495837	a high
0.0372269197	a proof
0.0370153317	allow for
0.0370103336	the theoretical
0.0370076137	of concept
0.0369130498	a factor of
0.0369012495	a key
0.0367546225	a significant
0.0367339690	efficiency than
0.0367013770	the conventional
0.0365358555	the complexity of
0.0364947956	the first
0.0361942466	these two
0.0361339013	a wide
0.0360763581	the key
0.0359513211	the major
0.0359404592	performance than
0.0358990984	this model
0.0358802611	to obtain
0.0357875422	because of
0.0357572661	method for
0.0356196211	known as
0.0355352218	to guide
0.0355060722	performed on
0.0354713208	the secret
0.0353099870	to determine
0.0353077234	a given
0.0351639219	the importance of
0.0350759447	series of
0.0350632703	the first time
0.0349399479	top of
0.0349224479	potential of
0.0348948833	ease of
0.0347864660	to create
0.0345819623	combination of
0.0345781960	presented to
0.0345267127	approach to
0.0343367078	found to
0.0343282074	an analog
0.0342830019	a tool
0.0342773393	evaluation of
0.0340013054	together with
0.0339509582	to map
0.0338071452	to allow
0.0336684459	for accelerating
0.0336234333	spectrum of
0.0335027011	a few
0.0334951039	description of
0.0334302195	the traditional
0.0333928205	the rapid
0.0333792363	and thus
0.0333634381	a network on
0.0332101727	built in
0.0331722606	a typical
0.0331011549	this new
0.0330156452	a scalable
0.0329224037	the basis of
0.0328441271	technique for
0.0327662417	enough to
0.0327546802	architecture co
0.0327341759	this study
0.0326166892	a standard
0.0326156106	to share
0.0326025487	a fixed
0.0324181051	concept of
0.0323986388	quality of
0.0323880836	class of
0.0323734096	demand for
0.0323381615	efficient than
0.0322717487	an error
0.0320857469	designed for
0.0320652201	in depth
0.0320263613	a critical
0.0320029569	in fact
0.0319723812	a certain
0.0319651372	new approach to
0.0319649597	related to
0.0318266836	in turn
0.0317716568	expected to
0.0316979670	the energy efficiency of
0.0316382369	described in
0.0315639009	type of
0.0315629244	support for
0.0313707326	to help
0.0312469634	relative to
0.0311954272	range of
0.0311934868	to apply
0.0311698393	of interest
0.0310659309	used by
0.0309735127	the desired
0.0309371169	this technique
0.0308716492	while also
0.0308677589	robust to
0.0308487996	hard to
0.0307166029	aim to
0.0307065674	to save
0.0305864937	a special
0.0305804850	this challenge
0.0305479748	the initial
0.0304749907	to develop
0.0304511187	in comparison with
0.0303940036	estimation of
0.0303523390	to estimate
0.0301947203	the ability to
0.0301733132	this scheme
0.0300567232	needed to
0.0300509885	an input
0.0300294966	to facilitate
0.0299814712	instead of
0.0299646280	scaling of
0.0299071722	implemented as
0.0298747111	used as
0.0298463064	aspects of
0.0298201032	a complete
0.0297568195	the presence
0.0297491780	limited to
0.0295226768	employed to
0.0294401778	a way
0.0294269198	developed to
0.0292688686	the gap between
0.0292493199	methodology for
0.0292433213	ability to
0.0292223884	implemented with
0.0292025222	the size of
0.0291518199	utilized to
0.0291139231	an experimental
0.0290191449	referred to
0.0289413306	the future
0.0289288473	a survey of
0.0289238153	a large number of
0.0288746427	to run
0.0288367906	a framework for
0.0286776146	to utilize
0.0286117830	lack of
0.0284004226	the dominant
0.0283829437	a detailed
0.0283219763	a peak
0.0282231384	result in
0.0281947203	the effect of
0.0281618445	size of
0.0280152277	a crucial
0.0279900882	latency by
0.0278818430	version of
0.0278353550	needs to
0.0278133735	a challenge
0.0278085560	to explore
0.0277246294	way to
0.0277242655	in detail
0.0276361388	usage of
0.0270241973	scheme for
0.0270191475	idea of
0.0269101300	work on
0.0268731655	a large amount of
0.0268560101	reported in
0.0268422316	to store
0.0268412730	goal of
0.0267836814	proposed to
0.0267147664	basis of
0.0265058667	form of
0.0264792571	a parallel
0.0263149783	a common
0.0261899479	a state of
0.0259494930	to use
0.0259288473	the feasibility of
0.0258134101	to eliminate
0.0256731655	the idea of
0.0255280536	a solution to
0.0255138698	a powerful
0.0253319972	a practical
0.0252822380	development of
0.0251947203	the concept of
0.0250899588	use of
0.0250149015	a lightweight
0.0249528926	interest in
0.0247645517	proof of
0.0247129461	study on
0.0245093846	likely to
0.0244017209	optimized for
0.0243757535	designed to
0.0243341797	to demonstrate
0.0242783908	attention in
0.0242361870	required to
0.0242174476	the cost of
0.0241947203	the effectiveness of
0.0241947203	the presence of
0.0240645342	to make
0.0240494351	a dedicated
0.0240476739	required for
0.0240370130	terms of
0.0239810183	alternative to
0.0238367906	the lack of
0.0237280536	a range of
0.0235507809	the efficiency of
0.0234951601	deployment of
0.0234260090	a commercial
0.0233897002	a bank
0.0232746641	exploited to
0.0231701239	the behavior of
0.0231541530	consumption by
0.0230359240	framework for
0.0230231194	a popular
0.0230208076	complexity of
0.0229707148	effectiveness of
0.0227013360	run on
0.0226765310	to execute
0.0225639621	solution to
0.0221653276	solution for
0.0221460175	dedicated to
0.0221328156	distribution of
0.0220614296	acceleration of
0.0219958854	the primary
0.0219690189	allows for
0.0219648792	the right
0.0219546388	factor of
0.0218886458	a general
0.0218547484	impact of
0.0217590935	a generic
0.0216281994	importance of
0.0214707851	a minimum
0.0211756619	understanding of
0.0210748190	for performing
0.0206580226	a fundamental
0.0206132465	a comprehensive
0.0205714465	useful for
0.0205649783	a prototype
0.0205280536	a combination of
0.0203903545	critical to
0.0203496682	a good
0.0202461185	effect of
0.0202273736	a baseline
0.0199762103	presented in
0.0198663378	a maximum
0.0198367906	the potential of
0.0198221099	for example
0.0197779670	the goal of
0.0197042130	exploration of
0.0196096044	the development of
0.0195695775	for designing
0.0194708206	shown to
0.0193984690	cost of
0.0192065912	capacity of
0.0188721752	required in
0.0187714311	similar to
0.0186548487	characterization of
0.0185013270	efficiency of
0.0180733639	approach for
0.0180713378	to identify
0.0180301253	to analyze
0.0179098086	integration of
0.0176885486	necessary to
0.0175692188	and hence
0.0172461814	capability of
0.0171730348	even with
0.0170274871	to find
0.0169492615	behavior of
0.0167112758	especially in
0.0164169962	corresponding to
0.0163599538	consumption of
0.0160840109	especially for
0.0160807449	tool for
0.0160450991	a class of
0.0159144421	in addition to
0.0158322244	an average of
0.0152961662	this paper provides
0.0148566146	a number of
0.0147223759	as compared to
0.0141447244	the integration of
