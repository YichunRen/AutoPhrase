0.9605315185	support recovery
0.9598641967	principal components
0.9598075256	white noise
0.9578506977	dynamical systems
0.9574180169	kalman filter
0.9569253960	community detection
0.9562415395	differential privacy
0.9562139793	hypothesis testing
0.9554226454	moving average
0.9552911866	treatment effect
0.9538989187	fisher information
0.9525766942	logistic regression
0.9521472251	wasserstein distance
0.9518875580	gradient descent
0.9514033660	bayesian inference
0.9499677315	compressive sensing
0.9497231276	markov chains
0.9496521289	markov chain monte carlo
0.9495303773	neural networks
0.9492800691	feature selection
0.9491853884	neural network
0.9490734337	mutual information
0.9487864653	markov chain
0.9487694392	concentration inequalities
0.9486809600	algebraic geometry
0.9486135415	likelihood ratio
0.9485640238	maximum likelihood
0.9484470397	random fields
0.9479712990	correlation coefficient
0.9477932527	instrumental variable
0.9466093079	phase transition
0.9463668586	total variation
0.9452494972	random vectors
0.9450629900	benford's law
0.9449861884	false discovery rate
0.9449124146	deep neural networks
0.9447608850	supervised learning
0.9442202266	optimal transport
0.9441973057	empirical bayes
0.9440537442	deep learning
0.9439207372	importance sampling
0.9439193010	clinical trials
0.9436937676	particle filter
0.9436808430	negative binomial
0.9434282653	phase retrieval
0.9428347713	granger causality
0.9427016924	causal inference
0.9425699554	random walk
0.9423706177	anomaly detection
0.9420133516	metric spaces
0.9416267386	stochastic processes
0.9415637611	compressed sensing
0.9411485385	support vector machines
0.9410317188	hilbert spaces
0.9410181992	exponential families
0.9409106637	exponential family
0.9407182192	fractional brownian motion
0.9406141006	ridge regression
0.9403077530	semidefinite programming
0.9402063538	principal component analysis
0.9400380799	shannon entropy
0.9396517500	uncertainty quantification
0.9395813380	reproducing kernel
0.9395776866	phase transitions
0.9390322951	brownian bridge
0.9385955876	covariance matrix
0.9385473082	social networks
0.9369928792	stochastic process
0.9368562096	spectral density
0.9367244381	sensitivity analysis
0.9366897391	instrumental variables
0.9366016413	random forest
0.9360382251	stochastic block model
0.9357188663	tail index
0.9353362014	quadratic forms
0.9353227876	machine learning
0.9352954265	model selection
0.9348161611	causal effects
0.9345608229	covariance matrices
0.9344821132	hidden markov models
0.9343596846	brownian motion
0.9343101344	ising models
0.9342628231	kendall's tau
0.9336165136	microstructure noise
0.9334332335	reproducing kernel hilbert space
0.9333518813	higher criticism
0.9324802119	markov random fields
0.9322956554	stochastic gradient descent
0.9319355893	diffusion processes
0.9314016349	random forests
0.9313680567	conditional independence
0.9312258267	sliced inverse regression
0.9312182162	hilbert space
0.9307240310	big data
0.9305057310	likelihood ratio test
0.9302181684	reinforcement learning
0.9298339457	experimental design
0.9297927431	confidence regions
0.9295277966	false discovery
0.9293016850	mahalanobis distance
0.9290869203	riemannian manifold
0.9290237146	directed acyclic graphs
0.9290147531	decision theory
0.9289240853	persistent homology
0.9288673820	spectral clustering
0.9287833385	bayes factor
0.9286393418	radon transform
0.9284657335	random field
0.9284428166	posterior consistency
0.9283910949	compound poisson
0.9282889435	bayes factors
0.9281814775	contextual bandits
0.9280057620	unit root
0.9279912134	dirichlet process
0.9279041834	mixture models
0.9278617057	optional stopping
0.9276429128	random graphs
0.9276313758	infinitely divisible
0.9276294628	long memory
0.9276242679	statistical physics
0.9275611327	breast cancer
0.9274469417	inverse problems
0.9273721746	cumulative distribution function
0.9273541299	stochastic block models
0.9273286853	point processes
0.9270954065	confidence interval
0.9270657562	smoothing spline
0.9267975309	persistence diagrams
0.9267838966	heavy tails
0.9262263768	hazard rate
0.9261889455	generalized linear models
0.9261632008	graphical models
0.9260718118	measurement error
0.9259197262	propensity score
0.9258654611	approximate message passing
0.9256479855	differentially private
0.9251690356	confidence bands
0.9248771962	multiple testing
0.9247037731	gaussian noise
0.9246777352	matrix completion
0.9245800700	nonparametric regression
0.9245451150	totally positive
0.9244430020	order statistics
0.9243283709	proportional hazards
0.9241671582	fourier transform
0.9240558828	unsupervised learning
0.9240233463	kernel density estimation
0.9240137802	normal distribution
0.9240040872	mixture model
0.9238057274	conjugate prior
0.9237851575	power law
0.9237170961	nuclear norm
0.9236687033	topological data analysis
0.9235026065	dimension reduction
0.9233036881	empirical risk minimization
0.9232968259	variable selection
0.9230749031	stochastic gradient
0.9229262248	universally consistent
0.9228068940	false alarm
0.9226905513	bayesian information criterion
0.9223377811	statistical inference
0.9223247890	auxiliary information
0.9221818746	social network
0.9219990776	nearest neighbors
0.9218815050	sufficient dimension reduction
0.9214851764	commutative algebra
0.9214564809	central limit theorem
0.9214124524	distributionally robust
0.9213824895	simulated annealing
0.9213489208	projected gradient descent
0.9211979080	penalized likelihood
0.9207309916	gaussian process
0.9206373885	gaussian graphical models
0.9206258661	clinical trial
0.9202578681	conditional expectation
0.9201242197	fused lasso
0.9199875135	riemannian geometry
0.9198887983	square root
0.9198821647	factor analysis
0.9194552696	decision theoretic
0.9194278656	smallest eigenvalue
0.9191630223	gene expression
0.9190981640	approximate bayesian computation
0.9190118008	matrix variate
0.9188408943	wild bootstrap
0.9187922412	risk management
0.9187683375	empirical likelihood
0.9185138012	particle filters
0.9184451995	breakdown point
0.9180845225	inverse probability weighting
0.9180587750	bayesian nonparametric
0.9179631228	hard thresholding
0.9178136148	probability density
0.9177891498	stochastic differential equations
0.9177861383	isotonic regression
0.9177371570	latent position
0.9177311754	persistence diagram
0.9176559618	local minima
0.9176424221	relative entropy
0.9175867775	potential outcomes
0.9174541787	riemannian manifolds
0.9173911791	oracle inequalities
0.9173562285	expected shortfall
0.9173438527	partially observed
0.9173331155	principal component
0.9166628579	lie groups
0.9164025155	akaike information criterion
0.9162051534	random matrix theory
0.9157625791	density estimation
0.9155037833	null hypothesis
0.9153593773	statistical learning
0.9151324050	lecture notes
0.9151140652	maximum likelihood estimation
0.9150870990	sharpe ratio
0.9149214410	likelihood ratios
0.9148874013	outage probability
0.9148642784	langevin dynamics
0.9147050063	unobserved heterogeneity
0.9146394946	reproducing kernel hilbert spaces
0.9146034296	autoregressive processes
0.9146009361	changepoint detection
0.9145905684	gaussian processes
0.9145291795	panel data
0.9142224531	gibbs sampling
0.9141951755	differential geometry
0.9140309385	wishart matrices
0.9137616454	banach spaces
0.9136171010	central limit theorems
0.9135739882	quantile regression
0.9135382008	large deviations
0.9134789500	irrepresentable condition
0.9133655282	information geometry
0.9133176138	stopping times
0.9131914269	frobenius norm
0.9131452323	bias correction
0.9129269200	independent component analysis
0.9127341287	empirical process
0.9125310678	message importance
0.9124389222	dantzig selector
0.9120706333	kronecker product
0.9120313709	confidence intervals
0.9118145595	complex valued
0.9118087759	simpson's paradox
0.9114935694	gibbs samplers
0.9113285334	pattern recognition
0.9112803320	failure rate
0.9112665220	block maxima
0.9112205826	message passing
0.9111191834	random walks
0.9110803305	stationary processes
0.9109781005	posterior distributions
0.9109512143	bayesian nonparametrics
0.9107464193	integer programming
0.9106338845	spherically symmetric
0.9105011519	wasserstein distances
0.9104054679	inverse problem
0.9103950163	collaborative filtering
0.9103525201	credible sets
0.9103164258	information theory
0.9102435161	armed bandits
0.9102075228	scoring rule
0.9100466500	trend filtering
0.9099854531	density function
0.9097763108	linear program
0.9097233934	linear algebra
0.9097069414	active learning
0.9096259580	weak convergence
0.9095231487	malliavin calculus
0.9091815802	euler characteristic
0.9090410783	treatment effects
0.9087140196	signal processing
0.9086481270	support vector machine
0.9086273139	confidence sets
0.9085445801	nuisance parameters
0.9082731545	change point detection
0.9082268845	ordinary differential equation
0.9081696344	stochastic blockmodel
0.9081407786	average treatment effect
0.9080432280	fdr control
0.9080207462	convex optimization
0.9079667745	random matrix
0.9075552963	oracle property
0.9075193787	characteristic function
0.9075150392	edgeworth expansion
0.9074384169	markov chain monte
0.9074177018	orthogonal arrays
0.9074127823	elliptical distributions
0.9072255218	null hypotheses
0.9072057130	kalman filters
0.9071855183	stochastic optimization
0.9071537306	pearson's correlation
0.9070729205	ordinary differential equations
0.9069542471	monte carlo
0.9068557449	average treatment effects
0.9067740847	variational inference
0.9067464683	fading channels
0.9067189139	discrete distributions
0.9067136940	gradient flow
0.9066858248	brownian motions
0.9066850432	deep neural
0.9066794489	quadratic form
0.9066738812	frequency domain
0.9066043699	low rank
0.9065647019	empirical risk minimizers
0.9064691184	moderate deviation
0.9063461398	iterated logarithm
0.9062581395	central limit
0.9061607248	variable screening
0.9061006443	regularly varying
0.9060915269	false discovery proportion
0.9060432398	differential equations
0.9059681976	statistical mechanics
0.9057783105	compactly supported
0.9057749059	lebesgue measure
0.9057348656	bayesian inversion
0.9056147245	intrinsic volumes
0.9054385062	fourier transforms
0.9053304541	reproducing kernel hilbert
0.9048802823	structural breaks
0.9048610632	halfspace depth
0.9046762179	point process
0.9046660771	united states
0.9046145162	euclidean distance
0.9044701193	early stopping
0.9044076999	loss function
0.9043129632	maximum entropy
0.9041836528	langevin diffusion
0.9041533805	random variable
0.9039930281	kernel ridge regression
0.9039180513	point clouds
0.9036413768	factorial designs
0.9034762797	lower bounds
0.9033842883	sensitivity indices
0.9032181246	covariance functions
0.9030024838	linear programming
0.9029666963	expectation maximization
0.9028204188	upper bound
0.9028061056	survival analysis
0.9027763222	large deviation
0.9025472988	dimensionality reduction
0.9023638314	nearest neighbor
0.9022600344	error terms
0.9021636457	maximum likelihood estimator
0.9020571102	game theoretic
0.9020019656	gaussian mixtures
0.9019236688	filter bank
0.9018743581	phylogenetic trees
0.9016483850	record values
0.9015545750	bayes risk
0.9014456837	discretely observed
0.9013593903	regular variation
0.9012434508	edgeworth expansions
0.9010450553	locally stationary
0.9010234482	doubly robust
0.9007269690	poisson process
0.9007051104	change point
0.9006872100	linear mixed models
0.9005970670	vector quantization
0.9005279109	relu nets
0.9004665606	image processing
0.9003481283	precision matrices
0.9003464155	algebraic statistics
0.9003309643	spatially inhomogeneous
0.9002906486	brownian semistationary
0.9000749380	minimax rates
0.9000650523	contingency tables
0.9000174001	stein's lemma
0.9000151452	small area
0.8999327584	standard deviation
0.8998694933	le cam
0.8998261625	ising model
0.8997701956	higher order
0.8997342117	convex cone
0.8997026961	upper bounds
0.8993827928	probability distributions
0.8992941128	proper scoring rules
0.8992771404	rare events
0.8991306215	elastic net
0.8990918358	correlation matrices
0.8990006309	interacting particle
0.8989097491	penalized regression
0.8987977754	random matrices
0.8987793376	key words
0.8983454839	species sampling
0.8983282128	long range dependent
0.8982349323	information theoretic
0.8981909289	spike train
0.8980928754	data analysis
0.8980394305	sliding blocks
0.8979879100	test statistic
0.8977800314	em algorithm
0.8977629625	operator norm
0.8976837276	large scale
0.8976178808	spot volatility
0.8975903557	random graph
0.8975169427	discovery rate
0.8974844837	probability theory
0.8974045689	discretely sampled
0.8973139203	signal detection
0.8972585764	quickest change detection
0.8972435618	summary statistics
0.8969938392	data augmentation
0.8969604778	missing data
0.8969423542	coordinate ascent
0.8969234257	banach space
0.8967291377	normalizing constants
0.8965094783	unit roots
0.8963837865	laplace transform
0.8963143205	doubly stochastic
0.8962757252	hill estimator
0.8961866572	fourth moment
0.8961600988	scoring functions
0.8961249802	piecewise deterministic markov
0.8960379404	sparse pca
0.8960327896	measurement errors
0.8959640347	linear regression
0.8959413631	max stable
0.8959299763	tail dependence
0.8958550789	variational bayes
0.8957980246	absolute deviation
0.8957692377	posterior contraction
0.8955511951	pickands dependence
0.8953604415	competing risks
0.8953172782	partially linear
0.8952539104	closed form
0.8952438441	moderate deviations
0.8952007031	change points
0.8950737120	fractionally integrated
0.8949393339	bahadur representation
0.8948976238	stochastic volatility
0.8948323058	le cam's
0.8946946040	conjugate priors
0.8945630915	lower bound
0.8944333822	fisher information matrix
0.8944127518	conformal prediction
0.8943752283	parameter estimation
0.8941426784	sparse recovery
0.8939727613	jeffreys prior
0.8938963177	partial differential equation
0.8937270596	linear discriminant analysis
0.8935907846	policy evaluation
0.8934980215	branching process
0.8934841337	besov spaces
0.8932987079	outlier detection
0.8932590883	fourth moments
0.8932149724	chaos expansion
0.8931952448	majority voting
0.8931128571	optimal design
0.8930997631	randomized experiments
0.8930795478	local asymptotic normality
0.8929866043	mass spectrometry
0.8929774254	hidden markov model
0.8929390770	convex programming
0.8929352201	distributionally robust optimization
0.8929008112	control variates
0.8928061011	false discoveries
0.8926581690	renewal processes
0.8925920358	supremum norm
0.8924941553	public health
0.8924360334	hypergeometric functions
0.8924316612	elliptically contoured
0.8923417051	convergence rates
0.8923215190	cox model
0.8922607985	discriminant analysis
0.8921353219	directed acyclic graph
0.8920268526	wiener process
0.8920250796	real world
0.8919400059	graph laplacian
0.8918751614	pairwise comparisons
0.8917773522	noninformative priors
0.8917228557	selective inference
0.8916897231	pareto distribution
0.8914434043	integer valued
0.8914320250	convex relaxation
0.8911656360	periodically correlated
0.8911526313	hawkes process
0.8910909315	betti numbers
0.8907558027	coordinate descent
0.8906281620	sequential monte carlo
0.8905688952	singular values
0.8904802604	long term
0.8904504659	hellinger distance
0.8903910006	filtered derivative
0.8903541417	electronic commerce
0.8903357289	empirical processes
0.8903309948	global sensitivity analysis
0.8903070237	partially identified
0.8899035233	largest eigenvalue
0.8898720084	thompson sampling
0.8898518071	stock market
0.8898370061	incomplete lineage sorting
0.8897224148	spearman's rho
0.8897082836	stein's unbiased risk
0.8897068970	random censorship
0.8892583852	adaptive sensing
0.8892263837	bregman divergences
0.8892029551	free energy
0.8891059144	graph laplacians
0.8890474270	convex bodies
0.8889808391	wasserstein barycenters
0.8889788552	main effects
0.8888815464	stein's method
0.8888595201	stratified random sampling
0.8888325983	covariance estimation
0.8887023219	familywise error rate
0.8886342765	branching processes
0.8886309565	data assimilation
0.8886214293	network tomography
0.8885309419	semiparametrically efficient
0.8885258144	tikhonov regularization
0.8884905609	rademacher complexity
0.8884664315	convex sets
0.8883024358	fusion center
0.8880740654	censored data
0.8880256244	limit theorems
0.8879636464	decision maker
0.8879215538	orthogonal polynomials
0.8877302416	gaussian graphical model
0.8876981113	conjugate gradient
0.8876168896	multiplier bootstrap
0.8876147803	brain connectivity
0.8875500045	ultrahigh dimensional
0.8874594320	naive bayes
0.8873390800	detection delay
0.8872390150	inclusion probabilities
0.8869084608	hinge loss
0.8866904241	covariance structure
0.8866000789	fractional brownian
0.8865942689	binary segmentation
0.8863019739	stopping rules
0.8862079516	preliminary test
0.8860635147	saddle points
0.8860227234	square integrable
0.8859956678	metric space
0.8859193610	composite likelihood
0.8859082219	spiked wigner
0.8858307121	nonconvex optimization
0.8857851333	langevin monte carlo
0.8856869945	stochastic approximation
0.8855526425	data streams
0.8853883900	stochastic dominance
0.8853719610	change detection
0.8853621508	gibbs sampler
0.8849416859	submatrix localization
0.8848980636	differential entropy
0.8847129854	survival data
0.8846819467	restricted eigenvalue
0.8845408328	cross validation
0.8842423419	tensor completion
0.8841589804	random variables
0.8841524413	regret bound
0.8839066864	partial sum
0.8838154672	bilinear forms
0.8837318797	unbiased estimators
0.8836034122	false positives
0.8835936907	weakly dependent
0.8835914525	profile likelihood
0.8835444998	normal distributions
0.8833824487	inverse regression
0.8833691523	data science
0.8831794523	impulse response
0.8831605054	functional data
0.8830495531	nuisance parameter
0.8830178097	cube root
0.8828175765	mediation analysis
0.8827301876	hypergeometric distribution
0.8826613171	latin hypercube
0.8826361620	odds ratio
0.8824463923	decision making
0.8824225438	saddle point
0.8823195354	bayesian predictive densities
0.8822139180	restricted isometry property
0.8822072644	markov process
0.8819824029	generalization error
0.8818798904	infinite divisibility
0.8818243854	randomly reinforced
0.8817388252	synthetic data
0.8817048942	gaussian process regression
0.8817044435	ranked set sampling
0.8816139063	loss functions
0.8815829687	gold standard
0.8815658881	scan statistic
0.8815163721	planted clique
0.8814002319	bregman divergence
0.8813960615	extreme values
0.8812858896	incomplete rankings
0.8812727556	scoring rules
0.8812569889	asset pricing
0.8812308414	positive semidefinite
0.8812034409	multinomial logit
0.8809529277	stopping rule
0.8808231055	computationally tractable
0.8807767961	log concave
0.8807329516	alternating minimization
0.8807136259	gaussian random field
0.8805939667	error bounds
0.8801059311	random design
0.8800015828	random walk metropolis
0.8799594065	sobol indices
0.8799386191	asset prices
0.8798796395	distribution free
0.8798614762	markov processes
0.8798449144	latent variables
0.8797769346	unmeasured confounding
0.8797221417	simple random sampling
0.8796373280	shrinkage priors
0.8796087495	heat kernel
0.8796032206	factor loadings
0.8795729359	years ago
0.8795514784	ancestral graphs
0.8795331761	gene trees
0.8795317375	matrix factorization
0.8794952621	compares favorably
0.8794127607	hurst parameter
0.8793703523	limit laws
0.8792548807	group testing
0.8792506298	real line
0.8792211829	real valued
0.8791971003	waiting times
0.8791397790	permutation tests
0.8791228445	extremal index
0.8790888081	kl divergence
0.8790854452	objective priors
0.8790042411	theoretical foundations
0.8789251603	determinantal point processes
0.8788680735	domination number
0.8787836038	chi squared
0.8787194094	positive definiteness
0.8786735183	reject option
0.8785957004	differential equation
0.8784660740	taylor expansion
0.8783907616	serial dependence
0.8781703941	dot product graphs
0.8780808992	wavelet coefficients
0.8780460713	positive definite
0.8779833093	group lasso
0.8778731464	semiparametric models
0.8777522705	error rate
0.8776008418	asymptotic optimality
0.8775503151	gaussian mixture
0.8775108376	stratified sampling
0.8773958691	benford behavior
0.8773861496	portmanteau test
0.8772730815	cumulative sum
0.8772208339	applied mathematics
0.8772133022	generative adversarial networks
0.8772022409	shortest path
0.8771783561	piecewise constant
0.8771335981	risk measure
0.8770764727	lepski's method
0.8769832101	arrival times
0.8769792273	reversible markov chains
0.8769686863	causal discovery
0.8769349754	markov equivalence
0.8769065998	signal recovery
0.8767971006	belief propagation
0.8767505868	sampling schemes
0.8767286903	information criteria
0.8766788029	undirected graphs
0.8766055728	contingency table
0.8765817828	multivariate normal
0.8765770524	context tree
0.8765693875	bandit problems
0.8763921517	benign overfitting
0.8761932336	wasserstein metric
0.8761728489	explanatory variables
0.8761099122	heat equation
0.8760908567	semicircle law
0.8760874585	toric ideal
0.8757791451	elliptically symmetric
0.8756733516	double descent
0.8754671239	ground truth
0.8753225475	false positive
0.8751708246	wavelet thresholding
0.8751534075	poorly understood
0.8750556019	besov bodies
0.8750338635	internet traffic
0.8750127965	renyi entropy
0.8749543641	minimum contrast
0.8749205367	invariance principle
0.8747727807	partial differential equations
0.8744811857	contiguous alternatives
0.8744588548	magnetic resonance imaging
0.8742913024	skew normal
0.8742685903	trek separation
0.8742480855	quantile function
0.8742419446	multiple hypothesis testing
0.8742393321	objective function
0.8742122401	bayesian network
0.8741766835	theoretical justification
0.8740269109	latent variable
0.8739889972	minimax optimal
0.8739071576	variational approximation
0.8737818535	hypothesis tests
0.8737512229	ergodic capacity
0.8736637645	multiclass classification
0.8735886431	stock returns
0.8734889639	covariance operators
0.8734316055	low dimensional
0.8734239990	cumulative incidence
0.8734222943	archimedean copula
0.8734079151	asymptotic efficiency
0.8733551519	asymptotically optimal
0.8733001123	signal strength
0.8732811399	scatter matrix
0.8732785461	absolute continuity
0.8732675983	nonlinear regression
0.8732054313	von mises
0.8731947557	speech recognition
0.8731508849	posterior concentration
0.8731185356	dictionary learning
0.8730060370	deep neural network
0.8729034575	signed rank
0.8728385171	roughly speaking
0.8728365308	graphon estimation
0.8727755025	spin glass
0.8726800707	logarithmic regret
0.8726664163	state space
0.8725526392	bandwidth selection
0.8725121642	hidden markov
0.8723874856	minimum aberration
0.8723501267	ad hoc
0.8723272092	component analysis
0.8722537298	factor models
0.8721850700	bayes estimators
0.8721342434	whittle likelihood
0.8721143366	seemingly unrelated
0.8720921774	sample splitting
0.8720713121	estimating equations
0.8718252249	lasso estimator
0.8718062898	statistical theory
0.8716774062	geodesic distance
0.8716418230	min max
0.8716127407	critical points
0.8714059863	block bootstrap
0.8714008470	stochastic differential
0.8713925617	exchangeable arrays
0.8712331038	dependence measures
0.8711999128	knockoff filter
0.8711798382	spectral projectors
0.8708612202	decision rules
0.8706774902	option pricing
0.8706294887	model checking
0.8706196415	bahadur efficiency
0.8705817372	bipartite graphs
0.8705808233	serially correlated
0.8705731893	stable law
0.8703877220	blomqvist's beta
0.8703861081	game theory
0.8701911833	large deviation principle
0.8700455107	vc dimension
0.8700222432	subset selection
0.8699807133	preferential attachment
0.8698968335	noninformative prior
0.8698536996	autoregressive models
0.8698501953	directed acyclic
0.8697718408	linear models
0.8697649913	query complexity
0.8695924215	triangular array
0.8695853368	decision trees
0.8695230283	quickest detection
0.8694601618	robust inference
0.8694328725	functional data analysis
0.8694063274	simulated data
0.8694040006	debiased lasso
0.8693669384	distance covariance
0.8693545898	gaussian random fields
0.8692416773	multidimensional scaling
0.8692355682	generalized pareto
0.8692295235	random effects
0.8692161364	kernel estimators
0.8692133393	shapley effects
0.8691703259	interaction effects
0.8690912043	massive data
0.8687703342	individualized treatment
0.8687321961	computationally efficient
0.8686826110	financial markets
0.8682109569	multiresolution analysis
0.8680987700	absolutely continuous
0.8680572542	quotient space
0.8679850283	gaussian mixture models
0.8678351966	dynamic programming
0.8678231163	generating function
0.8677026287	network analysis
0.8676660272	cox regression
0.8676525507	steady state
0.8675385568	kullback leibler divergence
0.8674936968	kernel regression
0.8672673314	hurst exponent
0.8672302116	von neumann
0.8672214357	countably infinite
0.8671712168	autoregressive model
0.8671707250	spike trains
0.8671370065	posterior propriety
0.8670610819	statistical inferences
0.8669456031	control charts
0.8668570331	repeated measurements
0.8668379827	cholesky decomposition
0.8667986978	blind source separation
0.8667108350	strictly stationary
0.8665267837	cox proportional hazards
0.8665161951	tangent space
0.8665149054	branch lengths
0.8665124935	generative models
0.8665075762	metropolis adjusted langevin
0.8664826480	squared error
0.8664239573	finite dimensional
0.8662120668	asymptotic normality
0.8658796385	akaike's information
0.8658573820	distance correlation
0.8658540483	subgraph counts
0.8658317395	structure learning
0.8658005685	stationary ergodic
0.8656362801	asset price
0.8655476737	long range dependence
0.8655106352	triangular arrays
0.8653465221	influence functions
0.8653315512	measurement noise
0.8653013045	acyclic graphs
0.8652893853	bias corrected
0.8652861920	bandit problem
0.8652758244	linear fractional stable
0.8652475838	convergence rate
0.8652433241	companion paper
0.8651533257	degree distribution
0.8651102807	random vector
0.8650546030	minimum description length
0.8649825171	directed graphs
0.8649769743	asymptotically minimax
0.8649230153	pac bayesian
0.8648245940	confidence region
0.8648134002	cumulative distribution functions
0.8647768737	renyi divergence
0.8647650910	ordinal patterns
0.8647477599	fisher metric
0.8647277507	linear combination
0.8646951818	evy process
0.8643511595	post selection inference
0.8643296646	blind deconvolution
0.8642932309	rare event
0.8642541519	oracle inequality
0.8639271999	adaptive minimax
0.8638288681	statistical analysis
0.8638286007	stock exchange
0.8637277852	explanatory variable
0.8637070653	error exponent
0.8635915154	point patterns
0.8634911173	fractional ornstein uhlenbeck
0.8634645464	high dimensional
0.8634388336	high dimensionality
0.8634134447	regression function
0.8634020288	credit risk
0.8633319004	multivariate anal
0.8632503716	score function
0.8632454723	regression model
0.8631100181	piecewise polynomial
0.8630218217	semiparametric estimation
0.8630134264	bias reduction
0.8629251848	mixed membership
0.8629237124	empirical risk minimizer
0.8628613200	key ingredient
0.8628482343	infinite dimensional
0.8628199452	wishart ensemble
0.8627950929	optimization problems
0.8625996942	hazard rates
0.8625863574	average run length
0.8625786390	recommender systems
0.8624228634	doa estimation
0.8622449803	level sets
0.8621869600	excess risk
0.8621242285	local differential privacy
0.8620636095	standard errors
0.8619965079	local linear
0.8619811556	reversible markov chain
0.8618881394	quantum physics
0.8618847789	probability measures
0.8617535848	cholesky factor
0.8616342661	baseline hazard
0.8616299468	stein discrepancy
0.8615973408	sample size
0.8615564875	convex hulls
0.8615470007	false alarms
0.8614589724	evolutionary trees
0.8612634335	prior information
0.8612518459	computationally cheap
0.8612338254	heavy tail
0.8611563767	distance multivariance
0.8611531759	computational biology
0.8610892615	local rademacher complexities
0.8609659413	longitudinal data
0.8609460517	unbiased estimation
0.8609299036	excursion set
0.8607656188	divergence measures
0.8607249233	optimization problem
0.8607092831	auxiliary variable
0.8606978393	sobolev spaces
0.8606514776	data mining
0.8604848553	magnetic resonance
0.8604154703	regret bounds
0.8603261297	random elements
0.8602982708	lindley distribution
0.8602678209	irregularly spaced
0.8602633388	directed graph
0.8602235471	quantum mechanics
0.8602226062	additive models
0.8601969278	alphabet size
0.8601877271	pastur law
0.8601506124	sample covariance matrices
0.8601083086	stochastic differential equation
0.8598112291	post model selection
0.8597613559	jump activity
0.8596975416	parametric inference
0.8596378142	canonical correlation analysis
0.8596269516	bayesian networks
0.8596061673	probability density functions
0.8595919416	long range
0.8593994119	gamma distribution
0.8591068276	regression models
0.8589355370	linear measurements
0.8589130513	empirical measures
0.8588902316	cumulative hazard
0.8588830172	objective functions
0.8588778042	adjustment sets
0.8588463917	linear inverse problems
0.8587957224	hurst index
0.8587794502	social science
0.8587134828	sobolev space
0.8587087236	moving averages
0.8587065796	hierarchical clustering
0.8586881455	variance reduction
0.8586743874	expectation maximisation
0.8585948767	level set
0.8585702828	sample complexity
0.8584539400	test statistics
0.8582593525	bayesian approach
0.8582352455	image denoising
0.8582082080	continuously differentiable
0.8581357882	latent factor
0.8580052032	fully connected
0.8579871277	brain imaging
0.8579625397	` `
0.8578935010	semiparametric efficiency
0.8578851852	relu networks
0.8578386702	spiked eigenvalues
0.8577815406	linear systems
0.8577703933	bayes estimator
0.8576841874	gamma distributions
0.8576154934	contamination model
0.8574346812	quantum state
0.8574124614	numerical integration
0.8574085382	proportional hazard
0.8573444494	sparse vectors
0.8573371906	learning rates
0.8573066208	shrinkage estimators
0.8572898022	poisson processes
0.8572262414	correlation function
0.8571670299	moment generating function
0.8570378550	state evolution
0.8570189053	identically distributed
0.8568897284	convex regression
0.8568437993	extremal dependence
0.8568190234	riemannian metric
0.8568142377	optimal stopping
0.8568000236	vector valued
0.8566689131	unbiased risk estimate
0.8566309505	estimating functions
0.8565560155	chi square
0.8564956858	significance level
0.8564331769	multinomial distribution
0.8564295484	confidence band
0.8563697323	compositional data
0.8563088414	moment condition
0.8561781342	conditional quantile
0.8560470734	factor model
0.8557126013	peer review
0.8557092982	condition number
0.8555568846	autoregressive process
0.8555476351	meta analysis
0.8555371177	species tree
0.8555263884	gaussian priors
0.8554782098	overlap gap property
0.8554698330	quasi likelihood
0.8553832076	strongly convex
0.8553752660	generalized linear model
0.8552978853	infectious disease
0.8552697334	transition probabilities
0.8551683843	stable distribution
0.8551287048	likelihood function
0.8550923841	geometric ergodicity
0.8550603280	autoregressive moving average
0.8550117569	shape restrictions
0.8549816439	additive noise
0.8549737311	principal component scores
0.8549606638	intensively studied
0.8549537042	geometrically ergodic
0.8549261490	reversible jump
0.8549141984	poisson distribution
0.8549045505	testing problems
0.8548655953	principal components analysis
0.8548440823	block thresholding
0.8547481683	convex functions
0.8547333757	fano's inequality
0.8546008103	data driven
0.8545242343	permutation test
0.8544447221	bayesian model selection
0.8544148431	easily verifiable
0.8544032328	initial condition
0.8544016167	prediction intervals
0.8543507879	interval censoring
0.8542492092	local polynomial
0.8542341522	familywise error
0.8542067531	risk minimization
0.8541030775	activation function
0.8540442377	hausdorff distance
0.8540360488	conditional probability
0.8540263476	random measures
0.8539752357	asymptotic independence
0.8539305195	post change
0.8538231044	categorical data
0.8537922660	sparse networks
0.8536326060	recent developments
0.8535997109	categorical variables
0.8535500088	white gaussian noise
0.8535185078	optimality criteria
0.8534723356	illustrative purposes
0.8534699821	nonparametric bayesian
0.8533726340	connected components
0.8532728711	levy processes
0.8532222555	robust estimation
0.8531668158	binomial distribution
0.8531612986	computational burden
0.8531502437	vector autoregressive
0.8531144132	identity testing
0.8530885622	garch models
0.8530750874	current status data
0.8529921108	prediction error
0.8529562153	multivariate distributions
0.8529552894	varying coefficient
0.8529254554	wishart distributions
0.8528943381	auto regressive
0.8528440782	fuzzy sets
0.8528316062	chain graph
0.8527401885	binary classification
0.8527348059	likelihood inference
0.8526233049	huber regression
0.8525969731	uniform convergence
0.8525523407	van der
0.8525007896	generic chaining
0.8524525466	exact recovery
0.8523583580	restricted isometry
0.8523396367	dependent random variables
0.8522603445	archimedean copulas
0.8522309664	berkson errors
0.8521369918	likelihood ratio statistic
0.8521153046	wishart matrix
0.8521087679	normalizing constant
0.8520723949	excursion sets
0.8520613074	shape parameter
0.8520254345	consistently estimate
0.8519496142	light tailed
0.8518439163	broadly applicable
0.8518324130	frequentist coverage
0.8517491912	takes place
0.8515406623	arma models
0.8514977412	log likelihood
0.8513258632	diffusion process
0.8513084395	jump diffusion
0.8512372889	neighborhood selection
0.8510938473	financial assets
0.8510438460	random effect
0.8509363742	compact sets
0.8508505747	excess mass
0.8507793565	mixing distribution
0.8507240769	high frequency data
0.8505641864	conditional moment
0.8505334537	rate distortion
0.8504545129	sparse regression
0.8503924486	wishart distribution
0.8503556765	asset returns
0.8502954915	experimental designs
0.8502588030	variational approximations
0.8501458584	multiple testing procedures
0.8500948736	covariance function
0.8499799520	weibull distribution
0.8499482480	globally optimal
0.8499097852	semi parametric
0.8498176871	multi armed bandit
0.8497713605	observational studies
0.8497687593	dna sequences
0.8496775294	hidden layer
0.8495643006	spectral estimation
0.8495495866	strongly mixing
0.8495268453	normal approximation
0.8495227115	hilbert space valued
0.8494852174	stochastic orderings
0.8494792019	l1 penalized
0.8493406853	topological summaries
0.8493320405	holonomic gradient method
0.8492813123	precision matrix
0.8492728547	easily implementable
0.8492024197	ambient dimension
0.8491957346	stochastic ordering
0.8491850566	biased coin
0.8491024797	beta distribution
0.8490937777	functional principal components
0.8490701871	group action
0.8490234507	convex combinations
0.8489391874	bernstein von mises
0.8489189829	hamiltonian monte carlo
0.8488241039	enyi divergence
0.8487893096	information criterion
0.8487570120	cauchy distribution
0.8486147810	composite hypotheses
0.8486090035	dirichlet processes
0.8484861553	optimal bandwidth
0.8484480483	causal effect
0.8484373778	single index
0.8484307884	parameter vector
0.8484222367	generalized bayes
0.8483593964	partial correlations
0.8483139349	partial correlation
0.8482284281	integrated volatility
0.8482137099	carma processes
0.8481199234	polynomial regression
0.8480046659	statistical models
0.8479522010	large dimensional
0.8477499687	distribution function
0.8477353922	link functions
0.8474243711	point cloud
0.8473771262	covariate adjustment
0.8473220025	confidence set
0.8472827263	high order
0.8472629533	high frequency
0.8472573880	false discovery rate control
0.8472223972	semiparametric inference
0.8471115251	ultra high dimensional
0.8471040652	spectral gap
0.8468746194	latent space
0.8468250246	small ball
0.8467951061	quantum language
0.8467891183	indian buffet
0.8467828605	stationary process
0.8467362286	semiparametric regression
0.8467339419	quantum homodyne tomography
0.8467332428	square root lasso
0.8465331574	numerical methods
0.8464895858	scale mixture
0.8464211570	high dimensions
0.8463699961	additive gaussian noise
0.8463612572	heavy tailed
0.8463501372	ergodic diffusion processes
0.8463486952	surface area
0.8463429267	gram matrix
0.8463269547	multivariate normality
0.8462896286	semi supervised
0.8462630961	optimal designs
0.8462478018	regression trees
0.8462202306	spatially dependent
0.8461900061	empirical bayes posterior
0.8461848336	likelihood ratio tests
0.8461331869	likelihood estimator
0.8461092485	approximately sparse
0.8457945523	exponential distribution
0.8457684052	telegraph process
0.8457653070	bayesian statistics
0.8456651098	wright fisher
0.8456613526	convex geometry
0.8453855430	l1 norm
0.8453321531	oracle properties
0.8452043685	euclidean spaces
0.8451483908	stationary gaussian
0.8451174239	generative model
0.8450323068	binary response
0.8449797965	metropolis algorithm
0.8449385937	fractional factorial designs
0.8448992305	block model
0.8448043564	random coefficient
0.8446628508	black box
0.8445666239	smoothing splines
0.8445389663	probability measure
0.8444093318	shape constrained
0.8443413446	simultaneous inference
0.8442860251	posterior distribution
0.8442462053	influence function
0.8442022660	expected utility
0.8440487723	asymptotic variances
0.8440398775	real life
0.8439688227	missing values
0.8439624481	notoriously difficult
0.8438881376	latent structure
0.8438563473	quadratic variation
0.8438467514	correlation coefficients
0.8438233938	tail probabilities
0.8437066162	covariate adaptive randomization
0.8436375484	linear operator
0.8435235873	stochastic partial differential equations
0.8434713826	unlabeled data
0.8433582287	sufficient condition
0.8432120952	computational effort
0.8432074506	open source
0.8431949589	distribution functions
0.8430552375	pseudo likelihood
0.8430271422	asymptotic minimaxity
0.8429829763	hierarchical models
0.8429090218	model averaging
0.8428922623	detection problem
0.8427999261	piecewise polynomials
0.8426254414	instantaneous frequency
0.8425080592	greedy algorithm
0.8424676403	stieltjes transform
0.8424068872	lie group
0.8422262389	gaussian distributions
0.8422148530	quantum tomography
0.8421909862	power spectrum
0.8421426476	data processing
0.8419333329	exponential decay
0.8418706644	error probability
0.8418652760	posterior contraction rate
0.8418497999	euclidean space
0.8417654408	learning theory
0.8416202506	sequential change detection
0.8414897234	results extend
0.8414692495	interior point
0.8414569568	bahadur kiefer
0.8414539062	unit cube
0.8413573677	nonparametric instrumental
0.8413362040	graphical model
0.8412117315	predictive density
0.8410601521	prediction errors
0.8410238950	sparse signals
0.8409516129	indicator function
0.8408392923	correlation matrix
0.8407318468	marked point
0.8406638606	multistage sampling
0.8406524044	bootstrap methods
0.8404982800	dense subgraph
0.8404663897	besov balls
0.8404322298	probability mass function
0.8404259909	mcmc algorithms
0.8403331015	intensity functions
0.8403269399	case studies
0.8402808996	dirichlet process mixtures
0.8402064173	markov models
0.8402063657	markov bases
0.8401044294	data sets
0.8400046245	zonal polynomials
0.8399657197	main novelty
0.8398626541	partial differential
0.8398560753	additive model
0.8398486963	online learning
0.8398404178	np hard
0.8397869144	partial sums
0.8397452886	canonical correlation
0.8395407833	quasi maximum likelihood estimator
0.8395304771	ornstein uhlenbeck process
0.8394580335	persistent betti numbers
0.8394335810	scale invariant
0.8391987613	credible set
0.8391492068	minimax rate optimal
0.8390163625	regression coefficients
0.8389645109	data set
0.8388985485	soft thresholding
0.8388918292	pac bayes
0.8388761445	spectral methods
0.8388271874	smooth function
0.8388108180	local optima
0.8387905373	piece wise
0.8387666036	uniformly distributed
0.8385933686	multi scale
0.8384907221	credible intervals
0.8383546933	boundary crossing
0.8383537896	model selection consistency
0.8383336939	link function
0.8383128720	markov property
0.8382798149	adaptive lasso
0.8381959794	moment restrictions
0.8381272308	gene regulatory
0.8381159570	covariate balance
0.8380956338	response surface
0.8379707715	sparse signal
0.8379123522	temporal dependence
0.8379091381	diffusion maps
0.8378847582	latent factors
0.8378787196	covariance matrix estimation
0.8378226884	dependence measure
0.8377402484	chain graphs
0.8376512127	predictive densities
0.8376118022	continuous distributions
0.8376008539	minimization problem
0.8375925826	dose response
0.8375043024	cramer rao
0.8374426615	cusum test
0.8374215082	fourth order
0.8373661966	nonparametric inference
0.8373292459	joint distributions
0.8370823772	poisson noise
0.8370128363	shape constraints
0.8368563001	tuning parameter
0.8368459445	stochastic integrals
0.8366570931	optimal rates
0.8366304146	linear processes
0.8365886287	computationally demanding
0.8365410192	continuous functions
0.8364903696	hypotheses testing
0.8364704601	total variation denoising
0.8364444069	false rejections
0.8363921502	stock price
0.8363649910	error bound
0.8362253049	uniformity testing
0.8362049194	smoothed periodogram
0.8362040463	super resolution
0.8361518724	log gaussian cox
0.8360048113	kernel methods
0.8359170391	bayesian inverse problems
0.8356580923	rank tests
0.8356215919	critical values
0.8356174858	false null hypotheses
0.8355872139	penalty function
0.8355022385	wasserstein space
0.8354794997	function spaces
0.8354568758	stochastic newton
0.8354209616	information transfer
0.8353784792	multivariate gaussian
0.8353710935	olya tree
0.8353242633	random sets
0.8352809460	sequential decision
0.8352309998	moment inequalities
0.8352144563	fractional brownian motions
0.8351695796	uniform attachment
0.8351443389	realized volatility
0.8350581596	sufficient statistics
0.8350382456	empirical evidence
0.8350286077	multiple comparisons
0.8349791483	heteroscedastic regression
0.8348769481	count data
0.8348568312	slightly stronger
0.8346963860	pure jump
0.8346838087	worst case
0.8346580467	autocorrelation function
0.8346237415	batch means
0.8345329965	jensen shannon
0.8345245609	prior distributions
0.8344931878	minimax lower bounds
0.8343918141	generalized linear
0.8343807461	rotationally symmetric
0.8343492558	saturated designs
0.8343464899	sequential analysis
0.8342979626	dually flat
0.8340835167	nuclear norm minimization
0.8339295242	medical imaging
0.8338953042	proposed test
0.8337059871	length biased
0.8336227682	langevin equation
0.8336181037	spiked covariance model
0.8335818955	quadratic loss
0.8335686740	log concavity
0.8334709105	classification problems
0.8333710289	robust statistics
0.8332654813	treatment assignment
0.8332293169	dispersion models
0.8331828062	spiked tensor
0.8331359885	garch processes
0.8331148506	set valued
0.8331050737	orlicz norm
0.8330740473	synthetic datasets
0.8329246231	statistical framework
0.8329228671	learning algorithm
0.8328674935	sample sizes
0.8328588905	kolmogorov smirnov
0.8328376043	characteristic functions
0.8328155602	false negatives
0.8327108590	indirect inference
0.8326909242	conditional growth charts
0.8325968374	suitably chosen
0.8325164183	probability distribution
0.8324132635	density ratio
0.8323342066	convex function
0.8323163939	affine invariant
0.8322991531	harris recurrent
0.8322714751	existing tests
0.8320208477	linear predictor
0.8319814940	limit theorem
0.8318544273	network models
0.8317636301	james stein
0.8317162085	stochastic gradients
0.8316716227	lower dimensional
0.8316112697	poisson point process
0.8315518553	computationally expensive
0.8315116568	compound decision
0.8315071391	perturbation theory
0.8314431822	density estimators
0.8314163738	random geometric graph
0.8313861390	received considerable
0.8313851365	statistical query
0.8311879110	quickest change
0.8311750655	reaction diffusion
0.8310908233	sample covariance matrix
0.8309592542	mathematical statistics
0.8309480499	markov random field
0.8308763975	false negative
0.8308234679	heterogeneous treatment effects
0.8308214435	longitudinal studies
0.8307978354	regression problems
0.8307495772	hilbert schmidt
0.8305455634	martingale difference
0.8305084151	model misspecification
0.8304846528	power spectra
0.8304688440	markov switching
0.8302758494	conditional probabilities
0.8302715624	improper prior
0.8301192267	measurement matrix
0.8300991595	smoothing parameter
0.8300775697	pairwise comparison
0.8299809780	high dimensional data
0.8299576257	error exponents
0.8298883149	contraction rates
0.8298616721	cure rate
0.8298613936	fold cross validation
0.8298505783	mutually independent
0.8298419576	cramer von mises
0.8298120248	closely related
0.8295187957	spatio temporal
0.8295105198	uniformly bounded
0.8294200790	minimax theory
0.8292012758	sparse linear regression
0.8290783370	asymptotic equivalence
0.8289906388	sequential tests
0.8289620750	stochastic orders
0.8289481270	quadratic risk
0.8289072424	benjamini hochberg
0.8288416215	deviation bounds
0.8288119006	space filling
0.8288071834	interval estimation
0.8287944498	locally stationary processes
0.8287929310	weak dependence
0.8287355118	shrinkage estimation
0.8287185508	normed division algebras
0.8287169035	mcmc methods
0.8285877578	linear functionals
0.8285391460	perform poorly
0.8284105968	moderate sample sizes
0.8284010785	van der vaart
0.8283438748	selection procedures
0.8282886912	type ii
0.8282523698	indirect observations
0.8281546510	neyman pearson
0.8280079730	spiked covariance
0.8279909755	optimality criterion
0.8276887111	independence testing
0.8276773168	perturbation bounds
0.8276359430	kernel estimator
0.8275247933	posterior concentration rates
0.8274433742	multiple hypotheses
0.8274297658	empirical spectral distribution
0.8274161241	partial information
0.8273682792	dependent data
0.8273581254	dependence structures
0.8271754589	panel data models
0.8270944114	metropolis hastings
0.8269756976	algebraic varieties
0.8269514844	smooth functions
0.8268918188	mixed graphs
0.8268384669	sparsity pattern
0.8267600057	nonparametric estimation
0.8266919482	diffusion coefficient
0.8266651190	deconvolution problem
0.8266552090	cost function
0.8266489197	structural break
0.8266147118	posterior contraction rates
0.8266107925	moment conditions
0.8265845269	computationally feasible
0.8265004283	minimum variance
0.8264710506	conditional distributions
0.8264570941	rank correlation
0.8264511936	inverse gaussian
0.8264325709	markov jump processes
0.8263810123	rejection sampling
0.8262839936	classification problem
0.8262440460	bounded variation
0.8261921194	composite likelihoods
0.8261610393	asymptotic variance
0.8261606331	statistical evidence
0.8261476894	strongly consistent
0.8261370937	correlation functions
0.8261342420	langevin diffusions
0.8260962550	gaussian measures
0.8260709681	folded concave
0.8260021536	recent advances
0.8259556891	general theory
0.8259451183	regularization methods
0.8259021397	generalization ability
0.8258845647	low degree
0.8257631558	sample means
0.8256416413	gaussian approximation
0.8255812271	matrix recovery
0.8255035669	proposed procedures
0.8253648583	conditionally conjugate
0.8253569753	misspecified models
0.8253327139	whittle estimator
0.8252782856	hypothesis test
0.8252184861	sufficient statistic
0.8250930387	bayesian procedures
0.8250349506	inference problems
0.8248734478	multiplicative noise
0.8248264223	concentration inequality
0.8247234241	robust regression
0.8247135055	social sciences
0.8246557615	measurable functions
0.8246420280	smooth backfitting
0.8245725167	weight function
0.8245723732	clustering algorithm
0.8245525703	absolutely regular
0.8245101078	scale parameter
0.8244202710	stable processes
0.8243021682	exact inference
0.8242893967	newly developed
0.8242442739	valid inference
0.8241544418	stochastic resonance
0.8241134137	invariance principles
0.8240316329	density functions
0.8238349009	strict stationarity
0.8237268198	bandit algorithms
0.8236842268	strictly convex
0.8236787653	piecewise linear
0.8236469762	learning algorithms
0.8236233540	design points
0.8234120853	asymptotic properties
0.8234027375	improper priors
0.8233481233	random coefficients
0.8233017201	spatial sign covariance
0.8232699461	completely random measures
0.8232583836	scoring function
0.8231991021	counter examples
0.8231829565	step ahead
0.8231045434	conditionally independent
0.8230458981	approximate bayesian
0.8230251231	asymptotically normal
0.8230225583	echet means
0.8229956421	information measures
0.8229902866	minimax risk
0.8229631917	proper scoring
0.8228342419	regression coefficient
0.8228333770	computational cost
0.8227666369	probability density function
0.8225764153	newly defined
0.8225332087	modal regression
0.8225123668	void size
0.8224674039	hypothesis testing problem
0.8224647846	saddlepoint approximation
0.8224381023	sparse precision matrix
0.8224034025	efficient algorithms
0.8223216364	theoretical foundation
0.8222344909	independence screening
0.8222283571	training samples
0.8222104667	asymptotic power
0.8221645205	finite population
0.8220586448	semi definite
0.8220460291	cluster analysis
0.8220283283	multivariate regression
0.8219853243	confidence sequences
0.8216944519	hermite polynomials
0.8216803094	nonparametric density estimation
0.8216629573	covariance parameters
0.8215281848	convex set
0.8215013248	survival function
0.8214325514	ornstein uhlenbeck processes
0.8214297981	alternative hypothesis
0.8214225656	counting processes
0.8214205109	orthogonal array
0.8213774835	generalized inverse
0.8212936041	low frequency
0.8211641806	current status
0.8211336120	selection procedure
0.8210112476	low rank matrix recovery
0.8209705573	nonparametric density
0.8209367195	spanning tree
0.8208661469	nonconcave penalized likelihood
0.8207477102	bayesian variable selection
0.8207117277	smoothness classes
0.8207040125	degree corrected
0.8206903822	type test
0.8206290962	laplace distribution
0.8206055004	kernel density estimator
0.8205714185	illustrative examples
0.8205659871	local alternatives
0.8204595167	rank based
0.8204287306	particle filtering
0.8202712885	ornstein uhlenbeck
0.8201793665	fractal dimension
0.8201481706	observation driven
0.8200277134	adaptive estimation
0.8199952521	input output
0.8199245560	asymptotically exact
0.8198455794	stress strength
0.8198413495	regression adjustment
0.8197778702	low rank matrix
0.8197704299	small sample
0.8197624741	optimal transportation
0.8197501114	posterior convergence rates
0.8196843731	accept reject
0.8195230332	affine equivariant
0.8194658622	sparsity inducing
0.8194145105	information matrix
0.8193847852	noise level
0.8193642959	adjacency matrix
0.8193184090	moderately large
0.8192493710	genomic data
0.8192385169	multivariate normal distribution
0.8191410955	cross validated
0.8191368150	finite mixture models
0.8191195049	besov classes
0.8191103087	chinese restaurant process
0.8190812094	local asymptotic mixed normality
0.8190742368	empirical beta copula
0.8190414338	sampling designs
0.8190324516	user friendly
0.8190037738	multi task
0.8189192433	natural numbers
0.8188403228	center outward
0.8186347860	parametric rate
0.8186285939	nearest neighbour
0.8186187724	gaussian errors
0.8185357401	mis specification
0.8185205253	finite alphabet
0.8185041108	variance estimator
0.8184517922	special attention
0.8183795828	multiple regression
0.8183196593	approximation error
0.8183091851	armed bandit problem
0.8182061625	generalized lasso
0.8181496314	post hoc
0.8180813927	ergodic diffusions
0.8180776461	sample space
0.8180444203	strong approximation
0.8179708334	markov properties
0.8178512211	coverage probability
0.8178497913	degree corrected block
0.8177746439	hawkes processes
0.8176503150	optimal sequential
0.8176411241	independent component
0.8175512652	correlation structure
0.8175101177	marshall olkin
0.8174371427	statistical modeling
0.8172881042	markov basis
0.8172479684	limiting distribution
0.8172155476	penalized estimators
0.8171317388	statistical learning theory
0.8170075005	random partitions
0.8169568740	function classes
0.8169482535	hidden regular variation
0.8168685801	cramer rao bound
0.8168511555	efficiency gains
0.8168468930	likelihood estimation
0.8168091983	wide applicability
0.8167573057	langevin algorithm
0.8167098201	observed variables
0.8166313204	convolution theorem
0.8165523427	proportional odds
0.8165451194	singular subspaces
0.8165280877	theoretical findings
0.8164791285	correction term
0.8164456018	monotone functions
0.8164448061	erdos renyi
0.8164291479	close connection
0.8164252987	fixed effects
0.8164041175	canonical correlations
0.8163519160	gaussian random
0.8163253523	posterior probability
0.8162959985	jump size
0.8162684439	hermite rank
0.8162210684	high throughput
0.8161954700	positive integer
0.8160592732	bernstein type
0.8160497522	nuisance functions
0.8160488729	locally private
0.8160218968	feynman kac
0.8158531830	linear regression models
0.8157323235	fairly general
0.8157267636	low rank tensor
0.8157146142	rosenblatt process
0.8156655341	undirected graphical models
0.8156438814	hazard function
0.8152688008	testing procedures
0.8152411526	density level sets
0.8151897144	estimation error
0.8151780758	shiryaev roberts
0.8151455805	bootstrap procedure
0.8151199061	block structure
0.8151121039	fourier analysis
0.8150656975	equi energy sampler
0.8149673644	max min
0.8149490662	random sampling
0.8148606958	sufficient conditions
0.8147312078	parametric models
0.8146424473	kernel density estimators
0.8146348917	censored survival data
0.8146265710	minimum distance
0.8144519726	risk measures
0.8141179174	short memory
0.8139012431	open problems
0.8138637614	entropy estimation
0.8138388284	er rao
0.8138255447	multi dimensional
0.8137845903	polynomial chaos
0.8137801332	unknown parameter
0.8137258978	orthonormal basis
0.8136458245	wavelet estimator
0.8136415447	clustering algorithms
0.8136198901	integrated squared error
0.8135705312	pitman yor
0.8134236400	regression setting
0.8133944531	building block
0.8133900652	rate optimal
0.8133848597	single trajectory
0.8133409994	standard gaussian
0.8133407825	x_ ij
0.8132982151	ensemble kalman filter
0.8132711933	star shaped
0.8132457981	supervised classification
0.8131933099	low rank matrix estimation
0.8130774992	half line
0.8129965588	excellent performance
0.8129836096	symmetric distributions
0.8129327331	main contribution
0.8128981739	latent process
0.8128921762	wrapped cauchy
0.8128476361	communication constraints
0.8127811146	penalized maximum likelihood
0.8127120086	marginal distribution
0.8125940345	small noise
0.8125051551	random noise
0.8124432674	long run
0.8123244774	stable distributions
0.8122607085	stochastic recurrence
0.8122560129	asymptotic results
0.8121750549	microarray data
0.8120543916	mixed level
0.8119874792	random projections
0.8119366250	undirected graphical
0.8118117985	computational complexity
0.8118000341	counting process
0.8117490432	high dimension
0.8115874085	moving block bootstrap
0.8115531990	computational challenges
0.8115188903	noisy data
0.8114028266	vice versa
0.8111774423	sample compression
0.8110454457	hilbert valued
0.8109164631	incomplete data
0.8108785275	bayesian posterior
0.8108500905	density deconvolution
0.8108338457	expected length
0.8108198962	variance estimators
0.8107386728	variance estimation
0.8106170504	considerable attention
0.8105712008	empirical risk
0.8105283302	parallel systems
0.8104606360	gaussian process prior
0.8103493027	measurable space
0.8102504798	tsallis entropy
0.8101436275	binary choice
0.8101307998	special emphasis
0.8100137774	poisson regression
0.8100104275	maximum likelihood estimates
0.8099735382	behrens fisher problem
0.8099663170	bootstrap method
0.8098434126	pre averaging
0.8097456221	sparsity level
0.8097386988	logistic distribution
0.8096367962	regression framework
0.8096184299	density estimator
0.8096060295	widely applicable
0.8095888156	genome wide association
0.8095625395	computationally intensive
0.8095620069	risk assessment
0.8095561140	standard methods
0.8094370600	location parameter
0.8092543839	power function
0.8092337780	mixing coefficients
0.8092217335	asymptotically equivalent
0.8092156842	y_ ij
0.8091427535	channel capacity
0.8090266620	log normal
0.8090250364	statistical significance
0.8089480068	sharp oracle inequalities
0.8089431505	indian buffet process
0.8087881638	joint distribution
0.8087484418	scatter matrices
0.8086148080	short range dependent
0.8085856040	point pattern
0.8083680514	rao blackwell
0.8083457108	cross sectional
0.8083055052	linear transformations
0.8082613236	error term
0.8082035565	functional linear regression
0.8081764785	data collection
0.8080779122	kernel function
0.8080532624	directional data
0.8080010483	half space depth
0.8077326781	correct specification
0.8076254747	nonparametric tests
0.8075921209	posterior inference
0.8075905777	stick breaking
0.8075596635	data points
0.8075229597	null space property
0.8075158936	restrictive assumptions
0.8074559098	complex networks
0.8071927133	arbitrarily large
0.8071397400	measurable function
0.8071272420	finite sample
0.8070963762	receiver operating
0.8070531677	evy driven
0.8069737281	tuning free
0.8069437054	network structure
0.8067776973	multi armed bandits
0.8066094840	surrogate loss
0.8065663181	regularized estimation
0.8065604237	learning problems
0.8064751053	survey sampling
0.8063763826	high dimensional linear regression
0.8063099549	enyi entropy
0.8062760485	covariate adjusted
0.8062586500	state space models
0.8062427066	cornish fisher
0.8062084771	sequential estimation
0.8061198695	observed data
0.8061181346	auxiliary variables
0.8061083440	partial derivatives
0.8061015793	euclidean norm
0.8060405299	convex relaxations
0.8060130405	function space
0.8059267793	inequality constraints
0.8059254364	spatially correlated
0.8056282956	logarithmic factors
0.8055953674	kiefer wolfowitz
0.8054139038	infinite variance
0.8053154068	infinite series
0.8053012838	sequential change point detection
0.8051227868	semi supervised learning
0.8050848671	regression analysis
0.8050433759	previous works
0.8050091080	gene tree
0.8049848681	low rank matrices
0.8048221967	sparse graphs
0.8048184037	cosmic microwave
0.8047808546	spectral densities
0.8047661898	gaussian copula
0.8045294186	sequential importance sampling
0.8044719726	space filling designs
0.8043733933	small perturbations
0.8043300332	ranked set
0.8042227369	uniform consistency
0.8042169755	sparse principal component analysis
0.8040348049	additive functional
0.8039677930	impossibility results
0.8039248409	short term
0.8039078641	stationary sequences
0.8037813643	quantum systems
0.8037576680	stein type
0.8037319928	acceptance rejection
0.8036825879	contraction rate
0.8035835773	regular grid
0.8035077171	sampling design
0.8035047526	minimization problems
0.8033585577	independent random variables
0.8033489021	unit sphere
0.8033385411	minimax optimality
0.8032502022	strong dependence
0.8032058711	compatibility condition
0.8031671382	vapnik chervonenkis
0.8031116860	conditional density
0.8031088354	risk bound
0.8030766445	stochastic volatility models
0.8030050017	cauchy stieltjes
0.8029301115	model choice
0.8029074054	positive definite matrices
0.8028609182	monte carlo simulation
0.8028537930	special cases
0.8027436849	finite state space
0.8026108883	strong mixing
0.8025891586	numerical experiments
0.8025889118	privacy preserving
0.8025663557	false discovery rates
0.8025629720	arbitrary dimension
0.8024567851	class labels
0.8023705145	kalman filtering
0.8023663406	testing problem
0.8021961657	qualitative robustness
0.8021824163	bootstrap consistency
0.8020810268	matrix valued
0.8019968772	tracy widom law
0.8019097551	intrinsic dimension
0.8018674162	sample covariance
0.8018306088	theoretical guarantees
0.8017955627	stochastic block
0.8016019848	family wise error rate
0.8014404264	image analysis
0.8014313809	besov space
0.8012950210	observational data
0.8012799189	appropriately chosen
0.8011613383	sliced inverse
0.8011517009	statistical accuracy
0.8011408840	minimax rate
0.8011266402	super population
0.8011050633	bayesian updating
0.8010028358	network data
0.8009372403	probit regression
0.8007961409	conditional quantiles
0.8007740137	closeness testing
0.8007439358	thresholded lasso
0.8007339014	dose finding
0.8006867241	expected loss
0.8006353066	extreme events
0.8006234892	efficient estimation
0.8005835698	tuning parameters
0.8005612445	block models
0.8002901655	symmetric matrix
0.8002743529	toeplitz matrices
0.8002280403	penalized spline
0.8002247478	black scholes
0.8001142286	binary data
0.8000451375	convex cones
0.8000347254	element wise
0.8000204214	likelihood based
0.7999946550	er von mises
0.7999792579	limiting spectral distribution
0.7998879672	evy processes
0.7998807446	markov kernels
0.7998422622	sample paths
0.7997934860	grenander estimator
0.7997836717	extensively studied
0.7997210121	support function
0.7997075061	future research
0.7996656487	fractional levy
0.7996501190	risk bounds
0.7995657814	logarithmic factor
0.7995172165	probabilistic models
0.7994018028	inverse gamma
0.7993464081	empirical process theory
0.7992870967	selection criteria
0.7991464948	variance function
0.7990643545	single index models
0.7989327138	test procedures
0.7989223165	remain valid
0.7988625979	selection bias
0.7987347910	dirichlet prior
0.7987288500	initial estimator
0.7985385525	normal mixtures
0.7984881925	horseshoe prior
0.7984343454	mixing conditions
0.7984094379	open problem
0.7983831063	power series
0.7983738589	tree models
0.7982988955	probability space
0.7981749316	sampling method
0.7981439395	data fidelity term
0.7981288097	provable guarantees
0.7981245324	moore penrose
0.7981081477	simulation studies
0.7980877951	stationary increments
0.7980361408	testing independence
0.7979331838	briefly discussed
0.7977802056	gaussian kernel
0.7977264999	semi selfdecomposable
0.7977025200	semi latin
0.7976721514	relevant variables
0.7976515725	impossibility result
0.7975835001	scaling limits
0.7975605967	practical relevance
0.7975591648	dependency structure
0.7975140289	main result
0.7975091077	binary outcomes
0.7974939522	monte carlo methods
0.7974868026	starting point
0.7974452279	maximum likelihood estimators
0.7971544995	related problems
0.7971271793	gaussian graphical
0.7971102689	huber loss
0.7969799865	nonparametric component
0.7968508694	kullback leibler
0.7968418551	error rates
0.7968247204	population genetics
0.7968076622	fisher rao
0.7966061762	minimax estimation
0.7965062617	description length
0.7964727794	monotone function
0.7964137262	row wise
0.7963566286	orthogonal matrices
0.7963150773	dependent processes
0.7963040065	estimation problems
0.7962182694	phase space
0.7962034173	limiting behaviour
0.7961457179	statistical estimation
0.7961231130	fixed design
0.7960792727	tensor train
0.7960682440	empirical characteristic function
0.7960576225	conditional independences
0.7959854192	null distribution
0.7959782966	concrete examples
0.7959694303	global sensitivity
0.7956526627	superior performance
0.7956458395	adjacency matrices
0.7956425401	property testing
0.7955825521	order book
0.7955337219	regularized estimators
0.7954646620	scaled lasso
0.7954479365	simulation results
0.7954422157	asymptotic analysis
0.7953810151	vy measure
0.7953223616	tail bounds
0.7952600247	residual variance
0.7952464116	group sparsity
0.7952339785	sensing matrices
0.7950860590	numerical simulations
0.7949583980	statistically efficient
0.7949420821	stationary point
0.7949164387	design matrices
0.7948898188	quantum state tomography
0.7948824368	experimental data
0.7948164964	independent components
0.7947558746	anti concentration
0.7947315815	noisy observations
0.7947209838	square error
0.7946904782	numerical examples
0.7946474671	nadaraya watson
0.7945747604	latin squares
0.7945595824	orthogonal series
0.7945430711	gibbs posterior
0.7945006553	regime switching
0.7943753280	underlying graph
0.7943489071	high resolution
0.7942748272	past observations
0.7942510344	band limited
0.7942245686	generalization bounds
0.7941997001	reduced rank
0.7941571671	randomly sampled
0.7940961330	sufficiently large
0.7940444752	log concave densities
0.7939348806	generalized hyperbolic
0.7939200154	multi step
0.7939083733	state spaces
0.7937717450	power functions
0.7937471501	posterior probabilities
0.7936966574	heterogeneous data
0.7936932670	low temperature
0.7935216647	complex systems
0.7935129689	score functions
0.7934194584	local asymptotic
0.7934132495	fisher rao metric
0.7933849377	random samples
0.7933365318	intensity function
0.7933266842	feature space
0.7933233597	bayesian analysis
0.7933034757	statistical efficiency
0.7932890103	commonly encountered
0.7932755927	sparsity constraints
0.7932716579	solution path
0.7931163413	mittag leffler
0.7930756613	spectral method
0.7930386805	policy learning
0.7929839981	causal models
0.7929505965	selection consistency
0.7929312142	statistical power
0.7929105431	strictly positive
0.7928945860	coarse grained
0.7926845796	predictor variables
0.7926435366	universally optimal
0.7926286998	key element
0.7925810670	significance levels
0.7924937203	structured sparsity
0.7924908008	bayesian predictive
0.7923943467	sparsity promoting
0.7922319962	dependent sequences
0.7922028888	covering numbers
0.7921559832	reconstruction problem
0.7921515540	zeroth order
0.7921416848	dimension independent
0.7921340640	quasi monte carlo
0.7921054007	point estimation
0.7919924246	integral equations
0.7919768247	monte carlo simulations
0.7919752155	hodges lehmann
0.7919306794	regularity conditions
0.7919254631	kernel smoothing
0.7918373504	test procedure
0.7917840467	multiple change points
0.7917382189	statistical error
0.7917083447	sectional variation norm
0.7916916978	sequential testing
0.7916562006	wavelet based
0.7915854643	target density
0.7915567530	wald type
0.7915218968	johnson lindenstrauss
0.7915011202	theoretically justified
0.7913475299	bootstrap based
0.7913222497	marginal distributions
0.7912163714	training data
0.7911021888	heavy tailed distributions
0.7910957726	robust estimators
0.7910843088	dynamic systems
0.7910385633	hyper parameter
0.7910216183	bracketing entropy
0.7910005391	serial correlation
0.7908829711	intermediate efficiency
0.7908120241	tracy widom
0.7907921834	estimation procedures
0.7907578187	negative binomial distribution
0.7907039956	robbins monro
0.7906906488	bandit setting
0.7905855766	confidence level
0.7904589393	independence test
0.7904343063	proposed estimator
0.7904015331	simulation experiments
0.7902445993	maximal correlation
0.7902140245	parameter space
0.7901619291	sample quantiles
0.7900166014	linear mixed model
0.7899944881	density power divergence
0.7899909490	information content
0.7899517292	sparse representation
0.7898831461	hypergeometric function
0.7898603549	asymptotically efficient
0.7896903097	convex program
0.7896852865	respondent driven sampling
0.7896808480	sparse vector
0.7895836249	curved exponential family
0.7895728602	proposed method
0.7895579395	poisson point processes
0.7895316288	point wise
0.7895239537	real data
0.7894958554	stationary distribution
0.7893378361	importance weights
0.7891827573	quantum states
0.7891590819	tail behaviour
0.7891163413	kaplan meier
0.7891025460	multi category
0.7890733930	galton watson
0.7890360879	remains largely
0.7888547480	convergence speed
0.7888055684	testing procedure
0.7888004605	latent feature
0.7886570900	statistical tests
0.7885947183	chinese restaurant
0.7885491454	type estimators
0.7885283076	random projection
0.7885114587	estimation techniques
0.7883524524	cox ingersoll ross
0.7883509267	prior distribution
0.7883067290	fixed point
0.7882574644	finite variance
0.7881882942	abrupt change
0.7881244594	penalty functions
0.7881107118	change point estimation
0.7880601103	l1 regularized
0.7879922065	weighted average
0.7879842563	brown resnick
0.7879064568	durbin watson
0.7878436194	bernstein inequality
0.7878355731	epsilon machines
0.7877399838	long standing
0.7877076657	hierarchical bayes
0.7876897607	exact computation
0.7876337269	posterior predictive
0.7876302008	dimensional sphere
0.7876290804	power variations
0.7876052669	higher dimensions
0.7875955421	type ii error
0.7875477448	generalized gamma
0.7875409348	supercritical case
0.7874345758	concave penalty
0.7874291687	discrepancy principle
0.7873888500	sample average
0.7873823702	performance guarantees
0.7873682670	finite horizon
0.7873620290	sensing matrix
0.7872839435	inductive inference
0.7872768406	short note
0.7872417827	matrix denoising
0.7872304470	px da
0.7871947337	distance based
0.7871097635	estimation errors
0.7869594227	fisher snedecor
0.7868327112	likelihood approach
0.7868097185	arbitrarily small
0.7867661538	random environment
0.7866476482	logistic model
0.7865806364	kl ucb
0.7865097154	euclidean ball
0.7864853736	theoretical aspects
0.7864504083	margin condition
0.7864403180	monte carlo method
0.7863878488	global convergence
0.7863693652	extensive simulation studies
0.7862354103	model adequacy
0.7858610449	bayesian estimation
0.7857991627	scan statistics
0.7857393003	euler scheme
0.7856569409	high dimensional inference
0.7856414134	spiked matrix
0.7856412273	misclassification error
0.7855401992	statistical methods
0.7855261789	lead lag
0.7854987562	simultaneous confidence bands
0.7854175975	convolution type
0.7853936703	log linear models
0.7852938502	garch model
0.7852922960	density matrices
0.7850986099	log determinant
0.7850838811	gaussian shift
0.7850502610	mann whitney
0.7850352460	coverage accuracy
0.7849842912	l2 norm
0.7849787241	recently gained
0.7849562761	laplace approximation
0.7848857041	birnbaum saunders
0.7848367049	mixed effects
0.7847235044	sufficiently sparse
0.7847149228	statistical independence
0.7846347223	model selection criteria
0.7846256790	statistically significant
0.7846207535	glivenko cantelli
0.7845719519	aggregation procedure
0.7845427503	model free
0.7845287484	statistical properties
0.7844405941	testing monotonicity
0.7843746305	markov chain monte carlo methods
0.7843687641	statistical guarantees
0.7843280303	median regression
0.7843103236	multivariate analysis
0.7842974623	jensen shannon divergence
0.7842623506	existing estimators
0.7842356860	infinite activity
0.7841848954	underlying process
0.7841254292	clopper pearson
0.7840663918	practically relevant
0.7839949256	distributed random variables
0.7839382891	effective rank
0.7839037763	statistical optimality
0.7838318720	topological features
0.7837136117	laplace transforms
0.7836759204	frequentist inference
0.7836443334	affine transformations
0.7836328198	levy process
0.7835958673	local maxima
0.7833444245	manifold learning
0.7833435296	identifiability conditions
0.7833193923	numerical studies
0.7831586602	moment assumptions
0.7831256858	conformal inference
0.7829598603	prediction accuracy
0.7828353931	resulting estimator
0.7827975185	existing algorithms
0.7827946311	low rank matrix completion
0.7827408740	newton raphson
0.7827202773	technical tool
0.7824386695	multivariate quantiles
0.7824277661	earlier results
0.7823999817	independence tests
0.7821979526	research areas
0.7821799141	model comparison
0.7821670992	cox process
0.7819875305	determinantal point
0.7819116258	recent results
0.7818944827	fundamental question
0.7818834912	learning rate
0.7818685601	estimation procedure
0.7818219238	gaussian distribution
0.7817388790	coverage probabilities
0.7815896525	significant improvement
0.7815887524	discrete choice
0.7814458175	mixed normal
0.7813840932	sequence length
0.7813122998	sufficiently smooth
0.7812497915	predictive inference
0.7812398018	berry esseen
0.7811114135	cryo em
0.7810930090	low snr
0.7810231236	linear constraints
0.7809895054	multivariate elliptical
0.7809654970	based methods
0.7809592545	random measure
0.7808983855	optimal allocation
0.7808725033	ml degree
0.7808676529	graph partitioning
0.7807885384	analytically tractable
0.7805598021	linear model
0.7805151359	closed forms
0.7804688008	kernel density
0.7804631242	behrens fisher
0.7804228727	exchange rates
0.7804060850	limiting process
0.7804044962	complex models
0.7800663687	robust tests
0.7800505564	maximum likelihood estimate
0.7798850484	adaptive estimators
0.7796966881	statistically optimal
0.7796727308	mild regularity conditions
0.7796128522	tangent spaces
0.7795660985	rare weak
0.7795658931	nonzero entries
0.7795238100	independent random
0.7794808465	step size
0.7794713442	nonparametric kernel
0.7794344199	easily computable
0.7794231314	tree structured
0.7793559280	proper scoring rule
0.7793473432	linear forms
0.7793025965	stochastic geometry
0.7792729935	summary statistic
0.7791659702	change point localization
0.7790695943	multivariate statistics
0.7789619125	existing methods
0.7788310559	spectral analysis
0.7787349809	bayes optimal
0.7787046248	numerical illustrations
0.7786770048	cluster structure
0.7786405838	lognormal distribution
0.7786395866	prior knowledge
0.7785427757	functional delta method
0.7785186636	highly correlated
0.7785149786	delayed acceptance
0.7784949548	symmetric matrices
0.7784101597	hessian matrix
0.7783932672	theoretical investigations
0.7783822474	uniform prior
0.7783800180	multi armed bandit problem
0.7783675796	kalman bucy
0.7783424731	ordinary smooth
0.7783410484	weaker conditions
0.7782833863	projective shape
0.7782661082	bh procedure
0.7782418218	semi markov
0.7781770651	causal structure
0.7781073798	large sample
0.7780057963	laplace beltrami
0.7779002202	existing results
0.7778990667	copula based
0.7778207937	extensive simulations
0.7777505424	multiple tests
0.7777150081	lipschitz continuous
0.7776918821	anderson darling
0.7776448301	coordinate wise
0.7776341181	design based
0.7775624073	global optimization
0.7775566569	transition matrix
0.7775252155	goldenshluger lepski
0.7773896383	stable laws
0.7772236836	nonparametric estimators
0.7771863789	post stratification
0.7771270012	article investigates
0.7769634922	error variance
0.7769051137	survival times
0.7768765972	gauss markov
0.7768244824	rank test
0.7765306456	measure theoretic
0.7764151844	weight functions
0.7763997885	statistical consistency
0.7763440383	iterative thresholding
0.7763397711	aberration criterion
0.7763311952	asymptotic setting
0.7762767981	increasing dimension
0.7761953935	skew symmetric
0.7761951552	empirical copula processes
0.7761359574	squared error loss
0.7759035076	conditional sampling
0.7758755426	numerical simulation
0.7757658286	limit distributions
0.7757644597	independent and identically distributed
0.7756514252	location scale
0.7755671377	covariance operator
0.7753672946	fractional factorial
0.7753302521	divergence speed
0.7753119102	crossing probabilities
0.7752885111	local whittle
0.7750880242	covariance structures
0.7749617477	asymptotic relative efficiency
0.7747745915	euclidean parameter
0.7747303548	usual stochastic order
0.7745940191	newly proposed
0.7745465350	inverse probability
0.7743876724	potential outcome
0.7743685885	shape restricted
0.7742797931	conway maxwell poisson
0.7742281397	short range
0.7740032834	latent positions
0.7739336281	persistent betti
0.7739228936	asymptotic consistency
0.7738586954	inhomogeneous poisson processes
0.7737151074	conditional expectations
0.7736865506	spectral embedding
0.7736296732	transition matrices
0.7736097664	local polynomial regression
0.7735631514	log price
0.7735503981	single index model
0.7734415444	fixed domain asymptotics
0.7734334991	likelihood estimators
0.7733652049	desirable properties
0.7733487544	curie weiss model
0.7733412082	multiple imputation
0.7729957096	davis kahan
0.7728709586	support size
0.7728686905	sobolev classes
0.7728659443	convex penalty
0.7727576787	asymptotically correct
0.7726198515	exponentially weighted
0.7725922499	arma garch
0.7725781025	uniform distribution
0.7725067720	coefficient functions
0.7724898274	information theoretic limits
0.7724438481	article develops
0.7723881919	largest root
0.7723796115	sampling scheme
0.7723602000	score test
0.7722011955	limit distribution
0.7721931965	uniformly consistent
0.7720989723	computational tractability
0.7720343286	berry esseen bound
0.7720211812	proper learning
0.7720108601	high dimensional linear models
0.7717937578	technical contribution
0.7717344591	sampling frequency
0.7716554646	sample eigenvalues
0.7715797791	bernstein von mises theorem
0.7715579467	theoretical properties
0.7714325440	stationary solutions
0.7713506396	statistical model
0.7712695470	correlated data
0.7712398018	horvitz thompson
0.7712190745	real numbers
0.7711537877	exponential weights
0.7711298541	model specification
0.7710721572	dependent errors
0.7709926230	community structure
0.7709874349	fiducial inference
0.7709058503	homodyne tomography
0.7708807377	population eigenvalues
0.7708571356	regression problem
0.7708409519	real data sets
0.7708351399	density matrix
0.7708032220	wasserstein geometry
0.7706151850	multi class
0.7706047102	concave majorant
0.7705729665	error control
0.7705625948	locally optimal designs
0.7705558181	spatial data
0.7704544425	high accuracy
0.7703297631	response variable
0.7703196616	great importance
0.7702542062	finite mixture
0.7701616118	diffusion tensor
0.7701117790	sparse structure
0.7699959089	sensitivity index
0.7699048662	high temperature
0.7698934695	data processing inequalities
0.7698438045	information flow
0.7698178371	simulation based
0.7698117924	parametric families
0.7695154536	super smooth
0.7694029433	small area estimation
0.7693278624	theoretical results
0.7692228753	density estimates
0.7691079391	zig zag
0.7690757742	sufficiently small
0.7690506126	dirichlet process mixture
0.7690504692	arises naturally
0.7690259080	exponential random graph
0.7689081151	wigner function
0.7688603666	learning problem
0.7687358259	building blocks
0.7685499990	integral functionals
0.7684910125	strong convexity
0.7684465303	light tail
0.7683912724	resulting estimators
0.7683269389	total variation distance
0.7683091782	loading matrix
0.7682745103	likelihood functions
0.7682662277	random censoring
0.7682573663	depth functions
0.7682095126	numerical implementation
0.7681901611	birth death
0.7681500174	functional linear
0.7681421659	tensor pca
0.7681220673	interval censored
0.7680415290	convergence results
0.7678937671	moment based
0.7678885292	finite sample properties
0.7678613158	quantile based
0.7678599515	optimal detection
0.7678083706	normal random variables
0.7677598005	optimal control
0.7677078005	sequential test
0.7675879009	parametric model
0.7675210322	spatially adaptive
0.7674148969	minimum divergence
0.7673918821	aalen johansen
0.7673572047	spectral theory
0.7671474794	kernel based
0.7671389707	common practice
0.7670404859	decision rule
0.7668658415	energy distance
0.7668571571	nonstationary processes
0.7667287732	optimal rate
0.7666795751	inferential procedures
0.7666163874	finite sample size
0.7666045585	resolution iv
0.7664698158	mixing density
0.7664412361	structural assumptions
0.7663630472	higher dimensional
0.7662969076	beta stacy
0.7662622829	boundary conditions
0.7661963874	exploratory data analysis
0.7661871074	random graph models
0.7661580320	interval valued
0.7660253391	lipschitz constant
0.7659354850	evy density
0.7658476183	vy driven
0.7658453833	post processing
0.7657786325	bivariate normal
0.7657648275	marginal likelihood
0.7657623123	statistical inverse problems
0.7657585657	normal means
0.7657213370	stationary random fields
0.7656908328	set ups
0.7656592205	maximum pseudo likelihood
0.7656173006	dependent random
0.7655321820	efficiently computable
0.7655281219	translation invariant
0.7654554611	spatial temporal
0.7654398616	multiplicative constant
0.7653371363	estimation problem
0.7653256095	linear structural equation models
0.7652071004	completely randomized
0.7651881441	objective bayesian
0.7650748999	diagonal matrix
0.7650155415	sparse high dimensional
0.7646973036	binary search
0.7645889526	real datasets
0.7645285390	performance bounds
0.7644500476	penalty term
0.7644420945	empirical success
0.7644044943	restricted strong convexity
0.7642922919	mild condition
0.7642716904	post selection
0.7640329849	descent algorithm
0.7639403828	dimensional space
0.7638367270	estimation efficiency
0.7637760494	randomly chosen
0.7637262922	smoothness conditions
0.7636909874	proposed framework
0.7636008927	gross error
0.7635931579	nonparametric testing
0.7635055784	based clustering
0.7634853305	mild assumptions
0.7634380438	multi variate
0.7634330751	group invariance
0.7633421157	linear combinations
0.7632997085	graphical model selection
0.7632475177	equivalence classes
0.7630846533	compact support
0.7630580865	asymptotic mixed normality
0.7629591258	essential graph
0.7629577479	multivariate density
0.7629141809	pearson correlation
0.7628706640	reference priors
0.7628669383	optimization algorithms
0.7628636397	closed form expression
0.7628614839	optimal convergence rates
0.7628276085	information theoretically optimal
0.7627701532	estimator attains
0.7626883225	bayesian hierarchical
0.7626312815	instance dependent
0.7626289323	analytical results
0.7625821616	grow exponentially
0.7625174749	distributional properties
0.7625048331	false rejection
0.7623722643	geometric interpretation
0.7623047234	unit circle
0.7621839701	independence models
0.7621367298	analysis reveals
0.7620213614	random geometric graphs
0.7619860113	analogous result
0.7619607986	attachment trees
0.7618747587	renewal process
0.7617070514	identified set
0.7616518448	signal to noise ratio
0.7616100576	successfully applied
0.7616096583	hyper parameters
0.7615707205	sparse alternatives
0.7615607371	quantile processes
0.7615513744	invariant distribution
0.7615466944	bayes rule
0.7615308682	random number
0.7614580269	large samples
0.7611789633	asymptotic distributions
0.7611409712	analytical expressions
0.7610770930	unknown vector
0.7610558060	statistical problems
0.7609231687	large datasets
0.7608780581	quantile process
0.7608731825	nonparametric bootstrap
0.7608064275	diffusion bridges
0.7607488469	random features
0.7607205257	sparsity assumption
0.7606697739	laplace beltrami operator
0.7606590575	results imply
0.7606481535	contraction coefficients
0.7606362381	basis functions
0.7606039475	central moments
0.7605720286	binary regression
0.7604964936	unit vector
0.7604794625	fokker planck equation
0.7604770309	multi reference alignment
0.7602446170	increasing domain
0.7602223470	truncated samples
0.7601763685	recent years
0.7601311035	randomization tests
0.7601068421	continuous mark
0.7600717782	application areas
0.7599965732	p_r p_r
0.7599786396	unbiased risk estimation
0.7599050003	multi resolution
0.7598819320	asymptotic theory
0.7597851996	elliptical distribution
0.7597681823	mathematical model
0.7597570257	local times
0.7596421023	enko pastur law
0.7594110441	multi layer
0.7593993385	computationally attractive
0.7593552602	gaussian fields
0.7593507877	simulation study
0.7592398018	fokker planck
0.7591963808	quantum fisher information
0.7590521723	likelihood equations
0.7590455952	theoretical result
0.7589860589	whittle estimation
0.7589764384	information processing
0.7589716379	theoretical analysis
0.7589127932	penalized estimator
0.7588801071	estimating equation
0.7588540619	predictive distributions
0.7588519113	nonconcave penalized
0.7588229565	clustering problem
0.7586563995	finite mixtures
0.7586251097	nonparametric statistics
0.7585804374	competitive performance
0.7584827271	wavelet analysis
0.7584824102	block wise
0.7584445619	absolute moments
0.7584375802	unknown parameters
0.7583702009	power laws
0.7583456124	pairwise distances
0.7583199336	isotropic gaussian
0.7582917806	ordinary least squares
0.7581674997	edge weights
0.7581184084	adaptive design
0.7581013649	barndorff nielsen
0.7580246161	slowly varying
0.7579204841	log likelihood ratio
0.7579064685	blumenthal getoor
0.7578485117	trace class
0.7577713542	computational methods
0.7577443358	data compression
0.7577132009	singular vector
0.7576318009	older class
0.7575390348	locally adaptive
0.7575123509	von mises fisher
0.7574392037	high dimensional data analysis
0.7574374975	graphical lasso
0.7573511384	effect sizes
0.7573113891	recent papers
0.7571080535	mild conditions
0.7570267004	information leakage
0.7569311075	data depth
0.7568084265	fast rate
0.7567809991	volatility process
0.7566591774	quadratic functional
0.7566515449	autocovariance function
0.7566461172	open question
0.7565681844	consistency guarantees
0.7565377901	bounded degree
0.7564489377	filtering problem
0.7564242048	carefully chosen
0.7563195176	linear operators
0.7563032062	gibbs measures
0.7561978078	indicator functions
0.7561474936	statistical manifolds
0.7561061111	cox processes
0.7560923374	coefficient matrix
0.7559997648	quantitative factors
0.7558627538	uncertainty principle
0.7558346567	multiple sources
0.7557975636	hanson wright inequality
0.7557694082	dependence function
0.7557454126	score statistic
0.7556505779	seminal paper
0.7556488320	test error
0.7555769139	recursive estimation
0.7555241679	spatial extremes
0.7555222250	linear prediction
0.7554953825	residual based
0.7554935974	shape parameters
0.7553664801	predictive performance
0.7551423084	random points
0.7551405335	complex wishart
0.7550620220	exponential growth
0.7549325885	marcenko pastur
0.7547680315	baum welch
0.7547078845	gumbel distribution
0.7547002892	generalization properties
0.7546494579	dempster shafer
0.7545835394	quadratic variations
0.7545184467	exponentially fast
0.7544867225	perturbation bootstrap
0.7544786907	fleming viot
0.7544606536	distributional assumptions
0.7544416829	passive learning
0.7544145504	asymptotic null distribution
0.7543333378	multivariate extremes
0.7543028765	generalized exponential
0.7541986559	repeated measures
0.7541217218	gene expression data
0.7539325885	bradley terry
0.7539228505	synthetic examples
0.7538010242	highly efficient
0.7537680315	hayashi yoshida
0.7537570118	singular subspace
0.7536010046	invariant tests
0.7535772655	eigenvalue density
0.7534205535	weak conditions
0.7533602512	uniformly valid
0.7533307307	dimensional case
0.7531393826	negative values
0.7531161642	consistently estimated
0.7529884740	bayesian framework
0.7529606670	regularization parameters
0.7529467777	sampling distribution
0.7528946564	exchangeable graphs
0.7528520140	arbitrary dependence
0.7528516522	parameter estimates
0.7527926719	crossover designs
0.7527684309	moment matching
0.7527066114	normal errors
0.7525913880	high quality
0.7525351548	local asymptotic minimax
0.7524751634	sequence prediction
0.7523411904	tensor decomposition
0.7521643643	tensor product
0.7521393718	type moderate deviation
0.7521311277	sobolev type
0.7519959980	generalized pareto distribution
0.7519830198	partially linear models
0.7519726591	posterior convergence
0.7519337434	proposed tests
0.7519102244	event times
0.7518527487	treatment groups
0.7518467036	ultra high
0.7517675304	probability simplex
0.7517308551	information theoretic lower bounds
0.7516860302	minimax separation rates
0.7516446015	average causal effect
0.7515988667	hidden markov chain
0.7515587355	order statistic
0.7515355502	functional deconvolution
0.7514047410	effect models
0.7514031084	scientific fields
0.7512898999	component wise
0.7512632867	sparse linear
0.7511982150	additive regression
0.7511901692	shape analysis
0.7511084771	convex hull
0.7510972405	average case
0.7510258511	coupling argument
0.7510133865	asymptotically distribution free
0.7508308579	global minimum
0.7507502120	variable selection consistency
0.7507333584	strictly increasing
0.7505725758	dimensional projections
0.7505130836	control variate
0.7504402714	asymptotic behavior
0.7504339837	verifiable conditions
0.7504297145	drift term
0.7503922490	specification testing
0.7503286138	response variables
0.7503111118	sparse matrices
0.7502945540	noise variance
0.7502453920	estimation method
0.7502135944	labeled data
0.7501885785	multi index
0.7501246831	adaptive elastic net
0.7500282704	statistical complexity
0.7499722606	independent observations
0.7499300129	matrix estimation
0.7498807759	sequential monte
0.7496755799	finite size
0.7496376136	multiple output
0.7496246125	beta distributions
0.7494197764	bernoulli random variables
0.7493733777	statistical manifold
0.7493710845	pre change
0.7493211526	concentration graph
0.7492822412	exchangeable random partitions
0.7492717986	model parameters
0.7492696103	armed bandit
0.7492010188	sharp bounds
0.7491628093	easily implemented
0.7491024378	appropriately defined
0.7489719179	increasingly popular
0.7487933812	high threshold
0.7487635750	asymptotic regimes
0.7487522151	volatility models
0.7487373168	squares estimator
0.7487286211	asymptotic behaviors
0.7486366074	treatment regimes
0.7484745648	variable length
0.7484550492	proposed methods
0.7484015724	finite state
0.7482043602	structural equation
0.7481892341	singular value decomposition
0.7481271128	sensor network
0.7480355131	posterior density
0.7480110624	major challenge
0.7479515157	strong law
0.7479335688	adaptive estimator
0.7479182704	previous results
0.7479034730	volatility matrix
0.7478796000	spectral radius
0.7478752351	constructing confidence intervals
0.7477924751	necessarily identically distributed
0.7477866094	minimax adaptive
0.7477521198	mixed integer
0.7474774704	growth rate
0.7474558504	high dimensional sparse
0.7474276071	cell probabilities
0.7473234650	unbiased estimator
0.7473106573	projection depth
0.7472903320	selection criterion
0.7472639702	bayesian credible
0.7472591348	higher moments
0.7472475852	surrogate model
0.7472153708	exponential weighting
0.7471756880	fisher matrix
0.7471707324	goodness of fit tests
0.7471145715	analytical expression
0.7469948757	deconvolution problems
0.7469409400	numerical results
0.7469378082	nonlinear filtering
0.7468278246	lasso type
0.7468265758	alpha skew
0.7467212962	glivenko cantelli theorem
0.7467188231	ergodic diffusion
0.7466733048	gradient based
0.7465703945	kaplan meier estimator
0.7465113044	parametric estimation
0.7464926239	information divergence
0.7464793139	computational efficiency
0.7463764842	main results
0.7462908394	slope heuristics
0.7462595993	random processes
0.7461780835	community recovery
0.7461152778	large data sets
0.7459904412	weight matrix
0.7459637895	prior specification
0.7458819425	boundary bias
0.7458767139	log linear
0.7458553906	estimation methods
0.7457607303	minimax risks
0.7457574628	outcome regression
0.7456450636	compound poisson processes
0.7454206784	dependent observations
0.7453926361	nested sampling
0.7453405779	quasi maximum likelihood
0.7453293835	specification tests
0.7453230703	exchange algorithm
0.7453204882	empirical measure
0.7451617590	local power
0.7451446663	modified cholesky
0.7451386315	high frequency financial data
0.7451377659	asymptotic distribution
0.7450321671	metric entropy
0.7449773237	short range dependence
0.7449508565	sequential detection
0.7447024679	error correction
0.7446572648	asymptotically pivotal
0.7446519040	bayesian nonparametric inference
0.7445716923	empirical distribution function
0.7445080477	kullback leibler loss
0.7441139497	nonzero coefficients
0.7440736738	numerical evidence
0.7440569951	probabilistic model
0.7437423989	briefly discuss
0.7437212847	kernel ridge
0.7436281160	symmetric channel
0.7436225640	proposed estimators
0.7435911942	step mle
0.7435441081	linear predictors
0.7434965170	square loss
0.7433101860	mixture distribution
0.7432377569	log concave distributions
0.7432254622	multi modal
0.7431324004	sample path
0.7427895198	asymptotically independent
0.7427626961	reference measure
0.7427114958	vasicek model
0.7426907577	random permutations
0.7425891800	regularity assumptions
0.7425641058	asymptotically linear
0.7425639003	quantile functions
0.7425055965	probability densities
0.7424678176	convergence properties
0.7424566829	latent class models
0.7424474799	proportional hazards model
0.7424336882	separation rate
0.7424000080	asymptotic expansion
0.7423228380	empirical distribution
0.7422275333	wald test
0.7420759562	tracy widom distribution
0.7418118092	memory parameter
0.7414299710	simulated examples
0.7414032942	left truncation
0.7412677460	arbitrarily close
0.7410429046	change point tests
0.7409993172	underlying distribution
0.7409750269	subspace clustering
0.7409537486	candidate models
0.7409400533	asymptotic bias
0.7409129747	gaussian white noise
0.7408908334	faster rate
0.7407518231	expectation maximization algorithm
0.7407075060	measure theory
0.7406518272	convex loss functions
0.7404620165	high dimensional regression
0.7404162996	pareto type
0.7403329531	prior probability
0.7403152117	multi stage
0.7402237051	random graph model
0.7401909176	response function
0.7401359856	design matrix
0.7401344222	failure times
0.7401338450	diagonal entries
0.7401301518	risk difference
0.7400469566	uniform confidence bands
0.7399182733	renewal theory
0.7398629094	vertex set
0.7398244129	hoeffding type
0.7398087937	background knowledge
0.7397988441	competing methods
0.7397659218	hanson wright
0.7397252438	survival probability
0.7394803834	training error
0.7394270722	information theoretical
0.7394221431	null distributions
0.7393022560	desirable property
0.7392728893	consistency properties
0.7392449237	differential operator
0.7392038592	constant fraction
0.7391938398	product limit
0.7391904097	low sample size
0.7391837957	confidence bounds
0.7390969036	consistent and asymptotically normal
0.7387279279	fixed width
0.7386376826	bandwidth choice
0.7385893706	minimax lower bound
0.7385886400	informative priors
0.7385871974	durbin watson statistic
0.7385172790	sensor networks
0.7385121235	clustered data
0.7384474616	model fitting
0.7383909348	cumulant function
0.7382574264	iterative algorithms
0.7382328098	oracle type inequality
0.7381114376	noise levels
0.7380606212	cand \ ` es
0.7380349834	bernstein type inequality
0.7378853570	financial data
0.7378505363	improved estimators
0.7378047484	decision problems
0.7377688847	bayesian methods
0.7377597602	statistical test
0.7377226145	genome wide
0.7376804347	observed entries
0.7376061787	unique solution
0.7375905878	rank minimization
0.7375422439	predictive risk
0.7375179337	score matching
0.7374584980	moment inequality
0.7374545406	selection rules
0.7373435927	specification test
0.7373407406	functional principal component analysis
0.7372686521	slower rate
0.7371765414	proposed methodology
0.7371402232	broad classes
0.7367706832	privacy guarantees
0.7367336286	markov model
0.7366562806	high probability
0.7365033387	berry esseen bounds
0.7364873750	functional linear model
0.7364421801	definite matrices
0.7364200829	sampling algorithm
0.7364030232	limiting laws
0.7362792484	reasonable assumptions
0.7362236396	state path
0.7361881791	data dependent
0.7361800327	leibler divergence
0.7361585853	fully adaptive
0.7361386384	rank aggregation
0.7360856605	conditional densities
0.7360483551	trace regression
0.7359375593	target parameter
0.7358524016	sample points
0.7358310596	hierarchical model
0.7358082629	projection theorems
0.7356326199	stationary points
0.7355668203	main theorem
0.7354958256	error analysis
0.7353090721	smoothness level
0.7352802432	bayes classifier
0.7352309652	results suggest
0.7351967124	base measure
0.7348816799	asymptotically valid
0.7348680353	comparative study
0.7347917268	variable importance
0.7347599166	additional assumptions
0.7347081104	observation scheme
0.7346266928	conditionally gaussian
0.7344914957	projection operator
0.7344313571	exponential tails
0.7343745314	continuous variables
0.7342123061	density regions
0.7341953055	classification error
0.7341548622	factorial design
0.7340822882	laplace deconvolution
0.7340111062	exponentially small
0.7339650618	tight bounds
0.7338888368	grenander type
0.7338738671	functional covariates
0.7337555905	standard deviations
0.7337259483	significance testing
0.7336307030	optimal policy
0.7335958417	autocovariance matrices
0.7335624272	generating functions
0.7335550049	type theorem
0.7335312676	similar results
0.7335010101	fractional poisson
0.7334957137	main contributions
0.7334444492	rademacher complexities
0.7333658982	particle systems
0.7333577588	poisson intensity
0.7333523235	weak assumptions
0.7332322218	minimum norm
0.7331885969	key technical
0.7331401075	vector space
0.7331098813	mathematical analysis
0.7331078848	fully nonparametric
0.7330494218	posterior sampling
0.7329093719	average variance
0.7329029075	finite set
0.7328847265	explicit formulas
0.7328766420	squared loss
0.7326452616	kohonen algorithm
0.7325407387	weibull distributions
0.7325071347	fixed sample size
0.7322858140	wavelet estimation
0.7322525474	parameter inference
0.7322273518	linear regressions
0.7322215659	directed edges
0.7321386527	limit theory
0.7320354122	gaussian vector
0.7320221000	input variables
0.7320176581	function approximation
0.7319454681	conditional distribution
0.7319068373	maximum score
0.7318927536	sampling error
0.7318354125	prior measures
0.7318284472	results reveal
0.7318105558	regularity properties
0.7317668962	widely linear
0.7315935903	recent works
0.7314673345	undirected graph
0.7314141120	heteroscedastic noise
0.7313934857	quadratic functionals
0.7313730767	finite moments
0.7313669612	hamiltonian monte
0.7313483757	marked empirical
0.7312775972	nominal level
0.7311273085	multiple testing procedure
0.7310350233	adaptive confidence bands
0.7310199700	probability converging
0.7308946447	meta algorithm
0.7308308389	regression parameters
0.7307949360	spatial processes
0.7307853570	optimum design
0.7306481799	graphical gaussian
0.7306334856	learning task
0.7305290470	convex order
0.7305199422	finite sample performance
0.7304350432	spectral domain
0.7303410102	parameter values
0.7303156504	asymptotic regime
0.7302402639	parameter spaces
0.7302319315	spectrum estimation
0.7302102174	fast computation
0.7301515181	riemannian metrics
0.7301102113	smoothness assumptions
0.7301042368	auto correlation
0.7300615017	case control studies
0.7300516132	mixture components
0.7299030533	function estimation
0.7298972553	standard error
0.7298737203	general framework
0.7297081263	binary tree
0.7297060011	model classes
0.7296327129	binary hypothesis testing
0.7296114542	local means
0.7295990057	cross section
0.7293562544	spatial statistics
0.7293483765	block diagonal
0.7292205753	noisy measurements
0.7291793392	group selection
0.7291074537	optimal weights
0.7290976276	asymptotic law
0.7289717909	asymptotic approximations
0.7289064574	pairwise interaction
0.7288772957	special case
0.7287097890	generalized additive models
0.7285836986	independence criterion
0.7283218791	quantitative bounds
0.7282568626	mcmc algorithm
0.7281639762	node degrees
0.7281097845	tail behavior
0.7280747576	low complexity
0.7280492950	obtained results
0.7279810432	examples include
0.7279741764	model complexity
0.7279158268	gaussian entries
0.7278918207	input parameters
0.7278820242	consistent tests
0.7278718386	faster rates
0.7278162309	asymptotic inference
0.7278104986	probabilistic forecasts
0.7277560341	moment estimators
0.7276794595	weak topology
0.7276623663	dimensional settings
0.7276371198	combinatorial structure
0.7276038141	average degree
0.7274781256	power loss
0.7274714562	microwave background
0.7274294693	recently introduced
0.7273867591	statistically consistent
0.7273260811	structural models
0.7273093805	homogeneous markov chain model
0.7272806753	variance components
0.7271736384	provide theoretical
0.7271469278	optimization algorithm
0.7269954022	ipw estimator
0.7269113196	error probabilities
0.7268362675	random dot product
0.7268074098	random coefficient ar
0.7267771808	functional spaces
0.7266894620	maximum degree
0.7265884537	greedy algorithms
0.7265438785	projection estimators
0.7264070928	representation theory
0.7263108265	previously established
0.7262605287	bradley terry model
0.7262224589	multi armed
0.7262091838	post lasso
0.7262045813	quadratic program
0.7261827864	variance bounds
0.7261665609	limiting distributions
0.7261642270	proposed algorithms
0.7261616545	quasi bayesian
0.7261292600	mixed models
0.7261024019	error distributions
0.7260781418	classical results
0.7260756188	large sample asymptotics
0.7260319789	weak recovery
0.7260216748	proposed model
0.7260015002	linear equations
0.7259743716	fisher matrices
0.7258578218	ratio test
0.7256746298	sparse additive models
0.7256209506	prediction function
0.7255755553	largest eigenvalues
0.7255658804	convergence guarantees
0.7255090324	random functions
0.7254777944	training sample
0.7254716478	entropy rate
0.7253860204	adaptive procedure
0.7252184001	kernel learning
0.7252091377	multiple wiener
0.7251431829	reconstruction algorithm
0.7250309603	statistical applications
0.7250184946	boundary points
0.7250066057	dimensional signals
0.7249237497	outcome variable
0.7248830743	epidemic models
0.7248132852	extreme points
0.7247808881	monte carlo experiments
0.7246871922	failure probability
0.7245491180	stochastic models
0.7244679861	regression depth
0.7244165286	ratio type
0.7243181141	degree distributions
0.7242620428	current literature
0.7242007305	multiscale bootstrap
0.7241813646	bipartite graph
0.7241041952	markov kernel
0.7240703131	discrete random variables
0.7239784468	auto covariance
0.7239774926	developed theory
0.7239762811	informative prior
0.7239618444	minimal sufficient
0.7239582415	general purpose
0.7239501795	stochastic dynamics
0.7239391110	separable hilbert space
0.7235854159	beta binomial
0.7235798361	davis kahan theorem
0.7235749568	data generating
0.7235048013	estimation accuracy
0.7234837341	optimal sample complexity
0.7234738658	dependence properties
0.7234263576	coefficient vector
0.7234175945	residual bootstrap
0.7233186186	poly logarithmic
0.7232870561	bi degree
0.7231611064	conditions ensuring
0.7231061599	computed efficiently
0.7230712535	proposed algorithm
0.7230675482	concentration results
0.7230529210	support points
0.7230260495	semi algebraic
0.7229329861	adaptive designs
0.7229219632	discrete observations
0.7228984999	weak consistency
0.7227853593	model based
0.7227624955	spectral algorithm
0.7227159367	point estimate
0.7226777331	karhunen lo \ ` eve
0.7225679016	kernel estimates
0.7225577984	coverage error
0.7224598161	shape theory
0.7223697373	density ratios
0.7222927145	signal matrix
0.7222319208	gaussian kernels
0.7220311696	cross correlation
0.7218880664	smooth transition
0.7218713745	scatter estimators
0.7218096648	reference prior
0.7218037569	additive components
0.7217643408	identification problem
0.7217239361	averaged version
0.7215910873	er rao bound
0.7215905831	robustness properties
0.7215725722	regularized regression
0.7215382051	double bootstrap
0.7215241225	case control
0.7214802456	technical conditions
0.7214480387	uniform norm
0.7214318148	streaming data
0.7212980372	analytic expressions
0.7212428054	population size
0.7212321920	graph based
0.7212054242	asymptotic representation
0.7211077279	practical implications
0.7210813967	random sums
0.7210446979	standard normal
0.7209382867	type estimator
0.7208438200	grows exponentially
0.7207986153	absolute error
0.7207709852	smoothness properties
0.7207384488	unifying framework
0.7207364425	hidden variables
0.7206596384	causal states
0.7206303497	integral representations
0.7206085944	problems involving
0.7205930395	monotone density
0.7205858670	decomposable graphical
0.7205344105	sparse group lasso
0.7204585167	diffusion equation
0.7204369489	based approach
0.7204253371	proposed family
0.7204161038	small probability
0.7204148337	bootstrap procedures
0.7203938355	tree structure
0.7203797577	diffusion models
0.7202714281	controlling procedures
0.7202475276	general setup
0.7202469996	recently proposed
0.7202372220	consistency results
0.7202164727	optimal recovery
0.7200641272	conditional inference
0.7199808100	logistic regression model
0.7199705571	evy measure
0.7199301628	statistical computational
0.7199216492	enko pastur
0.7198523341	large scale multiple testing
0.7197836002	computationally intractable
0.7197802756	bounded random variables
0.7196839553	small sample sizes
0.7196535348	gaussian sequence model
0.7196140818	practical applications
0.7195388713	model assisted
0.7195197063	log canonical
0.7193881857	based estimators
0.7192629318	cross entropy
0.7192557089	computational lower bounds
0.7192353401	fourier coefficients
0.7192203308	inverse binomial
0.7192195616	existing works
0.7191910571	low dimensional subspace
0.7191653261	computational costs
0.7191533481	hidden states
0.7191137940	threshold autoregressive
0.7190906953	likelihood estimates
0.7190495493	weighted sums
0.7189893374	quantile estimation
0.7189258735	estimated residuals
0.7189018358	cusum statistics
0.7188442905	extreme value theory
0.7187014474	high breakdown
0.7183322483	significantly outperforms
0.7182469020	stable tail
0.7182158957	generalized entropy
0.7181408292	inference methods
0.7181009672	block size
0.7180614636	resulting estimate
0.7180555121	inference procedures
0.7180400455	block designs
0.7180105195	pac bayesian bounds
0.7179646495	high dimensional setting
0.7178745252	positive semi definite
0.7178365198	communication cost
0.7178212462	functional linear models
0.7178053606	reliability theory
0.7176271853	control theory
0.7175239605	random intervals
0.7175101182	dimensional setting
0.7174790636	finite order
0.7174743916	ls estimator
0.7172650208	estimator achieves
0.7172612878	previously proposed
0.7172458393	multiplicative factor
0.7172154764	spectral measures
0.7172003519	selection rule
0.7171608012	linear transformation
0.7170280703	transition densities
0.7170153683	multi level
0.7170093626	private algorithms
0.7169683877	holds true
0.7168806651	experimental results
0.7166770653	numerous applications
0.7166553251	graph matching
0.7166442772	asymptotic framework
0.7165951248	der vaart
0.7165397573	detection boundary
0.7164133630	prediction risk
0.7163198103	practical applicability
0.7161271512	practical aspects
0.7160405147	dependent inputs
0.7159018969	dense regime
0.7158984917	inverse covariance
0.7158841127	rank sum
0.7158108674	orthogonal polynomial
0.7157014384	maximum mean discrepancy
0.7155383474	estimating function
0.7154435148	relative efficiency
0.7153654474	size increases
0.7152987799	multi object
0.7152341928	conditional dependence
0.7152072177	linearly independent
0.7150625253	discrete data
0.7150088708	probabilistic inference
0.7149237596	mixed graph
0.7148186382	smoothed bootstrap
0.7148158451	goodness of fit testing
0.7148114186	composite hypothesis
0.7147690910	general semiparametric
0.7147383948	regression functions
0.7146965204	empirical studies
0.7146720117	minimal penalty
0.7146024212	randomization test
0.7145838969	prior mass
0.7145767631	dependence structure
0.7145730882	easily computed
0.7145679461	compact riemannian
0.7145541758	product measures
0.7145529924	separation rates
0.7143600710	nadaraya watson estimator
0.7141840278	partition function
0.7141617509	change point analysis
0.7141180022	low noise
0.7140934773	discrete choice models
0.7140412727	linear span
0.7139758179	max domain of attraction
0.7138731881	markov matrices
0.7138601152	random sequences
0.7138065633	generalization performance
0.7137857348	missing mass
0.7137510642	structured signal
0.7137161081	gibbs type
0.7136569971	sparsity constraint
0.7135880136	activation functions
0.7134349852	singular vectors
0.7133602111	theoretical bounds
0.7132979050	compound poisson process
0.7132606841	asymptotically unbiased
0.7132307797	linear gaussian
0.7132114591	sign consistency
0.7132017821	series expansion
0.7131662469	concentration bounds
0.7131661452	conditional covariance
0.7131656896	sparse additive
0.7131252580	high frequencies
0.7130716573	score based
0.7129600403	inverse covariance matrix
0.7128860879	norm loss
0.7128468112	scale space
0.7128283319	driving noise
0.7128251215	ratio statistic
0.7128225294	manifold valued
0.7127743081	invariant measure
0.7125648194	maximum eigenvalue
0.7125357757	direct and indirect effects
0.7124356910	originally proposed
0.7124299102	proposed procedure
0.7124248714	spectral measure
0.7123616685	sample optimal
0.7123513436	isometry property
0.7121181862	lasso penalty
0.7120872934	elliptical symmetry
0.7120077169	maximum smoothed
0.7119637358	equi energy
0.7119251841	population risk
0.7119046218	geometric distribution
0.7118260670	parameter vectors
0.7118152966	inverse wishart
0.7117046655	strong consistency
0.7114117181	growth rates
0.7111789486	ergodic markov chains
0.7110386176	gaussian mixture model
0.7110277169	optimality conditions
0.7107959110	nonlinear models
0.7107915387	adaptive procedures
0.7107733185	reduced rank regression
0.7107616186	partial recovery
0.7106673626	article focuses
0.7104373162	applied probability
0.7104353580	kernel functions
0.7103791418	semiparametric transformation
0.7103325080	convex aggregation
0.7102300587	long memory processes
0.7102236661	extreme value copulas
0.7101074574	berry esseen type
0.7100144837	real data examples
0.7100085670	gibbs point processes
0.7098284213	stationary distributions
0.7097814745	edge set
0.7097420492	spiked model
0.7097317992	sequential sampling
0.7096615814	dependency graph
0.7096234711	classical methods
0.7094569993	jump rate
0.7094357140	fourier domain
0.7093700720	uncertain prior
0.7091867313	recently developed
0.7091134347	inference procedure
0.7089409716	recovery error
0.7089235901	cluster tree
0.7088949199	additive functionals
0.7088740797	log concave density
0.7088711067	leverage effect
0.7087746757	latent class
0.7087058199	noisy linear
0.7086195897	bayesian paradigm
0.7086036204	moment generating
0.7085903859	exact asymptotic
0.7085447352	mixture component
0.7085381696	degree heterogeneity
0.7082809421	conditional variance
0.7082677287	effective dimension
0.7082557158	wavelet series
0.7080662054	power spectral density
0.7080418327	results hold
0.7080208549	proof techniques
0.7080022474	approximate sparsity
0.7079409224	small sample size
0.7078807194	local dependence
0.7078739752	multivariate density estimation
0.7077630225	peaks over threshold
0.7077583954	smooth functionals
0.7076470771	sample performance
0.7076315672	asymptotically gaussian
0.7075953543	subspace recovery
0.7075843245	bayes theorem
0.7075462493	main ideas
0.7074769781	permutation based
0.7073356751	nonparametric models
0.7073094498	dimension free
0.7072860807	blind source
0.7072831496	deviation principles
0.7071482956	bounded domain
0.7069607542	main tool
0.7068755973	power behavior
0.7067796307	smoothness index
0.7067075349	linear regression model
0.7066334472	dimensional euclidean space
0.7066026598	simple hypotheses
0.7063669759	weighted bootstrap
0.7061813667	monitoring schemes
0.7061707298	iterative algorithm
0.7061319130	pair correlation function
0.7061220444	extreme order statistics
0.7059377177	symmetric spaces
0.7058515061	volatility estimation
0.7058111126	relative error
0.7056822604	threshold parameter
0.7054671286	robustness property
0.7054275119	dimensional subspace
0.7053517902	online regression
0.7053087632	approximation theory
0.7052388061	inference tasks
0.7052184326	random effects model
0.7052084427	recent research
0.7052075049	related results
0.7051590481	bounded support
0.7051007375	limit law
0.7050977578	coefficient function
0.7050575284	varying coefficient models
0.7050490884	underlying model
0.7050421684	analysis shows
0.7050093950	correlated wishart
0.7049264354	marked point processes
0.7049221015	exchangeable sequences
0.7048533530	evaluation metrics
0.7048389901	horvitz thompson estimator
0.7048385830	expected sample size
0.7048136108	modern applications
0.7048121717	direct effect
0.7047455563	global optimum
0.7047266092	moderate deviation principle
0.7047177130	conditional moments
0.7046915823	potential applications
0.7046680030	bayesian learning
0.7046529380	minimax estimators
0.7046041832	approximate sampling
0.7045657848	bridge estimators
0.7045325081	high frequency asymptotics
0.7044806333	predictor variable
0.7043998119	spatial domain
0.7043898390	theoretical guarantee
0.7043274093	widely applied
0.7042331825	matching priors
0.7042172083	kernel hilbert space
0.7041510029	support set
0.7041223563	bayesian shrinkage
0.7041042024	hierarchical bayesian
0.7040326629	computational limits
0.7040243154	message passing algorithms
0.7039974325	theoretical framework
0.7039972719	simulations illustrate
0.7039825890	phase type
0.7039569800	poisson distributions
0.7039023249	bounded set
0.7038853179	paper discusses
0.7038563718	thresholding estimators
0.7037623829	uniformly most powerful
0.7037493011	classification rules
0.7037270912	spiked random
0.7036891238	maximum likelihood degree
0.7036883876	empirical spectral
0.7036883101	group sequential
0.7036872590	riesz distribution
0.7036365235	measurement matrices
0.7035599543	based algorithms
0.7035478140	exchangeable random
0.7034255313	quasi stationary
0.7033230539	bayes predictive
0.7032100650	marginal regression
0.7031653390	model based clustering
0.7029240157	nonparametric bayesian inference
0.7029234084	lower and upper bounds
0.7028269704	low power
0.7027835183	component functions
0.7026963375	applications include
0.7026503486	initial conditions
0.7025856948	cox models
0.7024738963	binary variables
0.7023894049	white noise model
0.7023446519	previous approaches
0.7022875487	efficient estimators
0.7022839161	maximization problem
0.7022036593	theoretical claims
0.7021880035	spectral properties
0.7021743279	minimum sample size
0.7021694011	case cohort
0.7021024556	canonical correlation coefficients
0.7020699965	hermite processes
0.7020161065	phase transition phenomenon
0.7019059860	spatial correlation
0.7018540592	statistical hypothesis testing
0.7018371393	dynamic networks
0.7018044391	linear stochastic
0.7017893464	data stream
0.7017850560	scale free
0.7017144358	main challenge
0.7017129400	subject specific
0.7017013650	significantly outperform
0.7015194724	type inequalities
0.7015111363	prior measure
0.7014732878	gaussian vectors
0.7014393471	response vector
0.7013642892	open questions
0.7013325981	tensor valued
0.7012335473	regular graphs
0.7010596674	exponential dispersion
0.7010233580	state dependent
0.7010047815	stability property
0.7009924591	faster convergence
0.7009160262	nonzero components
0.7008446160	dynamic factor
0.7008433396	technical tools
0.7007225322	largest order statistics
0.7007196686	variation distance
0.7006044294	hierarchical structure
0.7004512737	linear spectral
0.7004136215	minimax optimal rates
0.7002343139	nonparametric bayes
0.7002310466	parameter identifiability
0.7001761991	urn model
0.7001252785	local search
0.7001163083	prediction problems
0.7000162930	nonparametric components
0.6999579010	reasonable conditions
0.6998401949	observational noise
0.6997883780	lasso path
0.6997735461	curie weiss
0.6997654222	concave densities
0.6997159489	mild moment conditions
0.6996980627	separable covariance
0.6996516583	simulated datasets
0.6996387917	generalized likelihood ratio test
0.6996364844	structural change
0.6995961899	regression vector
0.6994947887	simultaneous confidence
0.6994819477	logistic regression models
0.6993590328	lower tail
0.6993453379	degree sequence
0.6991701356	maximal inequality
0.6991654467	bootstrap approximation
0.6991593221	statistical procedures
0.6991406636	euclidean metric
0.6990950495	law of iterated logarithm
0.6990832227	exponential rate
0.6989189662	previously studied
0.6989090804	existing approaches
0.6988854270	recovery problem
0.6988825767	mixing properties
0.6988539786	general conditions
0.6988273975	multivariate data
0.6987659169	markov chain monte carlo algorithms
0.6985641362	bivariate copulas
0.6985531111	minimax regret
0.6985185746	predictive density estimation
0.6984200955	high dimensional covariance matrices
0.6983514879	structural equation model
0.6982888008	heston model
0.6982301469	shift parameter
0.6981222997	statistical tools
0.6980198865	additional information
0.6979324497	high level
0.6979097947	valid post
0.6978669738	bootstrap version
0.6977799466	resampling scheme
0.6977227940	subspace analysis
0.6976898126	shiryaev roberts procedure
0.6976745862	fast rates
0.6975873791	delta method
0.6975460581	spike and slab priors
0.6974749185	cross sectional dependence
0.6974461203	detection threshold
0.6973522301	nested models
0.6972996741	kolmogorov smirnov statistic
0.6972980996	optimal shrinkage
0.6972682910	residual life
0.6971909831	power law decay
0.6971077889	rate function
0.6970827042	smoothness assumption
0.6970512549	deep networks
0.6970235015	sequential prediction
0.6968644716	separation condition
0.6968628060	bayesian perspective
0.6968561084	high quantiles
0.6967700323	spectral risk measures
0.6967454725	vector field
0.6967149595	ergodic diffusion process
0.6964009575	important role
0.6963917381	lower bounded
0.6963639784	high dimensional vector
0.6963549896	lifetime data
0.6963540300	laws of large numbers
0.6963173593	beta type
0.6962734009	jump process
0.6962477217	conditional independence relations
0.6961205896	directional statistics
0.6960703349	practical importance
0.6960588828	fully bayesian
0.6960417598	success probability
0.6960192861	underlying distributions
0.6959454510	simulated and real datasets
0.6958618322	real wishart
0.6958054785	intensity estimation
0.6957061610	random sample
0.6956967786	small samples
0.6956693379	effective sample size
0.6956623483	exponential random variables
0.6955899460	carlo simulations
0.6955438794	strongly correlated
0.6955413775	extreme eigenvalues
0.6955296701	optimality results
0.6954936583	error distribution
0.6954533019	real case
0.6954039673	unknown variance
0.6952406399	sequential hypothesis testing
0.6951435893	prediction interval
0.6951056917	sharp oracle inequality
0.6950825557	graphical criterion
0.6950505126	main technical
0.6949487738	nonparametric regression function
0.6948266232	consistency and asymptotic normality
0.6947601792	copula density
0.6947240232	random networks
0.6946932421	partial order
0.6946898815	transformation function
0.6946066970	prior probabilities
0.6944025315	sparsity levels
0.6943505090	quasi maximum likelihood estimation
0.6941742034	location scale family
0.6941632986	large networks
0.6939921251	bayesian theory
0.6939459047	completely random
0.6938345308	block length
0.6937957938	generative adversarial
0.6937593267	optimality properties
0.6936636785	explicit expressions
0.6935426128	additional assumption
0.6933972118	forward operator
0.6933850595	indirect effects
0.6933734059	iterative procedure
0.6933733660	functional time series
0.6933696802	variational problem
0.6933376923	periodic function
0.6933175410	shrinkage estimator
0.6932588787	curved exponential
0.6931915084	stein unbiased
0.6931562824	natural language
0.6930694679	continuous function
0.6930466049	shape invariant
0.6927222333	moment bounds
0.6926839755	predictive distribution
0.6926787655	conditional entropy
0.6926619026	tail parameter
0.6925533401	set size
0.6924980251	probabilistic properties
0.6924977613	poisson dirichlet
0.6923625384	compact set
0.6922697277	realized covariance
0.6922655463	independence assumption
0.6922262348	closed sets
0.6922003140	random partition
0.6921964502	desired level
0.6920998493	kernel matrix
0.6920596570	missing at random
0.6920440520	fast algorithms
0.6920306342	minimax bounds
0.6920090150	unit vectors
0.6919326360	manifold estimation
0.6919303959	result holds
0.6918098489	block sizes
0.6917826771	simulations confirm
0.6917698738	linear inverse
0.6917323978	variational analysis
0.6917181536	random trees
0.6916743045	rigorous proof
0.6916513401	statistical functionals
0.6915883649	ergodic markov chain
0.6915635047	rank correlations
0.6915580087	modern scientific
0.6915397730	extensive numerical experiments
0.6914385187	spatial sign
0.6914187099	markov decision
0.6913174435	null and alternative hypotheses
0.6913157366	vector fields
0.6911958676	population covariance matrices
0.6911653256	decision functions
0.6911057300	prediction loss
0.6911002751	barndorff nielsen and shephard
0.6909984311	weaker assumptions
0.6909871173	completion problem
0.6909496361	topological structure
0.6908657492	independent increments
0.6908103730	spatial dependence
0.6907888185	recovery guarantees
0.6905137568	high dimensional covariates
0.6904574638	adaptive wavelet
0.6904198091	holonomic gradient
0.6903730441	shrinkage prior
0.6903715386	proposed approach
0.6902745197	discrete distribution
0.6902205225	chain monte carlo
0.6901634139	generalized linear mixed
0.6900578245	upper and lower bounds
0.6899121008	extensive numerical
0.6899033649	interaction model
0.6899017465	finite samples
0.6898324140	regression parameter
0.6898212802	log likelihood ratios
0.6897940291	frequentist coverage of adaptive nonparametric bayesian
0.6897414483	type bounds
0.6896743609	adaptive sampling
0.6895900116	numerical analysis
0.6894252681	information theoretically
0.6893459237	state domain
0.6893056859	parametric family
0.6892872786	batch size
0.6892627912	approximate message
0.6892583003	result implies
0.6892549818	empirical copula
0.6891981068	long run variance
0.6891728478	target distribution
0.6890536913	physical systems
0.6890121082	latent tree
0.6889622376	fixed alternatives
0.6889498010	integrated squared
0.6889266807	logistic loss
0.6888291096	bounded interval
0.6887756066	gaussian orthogonal
0.6887232438	optimal prediction
0.6886639021	oracle inequalities in risk minimization
0.6885511578	point estimates
0.6885102492	max stable processes
0.6885026845	sampled data
0.6883701881	arise naturally
0.6883219700	times series
0.6881775294	active subspace
0.6881335792	measurement vectors
0.6880537613	convolution model
0.6880256239	gaussian approximations
0.6880200182	mixing condition
0.6879331690	result shows
0.6879233120	statistical research
0.6878830040	fisher information metric
0.6878759666	recently received
0.6877437380	partial likelihood
0.6877256209	quantum statistics
0.6876825861	large graphs
0.6876385210	randomization based
0.6875423019	index set
0.6874231950	general result
0.6874204714	quasi posterior
0.6874175963	benjamini hochberg procedure
0.6874049172	finite support
0.6873449885	dynamic models
0.6872317488	bootstrap approximations
0.6872312246	probability mass
0.6871610938	shape matrix
0.6871343496	penalized criterion
0.6871196622	real world data
0.6870545835	target function
0.6868977595	finite sample behaviour
0.6868573419	stationary solution
0.6867974804	small scale
0.6867085486	parametric bootstrap
0.6866817900	robust mean estimation
0.6866533357	uniform convergence rate
0.6866398245	optimal solutions
0.6866113498	functional predictors
0.6865793168	sampling policy
0.6865033364	minimum risk
0.6863998952	logistic models
0.6863591148	sparsity assumptions
0.6862579630	random errors
0.6862295075	drift coefficient
0.6860241707	high dimensional statistics
0.6859753924	bivariate extreme
0.6857581151	sampling times
0.6857468755	optimal solution
0.6857321939	alternative hypotheses
0.6857232762	current state
0.6857188727	poisson binomial
0.6856688467	severely ill posed
0.6856661751	tyler's m estimator
0.6856002683	type deconvolution
0.6855886180	principal component regression
0.6854920407	bayesian setting
0.6854548657	nonlinear regression models
0.6853654929	normalized maximum likelihood
0.6853647942	relevant features
0.6853541903	unit variance
0.6853439990	divergence based
0.6852229608	challenging task
0.6851322664	previous studies
0.6851162132	convergence result
0.6851095571	block sparse
0.6850633640	population covariance matrix
0.6850215827	likelihood free
0.6849384250	statistical experiment
0.6848395972	valid statistical inference
0.6848253100	geometric graphs
0.6846611552	alternative methods
0.6845915740	sharp minimax
0.6844567833	piecewise constant functions
0.6843801571	equivariant estimators
0.6843497994	spectral algorithms
0.6842279677	critical point
0.6841112461	hazards model
0.6841049767	bandwidth parameter
0.6840993027	tail asymptotics
0.6840382269	large covariance matrices
0.6839470761	covariate adaptive
0.6838678441	result extends
0.6838622592	tail copula
0.6838210131	fully observed
0.6837942066	prior densities
0.6837122142	critical threshold
0.6836607579	exact sampling
0.6835657030	bernstein von
0.6835549518	random series
0.6835474367	probabilistic approach
0.6835311612	data analytics
0.6834595472	unknown smoothness
0.6833912402	rosenblatt distribution
0.6831812118	unknown sparsity
0.6830120933	data collected
0.6828761182	sheds light
0.6828143781	estimators achieve
0.6826822512	widely studied
0.6826036094	paper develops
0.6825479623	noisy observation
0.6825325663	regular models
0.6824027674	covariate distribution
0.6823469074	optimal scaling
0.6821306591	extensive monte carlo
0.6820663738	simultaneous confidence intervals
0.6820612625	estimator satisfies
0.6820405475	model selection procedure
0.6818877922	resampling based
0.6818711734	fisher's information
0.6818557210	basic properties
0.6818440108	fmri data
0.6817621862	structural assumption
0.6817614505	nonlinear inverse problems
0.6817605103	asymptotic coverage
0.6816804850	affine estimators
0.6816749861	results include
0.6816692929	normal law
0.6816531513	eigenvalue distribution
0.6816521308	gaussian designs
0.6816464913	large scale inference
0.6816275967	dimensional subspaces
0.6815768112	missing observations
0.6813118296	threshold selection
0.6812407979	score tests
0.6812351209	high dimensional covariance
0.6812093501	markov regime
0.6811968954	regularization parameter
0.6810157188	mixture autoregressive
0.6809609097	independence relations
0.6809405265	rate optimality
0.6808937245	missing entries
0.6808305195	multinomial distributions
0.6807904680	observation times
0.6806891983	general setting
0.6806594043	relevant information
0.6806302199	constant factor
0.6805956299	underlying signal
0.6805510758	minimal conditions
0.6804711584	extensive simulation
0.6804426051	feature vectors
0.6803945673	additional structure
0.6802845903	symmetric stable
0.6802798515	dimensional vector
0.6802778898	data types
0.6802562896	stationary gaussian processes
0.6802011041	law of large numbers
0.6801206645	numerical study
0.6800105812	reconstruction error
0.6799634279	product space
0.6799579169	adaptive confidence
0.6799410200	step function
0.6799281733	based inference
0.6798113416	kernel matrices
0.6797802023	convex body
0.6797079449	upper confidence
0.6795834169	nonparametric setting
0.6795143851	consistent model selection
0.6794370255	mises theorem
0.6794250127	extreme quantiles
0.6792978598	thresholding rules
0.6792956567	independent samples
0.6792160111	growth model
0.6791913738	gaussian random variables
0.6791024548	efficient computation
0.6787740530	multi parameter
0.6786898180	dependent variable
0.6786040173	error guarantees
0.6785901795	asymptotic level
0.6784656617	ml estimators
0.6783374458	deviation inequality
0.6781776978	parametric form
0.6781630272	learning tasks
0.6781143859	uniform bounds
0.6780920267	detection problems
0.6780866440	estimation theory
0.6780408234	quadratic covariation
0.6779864481	random initialization
0.6779706445	network structures
0.6779653419	deviation probabilities
0.6779379674	closed form solution
0.6779210361	asymptotic dependence
0.6778172167	discovery rates
0.6777817433	metric measure
0.6777196465	consistent estimators
0.6777097921	independently distributed
0.6776797135	location parameters
0.6776734125	ml estimation
0.6776430405	multiple change point
0.6775028179	kernel mixture
0.6773661925	inference tools
0.6772992576	sampling algorithms
0.6772683097	metropolis hastings algorithm
0.6772021283	increasingly important
0.6771769951	training examples
0.6770501943	results obtained
0.6770223572	estimated consistently
0.6769794443	grow large
0.6769592259	constraint based
0.6769398246	mild assumption
0.6768945891	numerical performance
0.6768163090	statistical literature
0.6768077738	confidence levels
0.6767559660	unknown error
0.6767521742	temperature parameter
0.6767122179	detection procedures
0.6766633401	convex loss
0.6765888363	scale parameters
0.6764451504	heavy tailed data
0.6762938549	smoothing parameters
0.6760634054	pc algorithm
0.6760460129	hazard rate function
0.6760330071	pair correlation
0.6760081788	sequential procedures
0.6759583113	spectral representation
0.6758587777	regular case
0.6758504188	unbiased estimates
0.6758322406	prediction regions
0.6757991390	exponential inequalities
0.6757756697	model selection method
0.6757196847	normal mixture
0.6756766254	projection based
0.6756485388	clustering method
0.6756306296	pitman yor process
0.6756291966	local levels
0.6756037023	fully characterize
0.6755998177	low rank approximation
0.6755584975	risk function
0.6754962754	variance functions
0.6754923353	simulation study shows
0.6753712572	general results
0.6753672604	linear dynamical systems
0.6753119934	stability properties
0.6752489914	mixed fractional
0.6749362943	gaussian models
0.6749341818	stochastic gradient algorithm
0.6747413181	point mass
0.6746595078	popular technique
0.6746514027	independence model
0.6745699696	spectral density estimation
0.6745419370	observation points
0.6744787028	tail probability
0.6742204335	divisible laws
0.6741785268	reduced bias
0.6740457613	spectral graph
0.6739965518	selection problem
0.6739651917	monotonicity property
0.6738487994	association studies
0.6738042594	exponential inequality
0.6737813799	quantile estimators
0.6737540647	norm minimization
0.6736844402	bivariate distribution
0.6736232222	unknown regression function
0.6736185802	data sources
0.6736053302	numerical experiment
0.6735985319	limiting case
0.6735915845	false alarm probability
0.6735111353	structured distributions
0.6734417036	dimension grows
0.6733727522	kolmogorov distance
0.6733305531	mixing sequences
0.6733014892	tailed distributions
0.6731524918	bayesian credible sets
0.6731509104	dimensional data
0.6730920564	bounded continuous
0.6730024468	monte carlo simulation study
0.6729443597	minimum spanning
0.6729332280	finetti's theorem
0.6728968227	linear estimators
0.6728479814	finite sample performances
0.6727441462	asymptotic expression
0.6727037108	finite interval
0.6726354384	ensemble kalman
0.6725078111	survival models
0.6724231758	latent variable model
0.6723859302	sparse regime
0.6723105889	individual sequences
0.6722996842	convergence holds
0.6722438845	natural extension
0.6722357292	stochastic systems
0.6722216597	group structure
0.6721934420	empirical results
0.6721347209	multi sample
0.6721244560	observation noise
0.6720660652	equivalence class
0.6720269272	minimum distance estimation
0.6719183046	sharp oracle
0.6718527459	range dependence
0.6717180242	step sizes
0.6715715203	conditional kendall's tau
0.6714657184	screening methods
0.6714301105	screening property
0.6713994526	parameter estimation problem
0.6713856675	map estimator
0.6712447969	baseline hazard function
0.6711203043	approximate likelihood
0.6711040012	binomial distributions
0.6710533592	relative performance
0.6710384079	spectral norm
0.6710137658	asymptotic normality result
0.6706307777	selection methods
0.6706034380	adaptive lasso estimator
0.6705128964	results cover
0.6703713516	power analysis
0.6702369670	random probability measures
0.6702344319	explicit forms
0.6701976758	density estimate
0.6701465886	posterior computation
0.6700191120	coverage properties
0.6699953486	integral representation
0.6699602034	detection performance
0.6699167405	large sample sizes
0.6699153668	lineage sorting
0.6698373183	extensive experiments
0.6697629532	concave penalized
0.6697554507	ordered set
0.6696940240	paper introduces
0.6696355115	weighted likelihood
0.6696323952	risk minimizers
0.6696066427	real data analysis
0.6695748111	increasing function
0.6695567833	population level
0.6695345746	search space
0.6695125433	group size
0.6695099015	quantum fisher
0.6694622848	null model
0.6693255303	moving average processes
0.6691476514	individual tests
0.6690891360	variational bayesian
0.6690062032	arm identification
0.6689102282	marginal densities
0.6688124258	modern machine learning
0.6687317838	tree based
0.6687193818	leading order
0.6686882153	inhomogeneous poisson
0.6686541635	asymptotic expansions
0.6686455119	remains valid
0.6686430172	jump measure
0.6684563650	consistent estimation
0.6684388064	compact interval
0.6684260138	marginal density
0.6684151810	detection rules
0.6683809994	model building
0.6683669548	attention in recent years
0.6683388214	hellinger loss
0.6682977505	adaptive density estimation
0.6681702064	generalized linear mixed models
0.6681656187	property holds
0.6681444614	parameter free
0.6681094921	continuous state
0.6679887604	semiparametric efficiency bound
0.6679380300	multivariate normal distributions
0.6677741166	structural parameters
0.6676380054	integrated covariance
0.6676179015	rigorous analysis
0.6675652672	high dimensional gaussian
0.6674867272	linear spectral statistics
0.6673487735	privacy constraint
0.6673428960	truncated pareto
0.6673127868	log concave maximum likelihood estimator
0.6672637442	theoretical insights
0.6671470174	mixture priors
0.6671365893	nuclear norm penalized
0.6671311139	rank statistics
0.6670669537	bayesian hypothesis testing
0.6670631123	distributional results
0.6669777630	infinite order
0.6669105548	efficient inference
0.6668316047	higher power
0.6666528740	genetic data
0.6665129221	ill posed inverse problems
0.6664161767	proof technique
0.6663059530	principal subspace
0.6662263118	poisson approximation
0.6661396625	proposal distribution
0.6661036743	classical statistics
0.6660797675	approximation errors
0.6660735232	robust estimates
0.6660479353	pseudo posterior
0.6658789509	monte carlo approximation
0.6658722567	hidden variable
0.6658050255	spectral density matrix
0.6657812804	based test
0.6657315660	problems arise
0.6656010410	intractable posterior
0.6655789557	uniform convergence rates
0.6654571565	practical implementation
0.6654441171	alternative approaches
0.6652527506	statistical performance
0.6652407952	linear approximation
0.6652297361	stronger assumptions
0.6651517352	risk factors
0.6650518492	monotone regression
0.6649977003	paper proposes
0.6649968526	exponentially distributed
0.6647218437	partial sum process
0.6647042578	upper tail
0.6646107007	random intersection
0.6646075938	interval censored data
0.6645077565	state space model
0.6644589004	numerical approximation
0.6643910171	regularization method
0.6643529552	data analyses
0.6642742130	based approaches
0.6641747475	important question
0.6640535334	training set
0.6639987556	geometric approach
0.6637594726	naive estimator
0.6637454575	change point problems
0.6636356838	fundamental limits
0.6636280039	prove consistency
0.6636016816	proportion of true null hypotheses
0.6635876962	spectral estimator
0.6632292799	half space
0.6630987006	procedure outperforms
0.6630905779	predictive power
0.6630863857	bias reduced
0.6630563283	uniform limit theorems
0.6629017709	leading constant
0.6627977482	key features
0.6627525602	transition kernel
0.6627369798	symmetric positive definite
0.6625160384	skew normal distribution
0.6625082277	map estimate
0.6624312871	accurately estimate
0.6623937871	stable convergence
0.6621590199	underlying population
0.6619971986	specific examples
0.6619713749	statistical practice
0.6619480499	unknown drift
0.6618634180	discussion of ` `
0.6617995086	regression adjusted
0.6617313507	reweighted least squares
0.6616980747	consistency result
0.6616714917	stochastic heat
0.6616689294	identically distributed random variables
0.6616399487	uniform sampling
0.6616354528	long history
0.6615991994	important case
0.6615108367	key results
0.6615102720	objective prior
0.6614889662	unlike previous
0.6614833009	median of means
0.6614036484	analogous results
0.6613822348	gaussian white noise model
0.6613361989	chi square test
0.6612446410	order selection
0.6611390111	strong sense
0.6610577843	unbounded support
0.6610069445	multivariate bernoulli
0.6609739711	lasso solution
0.6609469849	underlying density
0.6609048987	exponential distributions
0.6608523058	variance case
0.6607194494	graph structure
0.6607032117	arch models
0.6606999898	adaptive confidence sets
0.6606895719	tree space
0.6606785213	quasi likelihood analysis
0.6605561596	generally applicable
0.6605450609	linear inverse problem
0.6600958503	stable motion
0.6600023836	expected degree
0.6599230747	sparse poisson
0.6598987047	gaussian case
0.6597430522	gaussian process priors
0.6597359301	convex constraints
0.6596007817	partial least squares
0.6594459265	performance measures
0.6593589292	algorithm achieves
0.6591249226	instrumental regression
0.6590717540	decision theoretic framework
0.6590276574	high dimensional settings
0.6589002942	pairwise markov
0.6587352071	power divergence
0.6586297658	smooth signals
0.6585607873	spiked population
0.6584977086	single step
0.6584428549	fundamental problems
0.6583958360	sparse linear models
0.6583698115	symmetric group
0.6582786703	marginal log linear
0.6582728058	fixed size
0.6581647594	artificial neural
0.6580859903	decreasing density
0.6580530455	stochastic order
0.6580355768	log density
0.6580040772	spline basis
0.6578667691	adaptive nonparametric
0.6578458562	asymptotic expressions
0.6577867511	minimax convergence rate
0.6577576361	sign covariance
0.6577023172	asymptotic behaviour
0.6575986874	sequential monte carlo methods
0.6575847867	generalized additive
0.6575365988	contrast function
0.6574447651	multiple change point detection
0.6574175495	extended version
0.6574088998	population means
0.6574021023	scaling parameter
0.6573956380	point estimators
0.6573692643	analytic form
0.6573355468	algebraic properties
0.6572977989	univariate distributions
0.6571957960	partially linear model
0.6571953338	practical situations
0.6570916777	natural exponential
0.6570140143	lasso based
0.6569442221	predictive accuracy
0.6567599061	noise matrix
0.6567446334	simulation examples
0.6567350542	results complement
0.6567339889	infinitely divisible distributions
0.6566921526	complete data
0.6566540822	possibly infinite
0.6564355478	matrix perturbation
0.6560650648	typically assumed
0.6560230894	number of hidden units
0.6559566141	practical problems
0.6558973058	moment constraints
0.6557567997	location scale model
0.6557417656	max mixture
0.6556336550	true parameters
0.6555352719	theoretical validity
0.6554306387	high dimensional time series
0.6554236374	complexity measure
0.6554210521	statistical experiments
0.6552103335	location mixture
0.6551671070	penalized contrast
0.6550908872	mixing processes
0.6549014688	asymptotic minimax
0.6548043188	high density
0.6547796402	shape space
0.6546672800	simulation experiment
0.6546476269	elliptical models
0.6546271334	direction method of multipliers
0.6545802111	urn models
0.6544505993	significantly improve
0.6544265146	positive probability
0.6542735121	design density
0.6542335971	discrete random
0.6541335383	strictly consistent
0.6540979032	linear space
0.6540541002	pointwise estimation
0.6540357895	sequential probability
0.6540157297	smooth densities
0.6538239288	diffusion model
0.6538193117	closed form expressions
0.6535924800	global local
0.6535904200	completely monotone
0.6535023528	posterior measures
0.6534388756	fundamental importance
0.6533149506	sharp lower bound
0.6531620086	original process
0.6531193687	robust estimator
0.6531134056	theoretic framework
0.6530745274	gamma process
0.6529878223	statistical approaches
0.6529014682	growth charts
0.6528371569	sequential empirical
0.6527383501	variation norm
0.6525413688	theoretical predictions
0.6525154149	global testing
0.6524625765	fractional diffusion
0.6524153563	spatial regression
0.6524150182	main aim
0.6522401374	paper reviews
0.6522225288	optimal posterior contraction
0.6522181339	optimal performance
0.6522147099	linear discriminant
0.6522086182	distribution free tests
0.6521621285	high dimensional models
0.6521560422	finite sample breakdown
0.6521405548	strong evidence
0.6521013241	permutation invariant
0.6519998493	previous literature
0.6519463657	location scale mixture
0.6519440199	fixed dimension
0.6518676568	sparsity conditions
0.6518548017	type inequality
0.6518157742	empirically demonstrate
0.6515654630	approximation methods
0.6514598964	matrix theory
0.6513429455	minimum density power
0.6513297828	division algebras
0.6512111579	quantum information
0.6511688951	real applications
0.6511553506	` adl
0.6509649194	representation theorem
0.6509251597	deviation bound
0.6509233901	largest singular
0.6508774408	design theory
0.6508301343	perturbation analysis
0.6507880786	single observation
0.6505625386	privacy constraints
0.6503458027	recursive algorithm
0.6503049664	statistical risk
0.6502140925	stochastic integral
0.6501835412	kolmogorov smirnov test
0.6500814358	introduced recently
0.6500367789	asymptotically consistent
0.6500186194	multiple testing problem
0.6499828003	function class
0.6499342085	network model
0.6498956606	smoothness parameter
0.6498598094	slow rates
0.6497937334	randomly weighted
0.6497341634	class includes
0.6497151362	covariance estimator
0.6495949487	divide and conquer
0.6493792011	optimal tests
0.6492483480	transformation model
0.6492135133	potential function
0.6491496792	machine learning methods
0.6488809571	approximate factor
0.6488535897	logit models
0.6488450076	singular value thresholding
0.6484570169	graph selection
0.6484462199	standard assumptions
0.6484371906	poisson dirichlet process
0.6483510920	ambient space
0.6483332108	valid confidence intervals
0.6483031718	group sparse
0.6482754267	continuous distribution
0.6481385179	unit ball
0.6480816775	convergence complexity
0.6480808191	statistical perspective
0.6479720209	real world networks
0.6479456760	variable selection problem
0.6479098075	paper concerns
0.6477624425	self exciting
0.6477513940	nonparametric maximum likelihood
0.6476762440	power properties
0.6473075367	stationary gaussian process
0.6471719421	sample size increases
0.6471067065	sparse estimation
0.6470648003	log likelihood function
0.6470156934	general state space
0.6469546279	low order
0.6469543524	proposed test statistic
0.6469135755	randomized experiment
0.6468609411	stochastic partial differential equation
0.6468564731	mixture density
0.6467109393	size biased
0.6467061970	vector machines
0.6467020193	mild regularity
0.6466943556	likelihood principle
0.6465169281	simulation study illustrates
0.6464503744	regularization techniques
0.6464445504	functional central limit theorems
0.6463823785	extended empirical likelihood
0.6463306231	bernoulli distributions
0.6462343039	consistent variable selection
0.6462079019	cumulative distribution
0.6461054229	approximation algorithms
0.6458166316	fixed domain
0.6458084380	normal vectors
0.6457641828	mixture modeling
0.6457489011	conditional density estimation
0.6456417586	quantile regression models
0.6454742826	classical setting
0.6454261140	infinite sequence
0.6453574541	descent algorithms
0.6453558456	hybrid estimator
0.6449965752	signal to noise ratios
0.6448860245	rate adaptive
0.6446045893	accelerated failure
0.6445527833	statistical methodology
0.6441899404	expected values
0.6441021133	heteroscedastic data
0.6439365491	explicit expression
0.6438990308	multivariate setting
0.6438672865	important issue
0.6438541042	nonparametric prior
0.6438269876	empirical distributions
0.6437288763	probability generating
0.6435966829	nonparametric regression model
0.6435351850	asymptotic validity
0.6434727114	common change
0.6434379195	real world datasets
0.6434373547	continuous shrinkage priors
0.6433737447	initial estimators
0.6433652579	semiparametric efficient
0.6430100719	efficiency bounds
0.6428386431	simple random
0.6426839435	resulting estimates
0.6426213206	previous methods
0.6426148145	phase retrieval problem
0.6425937766	bernoulli distribution
0.6425762708	raw data
0.6425740172	linear dependence
0.6422634468	computationally efficient algorithm
0.6422564810	conditions required
0.6421198492	kernel hilbert spaces
0.6419870135	applications involving
0.6418995648	stationary time series
0.6418936950	recovery of sparse signals
0.6418479199	positive random variables
0.6415474541	existing literature
0.6415429923	taking into account
0.6415046758	classical result
0.6414183561	competing risks data
0.6412081308	structural parameter
0.6410926361	simultaneously estimate
0.6410909444	results generalize
0.6410116450	high dimensional robust
0.6409225013	poisson distributed
0.6408743549	node degree
0.6408670261	direct application
0.6407816880	self organizing
0.6407414423	results provide
0.6406666717	goodness of fit test
0.6406467979	convex optimization problem
0.6406199316	stable random fields
0.6405208764	self similarity
0.6404839699	minimax estimator
0.6404264521	variate normal
0.6403688277	complexity analysis
0.6400542737	dimensional manifold
0.6399270460	computationally simple
0.6398974044	carlo simulation study
0.6398775658	fundamental statistical
0.6398616846	dimensional spaces
0.6397465031	independent noise
0.6397351420	strong approximations
0.6396812274	limit behavior
0.6396398620	normal gamma
0.6396282873	newton raphson algorithm
0.6395965119	noise density
0.6395320248	simulations demonstrate
0.6395252099	matrix ensembles
0.6395078588	bayes procedures
0.6394665688	stochastic volatility model
0.6394097674	significance test
0.6393073912	asymptotic normal
0.6392188613	weak law of large numbers
0.6389389320	higher order moments
0.6387956141	recent studies
0.6387491680	temperature data
0.6387315860	bayesian regression
0.6386630584	modeling framework
0.6384513111	exact expressions
0.6384152253	covariance kernel
0.6380752132	mathematical models
0.6380552088	weakly consistent
0.6379959538	based tests
0.6379183422	theoretical studies
0.6377163379	simultaneous testing
0.6376230881	provide sufficient conditions
0.6375842447	semiparametric regression model
0.6374975354	provide evidence
0.6374112298	mixture prior
0.6372579258	correlation structures
0.6372035966	functional principal component
0.6369404132	consistency property
0.6368610112	positive dependence
0.6367732445	linear mixed
0.6366998258	log factors
0.6366083558	quasi maximum
0.6364691396	noiseless case
0.6364608065	bayesian estimators
0.6363967711	nonlinear model
0.6363271291	model selection procedures
0.6363062672	existing procedures
0.6361777879	empirical likelihood approach
0.6361708040	convex analysis
0.6360492182	transport problem
0.6359523530	pseudo random
0.6359403141	functional parameters
0.6358982230	source separation
0.6358815442	monte carlo algorithms
0.6358129437	gaussian matrices
0.6356071256	generalized method of moments
0.6354683023	false null
0.6354389321	long standing problem
0.6353508535	maximum likelihood type
0.6352664787	mixture based
0.6352437392	clique problem
0.6351887955	sparse and low rank
0.6350898868	deviation inequalities
0.6347124274	natural conditions
0.6346382144	explicit formulae
0.6345805199	empirical bayes methods
0.6345487200	main objective
0.6344547485	finite sample bounds
0.6344279610	kernel estimation
0.6343897395	complexity penalty
0.6343311239	error estimates
0.6342709112	pseudo marginal
0.6341307707	easy to implement
0.6339428690	estimator outperforms
0.6338540599	test functions
0.6338195467	synthetic and real data
0.6338126278	local average
0.6334137956	asymptotic sense
0.6333630575	weak regularity conditions
0.6333302723	existing theory
0.6332545110	natural estimator
0.6332155941	local linear regression
0.6330738438	unknown distribution
0.6329487520	asymptotic relative
0.6329403099	high frequency observations
0.6328555193	eigenvalue based
0.6328036401	false alarm rate
0.6327613655	quantile estimator
0.6327521977	neural network models
0.6327139395	location model
0.6326162305	transformation models
0.6324936142	ratio statistics
0.6324135531	high dimensional problems
0.6323519712	asymptotic confidence
0.6322360189	noise model
0.6322306477	minimax robust
0.6322297386	local shrinkage
0.6322224895	network size
0.6321672432	survival functions
0.6321333023	taking values
0.6320361101	finite fourth moment
0.6319141843	confidence distribution
0.6317667262	high power
0.6317648736	grenander type estimator
0.6316463860	multiple comparison
0.6315477479	unknown covariance matrix
0.6314207842	type i error
0.6314190502	prior free
0.6312974825	spectral estimators
0.6311792160	continuous random variables
0.6311441051	covariate information
0.6310068512	james stein estimator
0.6309447169	exponential family models
0.6308454467	posterior convergence rate
0.6308087993	empirical performance
0.6307957544	true null
0.6307664576	method works
0.6307661282	v fold
0.6307600204	estimation strategy
0.6306899097	equation models
0.6306505873	monotone hazard
0.6306487930	simulations suggest
0.6305368299	two parameter poisson dirichlet
0.6304626930	sequential change point
0.6303608648	poisson random measures
0.6302240431	statistical analyses
0.6301991813	bias variance
0.6300904441	underlying data
0.6299734904	adjusted langevin
0.6298268688	hazard functions
0.6297147246	derive explicit
0.6297012821	linear unbiased estimator
0.6291700032	machine learning tasks
0.6289717895	fixed domain asymptotic
0.6289270394	variable bandwidth
0.6288915310	valued random variables
0.6288868480	random designs
0.6286416932	integrated moving average
0.6285356161	hypothesis testing problems
0.6284696976	differential equation models
0.6283951947	maximum likelihood method
0.6282392846	rate depends
0.6281927520	convex combination
0.6280392781	resulting posterior
0.6280236828	exponentially large
0.6279100216	median based
0.6274506047	structured covariance
0.6274488290	da algorithm
0.6273197239	dimensional parameter
0.6272319313	sample spaces
0.6270995535	independent variables
0.6269440785	logarithmic terms
0.6267962440	simple form
0.6267390534	sequential design
0.6265509741	armed bandit problems
0.6265242961	minimax sense
0.6264700329	transition probability
0.6262873924	asymptotically normally distributed
0.6262723355	financial time series
0.6262273185	generalized likelihood ratio
0.6261538670	examples illustrate
0.6260430222	regression quantiles
0.6259156295	prediction performance
0.6258537540	local scale
0.6257702973	high dimensional space
0.6257529887	received much attention
0.6257148813	variance decomposition
0.6255727056	minimax rates of convergence
0.6254229839	signal plus noise
0.6253323867	finite markov
0.6250489434	goodness of fit
0.6249507270	degrees of freedom
0.6247673030	problem arising
0.6245139868	support vector machines with applications
0.6245065592	clustering methods
0.6244554298	log concave density estimation
0.6241849194	multivariate linear regression
0.6241538353	infinite dimensional space
0.6239984690	low dimensions
0.6239544023	sample correlation matrices
0.6239121787	mathematical framework
0.6238600289	likelihood ratio statistics
0.6238204165	distribution families
0.6237075027	minimax error
0.6236888725	independent copies
0.6236058465	deterministic function
0.6236001174	relevant parameters
0.6235927366	suitable choice
0.6234571227	recently established
0.6233809769	high dimensional sparse regression
0.6233545226	response functions
0.6232599607	general alternatives
0.6232218495	varying coefficients
0.6232044835	specific case
0.6230980318	input distribution
0.6230527759	extreme cases
0.6228853829	mild moment
0.6228682605	relative errors
0.6228574273	testing hypotheses
0.6227723782	fully data driven
0.6227718952	estimation performance
0.6226909396	data contamination
0.6226099932	data matrix
0.6225582774	optimal order
0.6225459244	strong assumptions
0.6225144378	real data set
0.6224209339	unified framework
0.6222758475	significantly faster
0.6222699548	lower order
0.6222407773	efficient algorithm
0.6222347487	empirical findings
0.6217744425	bayesian inverse
0.6217287875	gradient algorithms
0.6217201845	nonlinear time series
0.6217018852	kernel type
0.6216743356	multivariate regular variation
0.6216468863	fixed number
0.6215720666	case study
0.6215218161	nonlinear processes
0.6214973208	generating mechanism
0.6213153306	local independence
0.6211028788	statistics and machine learning
0.6210201437	family wise
0.6209582399	small set
0.6208472720	lipschitz functions
0.6208281758	concentration rates
0.6207482767	challenging problem
0.6206276816	specific cases
0.6205137179	low dimensional space
0.6202283606	empirical variance
0.6201873004	support vector
0.6201432198	dependence assumptions
0.6201419952	maximum marginal likelihood
0.6200364830	geometric rate
0.6200332419	low rank signal
0.6199515567	er von
0.6199265314	beta mixing
0.6199063738	long range dependent sequences
0.6199051346	white gaussian
0.6196207326	spline estimators
0.6195913654	empirical applications
0.6194920526	scale mixtures
0.6194733437	sampling methods
0.6194521028	real data application
0.6193357193	covariance models
0.6192617424	function values
0.6192416490	empirical eigenvalues
0.6192089231	stochastic partial differential
0.6190948706	depth function
0.6190592137	likelihood based inference
0.6189407984	low dimensional structure
0.6188835158	incomplete information
0.6188330321	probabilistic method
0.6187469125	analytical approach
0.6186655026	central role
0.6186069814	programming problem
0.6185742429	data structures
0.6184340848	dimension parameter
0.6183946181	theoretical performance
0.6183930211	potential functions
0.6182879878	information theoretic lower bound
0.6182420783	main focus
0.6178180976	important cases
0.6176920387	multivariate hawkes
0.6175953366	centered gaussian
0.6175704028	detecting sparse
0.6173725639	parameter dimension
0.6173368201	nonparametric maximum likelihood estimator
0.6172635788	graph models
0.6171850547	noise free
0.6171713126	paper presents
0.6171678138	recent literature
0.6170175626	optimal approximate
0.6170043881	numerical solution
0.6168968379	real life data
0.6168819032	sampling distributions
0.6167029009	concentration rate
0.6165003685	semi martingale
0.6164845065	penalized least squares
0.6164607295	likelihood method
0.6163377021	theoretical study
0.6162099601	dag models
0.6162075525	high dimensional regime
0.6160804390	current methods
0.6160221250	adaptive rate
0.6159242372	normal random vector
0.6159195806	de biasing
0.6159076430	paper establishes
0.6158918917	bayesian risk
0.6157700415	information measure
0.6157361935	nonparametric methods
0.6156290925	variance parameter
0.6156184924	adaptive inference
0.6155261255	obtained rates
0.6155136527	gamma distributed
0.6154970891	real world applications
0.6154930567	risk analysis
0.6154890213	sampling strategy
0.6154367150	response regression
0.6153645269	chi squared distribution
0.6153190699	transformed data
0.6153128514	drift estimation
0.6151355778	geometric structure
0.6151297349	takes into account
0.6149465812	traditional approach
0.6148872785	sum of squares
0.6148398829	norm penalty
0.6146615511	multivariate functions
0.6145809923	obtain sharp
0.6144425907	quantum hypothesis testing
0.6144370568	wise error rate
0.6143816789	brownian motion with hurst
0.6142537989	ill conditioned
0.6141069862	explicit bounds
0.6140857447	approximation algorithm
0.6140387849	variance covariance matrix
0.6139079535	choice models
0.6138559463	correlated variables
0.6136149708	special structure
0.6135748933	gaussian random vectors
0.6135608852	state tomography
0.6135084482	exponential moments
0.6132422271	monte carlo study
0.6131218036	partial likelihood estimator
0.6128274429	long run covariance
0.6127130499	deterministic markov processes
0.6126128812	exact results
0.6126109540	reference alignment
0.6125571974	exact tests
0.6124634034	standard brownian motion
0.6124263537	selection method
0.6123584030	spatial point process
0.6123042696	uniform in bandwidth consistency
0.6119663294	index models
0.6119566408	spike and slab
0.6117434370	sampling points
0.6116266309	slope function
0.6116135804	semi parametric estimation
0.6115994742	functional form
0.6113002002	linear regression problem
0.6112696796	treatment effect estimation
0.6112579933	squared risk
0.6112380973	standard model
0.6111932551	independent identically distributed
0.6111013657	linear state space models
0.6110747398	type statistics
0.6110084296	independent sample
0.6109383074	hidden units
0.6105353337	birth and death
0.6105051611	minimax lower
0.6104277762	standard brownian
0.6103559864	sequence data
0.6103289276	cramer rao lower
0.6101673062	promising results
0.6100824587	asymptotically efficient estimators
0.6099696282	important examples
0.6098149949	alternative proof
0.6097716292	type test statistic
0.6096169392	reconstruction method
0.6094487921	set theory
0.6093754051	approach consists
0.6093497249	normal random variable
0.6093332185	asymptotic risk
0.6092924318	squared hellinger
0.6092220401	transition density
0.6091549597	com poisson
0.6091263715	dimension reduction methods
0.6089976213	predictive models
0.6087326689	real data experiments
0.6087025941	dirichlet distribution
0.6086525642	walk metropolis
0.6085273354	type priors
0.6083551571	quasi likelihood function
0.6083277662	full duplex
0.6081799594	robust learning
0.6081722896	independent poisson
0.6078614298	free probability
0.6076646849	sample efficient
0.6076558104	least angle regression
0.6076259475	log factor
0.6074693432	synthetic and real world
0.6074038395	random sequence
0.6072706872	risk estimation
0.6072249576	probability matrix
0.6070276045	nonparametric priors
0.6070227072	honest confidence
0.6069534686	wavelet estimators
0.6067813994	data generating mechanism
0.6067343111	subgaussian random
0.6066823992	entropy estimators
0.6065875958	projected gradient
0.6065786557	polynomial approximation
0.6064936903	exponential concentration
0.6064208015	degree corrected stochastic
0.6062766924	ii distributions
0.6061487937	donoho and jin
0.6061245836	limiting variance
0.6060991771	prediction based
0.6059828739	general form
0.6059454270	error density
0.6059213781	frequentist properties
0.6058988103	finite sample behavior
0.6057686601	piecewise deterministic
0.6057197250	acyclic graph
0.6056089552	penalized maximum likelihood estimator
0.6055743164	actual data
0.6052854004	single sample
0.6051829474	function valued
0.6051294848	modulus of continuity
0.6050614510	bayes consistency
0.6050385823	regularized estimator
0.6050143621	regularized estimates
0.6050033047	cross covariance
0.6049108500	modern data
0.6048965865	gaussian regression
0.6048541929	consistency rates
0.6048431989	important task
0.6048350951	converge weakly
0.6047390734	obtain explicit
0.6044748839	local rademacher
0.6044347453	ornstein uhlenbeck type
0.6043098132	minimum coverage
0.6042737748	numerical method
0.6042593339	memory processes
0.6042322897	article introduces
0.6041978090	mixing distributions
0.6041626282	minimax testing
0.6040808815	deconvolution model
0.6040787313	standard approaches
0.6040132645	drift parameter
0.6039870185	completely data driven
0.6039830532	efficient method
0.6039720896	stochastic algorithm
0.6039305547	dimensional vectors
0.6038726517	communication systems
0.6037791550	law invariant
0.6036984979	vector machine
0.6036247202	log log
0.6035580290	parametric assumptions
0.6034583989	ill posed
0.6034561683	tail empirical process
0.6032765374	optimal algorithms
0.6032679611	best arm identification
0.6032274409	series representation
0.6032136355	gaussian design
0.6029934190	semiparametric estimator
0.6028682433	curse of dimensionality
0.6028549181	bayes estimation
0.6028541648	mises fisher
0.6028504935	constrained optimization
0.6028324926	2004 ims medallion lecture
0.6027765181	minimal assumptions
0.6026815280	likelihood ratio test statistic
0.6026459611	dot product
0.6024618921	sample correlation
0.6023551025	modern statistics
0.6022813153	row and column
0.6020551046	sparse matrix
0.6018742982	sharp lower
0.6018318345	homogeneous markov
0.6017353311	regression settings
0.6012718585	large sample theory
0.6012426275	smooth density
0.6012282045	method achieves
0.6012145275	bayesian models
0.6012135570	practical performance
0.6011842173	ordinary differential
0.6010017174	optimal sampling
0.6009658910	coefficient matrices
0.6009298062	degree of freedom
0.6008906666	empirical likelihood ratio
0.6008663434	pareto distributions
0.6008490752	nonparametric techniques
0.6008461533	paper shows
0.6007352609	uniform distributions
0.6006894596	integrated square
0.6006157769	distribution dependent
0.6005907233	latent variable models
0.6003822867	noisy matrix
0.6002693301	spiked population model
0.6002458904	moment method
0.6001162906	max stable process
0.6001003487	simulated and real data sets
0.6000241917	minimax convergence rates
0.5999869632	estimation and variable selection
0.5999846840	spatial point processes
0.5998584029	chi square distribution
0.5998255253	sparsity parameter
0.5994712850	exact confidence intervals
0.5994446679	sample moments
0.5993214832	large sample limit
0.5992968153	simple hypothesis
0.5992615731	quantum homodyne
0.5991437696	price process
0.5991312121	intensity parameter
0.5990946923	randomized algorithms
0.5990260545	type large deviation
0.5989183352	fast convergence
0.5988719439	target distributions
0.5986743164	hold uniformly
0.5984330430	gaussian random vector
0.5983368068	paper investigates
0.5983130926	normal model
0.5982207236	simulated and real data
0.5981922822	linear subspace
0.5980373279	family wise error
0.5980070420	karhunen lo \ `
0.5979393163	closed testing
0.5977340237	generalized spiked
0.5975587163	large numbers
0.5973752902	called `
0.5969576099	lo \ ` eve
0.5968590341	location scale distributions
0.5967868370	mean integrated squared error
0.5966294993	nonparametric estimator
0.5965217380	asymptotically efficient estimator
0.5964834426	search algorithm
0.5964488864	average treatment
0.5962435908	multivariate linear
0.5959339084	thresholding procedure
0.5959002182	drift and minorization
0.5958390403	larger class
0.5957751482	classical estimators
0.5956909436	weak limit
0.5956590387	logarithmic term
0.5956552789	finite rank
0.5955953087	classical approaches
0.5955938790	jump processes
0.5952924852	reversible markov
0.5952891466	powerful test
0.5950196804	robust procedures
0.5949939582	nonparametric rate
0.5946399138	semiparametric model
0.5943730020	high dimensional datasets
0.5942305127	chi squared test
0.5939943898	product structure
0.5938581308	skewness and kurtosis
0.5937975318	dimensional unit
0.5937433880	importance measure
0.5936664748	approximate maximum likelihood
0.5936400098	fan and li
0.5936009452	allowed to grow
0.5934742512	change point detection problem
0.5933461579	mean residual life
0.5932837632	normalized partial
0.5932367177	local information
0.5930905214	reward distributions
0.5929213102	unit interval
0.5929112251	type conditions
0.5929033780	carlo methods
0.5927962615	main result shows
0.5927370218	distribution testing
0.5926859301	unknown signal
0.5926377173	extreme value index
0.5926088905	functional regression
0.5925684443	general assumptions
0.5923461536	poisson point
0.5922396879	quasi likelihood ratio
0.5921710588	optimal threshold
0.5921505090	method called
0.5920348562	bootstrap inference
0.5917742351	chi square distributions
0.5916576383	possibly nonlinear
0.5915651928	screening procedure
0.5915646018	model class
0.5914541320	galton watson process
0.5913422399	message passing algorithm
0.5912010408	correlation based
0.5911506402	achieving optimal
0.5911354400	prior density
0.5910719973	depth based
0.5910705359	gaussian model
0.5910199731	large dimensions
0.5909537498	smoothness class
0.5909204899	approximation results
0.5908601258	rows and columns
0.5908361235	randomized clinical
0.5907956762	parameter identification
0.5907737391	varying coefficient model
0.5907063040	nonparametric function
0.5906941494	heavy tailed errors
0.5906866726	risk functions
0.5906692462	precision matrix estimation
0.5906615690	accelerated failure time
0.5903486968	limit process
0.5903137429	information rate
0.5902967392	orders of magnitude
0.5902081415	world datasets
0.5901728937	stationary functional time series
0.5899908743	simulated data sets
0.5899224470	differentiable functions
0.5898858544	asymptotic limit
0.5898420956	nonlinear statistics
0.5898275707	popular methods
0.5897951157	penalized estimation
0.5896490518	graphical structure
0.5895335411	group lasso estimator
0.5893920534	regularization function
0.5892672346	multivariate time series
0.5892411664	information loss
0.5891882060	normal models
0.5890405603	generalized estimating equations
0.5889435104	good turing
0.5887727654	right censored
0.5886056128	kolmogorov smirnov type
0.5884435088	asymptotically sharp
0.5884333059	optimization methods
0.5882471353	density power
0.5882446060	statistical dependence
0.5881040231	improved performance
0.5880721713	invariant density
0.5880175398	optimal estimation
0.5879640931	spline regression
0.5876495264	additive gaussian
0.5876072998	data point
0.5875547590	parameter set
0.5875470760	result applies
0.5875362089	structured linear
0.5874820655	based techniques
0.5872771705	backward stochastic
0.5870479602	unified theory
0.5868916632	optimal treatment
0.5868737876	low rank structure
0.5867777185	estimator enjoys
0.5867627465	problem consists
0.5867232828	empirical likelihood based
0.5866795750	noise distributions
0.5866114129	f_ \ theta
0.5866042878	locally asymptotically
0.5864145273	exact simulation
0.5864104977	gaussian assumption
0.5864076541	type bound
0.5861973499	underlying parameter
0.5861100314	present paper
0.5859597249	empirical data
0.5859374190	high dimensional sparse linear
0.5857028016	computational experiments
0.5855781356	divergence estimators
0.5855652225	adaptive testing
0.5854607630	flexible framework
0.5854133318	information matrices
0.5853559579	kernel method
0.5851174213	real examples
0.5850386322	gibbs point
0.5849877533	mean square error
0.5849867853	carlo simulation studies
0.5849044529	observation model
0.5848461536	biological data
0.5848112619	projection algorithm
0.5844844218	dependence conditions
0.5844465769	thresholding algorithm
0.5843142023	standard estimators
0.5841942189	mixed model
0.5840607225	general parametric
0.5839637711	computational algebraic
0.5838482987	resulting algorithm
0.5834898077	weak moment
0.5834309113	stochastic matrices
0.5831771555	linear structural
0.5830857810	popular models
0.5827224518	x ray
0.5826365660	estimation consistency
0.5825350585	reduction technique
0.5824719838	sure independence screening
0.5824380504	smooth functional
0.5820047184	discrete variables
0.5819620857	fractional ornstein
0.5818198534	unified analysis
0.5817674311	dimensional covariance matrices
0.5816099967	random effects models
0.5815343064	bayesian lasso
0.5814711756	self normalized
0.5814388897	linear spaces
0.5814147322	asymptotic performance
0.5813963804	estimation scheme
0.5813472942	statistical functional
0.5813291763	minimax optimal rate
0.5811123364	mixed effects models
0.5810821625	techniques developed
0.5810528010	uniform random
0.5809453335	bayes posterior
0.5809411898	optimal learning
0.5808792391	bounded functions
0.5808745229	weighted empirical
0.5808395536	asymptotic approximation
0.5807994823	censoring model
0.5805407882	lasso problem
0.5805296790	weighted graph
0.5803783187	bayesian model
0.5801357005	selection problems
0.5801156655	nonparametric model
0.5800818471	finite measure
0.5800169026	identity matrix
0.5800151113	suitable assumptions
0.5799387270	empirical loss
0.5799029648	empirical bayesian
0.5798787059	private estimation
0.5798227497	bias variance trade off
0.5798152615	null space
0.5798032061	constant factors
0.5796992890	efficiency bound
0.5796496176	structural equation models
0.5796275461	simple examples
0.5795902616	initial distribution
0.5795009702	change point model
0.5793436446	sparse models
0.5793107951	bayesian computation
0.5791857921	covariance parameter
0.5790647665	bayes error
0.5790335017	procedure performs
0.5790086358	f_ \ epsilon
0.5788153084	linear wavelet
0.5786862961	free approach
0.5786302273	nonparametric multivariate
0.5785434885	kernel type estimator
0.5784992323	inferential model
0.5784533049	outperforms existing
0.5784512912	optimal inference
0.5784145104	approximation problem
0.5783181138	variable selection methods
0.5783177359	limit results
0.5783111724	gaussian measurements
0.5782336849	large covariance
0.5781800007	statistical inverse problem
0.5781261185	nonparametric approaches
0.5778911335	standard normal distribution
0.5777664293	series models
0.5775603189	order moments
0.5774438036	generalized likelihood
0.5774254818	structural function
0.5773422691	optimal estimator
0.5772718060	main goal
0.5770081113	averaged stochastic
0.5769371832	dependent noise
0.5765905871	accurate estimation
0.5763371343	decay rate
0.5761524046	mixture regression
0.5761479979	gradient estimator
0.5761463898	high dimensional random vectors
0.5760147580	best linear unbiased
0.5759627728	semi parametric models
0.5758052750	change point problem
0.5757226112	common factors
0.5757022501	important practical
0.5755866699	self adjoint
0.5755768672	domain of attraction
0.5752854021	probability estimation
0.5751331583	mean field variational
0.5749138466	moving average process
0.5749044336	optimal design problem
0.5748778474	support estimation
0.5747801301	asymptotic size
0.5747650390	machine learning algorithms
0.5747109724	real dataset
0.5745704283	b splines
0.5745098365	sampling without replacement
0.5744798024	inferential methods
0.5743100473	generalized maximum
0.5742194511	clustering problems
0.5740114073	efficient implementation
0.5738243275	observed sample
0.5737599512	random times
0.5736759611	stationary sequence
0.5736420521	effect estimation
0.5735392653	real data applications
0.5731797144	achieve optimal
0.5730863549	model assumptions
0.5728880740	bayes estimate
0.5726804648	fast learning
0.5726378322	biased estimators
0.5725129419	bootstrap tests
0.5721983709	numerical results demonstrate
0.5721577555	classical tests
0.5718345120	difficult problem
0.5718230286	correlation analysis
0.5716824160	sparse principal
0.5715978067	sparse normal
0.5715472464	gaussian component
0.5715355038	p boxes
0.5714609597	multiple test
0.5712185952	unknown density
0.5710530402	efficient score
0.5710019148	divergence estimator
0.5708275175	graph sampling
0.5707123864	modeling approach
0.5706444063	high dimensional linear model
0.5704156606	information metric
0.5704060928	weighted graphs
0.5703761687	machine learning techniques
0.5702252857	stable process
0.5701572341	goldenshluger and lepski
0.5701561742	spherical gaussian
0.5701064543	stochastic matrix
0.5698663851	bernstein von mises theorems
0.5698471018	stable random
0.5697601217	testing algorithms
0.5697310415	negative log likelihood
0.5696809233	diverging number
0.5695966851	point estimator
0.5695610019	model dimension
0.5694318850	functional parameter
0.5694317048	large scale problems
0.5694232289	gaussian random variable
0.5693586440	examples including
0.5693235157	copula models
0.5692305746	multivariate location
0.5691162050	estimators perform
0.5690893010	speed of convergence
0.5690725721	traditional methods
0.5690231604	bayesian nonparametric approach
0.5690091870	eigenvalue condition
0.5689387888	normalized maximum
0.5688253861	competing estimators
0.5686547805	sectional variation
0.5683666709	change point estimator
0.5681098108	empirical likelihood method
0.5679129986	zero inflated
0.5678513603	bayesian method
0.5678183341	point of view
0.5677739837	consistent estimates
0.5677037899	sequential data
0.5676147614	statistical inverse
0.5674677358	statistical techniques
0.5673980461	approximate posterior
0.5673830186	general approach
0.5673642259	strong control
0.5672733185	conditional likelihood
0.5672525184	parameter estimator
0.5671804583	independent random vectors
0.5671785296	large dimension
0.5670117698	scaling limit
0.5670096141	minimax framework
0.5668553709	improved estimator
0.5667359715	mixture of normals
0.5667040239	sparse estimators
0.5666446694	akaike information
0.5665282467	estimation and hypothesis testing
0.5665198717	pseudo maximum likelihood
0.5665163738	high dimensional logistic
0.5664169842	high probability bounds
0.5663300840	statistical behavior
0.5662162275	recurrent markov
0.5662155093	numerical studies demonstrate
0.5662025756	matching problem
0.5661924380	robust optimization
0.5661897485	finite dimensional parameter
0.5660740520	analyzing data
0.5657374840	context specific
0.5655371508	common problem
0.5653608571	survey data
0.5653569769	geometric median
0.5653057659	provide rigorous
0.5653046937	main theoretical
0.5652084079	small size
0.5650806985	bootstrap confidence intervals
0.5650209171	large data
0.5649086478	analysis tools
0.5648793404	statistical hypothesis
0.5647913521	important applications
0.5647373737	systematic study
0.5646831350	consistent estimator
0.5645407285	results demonstrate
0.5643321530	high dimensional limit
0.5643274422	probability weighted
0.5643113247	mean squared error
0.5642729936	detailed study
0.5640648063	computational algorithms
0.5639904493	optimal convergence rate
0.5639380715	rate of convergence
0.5639175852	layer neural
0.5638670270	gaussian densities
0.5638629341	high dimensional covariance matrix
0.5638364645	markov chain monte carlo algorithm
0.5638186766	high dimensional linear
0.5636763680	estimator converges
0.5636105509	detection procedure
0.5630575453	constrained maximum
0.5628559125	data driven procedure
0.5627821426	main idea
0.5626092838	efficient estimator
0.5625708926	data matrices
0.5623689289	log concave distribution
0.5622650191	likelihood based methods
0.5622030314	data adaptive
0.5620682895	local minimax
0.5618624481	squared distance
0.5618048329	frequency data
0.5617644531	inference problem
0.5617293959	method of moments
0.5615318077	subspace estimation
0.5614122039	simple models
0.5613639653	accurate inference
0.5613538388	e commerce
0.5613431027	multiple linear regression
0.5611932632	general bound
0.5609648342	mixture distributions
0.5609228977	true null hypotheses
0.5608449960	gamma model
0.5607661073	rate optimal estimators
0.5607066543	closed convex
0.5606926690	graph estimation
0.5606341072	benjamini and hochberg
0.5605444515	scalar response
0.5603345711	model selection problem
0.5602682394	covariance estimators
0.5601615799	machine learning applications
0.5601006387	resulting test
0.5600202409	simulation studies demonstrate
0.5600052717	adaptive choice
0.5598961346	study shows
0.5591838901	specific classes
0.5591298132	breakdown and groups
0.5590630952	empirical examples
0.5590325182	reduction techniques
0.5589549290	metropolis adjusted
0.5589342985	true model
0.5588632136	arbitrary order
0.5583599150	information geometric
0.5583481122	true distribution
0.5579656312	binary symmetric
0.5579234078	lasso procedure
0.5579228204	step procedure
0.5577295229	sharp analysis
0.5577141755	_ \ ell
0.5577133257	signal estimation
0.5576101948	response data
0.5575643500	illusion of progress
0.5573978609	binomial regression
0.5573494676	study variable
0.5573086680	penalized least squares estimator
0.5572539745	exponential random
0.5571471015	underlying function
0.5570807524	dirichlet model
0.5569734459	stein's unbiased
0.5568229789	de biased
0.5563675733	exponential models
0.5562760669	experiments demonstrate
0.5562484933	inner product
0.5562345430	parametric tests
0.5559890396	selection scheme
0.5559324441	penalized empirical risk
0.5557531209	model selection problems
0.5556975970	provide explicit
0.5555537895	recent theoretical
0.5555405088	b spline
0.5554836146	weighted least squares
0.5554081564	stochastic model
0.5553376826	derive convergence rates
0.5550635188	provide conditions
0.5549697690	error processes
0.5549329104	extensive simulation study
0.5549048831	data driven selection
0.5548881410	` ag
0.5548730845	order autoregressive
0.5548702668	near epoch
0.5548246006	true values
0.5545745436	sample canonical
0.5544973291	rank based inference
0.5542811782	measures of concordance
0.5542279695	data objects
0.5541763314	establish minimax
0.5541278092	multivariate nonparametric
0.5538517098	general dependence
0.5534862163	order tensors
0.5533325262	applications to real data
0.5533298552	powerful tool
0.5533030179	sampling procedure
0.5531141585	develop efficient
0.5528603126	suitable conditions
0.5528567189	allowed to increase
0.5527767281	quantile regression model
0.5527268033	lack of fit
0.5526778789	infinite dimensional parameter
0.5524979736	empirical quantile
0.5524156733	data splitting
0.5524016466	random dot
0.5522300364	asymptotic tail
0.5521718761	linear functions
0.5521493089	location scale models
0.5520694050	improved estimation
0.5520317206	difference in means
0.5519640203	discrete case
0.5519423109	estimation in high dimensional
0.5518846144	general markov model
0.5516098838	sub gaussianity
0.5514949658	maximum likelihood approach
0.5514484226	data generating process
0.5514312327	motion with hurst parameter
0.5511730891	optimal adaptive
0.5509123599	discrete probability
0.5508209890	functional autoregressive
0.5508063532	computer vision
0.5506968957	poisson sampling
0.5506014422	empirical covariance
0.5503884914	possibly dependent
0.5503204281	random set
0.5503045572	matrix multivariate
0.5500292694	statistical information
0.5499459134	univariate regression
0.5496438821	estimator selection
0.5496438213	likelihood theory
0.5495845286	variable selection and estimation
0.5495786785	bayesian procedure
0.5495048309	model includes
0.5493049576	estimator performs
0.5492661159	location and scale
0.5492577576	long memory parameter
0.5492259697	dimensional spiked
0.5488550317	diffusion coefficients
0.5488157106	conditional tests
0.5487198262	parametric component
0.5485113810	regression curve
0.5483690749	asymptotic covariance
0.5483624698	number of mixture components
0.5482303318	measure space
0.5481473199	two layer neural
0.5479785476	linear quantile regression
0.5479347556	univariate random
0.5477349460	parameter estimators
0.5477162462	information based
0.5476821755	model uncertainty
0.5476628095	ill posed linear inverse
0.5476340395	theoretic approach
0.5475182763	strong law of large numbers
0.5474732928	coefficient models
0.5474583403	lasso method
0.5474573646	unknown function
0.5473697322	optimal estimators
0.5472532828	inference functions
0.5471400380	single realization
0.5470048732	uniform bound
0.5468920242	standard statistical
0.5467631137	projection pursuit
0.5467217829	oracle estimator
0.5466148886	minimax results
0.5465874736	true parameter
0.5465342105	generating distribution
0.5465323253	long memory stochastic
0.5464344253	random process
0.5463623524	series estimator
0.5461149079	nonparametric problems
0.5460850123	rates of convergence
0.5457776425	regression estimators
0.5455897068	order of magnitude
0.5455188486	empirical copula process
0.5452057059	computational statistical
0.5451995977	classification methods
0.5451750740	dimensional random vectors
0.5451714360	gaussian location
0.5451137891	drift parameters
0.5450267876	recursive kernel
0.5449759232	classical statistical
0.5448799647	sample drawn
0.5447710042	run length
0.5445927374	gaussian likelihood
0.5445891026	topological data
0.5445605440	shown to converge
0.5445137808	adaptive tests
0.5442018958	independent and identically
0.5440037262	monte carlo sampling
0.5436962432	two sided
0.5436820360	lasso estimators
0.5436752957	type tests
0.5436455131	bayesian approaches
0.5435334513	asymptotic covariance matrix
0.5434550164	slope parameter
0.5429728743	unbiased estimate
0.5426290194	sample variance
0.5423778004	previously obtained
0.5423731654	allowed to vary
0.5422050353	sparse covariance
0.5421755699	paper describes
0.5420521604	asymptotic normal distribution
0.5420492622	approach works
0.5420257964	probability models
0.5419812691	probabilistic analysis
0.5418553465	average run
0.5418520988	important special case
0.5418263735	extreme value statistics
0.5418253465	regression estimator
0.5417411393	optimal strategy
0.5416363456	large sample size
0.5415203778	pre and post
0.5411434850	gaussian measurement
0.5411163249	signal to noise
0.5410999444	parametric regression
0.5409635608	science and engineering
0.5403376508	geometrically ergodic markov
0.5401584986	low rank covariance
0.5401074770	underlying structure
0.5396302854	regression method
0.5395317279	deconvolution kernel
0.5393994203	biased sampling
0.5393127021	strong laws
0.5392093934	self contained
0.5390058327	generating process
0.5387938920	based estimator
0.5385886552	exact solution
0.5385412193	recently shown
0.5383878928	linear complexity
0.5379989617	explicit form
0.5379839957	central wishart
0.5376886448	penalized maximum
0.5376882087	adaptive nonparametric estimation
0.5376237012	paper examines
0.5375755020	gaussian variables
0.5372795896	type distributions
0.5372137786	gaussian distributed
0.5372060626	variate distributions
0.5369354183	concentration bound
0.5368561930	asymptotic result
0.5365867047	mathematical theory
0.5363587856	dependence coefficients
0.5361494455	dimensional linear
0.5359591992	type algorithm
0.5357540928	construct confidence intervals
0.5352231516	operating characteristic
0.5349660811	normalized sums
0.5348738059	single index regression
0.5348213730	asymptotically normal estimator
0.5346811928	data driven bandwidth
0.5341699995	marginal posterior
0.5341257008	sample based
0.5339860558	interval estimators
0.5337861497	buffet process
0.5337107698	stationarity and ergodicity
0.5337022265	size distributions
0.5336369222	learning framework
0.5336343780	function on scalar
0.5333234281	gaussian quasi likelihood
0.5332485504	gaussian linear
0.5331751874	structural properties
0.5331467713	small constant
0.5330162085	inference method
0.5329368232	selection consistent
0.5326365217	response adaptive
0.5325237979	criterion function
0.5323835832	limiting behavior
0.5323500693	model errors
0.5323380396	moving average random
0.5322882419	detection method
0.5321338536	proposed class
0.5320984630	bayesian optimization
0.5320920670	poisson model
0.5319704235	finite sample sizes
0.5319318908	bias and variance
0.5318962187	statistical estimators
0.5317506600	simple linear
0.5315708255	robust covariance
0.5313905205	information bound
0.5312974930	probability matching
0.5311457873	main purpose
0.5310807235	off line
0.5309731344	valued random
0.5309690737	concave density
0.5309553134	direct and indirect
0.5308409715	computer science
0.5308302586	results confirm
0.5307351468	inference framework
0.5306493661	simulated and real
0.5303484148	location and scatter
0.5303011472	high dimensional estimation
0.5300434565	gradient methods
0.5300349016	parameter selection
0.5297961298	estimation and model selection
0.5296248278	market data
0.5294219876	optimization based
0.5293215438	multivariate extreme value theory
0.5292242287	extreme value copula
0.5291568908	finite and infinite
0.5288579625	complex gaussian
0.5288264184	problem arises
0.5287117382	ii errors
0.5286713122	probability model
0.5286663861	geometric graph
0.5285467562	estimation of linear functionals
0.5285462842	gradient descent algorithm
0.5283581921	nonparametric regression models
0.5278763714	numerical experiments on simulated
0.5278690304	synthetic and real world data
0.5277884699	monotonicity properties
0.5277638536	asymptotic convergence
0.5275799931	valued data
0.5274996575	discrete or continuous
0.5274925075	probability function
0.5269951147	optimal test
0.5266903474	regression estimation
0.5264675614	basis pursuit
0.5264419731	based method
0.5262649674	cox proportional
0.5262508767	unknown noise
0.5262496833	optimal kernel
0.5261767174	establish consistency
0.5260768637	short and long
0.5260349310	one sided
0.5259922886	upper and lower
0.5259781133	linear process
0.5258930318	reduction methods
0.5258108538	gaussian matrix
0.5256917358	location and scale parameters
0.5255912179	inference algorithms
0.5255012634	switching models
0.5254352935	called ` `
0.5253598725	fan et al
0.5251530007	imaging data
0.5251085840	establish asymptotic normality
0.5250196045	gaussian cox
0.5249955673	multi reference
0.5249437446	change point test
0.5248023657	optimal filter
0.5247475758	uhlenbeck process
0.5244622932	noise variables
0.5244357639	power distribution
0.5244296184	article considers
0.5244029759	nonparametric bayesian approach
0.5243393059	functional principal
0.5243004631	modern statistical
0.5242622092	multiple index
0.5239913133	statistical settings
0.5239762380	gaussian process model
0.5238635075	de la
0.5238330932	high dimensional asymptotic regime
0.5238287061	sup norm
0.5237317924	easy to compute
0.5235725649	low computational
0.5234742378	proposed scheme
0.5230251435	expression data
0.5226507299	local and global
0.5225256362	large number
0.5224758154	errors in variables
0.5222288888	means problem
0.5222024808	local linear estimator
0.5217837139	symmetric distribution
0.5217239594	global and local
0.5216241276	rates of contraction
0.5216231037	dependent case
0.5215777182	simple closed form
0.5215167755	exact test
0.5214407472	discrete models
0.5214355877	tensor data
0.5214116846	conditional limit
0.5213610199	classical theory
0.5212017700	practical algorithm
0.5211115797	bandwidth kernel
0.5210373091	prove strong consistency
0.5210336806	domain asymptotics
0.5209084330	bayesian and frequentist
0.5208845227	large sample properties
0.5208468814	cand \ `
0.5207923970	function satisfies
0.5205174483	nonparametric change point
0.5204122709	asymptotic confidence intervals
0.5201102265	multivariate stochastic
0.5197686262	positive and negative
0.5192982368	best subset selection
0.5192633102	definite functions
0.5190255433	functional analysis
0.5189891341	optimal testing
0.5189123035	model averaged
0.5188700133	truncated data
0.5188664006	model selection methods
0.5188512847	theoretically and empirically
0.5187200204	well behaved
0.5186157884	bayesian nonparametric estimation
0.5185805756	sharp asymptotic
0.5185015808	likelihood based estimation
0.5183786798	finite dimensional distributions
0.5183519247	state estimation
0.5182089027	sample complexity bounds
0.5181515652	statistical problem
0.5178460462	quasi monte
0.5176658666	error covariance
0.5175555145	recent paper
0.5174383236	limiting spectral
0.5172128359	price data
0.5170896182	optimization techniques
0.5169969714	efficient methods
0.5169174255	form statistics
0.5168824378	bootstrap approach
0.5167398743	dimension increases
0.5165990178	volatility model
0.5163627344	high dimensional linear regression model
0.5161654300	conditional least squares
0.5161200199	data samples
0.5160083845	time varying
0.5160070827	outcome model
0.5159372068	proposed approaches
0.5158955117	order tensor
0.5158462472	censorship model
0.5157888047	extreme order
0.5157537026	multivariate garch
0.5157344104	univariate and multivariate
0.5156486014	sub gaussian
0.5152001511	asymptotic risk bounds
0.5149712381	pseudo maximum
0.5148802957	markov random
0.5147702380	random tensor
0.5146640492	multiple hypothesis
0.5146623894	important problems
0.5144651198	minimum mean squared error
0.5144241231	data based
0.5144124500	probability of causation
0.5141487003	graph theory
0.5138878294	likelihood estimate
0.5137305254	self similar
0.5137301550	important statistical
0.5136346720	adaptive randomization
0.5135702532	unified treatment
0.5135670288	second order cone
0.5135633123	empirical characteristic
0.5134844145	propose and analyze
0.5133349169	gaussian correlation
0.5132176991	sample case
0.5131327010	co kriging
0.5131032999	estimated parameters
0.5128991294	proofs rely
0.5128201040	off diagonal
0.5126327541	numerical model
0.5125599530	independent gaussian
0.5124819551	derive upper bounds
0.5121105232	discovery rate control
0.5120697994	first passage
0.5120525212	threshold estimator
0.5120016368	monte carlo algorithm
0.5117740111	nonlinear autoregressive
0.5115286620	optimal linear
0.5115155424	change point models
0.5113908419	multivariate dependence
0.5113563528	fixed design regression
0.5113286660	markov transition
0.5110733918	generalized gaussian
0.5109825613	bayes type
0.5109217922	consistent and asymptotically
0.5108354720	normal limit
0.5107402360	uniform in bandwidth
0.5107060965	criticism test
0.5107039881	vector parameter
0.5106670153	right censoring
0.5106383235	true regression function
0.5105829130	sequence model
0.5105762296	underlying probability
0.5105693763	gamma random
0.5103976047	multivariate case
0.5103693896	log linear parameters
0.5103450272	joint density
0.5103114057	analysis of variance
0.5101531525	type processes
0.5101054452	carlo sampler
0.5099839779	well separated
0.5099328335	world networks
0.5099211370	most probable
0.5095433334	covariance model
0.5095420644	applications including
0.5093496016	noise process
0.5093403251	large and moderate
0.5092485812	general methodology
0.5092269969	new york
0.5091911720	treatment and control
0.5091059008	unified approach
0.5090976636	real and simulated data
0.5089804574	classical approach
0.5088223916	log concave maximum likelihood
0.5088025318	linear functional
0.5087353850	convergence analysis
0.5085582995	extreme value distribution
0.5083846236	ill posedness
0.5082018199	distribution regression
0.5082004995	theoretical support
0.5081158468	detection algorithm
0.5080842571	real and complex
0.5080177537	regression with random design
0.5075575743	prediction problem
0.5072062653	least concave majorant
0.5071931702	optimal choice
0.5070437014	properties including
0.5069840209	sparse gaussian
0.5066022040	density based
0.5065335210	matrix completion problem
0.5064133062	sampling problem
0.5064003461	converges weakly
0.5063340900	unknown scale
0.5063336006	order derivatives
0.5061233763	high dimensional scaling
0.5060882400	gaussian sequence
0.5057349636	based procedures
0.5056730560	stationary linear
0.5054758080	latent variable graphical model selection via
0.5054547030	positive rate
0.5054480089	optimal bayesian
0.5051337233	data examples
0.5050875838	correlated errors
0.5047608580	probabilistic framework
0.5047364320	important properties
0.5046914884	drift function
0.5045329059	lower and upper
0.5045175008	linear shrinkage
0.5045020377	underlying parameters
0.5044214518	asymptotically unbiased estimator
0.5044018683	temporal and spatial
0.5042539812	correct model
0.5042154763	non central wishart
0.5039276855	paper demonstrates
0.5038324359	classical multivariate
0.5036930947	dimensional diffusion
0.5035993906	discrete and continuous
0.5035741709	bootstrap algorithm
0.5035544297	existence and uniqueness
0.5034343946	statistics literature
0.5033993134	optimal regret
0.5026411300	adaptive bayesian
0.5025032404	model selection approach
0.5024778049	max linear
0.5023155206	interaction models
0.5022396950	regularized maximum
0.5020057297	empirical study
0.5019952812	uniform error
0.5018837313	theoretical and practical
0.5017043956	testing multiple
0.5016693244	sparse and dense
0.5014556712	unknown distributions
0.5013916276	regularized least squares
0.5012288252	regression estimates
0.5011621026	process converges
0.5006875830	underlying regression
0.5005759065	dimensional regression
0.5001627696	linear and nonlinear
0.4999512466	key tool
0.4999454919	establish asymptotic
0.4999296435	converges almost surely
0.4997989004	two layers neural
0.4997471008	linear estimation
0.4995341568	uniform confidence
0.4993941052	means and variances
0.4992359874	procedure called
0.4990225371	k nearest neighbor
0.4989558030	nonstationary time series
0.4988999476	derive simple
0.4988644470	continuous and discrete
0.4986281992	concentration of measure
0.4985358978	polynomial rate
0.4983300753	exponential bounds
0.4983222650	results showing
0.4981176417	penalized log
0.4980405698	parametric methods
0.4977862867	annals of statistics
0.4974885717	covariance graph
0.4974532076	complex data
0.4970463261	change of measure
0.4968620931	negative log
0.4967738398	estimation algorithms
0.4967531530	shrinkage and selection
0.4965661972	alarm rate
0.4963740565	covariance matrix estimator
0.4962806764	linear regression problems
0.4962674876	bias and mean square error
0.4962419287	based models
0.4961834157	self normalization
0.4961349684	high frequency financial
0.4959627362	_ \ alpha
0.4957528723	integer valued time series
0.4956847137	sample behavior
0.4954959159	stationary and ergodic
0.4954701409	statistical method
0.4951708489	functional estimation
0.4950151191	weak and strong
0.4949977571	approach yields
0.4949944006	conditional maximum
0.4947073555	practical utility
0.4945901612	polynomial time algorithms
0.4944348786	additive white
0.4944270170	linear state space
0.4941817373	empirical application
0.4938721064	binomial and poisson
0.4938573261	f_ \ alpha
0.4936266433	differential equation driven
0.4935112048	drift and diffusion
0.4934850947	spike and slab prior
0.4933479630	exponential convergence
0.4932508999	models with latent variables
0.4931555855	including consistency
0.4931369775	fast rates of convergence
0.4928595859	estimation framework
0.4926958671	sufficient dimension
0.4925606822	proposed distribution
0.4924887343	uniform rates
0.4924390107	ill posed inverse problem
0.4919865374	kumaraswamy g
0.4919456253	samples drawn
0.4914660265	two armed bandit
0.4913328185	corrupted by noise
0.4910380943	establish sufficient conditions
0.4910354699	stage procedure
0.4908736188	set estimation
0.4907517233	crucial role
0.4906128034	tests of independence
0.4905112114	smoothed likelihood
0.4904080291	provide sharp
0.4903856400	size and power
0.4902315754	dependent error
0.4900215186	paper explores
0.4898687837	high dimensional distributions
0.4898071359	sparse precision
0.4896076825	right censored data
0.4895727240	algorithm for computing
0.4895425323	central subspace
0.4895071950	extreme value
0.4894859327	uniformly minimum
0.4894373863	bootstrap confidence
0.4894244045	important problem
0.4893724090	number of samples required
0.4893679000	paper extends
0.4892514705	provide finite sample
0.4891677301	well posed
0.4891181326	decision process
0.4890434032	derive upper
0.4890398129	minimal markov
0.4888904019	parametric and nonparametric
0.4888311228	well posedness
0.4887177491	simultaneous estimation
0.4886470559	univariate case
0.4884876448	theory developed
0.4884072861	extreme value analysis
0.4883492754	empirical estimator
0.4882153604	rare and weak
0.4881302867	estimation and prediction
0.4881121256	mis specified
0.4880736275	sensitive to outliers
0.4880032147	least square
0.4879928097	degree of ill posedness
0.4878517612	finite sample results
0.4877340877	well conditioned
0.4877230824	linear function
0.4873810955	type ii errors
0.4873093949	oracle type
0.4870897467	high dimensional case
0.4869625803	proof of concept
0.4869291451	design of experiments
0.4863956986	finite sample bound
0.4862739904	general case
0.4861890245	large probability
0.4859364791	polynomial time algorithm
0.4857982199	method of maximum likelihood
0.4857624784	robust and efficient
0.4857623896	general linear
0.4856899956	carlo algorithm
0.4856594185	small fraction
0.4856441995	linear latent
0.4855476638	valued function
0.4853529098	derive asymptotic
0.4853406711	averaging estimator
0.4852560484	carlo experiments
0.4850931786	arbitrary covariance
0.4850115509	dynamic model
0.4847794701	test of independence
0.4847671558	optimal rate of convergence
0.4847142633	pearson type
0.4846436441	binomial model
0.4846433585	multivariate extreme
0.4845480094	ball method
0.4845366351	frequentist and bayesian
0.4843313206	structural information
0.4842642995	gaussian density
0.4842593777	derive sharp
0.4841913394	key step
0.4841408158	method yields
0.4839234117	non negative
0.4834585474	univariate gaussian
0.4834273021	unknown matrix
0.4833678032	scalar parameter
0.4833522655	adaptive regression
0.4831823230	studies demonstrate
0.4830953762	second order
0.4830554582	theoretical and numerical
0.4829721699	coefficient of variation
0.4828986229	least squares
0.4828781118	central limit theorems for
0.4827550550	near optimal
0.4827543223	heavy tailed distribution
0.4827217125	expectation and variance
0.4826926701	method requires
0.4823839126	tight lower
0.4823818107	optimization procedure
0.4822810793	gaussian prior
0.4822539704	eigenvalues and eigenvectors
0.4821580223	introduce and study
0.4820913694	local geometry
0.4820252746	obtain asymptotic
0.4820233749	non identically distributed
0.4818776694	finite dimensional linear
0.4817696342	minimum mean squared
0.4817530765	inference results
0.4817255248	estimation and inference
0.4815793926	attachment model
0.4811101689	fast algorithm
0.4810221684	model components
0.4808594682	discovery proportion
0.4803551416	corrupted by additive
0.4803540876	u statistics
0.4802660132	optimal weighted
0.4800130303	distributed observations
0.4799554244	statistical and computational
0.4797420120	learning methods
0.4796112546	construct estimators
0.4793967786	population covariance
0.4793555175	sparse principal component
0.4793334820	poisson dirichlet distribution
0.4790159179	variation regularized
0.4787355154	component scores
0.4786575812	shapley value
0.4785275180	constant functions
0.4784672256	non trivial
0.4782284753	a b testing
0.4782021433	true density
0.4780859675	general method
0.4780307610	general formula
0.4778151377	minimal number
0.4778094895	tending to infinity
0.4777374137	problem of estimating
0.4777091641	positive real
0.4776767829	strong uniform
0.4776165412	mean squared prediction error
0.4775506963	regression and classification
0.4773871015	results require
0.4773585281	maximization algorithm
0.4773453362	death processes
0.4773294049	generalized least squares
0.4772862556	statistical procedure
0.4771996004	variance based
0.4768200633	analysis framework
0.4767099484	fractional gaussian
0.4766193809	point process model
0.4763906596	general model selection
0.4760097303	number of clusters
0.4759070778	process prior
0.4758366120	number of assets
0.4756782783	normal density
0.4756672489	nonparametric approach
0.4756082798	sampling techniques
0.4750323587	r von mises
0.4749532182	theoretically optimal
0.4745559698	upper bounded
0.4745435217	time consuming
0.4742743856	functional central limit
0.4742397989	computational and statistical
0.4741921906	finite sample distribution
0.4740980587	local alternative
0.4737571362	autoregressive time series
0.4737525014	high dimensional random
0.4737140466	define and study
0.4736787657	methods require
0.4736654512	normality results
0.4734377678	based measures
0.4733348463	probability and statistics
0.4733258587	bayesian mixture
0.4732037293	provide numerical
0.4729777762	provide asymptotic
0.4728275054	type models
0.4727929068	linear and quadratic
0.4725964886	paper studies
0.4722900660	spline estimator
0.4721983434	multivariate generalized
0.4721101595	examples demonstrate
0.4720642034	theory and practice
0.4720433254	analyzing high dimensional
0.4719548139	propose and study
0.4719402614	mixed data
0.4718542756	distributed estimation
0.4717179433	plug in estimators
0.4715475073	density operator
0.4712692849	valued observations
0.4709365969	real and simulated
0.4708874430	graph model
0.4707544935	exact minimax
0.4705197791	inference algorithm
0.4703516887	prediction and estimation
0.4702028009	for real normed division
0.4700815673	constructing confidence
0.4699336604	online algorithm
0.4699036718	establish uniform
0.4697535948	high dimensional consistency
0.4696723866	testing framework
0.4695374323	linear unbiased
0.4692064732	asymptotic distributional
0.4691021971	optimal minimax rates
0.4688439730	constrained least squares
0.4688260392	slab priors
0.4687743012	smirnov statistic
0.4682903130	optimal minimax
0.4682205636	tail empirical
0.4682079393	nonparametric procedures
0.4675191870	consistency and asymptotic
0.4674647383	positive constant
0.4673592518	regression methods
0.4672180106	true posterior
0.4671822871	independent bernoulli
0.4671394448	optimal rates of convergence
0.4670598211	testing equality
0.4667856607	statistic based
0.4666265477	expected number
0.4664989463	block gibbs
0.4664114000	estimation algorithm
0.4660989507	rank matrices
0.4660756339	point process models
0.4660325874	mathematical properties
0.4655057458	posterior analysis
0.4653793748	all or nothing
0.4653466613	consistent test
0.4652097345	theoretical perspective
0.4651647785	noise regime
0.4651021026	risk minimizer
0.4647332511	linear estimator
0.4644913139	restaurant process
0.4644804644	simulations and real data
0.4642855363	choice model
0.4640731489	data modeling
0.4638922832	functional dependence
0.4638622352	regression type
0.4636575929	low signal
0.4634712639	introduced and studied
0.4633842268	fractional stochastic
0.4630440868	expected error
0.4630201369	derive exact
0.4628787358	nonparametric framework
0.4627071084	varying tails
0.4626248603	method for constructing
0.4625773572	two sample test
0.4625392302	range dependent
0.4623887254	inference for high dimensional
0.4621729319	time changed
0.4621647023	tend to infinity
0.4620685808	range dependent data
0.4618161457	models include
0.4618155794	classification and regression
0.4617638940	broad class
0.4616543975	trade off
0.4616172051	optimal experimental
0.4611726831	matching pursuit
0.4610847001	functional central limit theorem
0.4610776246	spurious local
0.4607738556	optimal smoothing
0.4607010561	neighbor classifier
0.4605783547	article proposes
0.4604950172	_ \ lambda
0.4604469612	prior data
0.4601294496	functional limit
0.4600324573	point and interval
0.4599993121	matrix models
0.4599785810	shannon divergence
0.4599486020	asymptotic property
0.4598837446	standard bayesian
0.4595887557	approximation properties
0.4594425586	sequence of random variables
0.4594016245	leq \ infty
0.4590393283	explicit representation
0.4589133530	self decomposable
0.4588450443	sure screening property
0.4587426742	mixtures of gaussians
0.4586552647	simple and efficient
0.4585958067	individual data
0.4579872528	rank matrix recovery
0.4576622020	paper proves
0.4575756312	model called
0.4572138985	multiple samples
0.4571491484	random function
0.4571311973	degree polynomial
0.4570986080	family of distributions
0.4569725943	memory parameters
0.4567981891	detection and estimation
0.4566298321	valued functions
0.4565534640	frequency estimation
0.4564640442	binary random
0.4563770371	p_ \ theta
0.4563116747	unknown covariance
0.4562602848	synthetic and real
0.4562172139	continuous time processes
0.4561160494	composite null
0.4558251695	estimating parameters
0.4557445944	stochastic linear
0.4556978818	theoretical and computational
0.4556156232	number of edges
0.4553986563	diverge to infinity
0.4547963786	long memory time series
0.4544367246	one bit
0.4543896019	nonparametric additive
0.4543865730	detecting change
0.4543150172	testing method
0.4542441135	two stage
0.4540090255	nonparametric test
0.4537617141	asymptotic oracle
0.4536414529	non asymptotic oracle inequality
0.4535091365	high noise
0.4533604973	weighted estimators
0.4531673025	classical and bayesian
0.4530578778	definite matrix
0.4530327034	performance analysis
0.4530089218	thresholding methods
0.4530011309	parameter poisson dirichlet
0.4526280861	proposed and studied
0.4525355330	least favorable
0.4522164964	structured data
0.4520502916	high dimensional generalized linear
0.4518629437	present numerical
0.4518412498	infinite sample
0.4518323946	^ 4 5
0.4517653024	local asymptotic mixed
0.4516317381	selection operator
0.4508003421	dimensional continuous
0.4507222833	status data
0.4506741127	adaptive version
0.4504165854	noise distribution
0.4503913789	noise models
0.4500153865	bayesian non parametric
0.4494083043	general settings
0.4488245520	problems including
0.4487594583	shown to depend
0.4481895287	based procedure
0.4481561585	selected model
0.4478014092	stationary random
0.4477621342	simulated and real data examples
0.4476263836	current paper
0.4475879945	method outperforms
0.4475551998	input space
0.4474247967	proof relies
0.4473674315	log concave maximum
0.4472544532	density model
0.4471482885	key component
0.4471282305	theoretical and empirical
0.4470945314	powerful tests
0.4468389727	functional delta
0.4467299650	bayesian prior
0.4466698379	cut off
0.4464839451	asymptotic error
0.4464767101	theory and methods
0.4464683310	computational guarantees
0.4464440639	number of measurements
0.4463665153	numerical evaluation
0.4463379591	small simulation study
0.4462754801	small and large
0.4461455379	posterior rates
0.4461298780	samples required
0.4461049682	discrete time observations
0.4459492492	feature models
0.4458364325	pointwise asymptotic
0.4452510066	gaussian data
0.4450529488	minimax rate of convergence
0.4449020722	moving block
0.4448581367	based algorithm
0.4446997086	sparse bayesian
0.4446631807	high dimensional multiple
0.4446389723	matching lower
0.4445933836	variable models
0.4441378225	sparse high dimensional linear
0.4440142208	mean field limit
0.4438760546	distributed random
0.4438081002	total causal
0.4435358092	almost surely
0.4434928531	information contained
0.4431402039	learning models
0.4430303904	inhomogeneous random
0.4430265646	large matrix
0.4429100542	largest order
0.4428779532	resulting method
0.4427614234	results improve
0.4427188177	spatial point
0.4426813945	functional models
0.4422482749	squares estimators
0.4421100645	large sample behavior
0.4420729466	high dimensional functional
0.4419327695	sample testing
0.4416521698	separable hilbert
0.4415809607	local estimation
0.4415288327	paper addresses
0.4414760423	continuous shrinkage
0.4413658068	sampling model
0.4410543678	number of iterations
0.4409864271	optimal bound
0.4408424156	time series
0.4406618097	chain monte carlo algorithm
0.4403644951	high dimensional parameter
0.4402654563	distributed statistical
0.4401884431	column sums
0.4398529605	inner products
0.4398257647	methods developed
0.4396683503	resulting model
0.4396136104	number of neurons
0.4395733690	method performs
0.4394027800	size requirement
0.4391947479	alternating direction method of
0.4391351915	sparse random
0.4389134896	class classification
0.4388163215	normal random
0.4387893554	\ ` adl \ ` ag
0.4387820617	equations driven
0.4383744062	key role
0.4381013143	giving rise to
0.4380767623	an extensive simulation study
0.4380117470	theory and applications
0.4376580320	two sample testing
0.4376057445	rate of decay
0.4374940117	theoretical point of view
0.4374842030	theoretic properties
0.4374464271	geometric properties
0.4374412249	gradient method
0.4374355565	estimation and testing
0.4372662285	beta process
0.4372263904	classifier technology and
0.4370230833	derive minimax
0.4369766779	proposed statistics
0.4367866578	dimensional stochastic
0.4366772190	k means clustering
0.4362744868	limiting null
0.4362132389	optimal error
0.4361589643	corrected estimator
0.4360909172	fixed sample
0.4360444878	diverges to infinity
0.4360185865	strong theoretical
0.4360104696	popular tool
0.4359517205	parametric approach
0.4356821447	l_ \ infty
0.4355756561	selection algorithm
0.4355339901	convergence and asymptotic normality
0.4352890455	independently and identically
0.4351306192	number of samples
0.4346261590	leave one out
0.4345726012	positive density
0.4343790732	results apply
0.4343100336	decision processes
0.4342005236	heavy tailed random
0.4339759234	concave density estimation
0.4339392040	dimensional parameters
0.4339375243	presented to illustrate
0.4338171472	joint probability
0.4334927722	confidence sets based
0.4334779494	sums of independent
0.4334139003	empirical probability
0.4332228165	non parametric
0.4331998576	varying function
0.4331567002	fit test
0.4330417264	inequalities in risk minimization
0.4325743763	exponential covariance
0.4324714218	large scale data
0.4323935329	probability of error
0.4322993815	larger number
0.4321424743	bayesian point of view
0.4321185632	classical empirical
0.4320502703	weighted sum
0.4316569400	lasso and dantzig
0.4316176072	nonlinear least squares
0.4316155049	data dimension
0.4315973057	becoming increasingly
0.4315613293	ii error
0.4315580124	robust to outliers
0.4315279809	number of classes
0.4314146983	bayes procedure
0.4313791188	joint asymptotic
0.4304412231	previous paper
0.4300630487	norm based
0.4300593734	optimal bayes
0.4299007838	power spectral
0.4298152385	computer codes
0.4297786339	model size
0.4297139517	establish sufficient
0.4293830602	prove asymptotic
0.4293275349	statistic for testing
0.4292367317	least squares regression
0.4292206811	deviation principle
0.4287679895	structure estimation
0.4283144571	group model
0.4280284210	mixed linear
0.4280163869	positive semi
0.4279680292	adaptive group
0.4278815890	processes indexed
0.4276829266	paper considers
0.4270326818	iid random
0.4268553166	convex compact
0.4267702918	derive optimal
0.4266875559	stochastic dynamical
0.4266157578	estimator and derive
0.4265183193	high dimensional multivariate
0.4260150096	missing not at
0.4259683447	data driven choice
0.4259621600	experiments on simulated data
0.4253901228	closed form formula
0.4252652872	key idea
0.4251958049	general nonparametric
0.4251083439	role played by
0.4250613822	groups of variables
0.4250477878	least squares estimation
0.4250382799	stationary data
0.4249452988	illustrated on simulated
0.4248809396	convergence theorem
0.4247180133	without replacement
0.4247163587	normally distributed
0.4246319830	dimensional covariates
0.4246249485	non gaussian
0.4245731494	ill posed inverse
0.4243723625	covariate space
0.4243695129	heterogeneous treatment
0.4242097144	u statistic
0.4241689938	model order
0.4241613080	unbiased risk
0.4238435219	process of order
0.4234221523	shown to achieve
0.4232408131	grow to infinity
0.4230732192	nonparametric confidence
0.4230521118	gaussian white
0.4226353624	good turing estimator
0.4225742245	fixed and random
0.4221327551	conditional average treatment
0.4220037853	alternative models
0.4218980922	compared to existing methods
0.4217992336	approximation result
0.4217867384	pre specified
0.4217183572	sample of size
0.4216086475	simple conditions
0.4215800583	single change
0.4213847133	statistical data
0.4212667899	rate of contraction
0.4209787715	statistical point of view
0.4208604507	random orthogonal
0.4207275610	continuous time
0.4206465213	_ t \ geq
0.4204349061	driven stochastic
0.4199399600	obtain asymptotically
0.4197535877	article presents
0.4195203901	sample data
0.4194515782	robust nonparametric
0.4192859964	sample performances
0.4192669590	error in variables
0.4189712673	driven sampling
0.4188785771	perhaps surprisingly
0.4185032943	model structure
0.4184617485	design problem
0.4182092909	distribution theory
0.4181328096	observed random
0.4175465512	paper offers
0.4174247791	concentration properties
0.4174014449	error loss
0.4173462057	de finetti
0.4172406504	x_ n
0.4171717093	deviation theory
0.4171354010	general noise
0.4167160471	norm penalization
0.4164690119	multivariate distribution
0.4163069744	classical case
0.4158343578	bayesian variable
0.4157916856	asymptotic null
0.4156837221	stopping time
0.4156272251	continuous data
0.4155282295	sample coverage
0.4155032699	matching upper and lower
0.4155015102	karhunen lo \
0.4155015040	linear structural equation
0.4153925940	simulation and real data
0.4153765844	data driven method
0.4151923287	fractional stable
0.4149112462	least absolute
0.4149090117	spectral distribution
0.4148693626	step down
0.4148299236	noise condition
0.4146634890	families of distributions
0.4146423155	population model
0.4145918674	poisson random
0.4145512107	least squares estimator
0.4139661457	linear fractional
0.4138435151	sparse group
0.4138288113	non stationary
0.4135914530	distributed data
0.4135441285	set of points
0.4134299719	finite number
0.4134027814	homogeneous markov chain
0.4133597226	regularized m estimators
0.4133457366	variable selection in high dimensional
0.4130715982	side information
0.4130525666	product graphs
0.4130128723	de finetti's
0.4124558142	sheds light on
0.4123310512	index data
0.4122391039	dimensional variable selection
0.4120110957	markov chain model
0.4117042019	popular approach
0.4115912491	private data
0.4113185121	scale model
0.4112775518	gradient algorithm
0.4110764680	methods for estimating
0.4109239917	dimensional feature
0.4108092418	real log
0.4107927370	non degenerate
0.4106023160	positive definite functions on
0.4105512787	problem of reconstructing
0.4105338234	derive general
0.4104983320	sample problem
0.4104855832	exponential family of distributions
0.4104476563	selection and estimation
0.4103872452	type i
0.4100720491	limiting normal
0.4098433332	wide applications
0.4097304254	dt + \ sigma
0.4095827261	follow up
0.4095200343	time varying arch
0.4093324588	sequential hypothesis
0.4091470766	one parameter exponential family
0.4090912812	high dimensional statistical
0.4089567663	estimation approach
0.4088899431	input data
0.4087802637	provide simple
0.4087387622	scale multiple testing
0.4086486144	squared errors
0.4086464383	scale family
0.4085957160	statistical approach
0.4084428353	optimal bounds
0.4083717620	probability weighting
0.4083428760	parametric estimators
0.4081277498	off policy
0.4081213987	random error
0.4079656398	smallest eigenvalues
0.4075791029	provided to demonstrate
0.4074627595	the past decade
0.4074476563	approximation and estimation
0.4074222144	field limit
0.4073677529	independent normal
0.4073458035	among other things
0.4072294686	sparse data
0.4071640442	empirical version
0.4071057550	problem of recovering
0.4071005596	sided tests
0.4070195399	partial linear
0.4069087726	transition phenomenon
0.4068991482	likelihood test
0.4065870669	p values
0.4064396305	shown to hold
0.4064082040	penalized empirical
0.4061840338	chain monte carlo algorithms
0.4061551305	finite second moment
0.4058895157	order autoregressive process
0.4056922895	perform inference
0.4052495311	estimator and establish
0.4050829291	squares estimation
0.4050707897	first order autoregressive process
0.4050318682	parametric framework
0.4050303939	model error
0.4046741679	dimensional problems
0.4046344199	number of observations
0.4044285872	discrete graphical
0.4040748329	r package
0.4039996021	independent identically
0.4039472494	discrete times
0.4039030088	independent and identically distributed random
0.4038122771	process regression
0.4035812457	watson statistic
0.4034294663	exploratory data
0.4033490654	distribution estimation
0.4033370214	regression case
0.4032328274	under minimal assumptions
0.4029230027	computer experiments
0.4029160553	finite state markov
0.4028701495	^ tx
0.4028263029	practical point of view
0.4027464607	autoregressive moving
0.4025425785	rigorous theoretical
0.4022895287	experiments confirm
0.4021205809	sparse deep
0.4018502085	multiple random
0.4015748758	valued time series
0.4015086833	stationary markov
0.4013976852	class of priors
0.4010742418	index estimation
0.4009856030	parametric estimator
0.4009173334	independence structure
0.4007856782	algorithm converges
0.4006839080	average causal
0.4006621761	type distribution
0.4005864509	reduction method
0.4005317107	process priors
0.4004190612	learning setting
0.4002994932	method of proof
0.4002444106	multiple output regression
0.4001596182	specific model
0.4001170584	data application
0.4000546611	simple model
0.3999227404	log rank
0.3998200775	bernoulli random
0.3993473349	linear least squares
0.3992116817	likelihood analysis
0.3991412276	number of regressors
0.3990057272	general high dimensional
0.3989307213	sequential change
0.3988867741	inference in high dimensional
0.3987986998	spectral cut off
0.3986602846	norm error
0.3984480898	observed diffusion
0.3984148771	fixed time interval
0.3982981635	derive closed form
0.3980702349	average processes
0.3980432071	tensor model
0.3977695637	number of data points
0.3975062065	optimal local
0.3974281955	models including
0.3972828168	density models
0.3972475627	efficient sampling
0.3970814121	dimensional multivariate
0.3968531059	linear convergence
0.3967554727	o lya
0.3967037265	computer code
0.3966569153	user specified
0.3965559856	frequency observations
0.3965133387	generalised linear
0.3965048413	sub exponential
0.3964651037	multivariate regular
0.3964619380	ergodic process
0.3963866510	matrix normal
0.3963779023	markov jump
0.3960711382	variable model
0.3959265980	uniform asymptotic
0.3956826863	discrete fourier
0.3956650679	general distributions
0.3955901648	discrete time
0.3954239343	approach leads
0.3953897622	adaptive posterior
0.3953846147	experiments on synthetic
0.3953445438	asymptotic concentration
0.3952413620	1 bit
0.3949094818	independent data
0.3947849382	distributions defined
0.3947622602	regression algorithms
0.3945195921	le p \ le
0.3941893217	stochastic partial
0.3940546834	decision problem
0.3938385588	optimal properties
0.3935465410	lot of attention
0.3935199550	order terms
0.3932745500	variable regression
0.3930448043	_ \ infty
0.3926887950	classical nonparametric
0.3925735038	high dimensional bayesian
0.3923777217	number of columns
0.3923699507	hazards regression
0.3922843271	e chet
0.3922562493	linear and non linear
0.3921999496	general gaussian
0.3921813897	provide theoretical guarantees
0.3921716275	theoretic lower
0.3921462782	provide general
0.3920412071	out of sample
0.3919405406	non euclidean
0.3915025890	large random
0.3914947324	sequential importance
0.3913363924	normal data
0.3912399340	problems arising
0.3911352594	measures of association
0.3910919190	class of loss functions
0.3910652688	hold uniformly over
0.3909373092	observed time series
0.3907217096	_ \ mathrm
0.3904766435	parametric efficiency
0.3903342950	sample properties
0.3899543536	maximum likelihood estimation for
0.3899343421	model space
0.3898738277	low and high
0.3898450230	provide examples
0.3894436347	space time covariance
0.3891312785	_ i \ geq 1
0.3890953011	s & p 500
0.3888384769	non markovian
0.3886572277	class of prior distributions
0.3886131390	regression curves
0.3885473931	least squares linear regression
0.3884739279	measure of evidence
0.3879182297	non linearity
0.3877284154	construct asymptotically
0.3876479706	o lder
0.3875360248	no longer
0.3874983448	hidden regular
0.3874352121	paper aims
0.3873406701	taking advantage of
0.3871904209	positive random
0.3870549187	dimensional set
0.3870149702	continuous random
0.3867012386	classical problem
0.3864514111	linear ill posed
0.3864396541	bayesian estimator
0.3864094299	^ 2_1
0.3863000486	upper bounds on
0.3862843213	standard tool
0.3861170935	algorithm called
0.3860074752	number of communities
0.3858828221	~ \ cite
0.3858325317	provide sufficient
0.3857959540	errors in variables model
0.3857310345	continuous probability
0.3856923891	size distribution
0.3851285715	asymptotic oracle inequality
0.3851064106	important tool
0.3850771665	central limit theorem for
0.3850597086	strong consistency and asymptotic normality
0.3849573106	problem of computing
0.3847300282	convex risk
0.3844187093	multivariate random
0.3843901306	based estimation
0.3843104723	number of steps
0.3841916991	spherical random
0.3840043353	sigma ^ 2
0.3836261161	point detection
0.3835304487	model inference
0.3835007133	sample error
0.3832968082	automatically adapts to
0.3831395600	based bootstrap
0.3829797767	sharp phase
0.3829084866	this paper develops
0.3825991265	selection approach
0.3825654091	space models
0.3822125907	last decade
0.3821490598	based confidence intervals
0.3820367472	method relies
0.3817772873	statistical network
0.3817753292	random gaussian
0.3815373264	subspace spanned by
0.3809811693	time series models
0.3809370482	non linear
0.3809300686	estimation and model
0.3807791423	shown to attain
0.3806981665	selection for high dimensional
0.3806627464	square errors
0.3806315655	log gaussian
0.3804845487	in sharp contrast
0.3802436623	sup norm loss
0.3801646742	sample autocovariance
0.3799108188	failure time
0.3797924625	number of jumps
0.3797866344	effective sample
0.3796350244	observed at discrete
0.3795812303	gaussian stationary
0.3795630659	algorithm to compute
0.3794708036	simple approach
0.3793469742	study nonparametric
0.3792370489	class of distributions
0.3791169618	wide range of
0.3788992299	t tessellations
0.3788632778	type estimation
0.3787098732	eqnarray *
0.3786971333	number of predictors
0.3785366124	functional central
0.3784860434	estimation properties
0.3783252002	algorithm for learning
0.3779522516	closed form expressions for
0.3778986564	dependent time series
0.3778227697	matrix model
0.3777439742	multivariate normal mean
0.3777407128	response models
0.3777302276	establish strong
0.3775951650	so called
0.3775843062	almost sure
0.3774267355	conditional extreme
0.3773119765	robust test
0.3771119510	study confirms
0.3770561262	correctly specified
0.3769298801	conditional quantile function
0.3765242760	this paper proposes
0.3765075243	class of models
0.3764341614	constrained maximum likelihood
0.3763377054	order asymptotics
0.3759593877	series analysis
0.3759556514	coefficient model
0.3757810647	rank matrix estimation
0.3757535018	adversarial networks
0.3754216686	hold out
0.3754085763	statistical decision
0.3753945140	algorithms for computing
0.3746843152	testing data
0.3746378413	popular statistical
0.3744982842	chain monte carlo methods
0.3742486256	taken into account
0.3740847305	sampling rate
0.3740196845	information theoretic lower
0.3737726877	theoretic lower bound
0.3737622622	density level
0.3736641533	plug in estimator
0.3736277908	bernstein von mises theorems for
0.3735809273	bayesian decision
0.3732641587	family distributions
0.3730508388	non asymptotic
0.3730181222	uniform limit
0.3730014812	n ^ 1 2
0.3729656796	while maintaining
0.3728786810	classes of functions
0.3728100138	roberts procedure
0.3727497456	geometric characterization
0.3727229784	root n consistent
0.3726351099	driven by fractional
0.3726273297	bernstein von mises theorem for
0.3724932382	information bounds
0.3724729706	conditional kendall's
0.3724712860	method proposed
0.3723582361	finite discrete
0.3720557441	time to event
0.3719545828	data generating distribution
0.3717516022	process mixture
0.3717405436	mean field
0.3716971989	converges weakly to
0.3715741356	existing test
0.3715423574	type model
0.3715246267	under mild conditions
0.3714060695	class of estimators
0.3713306463	method to estimate
0.3713068715	number of blocks
0.3710142038	error process
0.3707945028	noisy case
0.3707063582	least squares estimators
0.3706126967	tests and confidence
0.3706073667	random data
0.3705745636	finite sample analysis
0.3705196904	two sample tests
0.3704760452	derive sufficient
0.3704681437	stochastic multi
0.3704654117	non homogeneous
0.3702550995	joint estimation
0.3700952963	gaussian error
0.3700822659	differential equations driven by
0.3700431805	power to detect
0.3699520507	concave distributions
0.3698827261	likelihood type
0.3697582788	time series analysis
0.3695401260	second moment
0.3695293009	number of species
0.3695258246	nearly linear time
0.3693900345	under weak assumptions
0.3693003747	van de
0.3692780084	rate estimation
0.3692069466	consistency and convergence
0.3689960391	learning techniques
0.3688103711	explicit formula
0.3686123302	set of candidate
0.3685793543	valid confidence
0.3685446055	value at risk
0.3679311075	non overlapping
0.3678321653	sparse estimates
0.3677866410	general model
0.3677337465	matrix estimator
0.3676689270	obtained by minimizing
0.3675342193	^ 1
0.3675105323	dimensional nuisance
0.3674691091	model estimation
0.3674563882	concentrates around
0.3674553273	conditional average
0.3668116112	fundamental problem
0.3667968842	weak law of large
0.3664254354	special class
0.3661475595	data model
0.3660173840	sub populations
0.3657367185	optimal number
0.3654032344	high degree
0.3649786041	selection properties
0.3649127574	nearly tight
0.3647919829	empirical beta
0.3646923349	carried out
0.3645867921	general stochastic
0.3644731505	testing based
0.3643359307	dependent stationary
0.3643246753	problem at hand
0.3643062349	regression approach
0.3641885386	regularized empirical
0.3641128541	erd \ h o s r
0.3640883101	compared to existing
0.3640259870	precise characterization
0.3637675252	high dimensional generalized
0.3635415589	this paper considers
0.3635135685	finite data
0.3633718905	method for estimating
0.3633377325	general multivariate
0.3631616874	order parameter
0.3629415308	continuous time markov
0.3628563181	data generated
0.3627704741	number of parameters
0.3626993340	lim_ n \ to \ infty
0.3626656079	_ \ epsilon
0.3626152678	little attention
0.3626132575	$ means clustering
0.3625844226	presented to demonstrate
0.3625501784	number of vertices
0.3625260987	based model
0.3624932018	real data example
0.3624274725	& p 500
0.3622706580	sparse model
0.3622311283	nonparametric mixture
0.3621030201	copula process
0.3619216581	indexed by functions
0.3618060812	local empirical
0.3613848307	a real data set
0.3610834818	squares estimates
0.3610725858	theoretical understanding
0.3609836810	problem of determining
0.3607577461	takes advantage of
0.3606389123	_ \ theta
0.3606013792	distributed variables
0.3603669642	high dimensional asymptotic
0.3602505746	beta copula
0.3601325300	provide exact
0.3597100088	likelihood methods
0.3596163185	establish consistency and asymptotic
0.3594962475	singular value
0.3592278705	self similar processes
0.3590210600	density and regression
0.3588678286	number of nodes
0.3586052105	asymptotic conditional
0.3579578068	multiple change
0.3579074763	strong law of large
0.3576377489	conditional mean
0.3574334446	error models
0.3571039613	e vy
0.3570318921	dimensional time series
0.3569241498	process framework
0.3567713301	sparsity oracle
0.3567644825	problem parameters
0.3564666628	technique for estimating
0.3563941056	rate functions
0.3563508926	alternative approach
0.3563073645	results illustrate
0.3563003812	thresholding estimator
0.3561062263	matching minimax
0.3560610897	estimation procedure based
0.3557773473	x_ 1
0.3555578175	results rely
0.3553917008	series forecasting
0.3553100452	testing and estimation
0.3551887275	non reversible
0.3549350827	locally d optimal
0.3547927335	well understood
0.3546993212	probability functions
0.3545904804	linear state
0.3545199775	_ k \ in \ mathbb
0.3544414695	obtain exact
0.3543203770	framework for modelling
0.3541717119	this paper introduces
0.3540818898	present results
0.3539394353	general asymptotic
0.3536244541	functional central limit theorem for
0.3535587299	adaptive kernel
0.3535383964	built upon
0.3534440309	a unified approach
0.3534097507	dimensional statistics
0.3533003812	bayes methods
0.3532519716	frechet mean
0.3531368077	posterior measure
0.3530877663	tends to infinity
0.3528814616	k 1
0.3525241515	generalized extreme
0.3524260263	restricted strong
0.3517380311	full generality
0.3516117672	original model
0.3515918392	quantum hypothesis
0.3511279514	gaussian observations
0.3509203848	identified models
0.3508087980	random linear
0.3507919936	provided to illustrate
0.3507071471	rank matrix
0.3505580949	computational lower
0.3503862377	motivated by applications
0.3503503376	^ 2d
0.3502280435	number of components
0.3498388320	commonly used
0.3496655146	p value
0.3495097235	integrated empirical
0.3492658516	probability bounds
0.3491494115	this paper presents
0.3490680641	simple to implement
0.3487969454	framework for studying
0.3487902944	t_ n
0.3487160339	generalized extreme value
0.3487064997	global markov
0.3486200722	studies and real data
0.3485663163	application to real data
0.3485500751	design setting
0.3484350888	bayesian optimal
0.3484095280	arbitrary number
0.3483747525	proofs rely on
0.3483682083	order cone
0.3478209911	shown to yield
0.3478119317	gaussian time series
0.3477580770	function based
0.3475475193	limit of large
0.3473755367	art algorithms
0.3473182456	independent copies of
0.3472862836	state hidden
0.3472771764	multivariate central limit
0.3471255823	this paper investigates
0.3470911262	less restrictive
0.3470565863	prior based
0.3470430533	^ 3
0.3468672448	standing problem
0.3467620759	based statistics
0.3467261668	estimation and hypothesis
0.3466499940	training dataset
0.3465345951	multivariate statistical
0.3464108478	universal constant
0.3462165575	broader class
0.3461999236	right truncated
0.3461469584	under mild regularity conditions
0.3461201323	wider class of
0.3460882619	proposed bootstrap
0.3459513169	free tests
0.3459487424	measure of uncertainty
0.3458835816	square distribution
0.3457939437	asymptotic upper bounds
0.3457280207	ordinary least squares estimator
0.3457103771	conditional survival
0.3453606943	n ^ 1
0.3453005894	distance estimation
0.3449628865	strong consistency and asymptotic
0.3448082426	derive non asymptotic
0.3447158935	= 1,2
0.3445634725	driven procedure
0.3444422902	et al
0.3444403802	means estimator
0.3442617481	multivariate gamma
0.3442118580	framework for analyzing
0.3440835538	improves upon
0.3440337934	goes to infinity
0.3440252020	put forward
0.3438306649	performance compared
0.3436835653	shown to perform
0.3436222035	models involving
0.3435475193	estimation and variable
0.3435453263	critical value
0.3432966159	symmetric random
0.3432425341	based framework
0.3432039150	squares regression
0.3431672267	method to construct
0.3431637045	a wide range
0.3431317212	index estimator
0.3431083797	study asymptotic properties
0.3431014279	general loss
0.3430690719	asymptotic bounds
0.3426922269	driven models
0.3426246768	bivariate case
0.3426011809	prove strong
0.3420772324	function estimator
0.3418912932	sample behaviour
0.3418298076	optimal convergence
0.3417642349	hochberg procedure
0.3416482028	empirical analysis
0.3415285379	step up
0.3414475344	first stage
0.3411747077	local differential
0.3409768021	upper bound on
0.3409258765	paper deals with
0.3407889877	high dimensional model
0.3407381769	obtain consistent
0.3406805539	estimation rates
0.3406639027	non decreasing
0.3406179679	ratio tests
0.3406157761	variance unbiased
0.3405546481	first order
0.3405372483	squares problem
0.3405362324	b stat
0.3404205444	take into account
0.3404059572	linear combinations of
0.3401321193	\ vartheta
0.3400676856	risk functional
0.3400516613	_ 0
0.3398411809	presence of outliers
0.3397325794	random probability
0.3397054168	local limit
0.3393537272	nearly optimal
0.3393518938	continuous time process
0.3392481124	finitely many
0.3391423350	suitable regularity
0.3391313857	analysis of contingency
0.3390571630	extend results
0.3389949365	consistent variable
0.3386597012	process models
0.3384832577	number of covariates
0.3384203441	optimal statistical
0.3383111235	insights into
0.3382992333	number of change points
0.3382911860	differential equation driven by
0.3381590810	convergence in distribution
0.3379221532	construct confidence
0.3378672456	exact confidence
0.3378646484	non central
0.3378530860	problem of finding
0.3377968847	convergence of moments
0.3377391239	resulting confidence
0.3376946463	continuous time stochastic
0.3375894819	prove upper bounds
0.3374788315	optimal sample
0.3374103738	mathbb r ^ n \ times
0.3371952733	large scale multiple
0.3370857827	nonparametric maximum
0.3370819577	data structure
0.3370630125	limited number
0.3370514861	sample situations
0.3369154894	variety of fields
0.3368885113	time inhomogeneous
0.3368556011	post model
0.3366961791	under suitable regularity
0.3366849203	true signal
0.3366586164	under mild assumptions
0.3364927742	go to infinity
0.3364120674	provide empirical
0.3361044460	linear observations
0.3358922303	finite fourth
0.3358244951	mar \ v
0.3356503324	range dependent time series
0.3355905655	approximation method
0.3354072136	_ \ mathcal
0.3352096799	partitioned into
0.3352058024	projection onto
0.3351180945	components analysis
0.3350727019	conducted to illustrate
0.3350431457	decomposed into
0.3349570842	comprehensive simulation
0.3349242395	order efficiency
0.3348604836	insight into
0.3348335701	moderate sample
0.3347079623	two step procedure
0.3344980845	normality result
0.3342332388	tailed errors
0.3339563190	\ approx
0.3339173456	testing for high dimensional
0.3338742433	local likelihood
0.3338307561	f _n
0.3337881499	probability ratio
0.3337150991	space time
0.3336751249	data distribution
0.3332692959	samples generated
0.3332683981	important class
0.3332091945	\ epsilon_
0.3330751735	bayesian point
0.3330442072	algorithm proposed
0.3330300740	dimensional linear model
0.3329818413	priori information
0.3329777996	continuous case
0.3328093297	non gaussian noise
0.3326345668	provided to support
0.3324836586	increase to infinity
0.3324681723	compared with existing
0.3324141603	second kind
0.3322714991	dimensional distributions
0.3321816725	two fold
0.3321531845	non convex
0.3321080870	simulation algorithm
0.3321005046	process mixtures
0.3320906474	range of applications
0.3320779253	number of particles
0.3313963284	problem of selecting
0.3312693595	simple method
0.3310408167	moments estimator
0.3310119989	dynamical system
0.3309537275	divided into
0.3305761016	without losing
0.3305675067	normalized random
0.3305645279	monte carlo markov
0.3304498478	an in depth
0.3303522991	finite sample properties of
0.3302341641	learning applications
0.3300465897	two component
0.3300424150	matrix regression
0.3299816032	\ cdot
0.3297159414	rank one
0.3296323256	two stage procedure
0.3296092015	y_ n
0.3295246670	one dimensional
0.3294168385	study demonstrates
0.3293890561	problem of detecting
0.3292103025	classical method
0.3291820436	orthogonal matching
0.3291519370	optimal asymptotic
0.3289993433	algorithm for solving
0.3288531804	$ \ rho_ 12
0.3285462261	\ cdots
0.3285225503	mean square
0.3285075774	noise limit
0.3283297595	based on minimizing
0.3283090838	parameters estimation
0.3282833989	test based
0.3281673734	illustrated by simulation
0.3276692810	the optimal minimax rate
0.3276294462	robust version
0.3274427133	nearly unstable
0.3272992640	two sample
0.3272596806	with high probability
0.3272551180	nonparametric statistical
0.3270864053	one step
0.3268963620	_ 1
0.3268712984	abrupt changes
0.3267419808	frequency asymptotics
0.3266908590	matching upper
0.3266017634	linear dynamical
0.3265079871	present article
0.3259581804	convergence in probability
0.3259499510	minimax optimal rate of convergence
0.3257370740	bayesian information
0.3253220291	simple algorithm
0.3249557021	rate control
0.3245693101	important application
0.3244419473	symmetric positive
0.3244090078	unknown number
0.3242743150	order to improve
0.3241145623	+ 1
0.3240071115	framework for modeling
0.3237282410	continuous time observations
0.3236397211	classes of distributions
0.3236267592	local convergence
0.3234841823	risk estimate
0.3234339085	study asymptotic
0.3232832748	frequency sampling
0.3231210910	model parameter
0.3227674455	popularly used
0.3226945736	time dependent covariates
0.3224605906	mass function
0.3224446427	kullback leibler divergence between
0.3223378944	test statistic based
0.3222105202	set up
0.3221505615	simple sufficient
0.3221102612	\ citet
0.3220367807	\ wedge
0.3219869398	problem of constructing
0.3218233062	more precisely
0.3217544398	\ theta_i
0.3214522383	larger than
0.3214408175	dependent covariates
0.3210867855	infinite number
0.3210092889	mixture of normal
0.3209593855	variables regression
0.3209170358	general theorem
0.3208136980	_ 1 \ leq
0.3207697641	non negligible
0.3207668506	based on high frequency
0.3207314197	under suitable conditions
0.3205787679	\ quad
0.3205681282	similar result
0.3204822725	the shelf
0.3204773560	\ texttt
0.3204461831	generalized functional
0.3201259758	simultaneous variable selection
0.3200812509	governed by
0.3199173882	sum_ j
0.3198627116	discriminate between
0.3197310724	well defined
0.3196884486	under high dimensional scaling
0.3196589966	\ circ
0.3196271578	sparse logistic
0.3195553399	sample test
0.3193000858	nonparametric estimation of
0.3192308178	score estimator
0.3190988546	\ equiv
0.3189780893	\ theta_0
0.3186627724	parametric density
0.3186450560	weaker assumptions than
0.3186201379	increasing number
0.3185246373	non gaussianity
0.3184153570	average number
0.3183980648	\ dots
0.3183868363	paper makes
0.3183186743	consistency of maximum likelihood
0.3182660511	learning approach
0.3181397800	paper derives
0.3180490199	matrices with independent
0.3178284387	dimensional linear regression
0.3176114057	norm regularized
0.3173670648	in high dimensions
0.3173514532	data illustrate
0.3170599456	over parameterized
0.3169944299	relations between
0.3165927274	spectral statistics
0.3165485682	isotropic positive
0.3165358675	dependent functional
0.3164159836	effects models
0.3163192797	distance estimator
0.3163183035	after model selection
0.3161832575	a small simulation study
0.3161529822	number of groups
0.3158207221	simultaneous confidence bands for
0.3153093830	consistent estimate
0.3152669074	\ geq1
0.3151447069	dimensional inference
0.3149847480	series data
0.3148318185	assumption of independence
0.3147762621	= 0
0.3144575671	method based
0.3144006403	time series forecasting
0.3142928221	linear regression model with
0.3142111302	measures of dependence
0.3140140944	weak regularity
0.3139828974	multivariate function
0.3138984445	two step
0.3138106828	dimensional data analysis
0.3137180128	order optimal
0.3136027652	tailed noise
0.3135870806	bayesian quantile
0.3135651670	o lder classes
0.3134580324	great deal of
0.3133545003	loss of power
0.3131846061	data distributions
0.3131566046	number of factors
0.3131489754	minimax convergence
0.3130842825	studies confirm
0.3129634876	bayes approach
0.3129440998	optimal up to logarithmic factors
0.3129237052	methods based
0.3128250227	d optimal designs
0.3127766605	a central limit theorem
0.3126514862	\ to0
0.3124459785	fr \
0.3123057179	without imposing
0.3121466945	\ otimes
0.3121238468	improve upon
0.3119717105	recent result
0.3119544503	problem of testing
0.3118356804	\ vert
0.3118165724	\ subseteq
0.3117994851	time periods
0.3117638877	near optimality
0.3117539712	converge in distribution
0.3114453039	into account
0.3113440183	\ citep
0.3112981909	distribution based
0.3112363159	two dimensional
0.3112001384	\ mathsf
0.3111808979	\ leq1
0.3111054625	non asymptotic concentration
0.3110975621	provide simulation
0.3110741183	this article presents
0.3110462845	bayesian linear
0.3108878414	proposed estimation
0.3106091023	m 1
0.3105805531	general markov
0.3105687611	problem in statistics
0.3104417326	greater than
0.3103883056	well suited
0.3103653350	dependence functions
0.3103361535	widely used
0.3101245540	m estimates
0.3100809185	\ ll
0.3100093254	asymptotic mixed
0.3097465243	run variance
0.3094523352	\ le1
0.3094523352	\ rightarrow0
0.3094283000	based on continuous time observations
0.3094146165	\ omega
0.3093522773	measure of dependence
0.3093362152	\ scriptscriptstyle
0.3093320028	explicit upper
0.3092868309	statistical results
0.3091697049	passing algorithms
0.3091447924	optimal posterior
0.3089126648	multivariate central
0.3087964273	^ 2
0.3085438210	n ^ 2 5
0.3085142313	\ geq2
0.3083805836	\ rm
0.3083105118	\ rangle
0.3082542638	sharp upper
0.3082377658	design regression
0.3081973003	general class
0.3081466945	\ beta_
0.3080634104	^ \ dagger
0.3080373393	sufficient conditions for
0.3080180404	non iid
0.3078482191	\ psi
0.3078274363	optimal model
0.3078178862	near linear time
0.3077975045	\ eta
0.3075099146	tree estimation
0.3074850708	varying parameters
0.3073474639	limit theorems for
0.3073138157	large values
0.3072494157	\ mathrm poly
0.3071467523	constructed based
0.3071382858	high dimensional variable
0.3070951207	sample theory
0.3070676354	taking values in
0.3069232072	as special cases
0.3068393227	penalized least
0.3066038762	nonparametric two sample
0.3065166941	polynomial time
0.3063650740	confidence intervals for
0.3062737152	\ stackrel
0.3061076826	\ delta_n
0.3060949457	service time
0.3058734373	study minimax
0.3055552819	without relying
0.3052726153	class of functionals
0.3051369080	non asymptotic upper bounds
0.3048213313	\ pi_0
0.3048125875	waiting time
0.3047105118	\ neq
0.3046342209	in high dimensional settings
0.3044710513	mat \
0.3042410657	non regular
0.3041513411	\ theta_n
0.3040892693	go beyond
0.3039603394	dt +
0.3039186997	in total variation distance
0.3038838496	wide class
0.3037928524	\ ensuremath
0.3037229514	worse than
0.3036653974	closely related to
0.3035106650	^ 4
0.3034279413	limiting behavior of
0.3033300905	rank 1
0.3032737152	\ qquad
0.3032464210	number of terms
0.3031275550	by efron et al
0.3029763145	frequentist coverage of adaptive
0.3029090712	life data
0.3029082945	_ i = 1
0.3028947348	not necessarily
0.3028183384	framework to study
0.3027424653	this short note
0.3027230569	optimal nonparametric
0.3025999080	\ ln
0.3025796365	dimensional regime
0.3025648872	\ bigl
0.3025381156	converge weakly to
0.3025196890	parameter function
0.3024015795	locally optimal
0.3023795148	^ 5
0.3023780767	true underlying
0.3023362152	\ biggr
0.3023023651	grows to infinity
0.3022203124	\ operatorname
0.3021440191	non adaptive
0.3021307561	test statistics based
0.3020250527	applications in machine
0.3019821264	own right
0.3019620738	bounded random
0.3016589966	\ bigr
0.3016570738	\ ldots
0.3015996981	identically distributed data
0.3015049360	shed light
0.3014790724	\ lesssim
0.3012928524	\ longrightarrow
0.3012593368	non parametrically
0.3011198825	art methods
0.3009757071	poincar \
0.3007436386	building upon
0.3006237580	\ sigma_n
0.3003555735	obtain results
0.3002538376	slower than
0.2999875268	a separable hilbert space
0.2997925419	a priori knowledge
0.2997176630	sampling problems
0.2996813587	the maximum likelihood estimator
0.2994790724	\ vee
0.2993138379	number of features
0.2993105118	\ textbf
0.2993034569	\ nu
0.2992656637	echet mean
0.2991975953	range of besov
0.2990813453	broader class of
0.2990462444	while retaining
0.2988237405	\ cite
0.2986069948	this paper addresses
0.2985461295	dimensional probability
0.2985019696	large number of
0.2984790724	\ biggl
0.2984346433	standard regularity
0.2980806619	selection in high dimensional
0.2980248121	general models
0.2980154896	= \ arg
0.2979626414	^ 6
0.2976298086	important special
0.2973970577	does not require
0.2973961295	time dependent
0.2971927493	matrix with independent
0.2971189773	occupation time
0.2970265970	\ lambda
0.2965698621	lower bounds on
0.2964354193	m estimation
0.2963105118	\ theta_
0.2960306074	\ pi
0.2958155454	infinitely many
0.2956211718	\ rho
0.2954659304	concentration inequalities for
0.2954417869	interplay between
0.2954337565	single parameter
0.2953495549	restricted parameter
0.2952737152	\ pi_
0.2951179364	erd \
0.2951093056	an important tool
0.2950489952	m estimators
0.2950074530	posterior contraction rates for
0.2949778283	conditional growth
0.2948850394	cram \
0.2947902004	carlo algorithms
0.2945543778	simple proof
0.2943899729	there exists
0.2942667119	\ sim
0.2942055280	skew t
0.2941931818	\ epsilon
0.2941163637	^ \ ast
0.2940695310	gr \
0.2940300088	suffer from
0.2938464404	applied to obtain
0.2938454408	establish conditions
0.2938155581	\ mu
0.2937785692	matrix based
0.2936414644	an information theoretic
0.2935682555	uniform central
0.2935332057	study illustrates
0.2934907480	general class of
0.2934071493	mean integrated squared
0.2933896803	test for testing
0.2933792065	an open question
0.2932799627	model framework
0.2931614128	x_ t
0.2930389556	asymptotic properties of
0.2930149619	broad class of
0.2930053496	bbb r
0.2929466945	\ overline
0.2928102366	$ th order
0.2926409663	faster than
0.2922762315	nonparametric random
0.2921496551	\ xi
0.2921028684	csisz \
0.2920981754	smaller than
0.2919606736	world applications
0.2918616267	central problem
0.2918016938	lower bounds for
0.2917477952	\ delta
0.2914506654	per iteration
0.2913703750	variety of settings
0.2910633434	davies and u
0.2909667486	well specified
0.2906982378	mean squared errors
0.2904313156	algorithm to estimate
0.2903404999	time scale
0.2903352723	large sample behavior of
0.2903012946	an open problem
0.2902591124	popular class
0.2901987410	\ sigma
0.2900971990	common approach
0.2898897359	\ epsilon ^ 2
0.2898518919	asymptotically equivalent to
0.2897380414	upper bounded by
0.2897370370	viewed as
0.2897264541	random model
0.2896670029	performs well
0.2894747394	\ varphi
0.2892636812	for real normed
0.2891400823	d 1
0.2889900847	aims at
0.2889865501	\ varepsilon_i
0.2888055561	confidence bands for
0.2887147172	estimators obtained
0.2885889862	\ langle
0.2885345517	a_ n
0.2884987756	t \ ge0
0.2882109804	mean estimation
0.2880667367	rank estimation
0.2880236050	linear statistical
0.2879889862	\ lambda_
0.2879315018	\ mu_n
0.2878902588	estimator proposed
0.2878363609	above mentioned
0.2878325743	\ kappa
0.2877668674	\ begin align *
0.2876878539	this article proposes
0.2876841688	a simulation study shows
0.2876589966	\ sigma_
0.2875889862	\ lambda_n
0.2875827089	family of tests
0.2875688737	binary hypothesis
0.2874425393	more sophisticated
0.2874281934	there exist
0.2872923519	sparse parameter
0.2872737152	\ mapsto
0.2872396099	a high dimensional setting
0.2871677819	this paper explores
0.2871623398	expressed in terms
0.2869925326	non stationary processes
0.2869780214	dx_t =
0.2869536069	\ sf
0.2869308942	k means
0.2868588563	tusn \
0.2868504145	conditions for consistency
0.2865889862	\ mbox
0.2865617520	vector based
0.2864891960	\ em
0.2864545511	error of order
0.2863076149	\ geq
0.2862437151	order moment
0.2861250655	time horizon
0.2860259388	performs better than
0.2859800918	procedures for testing
0.2858829393	much wider
0.2858763639	closed form formula for
0.2858752362	sharp oracle inequalities for
0.2858144522	valid statistical
0.2856814630	more importantly
0.2855778423	_ t \ in \ mathbb
0.2855043718	general framework for
0.2853282181	this paper discusses
0.2852415015	standard linear
0.2852249225	^ \ star
0.2851453938	sampling based
0.2851149047	well known
0.2850055411	approach to construct
0.2849460017	+ \ epsilon
0.2847842911	nonlinear inverse
0.2846211432	maximum likelihood estimation of
0.2845631955	number of outliers
0.2844190985	risk bounds for
0.2843537752	previous work
0.2843465468	testing methods
0.2843211243	detailed analysis of
0.2841826149	\ leq
0.2840902299	scale data
0.2840156568	bit matrix
0.2840098669	process model
0.2838807259	illustrative example
0.2838450730	parametric statistics
0.2836850141	the high dimensional setting
0.2836619921	temporal data
0.2836192666	third and fourth
0.2835936118	wide range of applications
0.2835821487	total variation distance between
0.2834281474	squares estimate
0.2832176627	gaussian markov
0.2831950172	sum_ i = 1 ^ n
0.2830447294	indexed by
0.2829819440	simultaneous variable
0.2829275554	\ tilde
0.2829129334	carlo test
0.2828883291	\ limits_
0.2827494874	variance covariance
0.2827062153	mean excess
0.2826965628	applications ranging from
0.2826619157	expected number of
0.2826577155	vector of parameters
0.2826442377	noisy high
0.2825558839	\ infty
0.2823338872	lower bound on
0.2822263616	\ theta_t
0.2819955692	construct confidence intervals for
0.2819808736	\ sqrt
0.2819686003	caused by
0.2817439970	an iterative algorithm
0.2816585619	\ emph
0.2815787301	extended empirical
0.2815626776	deviation results
0.2813119921	event data
0.2812173084	non asymptotic bounds
0.2811776730	projections onto
0.2810904683	finite sample performance of
0.2808791448	explicit expressions for
0.2808771120	squares approach
0.2808450730	general state
0.2806305735	process theory
0.2805419460	non parametric tests
0.2805026739	\ psi_n
0.2804710307	zero sum
0.2804518344	seminal work
0.2804165724	\ delta_
0.2803982936	wishart model
0.2803678073	estimation of high dimensional
0.2802882135	nonparametric method
0.2802479631	field theory
0.2801066512	the present paper
0.2795989177	problem dimension
0.2795233689	bayesian multiple
0.2793201029	bounded away from zero
0.2793015881	erd \ h o s
0.2792443526	accuracy of estimation
0.2792383062	procedure to estimate
0.2792000453	\ bf
0.2791889099	in recent years
0.2788445129	marginal log
0.2787889324	0,1 ^ 2
0.2787656312	student t
0.2786689232	estimators defined
0.2783821264	ask whether
0.2782927904	sample mean
0.2782909219	\ textit
0.2781851316	a real data application
0.2780053554	= \ int
0.2779828065	$ \ mathbb l _2
0.2778267839	= \ int_
0.2777094696	wasserstein distance between
0.2776579411	non vanishing
0.2776468942	among others
0.2775911181	data arising
0.2775762943	rank structure
0.2775465929	2s +
0.2774713117	provide consistent
0.2774268769	memory stochastic
0.2773407998	schr \
0.2771445126	illustrated through
0.2770535145	alternative method
0.2767846318	^ n_
0.2766652986	relationships between
0.2765701112	classical linear
0.2763387147	experiments illustrate
0.2762343643	simulations and real
0.2762170038	framework for testing
0.2762160859	finite time
0.2758766221	zero mean
0.2757793850	asymptotic normality of
0.2756765212	\ phi
0.2755520327	number of variables
0.2753234007	a logarithmic factor
0.2750617518	\ rightarrow \ infty
0.2750452822	spanned by
0.2749726543	attention in recent
0.2749552171	plug in approach
0.2746936316	number of points
0.2746731696	class of functions
0.2746127065	thorough numerical
0.2745954112	two step estimation
0.2745312706	under mild regularity
0.2744121375	establish non asymptotic
0.2743661278	provide non asymptotic
0.2742941032	\ ell
0.2741794776	subset \ mathbb r ^ d
0.2741435545	dimensional random
0.2741207077	particular emphasis
0.2740321783	\ xi_
0.2740160353	an asymptotic expansion
0.2739403492	general convex
0.2739315018	\ geq0
0.2738382666	bias and mean square
0.2737868212	upper bounds for
0.2736202815	estimation of conditional
0.2735410732	\ xi_n
0.2735337296	\ hat
0.2734674563	relationship between
0.2731316840	connection between
0.2731184687	so far
0.2730119482	an important issue
0.2729408993	plug in
0.2728981651	\ bolds
0.2728507967	\ frac
0.2728271081	statistics for testing
0.2726200792	belongs to
0.2725423917	order to construct
0.2725026739	\ varrho
0.2723657543	problem of identifying
0.2723441636	properties compared
0.2723408174	certain regularity conditions
0.2722270443	rely on
0.2722002090	loss of information
0.2721826171	1 \ leq i \ leq
0.2719980962	mean vector
0.2719436139	set of observations
0.2718726643	\ text
0.2718253307	\ tau
0.2717757797	precise characterization of
0.2717628767	\ varepsilon ^ 2
0.2716517517	\ prod_
0.2715944455	large class of models
0.2715728392	provide strong
0.2715201686	linear spectral statistics of
0.2715077044	correlated random
0.2715011232	few years
0.2714723822	recent advances in
0.2714052444	valid confidence intervals for
0.2713457998	the maximum likelihood estimate
0.2712904134	non central limit theorems
0.2712197788	\ varepsilon
0.2710605202	robust statistical
0.2709799189	periodic mean
0.2708436185	goodness of fit tests for
0.2707808716	the true regression function
0.2706190091	dealing with
0.2703100359	dependencies between
0.2702481365	bounded from below
0.2701611064	non uniform
0.2697413906	left and right
0.2695081078	no matter
0.2694658170	part ii
0.2694106184	fit tests
0.2693925726	regarded as
0.2691659219	\ widehat
0.2690968688	single point
0.2690435781	\ le
0.2689632945	the sample size increases
0.2689506057	simple procedure
0.2688900535	data sample
0.2688819544	confidence sets for
0.2688700835	based on thresholding
0.2688242406	general algorithm
0.2688092263	error estimation
0.2687536724	simultaneous variable selection and
0.2687377585	arising from
0.2687236826	efficient procedure
0.2686805163	more generally
0.2686725530	aimed at
0.2686568437	tests for testing
0.2686358466	motivated by
0.2684835296	process indexed
0.2684014669	variety of applications
0.2683574872	non compact
0.2683360809	maximum mean
0.2681763436	while keeping
0.2679441924	some mild conditions
0.2679430074	confidence regions for
0.2679416157	regression model with
0.2679282803	the false discovery rate
0.2677645578	non stationarity
0.2675969072	information about
0.2675445379	\ mathcal
0.2674403454	\ cal
0.2674296856	this paper studies
0.2673289540	coming from
0.2673195370	the last two decades
0.2672202116	birg \
0.2672195175	population mean
0.2672080171	lower bound for
0.2670757997	approach to estimate
0.2670714547	plus noise
0.2668119947	works well
0.2667102497	sample distributions
0.2666847492	^ 1 2
0.2666359971	optimal designs for
0.2666161323	detailed analysis
0.2666107620	measures defined
0.2665514840	a log concave density
0.2665343069	popular method
0.2664401739	\ mu_
0.2664034779	asymptotic statistical
0.2663427639	stochastic differential equations with
0.2660996633	inspired by
0.2660915662	mean shift
0.2658507130	observed process
0.2658261394	time homogeneous
0.2656220916	large enough
0.2655627963	\ theta
0.2655532098	class of problems
0.2654724914	time and space
0.2654117518	= \ sum_ i = 1
0.2651957006	p_ x
0.2651904597	doing so
0.2651141180	mean and variance
0.2650408957	non zero
0.2650311341	high computational
0.2650048760	tend to
0.2649624161	largest eigenvalue of
0.2648876262	\ sigma ^ 2
0.2648520158	large sample properties of
0.2647924983	adaptive estimation of
0.2647574152	time series modeling
0.2643204380	algorithm for estimating
0.2642120590	better understanding
0.2642119938	robust with respect
0.2640710153	time varying coefficients
0.2640547438	depend on
0.2639909908	scale models
0.2639305563	kernel mean
0.2638858202	non centrality
0.2636492904	p 1
0.2636404138	non zero components
0.2635625672	number of examples
0.2633315018	\ int_
0.2631847467	data sampled
0.2631472121	consistent estimation of
0.2630584966	chi ^ 2
0.2630410732	\ propto
0.2629315018	\ mathit
0.2628774514	nystr \
0.2628774514	gin \
0.2627532138	\ widetilde
0.2626923361	very mild conditions
0.2626723323	numerical properties
0.2626434722	1 \ epsilon
0.2626389761	$ \ mathbb l _p
0.2625430387	\ eps
0.2622909219	\ mathrm
0.2622570638	broad family of
0.2621344872	\ left
0.2619826210	\ big
0.2619725262	optimal rates for
0.2618147440	u and v
0.2617708788	$ \ ell_0
0.2617019300	a simulation study
0.2616494759	measure based
0.2616403236	iid case
0.2615496268	\ mu_i
0.2615128835	the null hypothesis
0.2614927534	necessary and sufficient
0.2612840593	model defined
0.2611879482	control studies
0.2611837040	test for high dimensional
0.2611130456	non symmetric
0.2611062648	time invariant
0.2610745987	priori knowledge of
0.2610596752	tests based on
0.2609302980	1 \ le i \ le
0.2609170210	without requiring
0.2608611600	\ boldsymbol
0.2607603776	relies on
0.2606922714	system identification
0.2605704179	this paper examines
0.2603971666	true function
0.2603204288	explicit error
0.2602668674	\ end align *
0.2600494722	asymptotic lower
0.2599696883	compared to previous
0.2598482483	driven by
0.2597720220	^ \ otimes
0.2596528865	study asymptotic properties of
0.2593697792	replaced by
0.2593688810	drawn from
0.2593034028	^ \ top
0.2591581615	analysis of high dimensional
0.2590254570	depending on
0.2589024130	and type ii errors
0.2588731696	unknown change
0.2588355949	non null
0.2588290809	stage estimator
0.2587631972	procedure proposed
0.2584914200	sub sampling
0.2584796067	construct adaptive
0.2584667520	a priori
0.2584096449	\ rightarrow
0.2582145130	increases to infinity
0.2581273639	comment on article by
0.2580898928	this paper establishes
0.2580151256	number of signals
0.2578936539	\ mathbf
0.2577952774	\ to \ infty
0.2577266976	frequently used
0.2576014159	\ alpha
0.2575694387	partial sums of
0.2573601475	stemming from
0.2573273471	set of variables
0.2572528787	minimax lower bounds for
0.2572224012	provide theoretical guarantees for
0.2571147570	approximate maximum
0.2570700531	method of estimation
0.2569214132	rates of estimation
0.2569127592	large sample theory for
0.2567067253	perform well
0.2566975864	weaker than
0.2565323660	regression based
0.2564959127	two level
0.2564649476	sum process
0.2564625737	l moments
0.2562770420	f divergences
0.2561458410	an upper bound
0.2559174123	a similar result
0.2558390606	$ \ ell_p
0.2558106228	error bounds for
0.2558012931	^ *
0.2556268217	two factor
0.2554803894	trade off between
0.2554575851	max domain of
0.2553188062	this article considers
0.2552495915	non smooth
0.2552243362	time delay
0.2551756632	bayesian density
0.2549718331	alpha = 1
0.2549661049	formulated in terms
0.2549331374	e values
0.2548973539	probability of false
0.2548878013	this paper derives
0.2548763656	interpreted as
0.2548588150	motivated by recent
0.2548120429	generalized version
0.2547919348	lead to
0.2546369764	a closed form expression
0.2546054068	depend upon
0.2544260044	non negative matrix
0.2543829374	^ \ alpha
0.2543539984	corresponds to
0.2543046774	sz \
0.2541318536	under model misspecification
0.2540854632	non stationary time series
0.2540682081	the art methods
0.2539865501	\ xi_i
0.2539666900	problem of model selection
0.2539457914	second order statistics
0.2539243079	confidence intervals based
0.2537012252	_ t \ in
0.2536877139	number of times
0.2535969524	not necessarily identically
0.2533621613	up to logarithmic factors
0.2533121860	well studied
0.2531981581	space of probability measures
0.2531949157	\ exp
0.2531323838	limit theorem for
0.2531015324	$ n ^ 1
0.2530300300	leads to
0.2529967087	functions defined
0.2528207374	| t |
0.2528203242	non ergodic
0.2527437379	general properties
0.2527313757	non uniqueness
0.2526561003	method to obtain
0.2525771350	thought of as
0.2525266525	depends on
0.2524397760	$ \ ell_
0.2524311201	uniform convergence rates for
0.2523276619	a_ p
0.2521660053	selection in regression
0.2521534620	correspondence between
0.2520449074	this paper describes
0.2520362107	\ | _
0.2518815905	\ lambda_2
0.2516834697	data driven choice of
0.2515501354	obtain optimal
0.2514656444	degenerate u
0.2513976325	1 \ alpha
0.2513471908	belong to
0.2513355648	bayesian approach to
0.2513203045	up to constant factors
0.2507799452	ill posed problems
0.2507647476	sum of squared
0.2507247832	general metric
0.2506108504	linear combination of
0.2504903368	earlier work
0.2504574100	deals with
0.2504554130	a stochastic differential equation
0.2504274875	class of algorithms
0.2503936512	two real data sets
0.2503833034	limiting distribution of
0.2502148528	efficient estimation of
0.2500623108	diverging number of
0.2499487263	a posteriori
0.2499377650	an infinite dimensional
0.2499351011	oracle inequalities for
0.2499198085	difference between
0.2499137861	same order of magnitude
0.2499121282	an unbiased estimate
0.2498590489	time instants
0.2497535104	serve as
0.2497010840	represented by
0.2496679505	devoted to
0.2496563936	y | x
0.2493772147	passage time
0.2489184546	wide class of
0.2487893069	parametric statistical
0.2487721923	weak convergence of
0.2487211595	linear time series
0.2486822272	moderate deviations for
0.2485638332	function defined
0.2485475024	sample bounds
0.2485271576	the sample covariance matrix
0.2483916085	component regression
0.2483025010	determine whether
0.2482559164	close to
0.2481666179	\ to 0
0.2481665013	general statistical
0.2481005958	bayesian generalization
0.2480205780	on line
0.2479569490	x_ i
0.2479389115	_ n
0.2478774050	order to obtain
0.2478383360	\ min_
0.2478145412	space setting
0.2478072574	two distinct
0.2477219364	differs from
0.2476159395	mean difference
0.2475793906	one parameter
0.2475659825	explicit formula for
0.2473929771	provide convergence
0.2472894988	asymptotic distribution of
0.2472629073	non asymptotic oracle inequalities
0.2470646845	_ *
0.2468594412	statistical inference based
0.2466951193	establish rates
0.2465305767	deal with
0.2464941858	this article
0.2464154893	influenced by
0.2463526013	provide sufficient conditions for
0.2463350599	\ boldsymbol x ^ \ rm
0.2462098244	sample complexity bounds for
0.2460282786	parameter estimation for
0.2459556321	= \ lim_
0.2457837185	data applications
0.2457776596	\ ell_2
0.2456820537	normal mean
0.2456404184	dependent gaussian
0.2455157860	approach to estimating
0.2454931984	more powerful
0.2454521622	r rao
0.2454297338	second order stationary
0.2453929950	much broader
0.2453203429	without knowing
0.2452638405	generated by
0.2452226289	construction of confidence
0.2451714279	asymptotic theory for
0.2449137057	\ ^ o semimartingale
0.2449059464	tradeoff between
0.2448507296	non separable
0.2447811931	\ pm
0.2446867676	compromise between
0.2446037869	a powerful tool
0.2446012591	well established
0.2445965201	\ sigma ^ 1
0.2445855256	even though
0.2445080661	finite sample analysis of
0.2444536069	\ theta_1
0.2444405494	inferences about
0.2443745605	stage least squares
0.2442237638	pure jump l \
0.2440315828	differences between
0.2439140561	good performances
0.2438496634	learning based
0.2437885799	asymptotic mean squared
0.2436739194	real random
0.2436183812	supported by numerical
0.2436177009	| rho
0.2435414954	this paper concerns
0.2434999708	an oracle inequality
0.2433891691	based estimates
0.2431967773	\ sum_
0.2431408380	\ | _2 ^ 2
0.2430286297	upper bound for
0.2428197338	much simpler
0.2427762717	subject to random
0.2426806260	procedure for estimating
0.2426788545	more broadly
0.2426528463	tests based
0.2425210066	stems from
0.2425043067	develop asymptotic
0.2424004165	second order stationarity
0.2423833361	concerned with
0.2422758153	method for high dimensional
0.2421571563	non local
0.2418485890	approach based
0.2417258861	number of nonzero
0.2416187193	algorithms based
0.2415885894	minimax estimation of
0.2415527649	\ xi_t
0.2414045764	increasing number of
0.2413291082	and real data examples
0.2412621320	this note
0.2412483991	gives rise
0.2411574172	an abrupt change
0.2411444320	mean and covariance
0.2411403850	mean variance
0.2410879031	accompanied by
0.2410860328	observed at high
0.2410433344	maximum likelihood estimators for
0.2410239240	z_ i
0.2410145661	time domain
0.2409787508	linear parameters
0.2409536069	\ nabla
0.2408994891	two real data examples
0.2408350812	low sample
0.2403974525	determined by
0.2401516012	= 1
0.2400855256	rather than
0.2397466687	belonging to
0.2397121126	squared distribution
0.2396670427	\ pmb
0.2396624747	driven approach
0.2394824151	change point detection in
0.2393937412	equipped with
0.2391723614	type 1
0.2391014159	\ beta
0.2390976367	focuses on
0.2390525910	per unit
0.2390268379	a fully data driven
0.2390237607	limiting distributions of
0.2389978144	gaussian stochastic
0.2389358347	n + 1
0.2389294682	classical model
0.2389213133	model with unknown
0.2388801287	\ mathbb
0.2388384792	\ ge
0.2387487772	sure screening
0.2386979007	generalized linear models with
0.2385731489	does not hold
0.2384860593	relying on
0.2383953382	\ | ^ 2
0.2383639101	focusing on
0.2382316630	sufficient and necessary
0.2381566064	illustrated by numerical
0.2381023104	\ begin equation *
0.2380925087	referred to as
0.2379589463	long range dependent time
0.2379220317	testing equality of
0.2378817168	robust alternative to
0.2378757215	\ gamma
0.2378727546	bayesian inverse problems with
0.2378114360	large class of
0.2378111978	non standard
0.2377883897	minimax lower bound for
0.2375982379	\ epsilon_i
0.2373036218	results establish
0.2372992217	coincides with
0.2372224669	\ psi_
0.2371910370	statistical inference for
0.2371870841	general procedure
0.2371677367	convergence rates for
0.2369906112	based on
0.2369249465	expressed in terms of
0.2368931756	statistical analysis of
0.2368531593	focus on
0.2367596060	estimator based
0.2366898313	mixing time
0.2366647839	ev \
0.2366388185	m estimator
0.2365786383	connections between
0.2365089490	$ \ ell_1
0.2363785604	a special case
0.2363637610	common mean
0.2362383630	the true density
0.2356005072	t \ geq0
0.2354230603	b ^ h
0.2353545697	serves as
0.2352390075	^ d
0.2352261897	squares method
0.2350629340	converges to
0.2349479867	n ^ 3
0.2347811931	\ sup_
0.2347690388	the true parameter
0.2347159386	selected estimator
0.2346285480	sum_ i = 1 ^
0.2346271200	y_ t
0.2345538248	proportion of true
0.2343974525	induced by
0.2343974525	characterized by
0.2343930145	robust to model
0.2342502033	running time
0.2342158814	geometric mean
0.2342090501	bayes method
0.2341149487	relation between
0.2340438587	proposed confidence
0.2340197326	to noise ratio
0.2338934657	a low rank matrix
0.2338504792	based on observations
0.2338137139	non identical
0.2337598912	\ frac12
0.2337442249	suffers from
0.2336841099	sampling models
0.2335411715	\ hat \ sigma
0.2335404825	| b |
0.2335192910	point analysis
0.2334063367	small values
0.2333603819	a case study
0.2333542659	more complicated
0.2333396118	on simulated data
0.2332224824	+ \ varepsilon
0.2331188027	mean values
0.2328160274	derive rates
0.2327813867	sufficient condition for
0.2326858724	illustrated by
0.2325327724	asymptotic behavior of
0.2324316512	\ mathrm opt
0.2322143962	u processes
0.2320902511	= \ frac
0.2320812310	number of tests
0.2320111030	distinguish between
0.2320089511	selection techniques
0.2319658922	n 1
0.2319452158	robust alternative
0.2318673225	three parameter
0.2317919650	approach for estimating
0.2317461344	bayesian nonparametric estimation of
0.2317310250	full rank
0.2317034272	_ j
0.2317013302	three dimensional
0.2315234151	joint estimation of
0.2314578972	estimators for estimating
0.2314192079	fractional brownian motion with
0.2312525060	a finite population
0.2310734701	estimated from data
0.2309285491	multiple linear
0.2309216919	these two estimators
0.2307038365	n ^ 2
0.2305413750	an important role
0.2305400623	via monte carlo
0.2305387419	departures from
0.2305267749	a convex optimization problem
0.2303462079	theoretical point
0.2302351475	hinges on
0.2301032775	first exit
0.2300420366	non i.i.d
0.2299540187	this article introduces
0.2299310166	nearly linear
0.2297916989	information theoretic limits of
0.2297108079	+ 2
0.2296827119	tight bounds on
0.2295749831	a closed form
0.2294932426	complemented by
0.2293786269	asymptotic behaviour of
0.2292747012	over besov balls
0.2291322677	sub optimal
0.2290305767	correspond to
0.2290259881	| _0
0.2290126511	tighter than
0.2289377918	results apply to
0.2288770619	\ mathbb r ^ d
0.2288455700	structural properties of
0.2288443448	p variate
0.2288306514	| |
0.2286672292	well chosen
0.2286192991	dimensional gaussian
0.2285294866	multi way
0.2284082476	f divergence
0.2283909823	set of conditions
0.2283547827	an empirical application
0.2283477633	harmonic mean
0.2281008124	relations among
0.2280893243	x_ k
0.2280754328	under certain conditions
0.2280678548	as soon as
0.2279518890	distribution supported
0.2279515725	the data generating process
0.2278010224	one hand
0.2275594811	linear functionals of
0.2275557702	flexible class of
0.2275133475	and multiple output regression
0.2274186165	supported by
0.2273852452	give rise to
0.2273839441	more important than ever
0.2273776405	perform very well
0.2273387960	error model
0.2273325094	\ underline
0.2273041135	at discrete times
0.2271354109	^ \ frac
0.2270764227	proof uses
0.2269880051	and van der vaart
0.2269206853	decide whether
0.2269000732	non centered
0.2267941447	laplace transform of
0.2267718583	\ ell_ \ infty
0.2267606866	proposed to estimate
0.2267461863	class model
0.2263228281	this paper
0.2262909117	modified version of
0.2261970665	growing number of
0.2261014993	likelihood based inference for
0.2258273790	\ inf_
0.2257344304	test statistic based on
0.2256886437	over parametrized
0.2255997532	at least
0.2255348453	an explicit expression
0.2252436113	1,1 ^ d
0.2252406269	testing against
0.2251156978	s_n =
0.2251005720	second stage
0.2250688710	approach relies on
0.2248214894	finite mixtures of
0.2247842391	absolute value
0.2247052437	first exit time
0.2245760118	goodness of fit test for
0.2245017939	limit theory for
0.2244792753	class of multivariate
0.2244056376	for finite sample sizes
0.2243942969	dependence between
0.2241177866	existing ones
0.2240404315	linear inverse problems with
0.2240193216	a heavy tailed distribution
0.2238855224	focused on
0.2237983073	step approach
0.2237882260	nonparametric regression model with
0.2236860388	spatial random
0.2236380718	\ mid
0.2235093952	\ end equation *
0.2234532165	first order autoregressive
0.2233994843	the sample size
0.2229999528	advantages over
0.2229933723	aiming at
0.2228815876	by introducing
0.2228219364	ranging from
0.2227554272	the total variation distance
0.2226157162	strong consistency of
0.2225685981	the unit sphere
0.2224356559	based upon
0.2224003622	positive part
0.2223769745	smallest eigenvalues of
0.2223142069	$ \ ell_2
0.2222591446	least angle
0.2221010159	correlations between
0.2219732874	stochastic comparisons of
0.2219646990	power against
0.2219050652	analysis methods
0.2219028618	proof relies on
0.2218746725	$ l_1
0.2218163984	interested in
0.2218128904	t ^ 1
0.2218051960	fourier transform of
0.2217896891	t 1
0.2217335302	\ right
0.2216835946	prior knowledge of
0.2216720441	data driven method for
0.2216118232	\ gg
0.2215088077	conditionally independent given
0.2214906776	interactions between
0.2213879984	relationships among
0.2213692832	obtained by
0.2212672893	and vice versa
0.2211545790	confidence sets based on
0.2210718547	general upper
0.2210454924	akin to
0.2210343625	related to
0.2209808001	context of high dimensional
0.2209726935	\ bar
0.2209588112	r type
0.2205970302	a directed acyclic graph
0.2205345982	na \
0.2204814511	contrast to previous
0.2204239893	total number of
0.2202933045	estimation of parameters
0.2202914580	learning literature
0.2202309448	mean square errors
0.2201737922	pertain to
0.2201530741	stochastic regression
0.2201271994	recent work
0.2200626696	time average
0.2200403128	set of samples
0.2200275538	explicit formulas for
0.2200098912	\ zeta
0.2199625545	confidence interval for
0.2198616443	class of densities
0.2198082462	xx ^
0.2195670050	the long memory parameter
0.2194912654	the central limit theorem
0.2193623282	converges to zero
0.2193604741	testing whether
0.2193143333	adaptive markov
0.2192672785	variety of problems
0.2192278222	x | y
0.2190508485	less than
0.2190454924	attempting to
0.2190232347	\ log
0.2187454736	applied to
0.2187178116	from noisy observations
0.2187001699	for such data
0.2183496241	degree of smoothness
0.2181982162	multiple change points in
0.2181481877	\ lambda_i
0.2178970644	world data
0.2178768991	d dimensional
0.2177416597	an unknown parameter
0.2176665538	most notably
0.2173665233	new central limit theorem
0.2172908813	\ sigma_t
0.2172626957	regression with unknown
0.2172353952	\ _x
0.2172205937	affected by
0.2172079965	defined by
0.2170224847	time frequency
0.2169149963	achieved by
0.2168477725	high dimensional linear regression with
0.2168295991	class of processes
0.2168107733	convergence rates of
0.2166748278	more accurate
0.2166594380	time series data
0.2165606844	presence of noise
0.2165264388	p 2
0.2164480869	third order
0.2164002118	the average run length
0.2163605806	at random times
0.2163181542	\ nu_
0.2162215953	processes sampled
0.2162135349	exact expressions for
0.2161936218	procedure based
0.2161559094	consistent model
0.2160012426	broad range of
0.2159802964	tending to
0.2158898062	special cases of
0.2157345214	goes to zero
0.2156837674	closed form expression for
0.2156519799	large relative
0.2155721077	a compact set
0.2154858592	more realistic
0.2154200086	the art
0.2153873440	models with latent
0.2153426740	a real dataset
0.2152650910	d optimal
0.2147534437	system of linear
0.2147215047	uniformly over
0.2147025352	an exponential family
0.2145677765	under consideration
0.2145265025	effect estimators
0.2143623722	the unit interval
0.2143612818	subjected to
0.2141434561	each agent
0.2140419966	captured by
0.2140133240	estimators based
0.2140066922	arbitrarily close to
0.2139942715	no change
0.2138700414	series model
0.2137734088	1 2
0.2137544003	$ dimensional gaussian
0.2137149686	\ ell_1
0.2137101005	the minimax rate
0.2133672818	assumed to
0.2133222406	a minimax lower bound
0.2132302155	sequences of random
0.2131881190	the long run
0.2130843865	behave like
0.2128681592	a by product
0.2128293953	independent samples from
0.2127698525	extreme eigenvalues of
0.2127001852	\ in \ mathds
0.2124607875	step towards
0.2124097544	$ norm
0.2123700795	hidden markov models with
0.2123415210	stationary stochastic
0.2122711818	do not
0.2122655863	each iteration
0.2119676842	each entry
0.2119352814	\ beta_0
0.2119159440	o s r \
0.2118234557	recent results on
0.2118197794	mean embedding
0.2117951166	$ th moment
0.2117783724	non monotone
0.2117705290	\ mathbb r
0.2115700683	application to real
0.2115626396	the true model
0.2114869923	variety of examples
0.2114362569	tests for high dimensional
0.2112808385	detecting changes in
0.2111971687	geometric characterization of
0.2111622161	from random matrix theory
0.2111288491	$ dimensional
0.2109874739	consistent estimates of
0.2106423137	refers to
0.2106031994	routinely used
0.2105480274	a constant factor
0.2104968935	an explicit form
0.2104758274	the conditional quantile function
0.2104510980	l ^ 2
0.2104027540	independence of two
0.2103463640	this paper shows
0.2103355256	much larger than
0.2100138380	^ k 1
0.2099353591	distance between
0.2098780872	non parametric bayesian
0.2098625583	rates of posterior
0.2098007075	without assuming
0.2097711818	does not
0.2097323744	r ^ d
0.2096883707	relatively small
0.2094811499	few samples
0.2093986295	a simple proof
0.2093776921	l _p
0.2093288837	methodology based
0.2093288837	criterion based
0.2092434119	the main idea
0.2091631242	one step estimator
0.2091510410	= 2
0.2091433510	while preserving
0.2091360665	class of continuous
0.2091199799	adl \
0.2090680810	so called `
0.2090370539	high dimensional mean
0.2090368158	the gaussian case
0.2090340515	concentration properties of
0.2090138694	\ displaystyle
0.2089792023	determining whether
0.2089646891	k 2
0.2089504888	do not require
0.2089217845	new tests
0.2089167908	propose to estimate
0.2088588346	some theoretical results
0.2087749178	many practical applications
0.2087031339	family of estimators
0.2085774513	rate data
0.2085520068	each sensor
0.2084460296	\ in \ mathcal
0.2083528701	i = 1
0.2083272249	large class
0.2083238355	a real data analysis
0.2082946878	respect to
0.2082584026	0,1 ^ d
0.2081995239	widespread use
0.2080902711	the optimal rate
0.2080796246	best arm
0.2079207351	root n
0.2078413381	wide variety of
0.2078378628	two groups
0.2077898296	distances between
0.2076375141	aims to
0.2075896276	a functional central limit theorem
0.2073186851	\ hat \ theta
0.2073164593	maximum likelihood estimation in
0.2072891959	true probability
0.2072179374	version of
0.2070995272	consists of
0.2070812505	shown to provide
0.2070433981	cumulative distribution function of
0.2069937350	not require knowledge
0.2069724707	theoretical properties of
0.2068646521	statistical properties of
0.2067715970	original data
0.2067571779	m_n ^
0.2066336567	range of problems
0.2066257544	makes use of
0.2065752684	more general
0.2065746919	analysis relies on
0.2065742232	least squares algorithm
0.2065332185	nonparametric estimators of
0.2064865962	two sample problem
0.2064110356	number n of
0.2063819934	likelihood ratio tests for
0.2063792138	rate of estimation
0.2062576481	the data generating distribution
0.2062576015	the high dimensional regime
0.2062276293	conditions for exact
0.2061978546	compared to
0.2060553670	\ _t
0.2059288837	technique based
0.2059040430	log n
0.2059002981	order to avoid
0.2058175468	convergence of empirical
0.2057825760	properties of maximum likelihood
0.2056682632	for low rank matrix
0.2056272602	the best achievable
0.2055847694	one step sparse
0.2055610370	a random vector
0.2055531805	for ergodic diffusion processes
0.2055496991	| x |
0.2054451073	\ begin
0.2052884577	q function
0.2052048428	a linear regression model
0.2051093351	followed by
0.2050512426	the general problem
0.2050142259	prove non asymptotic
0.2046895902	nearly minimax
0.2046058606	set of parameters
0.2045583589	subject to
0.2044695983	in high dimension
0.2044115058	^ \ beta
0.2043569706	_ i = 1 ^ n
0.2041723389	two step approach
0.2041679759	equations driven by
0.2040395540	regression models with
0.2039906624	efficient algorithms for
0.2039206131	a recent result
0.2038927013	large deviations for
0.2038274949	other related
0.2037688577	interest rate
0.2036937141	model setting
0.2035602794	decay rate of
0.2035509303	arise naturally in
0.2034633394	^ t
0.2034593169	minimax rates for
0.2034409868	\ ell_0
0.2034134322	estimator based on
0.2033979028	based likelihood
0.2033539937	lower and upper bounds on
0.2033522502	^ * _
0.2033007805	gap between
0.2032575665	scale distributions
0.2030477328	rate for estimating
0.2029805189	to construct confidence intervals
0.2029380580	converge to
0.2028754015	two phase
0.2027976222	obtained from
0.2027838498	a phase transition
0.2024796747	consistent estimate of
0.2024550816	\ boldmath
0.2024539524	under local alternatives
0.2024430045	exponential bounds for
0.2023127447	\ int
0.2022921079	tends to zero
0.2022858520	bounded away from
0.2022820684	consistent estimators of
0.2022688539	laws of large
0.2022449115	study convergence
0.2022007093	many covariates
0.2020374323	out of sample prediction
0.2020261598	some numerical experiments
0.2020048081	a numerical study
0.2019846674	currently available
0.2019273385	this problem arises
0.2019251490	leading to
0.2017862693	for small sample sizes
0.2017166869	$ nn
0.2017165556	model selection using
0.2016118334	the empirical copula process
0.2015155528	non singular
0.2013888427	consistent estimators for
0.2013368201	\ rho_
0.2012918457	a single realization
0.2012889167	arrive at
0.2012218023	information contained in
0.2011996280	new insights into
0.2010100859	implied by
0.2008601129	on synthetic data
0.2008331583	sequence of observations
0.2008164679	incorporation of
0.2007609008	non normal
0.2006083542	a general framework
0.2005333871	x \ _i
0.2005320109	converges in probability
0.2004794444	one parameter exponential
0.2003876877	before and after
0.2003812400	basic properties of
0.2003421615	large deviations of
0.2002660497	consisting of
0.2002625375	series setting
0.2002376672	sequence of random
0.2001777536	willing to
0.2001491144	$ l ^ 2
0.2000569795	resort to
0.2000520985	bivariate random
0.2000088167	likelihood ratio test for
0.1999865782	ratio model
0.1999284500	stationary functional
0.1998954605	\ bx
0.1998326910	theoretical understanding of
0.1998307618	approximated by
0.1997937662	starting from
0.1997640066	under weak
0.1997297439	normal estimators
0.1994861483	family models
0.1994815195	the key idea
0.1993998750	does not exceed
0.1993217245	supported on
0.1992564284	models considered
0.1991751677	balance between
0.1990481838	x y
0.1990112516	sample simulation
0.1989221403	residual sum of
0.1989144481	\ max_
0.1987837093	methods to estimate
0.1987509414	construction of optimal
0.1986577096	procedures based
0.1986000584	stronger than
0.1985488201	learning mixtures of
0.1985296084	a fundamental role
0.1984912087	properties of
0.1983448625	sum of independent
0.1981763036	law of large
0.1978647987	three step
0.1977752818	the minimax optimal rate
0.1977727826	non differentiable
0.1976860716	order to estimate
0.1976857134	k nearest
0.1976815014	leibler divergence between
0.1975627354	mean absolute
0.1975015741	of two random
0.1974877947	primary interest
0.1974719808	$ l_2
0.1974489555	a long standing
0.1974430872	\ min
0.1974215983	i = 1,2
0.1973526852	introduced by
0.1973138556	non convex optimization
0.1972521245	more flexible
0.1971894109	upper and lower bounds on
0.1971684781	prior distribution on
0.1970337137	shed light on
0.1969795140	constructed based on
0.1969610888	n ^ \ alpha
0.1968486600	equation driven by
0.1967877553	sparse high
0.1967475065	if and only if
0.1965526685	weighted sums of
0.1965045817	two components
0.1964899237	\ star
0.1962480879	questions about
0.1962458066	\ boldsymbol \ theta
0.1962338390	look at
0.1962115925	require knowledge of
0.1961239625	according to
0.1960379321	most importantly
0.1959040943	shown to
0.1958031625	notion of
0.1957951203	| _2 ^ 2
0.1957137692	in addition
0.1956637130	contingency tables with
0.1956311956	one and two
0.1955951220	an invariance principle
0.1954951615	t test
0.1954769784	\ sqrt \ log
0.1954211615	new perspective
0.1953127447	\ ast
0.1951567110	t \ ge 0
0.1951523437	deviations from
0.1951307199	\ in \ mathbb
0.1949258030	non parametric regression
0.1948781158	convergence analysis of
0.1948357895	non sparse
0.1947711818	= o
0.1947343873	recovery of sparse
0.1946142782	probability tending to one
0.1944870989	samples drawn from
0.1944155697	linear regression models with
0.1943744121	$ \ chi ^ 2
0.1943506442	one way
0.1943016303	order approximation
0.1941390556	iterated logarithm for
0.1941381304	true regression
0.1941080439	high degree of
0.1940682982	the true distribution
0.1939524513	model approach
0.1938975183	the standard normal distribution
0.1938901467	rich class of
0.1938525400	quantity of interest
0.1937777536	tries to
0.1937234033	random fields with
0.1936856800	mathbf r
0.1935527033	whether or not
0.1935233185	allowed to
0.1935140571	by monte carlo simulations
0.1935133950	drift estimation for
0.1934683460	deviation principle for
0.1934649798	t statistic
0.1934298682	at hand
0.1934168467	monotonicity properties of
0.1933034541	side result
0.1927017776	value theory
0.1926387166	question of whether
0.1925678616	p_ i
0.1924509938	time reversible
0.1924132595	\ in 0,1
0.1924064955	robustness against
0.1922054697	community detection in
0.1922026843	very popular
0.1922024576	an undirected graph
0.1920125050	under general conditions
0.1919592991	number of relevant
0.1918688771	mathematical properties of
0.1918137166	does not exist
0.1917687398	non asymptotic minimax
0.1916158225	chernozhukov et
0.1915618764	problem of choosing
0.1914286574	of such data
0.1914093791	^ 0
0.1914016534	robust against
0.1913835405	fast enough
0.1911895269	\ colon
0.1910829652	previously known
0.1910696419	access to
0.1910410675	representation theorem for
0.1910129311	_ i
0.1909032572	performance in terms
0.1908687503	= \ sum_
0.1907500560	$ dimensional vector
0.1906844451	depends only on
0.1906481165	non additive
0.1906349636	order structure
0.1906206551	\ alpha_n
0.1906000509	3 4
0.1904046992	the univariate case
0.1904002066	r ^ p
0.1903545427	\ lim_
0.1903524202	number of
0.1902976222	estimated by
0.1901514447	the average treatment effect
0.1901114642	= n ^ 1
0.1900644505	\ begin equation
0.1900561252	the matrix completion problem
0.1900248176	larger class of
0.1899912910	1 + \ alpha
0.1899061855	endowed with
0.1898722815	\ binom
0.1898526852	defined as
0.1898122512	\ | _2
0.1897592624	gamma 0
0.1897007805	equivalence between
0.1896336299	the design matrix
0.1896178786	limited number of
0.1895776018	acting on
0.1895342071	wide applications in
0.1895146938	expressed as
0.1894322096	terms of power
0.1893617464	0 1
0.1893545427	\ ell_p
0.1893328166	linear regression with
0.1891968014	a gaussian mixture model
0.1891411965	non informative
0.1891253497	size goes to infinity
0.1890826614	interval 0
0.1890137019	defined in terms
0.1890129883	the time of
0.1890129201	results presented
0.1890115618	l \
0.1889871900	an ar
0.1889237556	comment on
0.1889086379	the regression function
0.1889051399	\ in \ cal
0.1888848378	variation distance between
0.1888767594	popular class of
0.1888350980	observed through
0.1887920770	sample bias
0.1887863912	demonstrated through
0.1887523649	s ^ 2
0.1886989630	two parameter
0.1886886523	real time
0.1884567838	\ int_0 ^
0.1883837964	multiplied by
0.1883065930	n ^ 1 \ sum_
0.1882807655	main advantage of
0.1882445180	$ variate
0.1881831583	finite number of
0.1880953163	much more
0.1878989242	_2 ^ 2
0.1877795423	equivalent to
0.1877579382	\ xi_1
0.1877579382	\ asymp
0.1876081741	r ^ n
0.1874473995	least squares criterion
0.1874000037	l statistics
0.1872929569	in survey sampling
0.1872823611	under mild
0.1872487239	kernel estimation of
0.1872219054	_ t
0.1871851346	| x_i
0.1871354509	generalization bounds for
0.1871339838	\ rightarrow 0
0.1871048249	student's t
0.1871016317	\ mathcal o
0.1870982634	attracted much
0.1870976468	able to
0.1867613957	modeled by
0.1867507635	prove consistency of
0.1865919433	consistency and asymptotic normality of
0.1865855928	better than
0.1863658346	driving l \
0.1863485762	efron et al
0.1862015004	the so called
0.1861985464	family of models
0.1861460514	non parametric estimation
0.1860608256	the drift coefficient
0.1860313144	one by one
0.1858547010	normal linear
0.1858466794	change point detection for
0.1856330922	weak assumptions on
0.1855596742	particular attention
0.1855409934	estimation in nonparametric
0.1855269073	equal to 1
0.1853991871	popular tool for
0.1853257925	kernel k
0.1853195415	different ways
0.1853075819	$ fwer
0.1852929650	compared with
0.1852381538	different kinds
0.1852288254	improvement over
0.1852010980	+ \ infty
0.1851475884	estimation of multivariate
0.1851340967	concentration bounds for
0.1851014408	performance analysis of
0.1850660197	^ \ gamma
0.1850569827	non increasing
0.1849915274	hypothesis testing for
0.1848534178	x and y
0.1848390194	class models
0.1847292339	one sample
0.1847003672	\ ` es
0.1846795635	independent random variables with
0.1846466197	non asymptotic oracle
0.1846435441	upper and lower bounds for
0.1846156393	the error distribution
0.1845744681	fixed number of
0.1845577271	both simulated and real data
0.1845275939	asymptotic analysis of
0.1844439591	concentration inequality for
0.1844372860	generated according to
0.1844110900	contrary to
0.1843833683	combined with
0.1843588881	problem in statistical
0.1842759498	time scales
0.1842486907	other hand
0.1842150316	long time
0.1841946581	a key step
0.1841472922	applicable to
0.1841079980	an ergodic diffusion
0.1840004912	deviation inequalities for
0.1839429144	much faster
0.1838118528	non normalized
0.1837710154	ill posed linear
0.1837666321	unit ball of
0.1836934508	difficult to
0.1836588919	numerical evaluation of
0.1836193183	scale problems
0.1836055912	initial value
0.1835671271	become increasingly
0.1835509748	simulation studies show
0.1835397822	process indexed by
0.1835259792	minimax optimal rates of
0.1834597138	measure of statistical
0.1834262488	markov bases for
0.1833731372	n ^ \ frac
0.1833427470	natural generalization of
0.1832398202	drift parameters of
0.1832073852	recent developments in
0.1831843771	confidence intervals based on
0.1831807507	problems arising in
0.1831653361	nonparametric estimation for
0.1831209833	generated from
0.1831128787	based on continuous
0.1830996507	log ^ 2 n
0.1830826247	two fundamental
0.1830509188	non convexity
0.1828571171	new approaches
0.1828485312	new techniques
0.1828446348	most powerful
0.1827467662	aim at
0.1827210272	class of stationary
0.1827033204	extensively used
0.1825254589	the likelihood ratio test statistic
0.1824707829	mean vectors
0.1824686533	rrr ^
0.1823622998	independent interest
0.1822439210	| ^ \ alpha
0.1821967114	method performs well
0.1821838170	e chet mean
0.1821769264	a unified framework
0.1821556963	the noise level
0.1821407078	an unknown
0.1821386056	+ w
0.1819849957	classes of models
0.1818681613	to detect
0.1817594803	bounded below
0.1817492349	illustrated via
0.1817376347	mixtures of gaussian
0.1817355003	on riemannian manifolds
0.1817234123	cand \
0.1816925740	x _i
0.1815928898	in finite samples
0.1815350415	\ mathscr
0.1814695779	least squares method
0.1814513421	estimation under
0.1813793181	smooth enough
0.1813593476	a minimax sense
0.1812629967	analogous results for
0.1811733391	quantum system
0.1811616021	convergence rate of
0.1810926516	linear quantile
0.1810723458	\ | _1
0.1810697897	assessed through
0.1810654558	t \ geq 0
0.1810618863	illustrated by means
0.1809325138	general sufficient
0.1809115152	\ times
0.1808989812	convex combination of
0.1808966578	under very general conditions
0.1808491194	a strong law of large numbers
0.1807335302	\ mathbf x
0.1807128152	each node
0.1807044284	first kind
0.1805630233	$ l_
0.1805521334	the posterior distribution
0.1805416581	from discrete observations
0.1803397842	the false discovery proportion
0.1802971227	tends to
0.1801258105	new framework
0.1800538266	a large number
0.1799345638	converges at
0.1799151487	\ ell_
0.1798955874	in practice
0.1798135404	extended to
0.1796980504	adaptive estimation in
0.1796554287	x_t =
0.1795126347	discussed in detail
0.1794127454	large relative to
0.1794038149	presence of
0.1793987752	\ mathbb e
0.1793146174	general family
0.1793127146	sample fr \
0.1792126547	estimators based on
0.1792063252	the asymptotic covariance matrix
0.1791730527	m_ n
0.1791472922	equal to
0.1791368151	\ chi ^ 2
0.1790600752	gaps between
0.1790483376	a single observation
0.1790082443	minimum number of
0.1788732594	a gaussian random field
0.1788629475	runs in time
0.1788557598	pertaining to
0.1788267575	finite sample behavior of
0.1787694638	\ log n
0.1786795051	easy to
0.1785857633	second order structure
0.1784921910	in other words
0.1784878206	convex hull of
0.1784444792	null distribution of
0.1784057957	some mild assumptions
0.1784051634	a wide range of applications
0.1783932425	\ lambda ^ 0
0.1783312355	derived from
0.1782916077	non asymptotic framework
0.1781238140	| 1
0.1780884175	more or less
0.1780826182	dependencies among
0.1780821172	optimal rates of convergence for
0.1780656181	two step estimator
0.1779720006	adaptive density
0.1779649047	virtue of
0.1779012725	proportional to
0.1778789644	| \ ge
0.1778657268	e x_
0.1777887739	multivariate extreme value
0.1777770952	the nonparametric maximum likelihood estimator
0.1776076822	explicit formulae for
0.1775988561	originating from
0.1775411988	for long range dependent
0.1775041674	in gaussian white noise
0.1774861807	recently introduced by
0.1774115674	for high dimensional data
0.1773634986	point test
0.1773610527	full bayesian
0.1773437796	validated through
0.1773210856	due to
0.1772626269	come from
0.1772617156	\ beta _
0.1772544542	illustrated by means of
0.1772491769	new feature
0.1772219803	minimal assumptions on
0.1771690565	the moment generating function
0.1771359290	system of stochastic
0.1770979867	1 \ varepsilon
0.1770738935	test statistics based on
0.1770437832	extracted from
0.1769901557	denoted by
0.1769497208	simultaneous estimation of
0.1768720609	sub class
0.1768543380	spectral analysis of
0.1767563529	each row
0.1766889071	random samples from
0.1766254681	exponential inequalities for
0.1766058636	relatively few
0.1765992361	similar processes
0.1764673383	sums of random
0.1764227873	much larger
0.1763868749	g priors
0.1763170297	conditional distribution of
0.1762924597	parametric estimation of
0.1761257286	index regression
0.1761193553	the negative log likelihood
0.1760708180	least squares estimate
0.1760234505	\ sum_ j
0.1760050466	distribution of random
0.1759666553	this end
0.1759500561	p q
0.1758922590	under suitable assumptions
0.1758860366	well approximated by
0.1756508049	ratio of two
0.1755947651	estimation of gaussian
0.1755306182	more specifically
0.1754830864	an empirical bayes
0.1754789007	several authors
0.1754164299	special class of
0.1753851457	\ hat p_r
0.1753467317	second contribution
0.1752220784	class of probability
0.1751982238	attributed to
0.1751596960	very high dimensional
0.1751480099	almost sure convergence
0.1750345006	unknown probability
0.1750178878	limit laws for
0.1750047310	i + 1
0.1749950417	non response
0.1749493623	maximum likelihood estimators of
0.1749486559	with or without
0.1749046549	to one as
0.1748488561	stem from
0.1747394724	central limit theorem with
0.1747242248	annals of
0.1745892821	procedures based on
0.1745351714	written as
0.1744667400	problem of optimal
0.1744599929	other applications
0.1744424155	density with respect
0.1743979508	an unknown distribution
0.1743762176	bounded from above
0.1743395875	practical utility of
0.1743360436	each vertex
0.1742727969	regression with random
0.1741857791	much less
0.1741360134	1 \ gamma
0.1740462000	much smaller
0.1739586019	two way
0.1739539198	survival time
0.1738961898	best subset
0.1738713000	| \ cdot \ |
0.1738343093	much weaker
0.1738067349	a key tool
0.1737466746	mean squared
0.1736651070	j = 1
0.1736591454	related problem
0.1736186742	similar to
0.1735834779	this article studies
0.1735526629	non causal
0.1735505651	other areas
0.1735322268	non identically
0.1734766057	bayesian hypothesis
0.1733525234	ordinary least
0.1733208004	level sets of
0.1732903779	coordinate system
0.1732715886	$ \ ell_q
0.1732565734	asymptotic expansion of
0.1732458497	the familywise
0.1732320920	ij |
0.1732263351	link between
0.1730800274	\ `
0.1730539939	_ m
0.1730264762	the square root lasso
0.1730135846	divided by
0.1728965576	while achieving
0.1727818682	paper focuses on
0.1726656749	of true null hypotheses
0.1726577892	two layer
0.1725571016	problem of high
0.1725239955	case of finite
0.1724487764	change points in
0.1724359575	the interest of
0.1724144423	linear time
0.1724056742	\ sqrt n
0.1724020979	with long range dependence
0.1723871008	characterised by
0.1723822811	the precision matrix
0.1723607244	the familywise error rate
0.1723565408	new insights
0.1723004532	spite of
0.1722479260	transformed into
0.1719823802	variable selection in
0.1718813897	three problems
0.1718732680	\ subset
0.1718553587	as far as
0.1717768468	non asymptotic confidence
0.1716737423	owing to
0.1716073516	computer models
0.1715826774	class of linear
0.1715784539	an empirical study
0.1715345006	type large
0.1713970430	small number of
0.1713386391	necessary and sufficient conditions
0.1713217291	too much
0.1713066024	t _1
0.1713036356	$ \ cal
0.1712695191	first and second order
0.1712478845	the minimax sense
0.1712163917	best linear
0.1711502432	a system of
0.1711463054	support vector machines with
0.1711458612	attached to
0.1711430832	\ ^ o
0.1710379277	uncertainty quantification for
0.1710078072	distributional properties of
0.1709840473	the real line
0.1708571552	know whether
0.1708365594	a data driven
0.1708249046	characterization of
0.1708202257	while ensuring
0.1707160550	| \ hat \ beta
0.1706111455	| _2
0.1704595153	sample covariance matrices of
0.1704181975	an adaptive estimator
0.1704086177	technique based on
0.1703645289	the work of
0.1702908150	these results hold
0.1702678510	closed form expression of
0.1701912754	non zero coefficients
0.1701905603	links between
0.1700786057	\ leq p \ leq
0.1700372241	the spectral norm
0.1699350007	at most
0.1698545845	parameter estimation in
0.1698337709	class of adaptive
0.1698335128	phase transitions in
0.1697965580	the general case
0.1697757134	linear model with
0.1697649257	versions of
0.1697357789	procedure based on
0.1696532035	the likelihood ratio test
0.1695893509	defined on
0.1695063936	\ mathbf y
0.1694046583	$ dimensional euclidean
0.1693631611	fast rates for
0.1693141347	based on estimating
0.1692886289	asymptotic optimality of
0.1692046333	\ ast \ mathcal n
0.1691463473	accomplished by
0.1691035372	significantly better
0.1691016122	the art algorithms
0.1690525624	asymptotic results for
0.1689653692	for use in
0.1689613957	represented as
0.1689577307	integer valued time
0.1689155055	check whether
0.1689098183	\ theta _n
0.1688500594	based on simple
0.1687461623	bias and mean
0.1686745015	case of gaussian
0.1686590449	a fractional brownian motion
0.1686468352	problem of estimation
0.1686039247	test statistics for
0.1685284839	some regularity conditions
0.1685085136	random variables with
0.1684622091	exactly equal
0.1684080258	k monotone
0.1683967932	this paper extends
0.1683803666	_ k \ in
0.1683756976	bounds on
0.1683425700	assumptions about
0.1683384423	sufficient conditions under
0.1682830156	more robust
0.1680615521	several applications
0.1680231363	small time
0.1679141374	the decision maker
0.1678936500	based on gaussian
0.1678367511	as small as
0.1677863609	with probability one
0.1677451815	problem of approximating
0.1677306834	apart from
0.1676753595	optimal estimation of
0.1676102793	p = q
0.1674634813	| _ \ infty
0.1674259718	modeled as
0.1673905818	applies to
0.1673474897	a multivariate normal distribution
0.1673339255	optimal choice of
0.1673229551	bounds for sparse
0.1670632565	weighted sum of
0.1670328246	these results
0.1668825786	based on local
0.1667952007	index model
0.1667776004	\ h o
0.1667236356	with unequal
0.1665278058	sparsity assumptions on
0.1664364917	for high dimensional regression
0.1664319404	convex and non
0.1663684892	an arbitrary
0.1663651937	consistent estimator of
0.1663587185	using auxiliary
0.1663429335	non parametric statistics
0.1663255767	mutual information between
0.1662782371	much attention
0.1662335420	received much
0.1662306012	number of false
0.1661387794	for instance
0.1661256119	produced by
0.1661255441	description of
0.1660931249	fundamental role in
0.1660259035	the other hand
0.1659558634	become popular
0.1659469928	distinguishing between
0.1658946198	\ ge 0
0.1658778151	conditional mean estimator
0.1657845516	^ p
0.1657835004	of low rank matrices
0.1657566341	several examples
0.1657025511	coverage of adaptive
0.1656796549	the change of
0.1655947984	kappa \
0.1655347199	\ rightarrow \ mathbb r
0.1655179477	= f_
0.1654029763	run time
0.1653832021	n ^ 4
0.1653616365	\ | x \
0.1653550891	analysis of large
0.1653019851	m m
0.1651972754	regression function at
0.1651851927	regularity assumptions on
0.1651718097	the extremal index
0.1651552631	| _1
0.1650404425	processes indexed by
0.1650401972	\ subset \ mathbb r ^
0.1650305944	maximum likelihood estimator for
0.1650137010	prior work
0.1650078540	bayesian inference for
0.1649554982	a popular tool
0.1649354600	time series model
0.1648890624	examined through
0.1648679204	long memory time
0.1646521207	the ambient space
0.1646491282	brownian motion with
0.1646360366	more efficient than
0.1645929063	test based on
0.1645901593	right tail
0.1645598188	point problems
0.1645532646	nonparametric regression with
0.1644593876	problem of learning
0.1644281628	a wide variety
0.1643747210	case of independent
0.1643290186	\ alpha 1
0.1641369745	principal component analysis for
0.1640416407	random walk on
0.1640354426	a level
0.1639203185	$ \ | \ cdot
0.1638701218	mild conditions on
0.1638436636	the target distribution
0.1637951968	tail asymptotics of
0.1637801953	over threshold
0.1637728767	boundary value
0.1637343530	$ y = x \ beta
0.1637096325	estimation of
0.1636966136	= 1 ^ n
0.1636006162	improvements over
0.1635498557	geometric properties of
0.1635461950	| \ mathcal
0.1633831618	the minimax separation
0.1633362389	+ \ delta
0.1632672448	relatively little
0.1632411780	quadratic forms of
0.1631882814	analysis of random
0.1631839679	assumptions on
0.1631074956	a high dimensional
0.1631054573	sampled at
0.1630954850	differ from
0.1630952911	not identically distributed
0.1629270392	the log likelihood function
0.1629138239	_ p
0.1629105038	illustrated with
0.1628082966	based on exponential
0.1627016383	independence structure of
0.1626973098	comparing two
0.1626544559	equivalence classes of
0.1626357398	time points
0.1625599969	does not depend on
0.1625553640	\ end equation
0.1625457908	a key component
0.1625420478	under sparsity
0.1624864141	need to know
0.1624591428	y_i =
0.1623669565	as close as
0.1623645289	more and more
0.1623226464	within cluster
0.1623215078	test statistics under
0.1622945345	$ fold
0.1622840165	frequentist properties of
0.1622793778	^ n
0.1622239672	estimation for high
0.1622093177	the population covariance matrix
0.1622035452	contraction rates for
0.1621973115	class of tests
0.1621326259	\ ell_q
0.1620076247	$ th
0.1619911963	n k
0.1619813494	draws from
0.1619575864	theoretical justification for
0.1618573895	amenable to
0.1618571950	asymptotic equivalence of
0.1618214615	the propensity score
0.1618125866	event time
0.1617922108	aspects of
0.1617893509	relative to
0.1617741107	based on u statistics
0.1617528347	performs better
0.1617276095	two consecutive
0.1617066206	a random variable
0.1617001978	based on empirical
0.1616784888	discrepancy between
0.1615986443	problem of multiple
0.1615820608	similarity between
0.1615810614	robust estimation of
0.1615298363	h 1
0.1615050826	1 alpha
0.1614547049	problem of nonparametric
0.1614333049	an important application
0.1614147578	1 \ delta
0.1614049395	mean discrepancy
0.1613866537	time interval
0.1613250425	\ sim \ mathcal n
0.1612922167	results hold for
0.1611879455	non sequential
0.1611026241	a series of
0.1610718461	probability density function of
0.1610392867	arise from
0.1610089580	asymptotically normally
0.1609513024	h \
0.1609405934	unable to
0.1609359575	the subject of
0.1609359575	the focus of
0.1609232522	performance relative to
0.1608907063	the first step
0.1608602291	p_ n
0.1608289757	statistical estimation of
0.1608096977	$ \ widetilde
0.1607563971	easier than
0.1606692287	$ ary
0.1605733348	the paper considers
0.1605599263	the restricted isometry property
0.1605358870	achieves near
0.1605164772	a single
0.1605051756	thanks to
0.1602839018	sub linear
0.1601618715	estimation based on
0.1600338213	bounds for
0.1600222146	theory of optimal
0.1599915294	a crucial role
0.1599752191	number of hidden
0.1599106070	thus allowing
0.1598982671	theoretical guarantees for
0.1596738965	nearly matching
0.1596159794	near linear
0.1595994777	an unknown signal
0.1595991082	contaminated by
0.1595508011	\ geq 1
0.1594887159	unlike most
0.1593902458	for large scale
0.1593120801	one parameter family
0.1592363860	too small
0.1590506262	accounts for
0.1590425057	for hidden markov models
0.1590079369	robustness properties of
0.1589778251	probability measures on
0.1588223066	the empirical distribution function
0.1588076178	$ \ mathcal
0.1587873445	\ | \ hat
0.1587865344	easy to use
0.1586684089	the maximum likelihood estimators
0.1586251338	soon as
0.1585684361	based only on
0.1585533115	$ r_i
0.1584699548	on off
0.1583876269	an explicit
0.1583645289	with and without
0.1583358853	well suited for
0.1582718156	an alternative approach
0.1581806337	$ \ alpha
0.1581425225	dependence among
0.1580758516	achieved through
0.1580311956	the principle of
0.1580241479	general high
0.1579846602	the change point problem
0.1579481957	empirical version of
0.1578917538	new results
0.1578860366	more powerful than
0.1577622124	the true posterior
0.1577400218	gaussian mean
0.1577266973	bounded above
0.1576965624	as soon
0.1576618701	s_ n
0.1576286678	tau =
0.1576125998	| ^ 2
0.1576013071	relatively small number
0.1575976156	$ l_p
0.1575804749	_ + ^
0.1575379574	order information
0.1575377191	number of latent
0.1575349312	mean squared prediction
0.1575305180	smoothness conditions on
0.1575250375	functions defined on
0.1575211942	in high dimensional linear models
0.1574707503	researchers often
0.1574658918	= \ exp
0.1574359575	the selection of
0.1574177412	able to detect
0.1573971463	result holds for
0.1573860236	discrimination between
0.1572426659	full dimensional
0.1571822484	bridge between
0.1571676121	a broad range
0.1571483077	close to 1
0.1571072868	a convex body
0.1570594018	good finite sample
0.1570437686	estimators for linear
0.1570321134	within gibbs
0.1570205311	simulation results show
0.1569835765	\ in \ mathbb r ^
0.1569300642	mild assumptions on
0.1568941650	non positive
0.1568330465	future work
0.1567392867	satisfied by
0.1567192169	application to
0.1566429835	sampled from
0.1566050476	each cluster
0.1565748153	away from
0.1564653692	the dimensions of
0.1564599989	second order parameter
0.1564455118	least squares problem
0.1564447931	perform better than
0.1564359575	the problems of
0.1563537486	\ ge 1
0.1563052361	based methods for
0.1562972707	$ x_ ij
0.1562660162	to solve
0.1562225689	large compared to
0.1562165783	adjacency matrix of
0.1561796549	a network of
0.1561480112	consistency properties of
0.1561250229	= 3
0.1561119650	to overcome
0.1560852380	a real valued
0.1560672717	an exponential
0.1560446743	the parameter space
0.1559981369	a unifying
0.1559834428	1 3
0.1559359575	the hypothesis of
0.1558732938	consistent against
0.1558708203	this thesis
0.1557474524	an important
0.1556796549	the edges of
0.1556780101	an ill posed
0.1556516920	in high dimensional regression
0.1556502432	the tails of
0.1556502432	the effects of
0.1556168778	not too large
0.1555766470	a wide array of
0.1555711875	second order asymptotic
0.1555160285	small enough
0.1554990150	question whether
0.1554565362	two independent samples
0.1554482909	class of statistical
0.1554383615	the problem of estimating
0.1553777314	two parts
0.1553332566	the maximum likelihood degree
0.1553251210	process driven by
0.1552860186	comments on
0.1552675557	number of data
0.1552608448	linear and non
0.1552595673	k = 1
0.1552414251	range of models
0.1551907985	gives rise to
0.1551816266	a random sample
0.1551654775	to avoid
0.1551217991	clinical trials with
0.1550793724	converges in distribution
0.1550410933	the training dataset
0.1550343744	knowledge about
0.1550129883	the scale of
0.1549398870	1 dimensional
0.1548939407	and so on
0.1548439805	popular method for
0.1547864350	the log likelihood ratio
0.1547841022	an efficient estimator
0.1547607681	as well as
0.1546896744	le r
0.1546796549	and not on
0.1546562366	\ | x \ |
0.1546471402	mathematical theory of
0.1546098197	average value
0.1546094538	sharp bounds for
0.1545733487	value thresholding
0.1543936562	a small number
0.1543790221	each component
0.1543735853	a compound poisson
0.1543683284	particularly suitable
0.1543104327	two layers
0.1542947555	t x
0.1542917372	and real data analysis
0.1542072298	third moment
0.1541826049	an alternative
0.1541739284	a gaussian process
0.1541530767	scale mixtures of
0.1540369272	approach to model
0.1539835765	the prediction of
0.1539835765	the results of
0.1538748890	the single index model
0.1538113180	class of gaussian
0.1537609989	\ neq 0
0.1537544979	more precise
0.1537422409	sample size n
0.1537377346	non convex loss
0.1537312747	as opposed to
0.1537133970	a recent paper
0.1536974048	no effect
0.1536831705	an unknown vector
0.1536796549	the regime of
0.1535289950	approach based on
0.1535074213	a unified treatment
0.1534835765	the rank of
0.1534835765	the ratio of
0.1534526235	very little
0.1534463768	\ mapsto \ mathbb r
0.1534119072	with missing observations
0.1533858566	accounted for
0.1533803744	adaptive test
0.1533767142	^ \ infty
0.1533518994	measured by
0.1533505819	\ in \ mathbb r
0.1532117635	computation time
0.1531998708	dimensional distribution
0.1531929797	first hitting time
0.1531629179	linear models with
0.1530468452	capable of
0.1530417239	this problem
0.1530405220	several numerical examples
0.1530037133	numerical performance of
0.1528694218	an efficient
0.1527903308	the optimal convergence rate
0.1527897643	estimation for linear
0.1527891951	in high dimensional statistics
0.1527868889	least squares estimates
0.1527521020	distribution of order
0.1527514921	singular vectors of
0.1527513234	begin by
0.1526543791	new data driven
0.1525419415	converges in distribution to
0.1524835765	the entropy of
0.1524819564	supposed to
0.1524486717	sample tests
0.1524406595	wish to
0.1524028321	simulations indicate
0.1523801280	memory time series
0.1523105162	small compared to
0.1522691266	existence of
0.1522326376	unbiased estimators for
0.1521796549	and also to
0.1521469681	probability tending to
0.1521443734	functional form of
0.1520647270	the high dimensional case
0.1519835765	the process of
0.1519835765	the dependence of
0.1519835765	the gradient of
0.1519835765	the inference of
0.1519835765	the frequency of
0.1519808734	least squares projection
0.1518739851	estimation of large
0.1517987950	explained by
0.1517642357	stein's method for
0.1516839413	robust test for
0.1516161132	accounting for
0.1515746692	methods based on
0.1515619749	non parametric estimators
0.1515212577	$ optimal designs
0.1515163859	regret bounds for
0.1515155169	$ \ phi
0.1514918080	higher than
0.1514835765	a model of
0.1514648042	give sufficient conditions
0.1514018772	if and only
0.1513954743	a unified
0.1512623849	barndorff nielsen and
0.1512559081	to compute
0.1512166012	convergence properties of
0.1510474262	behavior of
0.1510129883	a population of
0.1509909614	accordance with
0.1509835765	the square of
0.1509835765	the likelihood of
0.1509730519	quantities of interest
0.1509673725	parameter of interest
0.1509667628	a functional central limit
0.1509036252	in order to
0.1508309142	v statistics
0.1508019760	set of data
0.1507752302	an application
0.1507434773	joint distribution of
0.1506877916	a lot of attention
0.1506713057	consists in
0.1506454261	class of random
0.1505925675	invariance principle for
0.1505895667	an explicit formula
0.1505872372	for high dimensional linear
0.1505809013	data consist of
0.1505606739	$ \ mathscr
0.1505444399	relatively simple
0.1505244377	classes of
0.1504835765	the order of
0.1504835765	a sample of
0.1504653692	the approach of
0.1504376556	large classes of
0.1503979944	$ l_0
0.1503812881	some special cases
0.1503587798	the stick breaking
0.1503433162	in machine learning
0.1503432921	the optimal sample complexity
0.1503207394	a response variable
0.1503131836	supplemented by
0.1502890678	converge to zero
0.1502877298	the test statistic
0.1502828295	first and second
0.1502567390	explicit expression for
0.1502361676	a scalar response
0.1502308004	prediction performance of
0.1501483192	a model selection procedure
0.1501396267	two points
0.1500941820	estimation via
0.1500862389	\ geq 0
0.1500584525	non central limit
0.1500324545	l ^ 1
0.1499801957	a consistent estimator
0.1498847830	non constant
0.1498730948	one stage
0.1497802976	making use of
0.1497177728	the sample autocovariance
0.1497136469	a scalar parameter
0.1497127443	a log factor
0.1496997943	to achieve
0.1496368704	l ^ p
0.1496339595	irrespective of
0.1495995710	cope with
0.1495847033	from noisy
0.1495468452	collections of
0.1495245968	_t =
0.1495211250	and real data applications
0.1493765685	limit behavior of
0.1493657499	d_n \
0.1492782782	1 norm
0.1492720018	class of sparse
0.1491585373	class of
0.1491268658	a universal constant
0.1489756203	asymptotic distribution under
0.1489711245	a finite sample
0.1489536121	$ \ mathbf
0.1489323159	\ varpi
0.1489274348	with respect to
0.1488645289	as large as
0.1487894588	\ mbtheta
0.1487732392	h 1 2
0.1487068639	\ sup_ t \ in
0.1486796549	the sizes of
0.1486540008	sparsity assumption on
0.1486506341	equivalence class of
0.1486462747	great interest
0.1485654418	\ sum_ i = 1 ^
0.1485562911	a standard tool
0.1485548969	mathematical framework for
0.1484600859	analytical expressions for
0.1484235379	samples from
0.1483182414	to understand
0.1482723445	+ \ frac
0.1482623916	evaluated at
0.1482192203	strong enough
0.1481918157	intervals based on
0.1481036983	\ log \ log
0.1480161399	v s
0.1479812736	risks data
0.1479106555	the stochastic block model
0.1477891875	an analytic
0.1477506334	theoretical support for
0.1477437077	^ q
0.1477346661	the inverse covariance matrix
0.1477267629	testing in high
0.1477204074	in high dimensional linear regression
0.1477015014	the selected model
0.1476727439	reconstruction from
0.1476568513	density estimation on
0.1474983403	very flexible
0.1474887653	the observed data
0.1474851582	$ \ tilde o
0.1474590013	problem of parameter
0.1474455422	also discuss
0.1474349978	$ \ boldsymbol
0.1473872006	scale mixture of
0.1473789041	a key role
0.1473421503	s 1
0.1473062554	space model
0.1472869455	$ \ hat
0.1472713194	the present article
0.1472304355	deviation inequality for
0.1472272740	the ideas of
0.1472112490	outperforms other
0.1471706582	the maximum likelihood method
0.1471572127	triangular arrays of
0.1471465010	particularly useful
0.1470120019	a modified version
0.1469873404	the total number
0.1469479208	t = 1
0.1468142394	subset of
0.1467917904	did not
0.1467051430	parameterized by
0.1466796549	the distance to
0.1466796549	the maximization of
0.1466740378	the minimum description length
0.1466462879	nonparametric estimator of
0.1466005841	to select
0.1465756627	a linear functional
0.1465350636	the signal to noise ratio
0.1465228037	kernel estimator of
0.1464653692	the phenomenon of
0.1464041247	extensively studied in
0.1463998901	powers of
0.1463900738	expressions for
0.1463550999	\ ge0
0.1462944786	critical points of
0.1462921165	uniformly distributed on
0.1462761170	nonparametric test for
0.1462397433	powerful tool for
0.1461931743	the probability density function
0.1460234526	converge at
0.1460005297	$ \ varepsilon
0.1458633898	available online
0.1457578085	number of model
0.1457085884	unbiased estimator of
0.1456544773	the elastic net
0.1456426725	parametrized by
0.1456371726	studied in detail
0.1455787410	c ^ 1
0.1455589562	so as to
0.1455398115	comparable to
0.1455227763	sufficient conditions on
0.1453944272	m g
0.1453572526	more general setting
0.1453568754	to estimate
0.1453227490	association between
0.1452418191	a change point
0.1452052503	the covariance matrix
0.1451455496	| x
0.1451425168	gibbs sampler for
0.1450936429	an effective
0.1450410982	expected value
0.1450367978	the fields of
0.1449276271	fourier coefficients of
0.1448939407	the way for
0.1448112657	non parametric density
0.1447643099	$ \ operatorname
0.1447432708	trying to
0.1447051800	an experiment
0.1446376905	used to construct
0.1446348823	to infinity
0.1446021405	a simple
0.1445950824	non negative random
0.1445498242	locally stationary time
0.1445449859	this result
0.1444244989	inference based on
0.1443897005	this paper generalizes
0.1443739604	y \ mathbf
0.1441977989	the model parameters
0.1441420215	\ boldsymbol x _i
0.1441130552	qualitative robustness of
0.1441115618	as long as
0.1440641233	central limit theorem in
0.1440004279	s ^ 1
0.1439907446	a high dimensional linear
0.1439795104	to perform
0.1436827149	moment conditions on
0.1436701916	theoretical foundation for
0.1436483079	contrast to most
0.1436362963	through simulation studies
0.1436162244	i 1
0.1435489881	estimation of linear
0.1435129883	the projection of
0.1435105171	hitting time
0.1435005297	$ \ omega
0.1434931328	$ \ ell ^ 1
0.1434899965	2 \ alpha
0.1434653692	the paper by
0.1433903761	minimax optimality of
0.1433276967	spectral representation of
0.1433249235	advantage over
0.1433030250	significance test for
0.1432315004	two block
0.1431744141	r ^ 2
0.1430562035	inference methods for
0.1430426367	$ \ widehat
0.1430412870	theta =
0.1429471799	estimators in high
0.1429259177	attempt to
0.1428649114	order to achieve
0.1428630174	based on data
0.1428008852	$ x_1
0.1427828513	set of random
0.1427799190	+ z
0.1426860313	divergence between
0.1426802220	a sparse vector
0.1426653509	a long history
0.1425356054	explicit expressions of
0.1425159114	x_ n +
0.1425011779	this paper offers
0.1424653692	the convergence to
0.1424424515	shrinkage estimator for
0.1424307802	asymptotic performance of
0.1423773037	error bound for
0.1423666014	for change point detection
0.1423286984	$ \ bolds
0.1422629129	$ \ theta_0
0.1422116859	hypotheses about
0.1421640133	\ bbu_1
0.1420926159	\ x_i \ _ i
0.1420483056	this work
0.1420205803	divergences between
0.1420020089	necessary conditions
0.1419757463	an iterative
0.1419464634	this issue
0.1418243056	equal to zero
0.1418239985	sampling from
0.1417610744	common practice in
0.1417318435	formed by
0.1416497692	approach leads to
0.1416309929	tailored to
0.1416041651	the em algorithm
0.1415989785	delta method for
0.1415717891	results rely on
0.1415536518	r ^ n \ times
0.1415481380	bayesian analysis of
0.1415167530	p ^ 1
0.1415151525	joint density of
0.1414653692	the results with
0.1414653692	the treatment of
0.1414202652	conducted to
0.1413177658	a complete characterization
0.1412423580	test statistic under
0.1411263284	an exact
0.1411094429	following question
0.1410612296	estimation method for
0.1410367978	the modeling of
0.1409749269	non parametric estimator
0.1409403293	first order methods
0.1409130027	time to event data
0.1408849069	an interpretation
0.1408331729	the minimax lower bound
0.1408062908	unknown regression
0.1407491082	independence between
0.1407467260	existing literature on
0.1407190875	confidence bounds for
0.1407171435	\ mh
0.1406920270	estimation of smooth
0.1406425932	approach to
0.1406255373	in state space models
0.1405370398	from noisy measurements
0.1405156941	well approximated
0.1405044740	by applying
0.1404991963	a small fraction
0.1404679449	time point
0.1404653692	the uncertainty of
0.1403484313	\ to \ mathbb r
0.1403085437	the minimax risk
0.1403004879	analysis of
0.1402472957	even if
0.1402163561	method based on
0.1401801496	an interesting
0.1401775512	practical implementation of
0.1400671360	generalized version of
0.1400561615	to assess
0.1400511871	tail behavior of
0.1400380601	_ +
0.1400214576	a probability density function
0.1400070444	a large class
0.1399796712	adapted to
0.1399363646	the finite sample performance
0.1399191967	a general methodology
0.1399094775	types of
0.1398939407	the paper also
0.1398937479	selected by
0.1398764166	make use of
0.1398661034	a_n \
0.1398044189	up to
0.1397885616	in high dimensional gaussian
0.1397163255	the multivariate case
0.1396453321	a kernel density estimator
0.1396072200	$ \ pi
0.1395989919	way contingency
0.1395776787	infinity norm
0.1395600601	theoretical guarantees on
0.1394535618	a general
0.1394515864	many real world
0.1394482055	non asymptotic risk
0.1394238852	epsilon 0
0.1393849703	mean pattern
0.1393767568	^ 2 \ log
0.1393637016	effective way
0.1393600938	significantly different
0.1393517305	small subset of
0.1392735855	spectral properties of
0.1392199777	posterior consistency for
0.1392023839	nonparametric part
0.1392012201	distributions over
0.1391885666	\ _
0.1391104171	sure independence
0.1390850644	many authors
0.1390572889	to choose
0.1390485487	method relies on
0.1390349416	ij =
0.1390239075	asymptotic distributions of
0.1389134154	r von
0.1388142394	extension of
0.1385751590	uniform consistency of
0.1385553340	a riemannian manifold
0.1384733040	comparisons between
0.1384590200	maximum likelihood estimate of
0.1384580084	small values of
0.1384541133	\ bbu_2
0.1384446495	an extended
0.1384073434	based on random
0.1384036252	by means of
0.1383960123	centered at
0.1383870016	an algorithmic
0.1383333523	2 3
0.1383253462	the model space
0.1382872774	\ mathfrak
0.1382382577	other contexts
0.1382040820	t \ in 0
0.1381149759	the true function
0.1380653601	one or two
0.1380360534	markov basis for
0.1380149650	learning rates for
0.1380011089	optimality properties of
0.1379909117	these bounds
0.1379726154	function belongs to
0.1379701505	possible extensions
0.1379465682	an estimation procedure
0.1379461258	order 1
0.1379323159	\ theta_2
0.1378727308	random fields on
0.1378009853	\ in \ mathbb z
0.1377374084	asymptotic theory of
0.1377328527	maximum likelihood estimator of
0.1377275109	1 + \ epsilon
0.1377256316	some additional assumptions
0.1376969033	= \ infty
0.1376655743	numerical experiments show
0.1376651635	asymptotic expansions for
0.1376348037	geometric structure of
0.1375914334	matrix completion with
0.1375600371	an unknown density
0.1375544968	estimation rate
0.1375378348	impact on
0.1375129883	the condition of
0.1375129883	$ a \
0.1373316401	focus here
0.1373229065	the art results
0.1373082075	geometric ergodicity of
0.1373074599	sampling distribution of
0.1372769573	regardless of
0.1372408701	the unknown function
0.1372392960	$ n ^ 2
0.1371777852	\ leq 1
0.1371706356	observed at
0.1371461330	the gaussian sequence model
0.1371344889	rests on
0.1371252259	each other
0.1371153102	in functional linear regression
0.1370961462	together with
0.1370778561	$ \ mathbb
0.1370776010	theoretical analysis of
0.1370199241	coverage probabilities of
0.1370078145	an unbiased estimator
0.1370013349	the problem of detecting
0.1369347590	$ \ delta_
0.1369323159	\ lambda_1
0.1369246852	mixture models with
0.1367697872	$ \ bar
0.1367682367	strong law of large numbers for
0.1367476391	fast algorithm for
0.1367328696	in fact
0.1365989826	\ alpha_k
0.1365479434	existing work
0.1365165784	$ \ beta
0.1364571063	estimation in high
0.1364433571	large values of
0.1364195603	structural changes
0.1363925932	quite general
0.1363422646	and real world data
0.1363297524	$ \ eta
0.1363195578	analysis of data
0.1362479372	each individual
0.1362288828	arises from
0.1362272740	in term of
0.1362170913	\ log p
0.1362156574	with regularly varying
0.1361613011	$ l_ \ infty
0.1361405396	performance of
0.1360800634	the statistician
0.1360402582	estimator converges to
0.1360136431	comes from
0.1359325612	$ \ delta_n
0.1359251329	conditions on
0.1359153785	two examples
0.1359126104	through numerical experiments
0.1358970265	\ ell ^ 1
0.1358939407	the observations in
0.1358939407	the classification of
0.1358266995	kernel estimators of
0.1358025051	model with random
0.1357979936	$ \ exp
0.1357501238	experimental results on
0.1357491825	defined through
0.1356796549	in distribution to
0.1356555895	do not assume
0.1356448258	this purpose
0.1356379821	the group lasso
0.1356161629	as efficient as
0.1355995548	$ \ tau
0.1355659368	_ i \ in \
0.1355282182	defined via
0.1355239751	the ambient dimension
0.1355074956	the maximum likelihood
0.1354984947	further study
0.1354381998	this context
0.1354317246	fundamental problem of
0.1354164665	+ \ lambda
0.1353741623	the change point
0.1353643813	existing results on
0.1353318904	the number of variables
0.1352763722	stationary time
0.1351857557	\ mathcal e
0.1351508780	the ground truth
0.1351426134	non asymptotic oracle inequalities for
0.1350755664	high dimensional non
0.1350496029	and social sciences
0.1349800413	with probability 1
0.1349699173	new model
0.1349281653	most basic
0.1349030526	new test statistic
0.1348977724	the slope heuristics
0.1348309394	this regard
0.1347111842	markov bases of
0.1346764206	sub models
0.1346320818	for high dimensional sparse
0.1345978286	provide conditions under
0.1345941166	a logarithmic term
0.1345129883	the information in
0.1345129883	the index of
0.1345032625	metric entropy of
0.1344535602	especially useful
0.1343939407	a view to
0.1343363284	the total variation
0.1343223966	an em algorithm
0.1342984343	consistency of
0.1342602033	\ | _0
0.1342535645	information criteria for
0.1341368704	2 \ beta +
0.1341218010	the above mentioned
0.1340952161	$ p \ ge
0.1340332510	$ \ varphi
0.1340140241	class of stochastic
0.1339945189	separation between
0.1339689546	seen as
0.1339662120	m n
0.1339395480	the noiseless case
0.1339271457	defined in terms of
0.1338907310	distribution belongs to
0.1338743191	an illustration
0.1338499240	\ to \ mathbb
0.1337471321	on real world
0.1337451498	$ \ theta
0.1337389405	existing results for
0.1337384118	under certain assumptions
0.1337115978	to learn
0.1337070308	two group
0.1336361994	$ n \ to \ infty
0.1336087829	the true signal
0.1334949482	a family of estimators
0.1334282284	this paper deals with
0.1333687242	described by
0.1332728158	general result on
0.1332614869	explicit form of
0.1332525176	sets of random
0.1332479420	consistency result for
0.1332170230	nonparametric methods for
0.1331991738	the most popular
0.1331946161	a priori information
0.1331537351	lies in
0.1331400734	t ^ 2
0.1331294380	some cases
0.1331227319	specific class of
0.1331203931	stable l \
0.1330986614	in terms of
0.1330966856	non asymptotic analysis
0.1330580184	breakdown point of
0.1330178422	regularly varying with
0.1330073536	$ \ epsilon
0.1329062199	by proposing
0.1329008231	in high dimensional sparse
0.1328856257	family of probability
0.1328781699	first two moments
0.1328295835	more difficult
0.1327362440	good performance
0.1326535168	based on recent
0.1326315277	results presented in
0.1326242526	$ s_0
0.1325129883	the volatility of
0.1325129883	the independence of
0.1324982536	less than 1
0.1324720803	for high dimensional linear regression
0.1324072200	$ \ nu
0.1322954859	the original
0.1322953550	dominated by
0.1322455473	the response variable
0.1322322287	random walks on
0.1322321864	performance guarantees for
0.1322308511	p 500
0.1321987678	_ k
0.1321618949	under regularity conditions
0.1321483056	associated with
0.1321125998	+ \ sigma
0.1320860631	autoregressive process with
0.1320674369	widely used in
0.1320544268	$ \ mu_
0.1320228837	from statistical physics
0.1320017953	$ \ pi_0
0.1319366625	the high dimensional linear
0.1319030128	more challenging
0.1318554005	thresholds for
0.1318304486	with probability at
0.1317982544	with hidden variables
0.1317755767	the asymptotic distribution
0.1317569824	new approach
0.1317419199	statistical tests for
0.1317205062	a positive constant
0.1317053565	natural extension of
0.1317052916	$ \ rho
0.1317032944	many popular
0.1316478922	inference about
0.1316333835	y x
0.1315989826	\ bullet
0.1315866968	$ \ psi
0.1315828354	of center outward
0.1315378764	to construct
0.1315129883	the surface of
0.1314605035	starting point for
0.1313038216	bounded away
0.1312935083	an additional
0.1312587755	\ mathbf s _n
0.1312500103	the number of observations
0.1312488016	in many cases
0.1312411833	this paper deals
0.1312239826	\ det
0.1312204074	collection of
0.1312147245	a nonparametric regression model
0.1311690642	neural networks with
0.1311305430	of independent random variables
0.1310743587	| z
0.1310433979	portion of
0.1310368389	bayesian estimation of
0.1309721021	$ v_m
0.1309404753	processes driven by
0.1308644034	\ gamma_
0.1308446577	= \ mathbf
0.1308010257	$ n ^ 4
0.1307100937	\ pi_i
0.1306636892	shrinkage priors for
0.1306564939	e optimal
0.1306486261	almost sure limit
0.1306430832	as good as
0.1305254211	subsets of
0.1304487007	while controlling
0.1304439677	comparison between
0.1304277095	distribution in terms
0.1303942345	to noise
0.1303457709	range of
0.1303457709	generalization of
0.1302916636	lack of
0.1302858286	this upper bound
0.1302590263	adaptive version of
0.1302553112	autoregressive models with
0.1301899140	general form of
0.1301664510	the missing mass
0.1299967345	\ end
0.1299072901	algorithm based on
0.1298916370	under strong mixing
0.1298857484	a fast algorithm
0.1298809782	constructed from
0.1298778734	k ^ 2
0.1298269726	contribute to
0.1298094262	important problem in
0.1298077136	approach to estimation
0.1297966136	\ mathbb r ^ n
0.1297902467	event of interest
0.1296928855	to date
0.1296029545	obtained via
0.1295924764	seeks to
0.1295753846	$ \ kappa
0.1295543214	$ \ vartheta
0.1295479159	construction of
0.1295416925	constructed by
0.1295129883	and prediction of
0.1295116471	wants to
0.1295072153	the true
0.1294851093	n \ times n
0.1294051371	practical use
0.1293928568	functional time
0.1293318591	^ c
0.1293298949	correlation between
0.1292747310	$ \ mathsf
0.1292659140	spectral distribution of
0.1292437638	y |
0.1290995216	presented here
0.1290777153	results concerning
0.1290585110	asymptotically normal under
0.1289845189	\ _i
0.1289575859	$ h_0
0.1289112652	_n = \
0.1288644034	\ alpha_
0.1288160387	across multiple
0.1288087060	family of
0.1287483485	the maximum likelihood estimation
0.1286873317	to bypass
0.1286672790	quite different
0.1286541277	estimators under
0.1286383366	iterative algorithm for
0.1286257912	= \ omega
0.1285976089	$ divergence
0.1285951505	without making
0.1285440363	refer to
0.1285233412	$ k 1
0.1285115347	each stage
0.1284617184	x_i ^
0.1283992360	a nonparametric
0.1283823678	model selection with
0.1283648511	consist of
0.1283157035	oracle inequality for
0.1283046202	\ mathbf z
0.1283003930	the same
0.1282630727	parameter estimation of
0.1281576195	in such settings
0.1281145688	an oracle property
0.1280966712	formulated as
0.1280685178	the first stage
0.1279612305	expected value of
0.1278825061	very small
0.1278671976	the sample space
0.1278139614	treated as
0.1278034883	an adaptive procedure
0.1277925594	near minimax
0.1277800754	numerical experiments on
0.1277760334	developed by
0.1277547466	bound on
0.1277536427	an extensive simulation
0.1277507795	this manuscript
0.1276463902	the number of change points
0.1275789017	arises naturally in
0.1275787381	the second step
0.1275291480	these tests
0.1274917748	$ f_0
0.1274555630	$ \ ell_ \ infty
0.1274486417	\ max
0.1273433868	$ \ delta
0.1273059288	number of random
0.1272838683	robust mean
0.1271475848	convergence of
0.1270949766	central limit theorem of
0.1270740469	conditions under
0.1270406702	estimators over
0.1270363476	provide necessary and sufficient
0.1269789142	signal plus
0.1269125222	holds even
0.1269046976	the likelihood function
0.1268297524	$ \ xi
0.1267692000	mean functions
0.1267149388	the adaptive lasso
0.1266314440	classical ones
0.1266025637	_ i = 1 ^
0.1266018763	to obtain
0.1265941014	a note on
0.1265870910	= x_i
0.1265331838	numerical results show
0.1264800487	$ \ theta_1
0.1264144341	based on real
0.1264119719	builds on
0.1264015062	cross validation for
0.1263828319	non independent
0.1263590331	each step
0.1263575952	normalizing constant of
0.1263540244	the excess risk
0.1263211702	\ alpha_0
0.1263052123	not well understood
0.1262984343	set of
0.1262779941	$ a_0
0.1262670954	a distribution free
0.1262489788	definition of
0.1261708079	statistical guarantees for
0.1261538263	to determine
0.1261123006	a limited number
0.1260845571	unified framework for
0.1260073536	$ \ sigma
0.1259851357	also discussed
0.1259428959	or equivalently
0.1258087060	representation of
0.1258037282	$ o_p
0.1257781887	$ t 0
0.1257656493	\ mu_1
0.1257640914	new theoretical results
0.1257632885	important role in
0.1257523473	asymptotic power of
0.1257392461	analysis aims to
0.1257201779	equality between
0.1257152792	controlled by
0.1256810299	spectral gap of
0.1256222226	variant of
0.1256016684	fundamental limits of
0.1255597660	tools from
0.1254691898	\ hat \ theta_n
0.1254639623	an appropriate
0.1254415718	the asymptotic variance
0.1254287124	$ \ ell
0.1253762264	the oracle estimator
0.1253732075	\ mathbb p
0.1253386418	spectral statistics of
0.1253192421	the local geometry
0.1252987918	paper aims at
0.1252951962	a simple test
0.1252611421	formulated in terms of
0.1252040694	try to
0.1252004576	frequentist coverage of
0.1251300507	an asymptotic
0.1251220445	n m
0.1250129883	in dependence of
0.1249822960	characterized in terms of
0.1249573214	$ \ langle
0.1249571292	two ways
0.1249434037	sums of
0.1249379500	corrupted by
0.1248920388	attained by
0.1248863576	the main goal
0.1248335268	propose to use
0.1247651619	also provide
0.1247249959	used to generate
0.1246503420	nonparametric tests for
0.1246314982	sample size goes to infinity
0.1246065618	k n
0.1245589942	p n
0.1245129883	a model to
0.1244857581	bounded from above by
0.1244544758	the identity matrix
0.1244118083	m dependent
0.1243834361	condition on
0.1243724013	the finite sample properties
0.1243721627	consistency of maximum
0.1243685084	| _
0.1241602714	relatively low
0.1241237722	the ordinary least squares estimator
0.1240909467	\ |
0.1240776840	$ erm
0.1240719302	very large
0.1240209324	observation time
0.1240076305	an unknown function
0.1237690704	general conditions on
0.1237195066	a suitable
0.1237101908	$ \ lambda_
0.1236533675	a critical threshold
0.1236411254	a large collection
0.1236119089	financial time
0.1236090520	the minimum description
0.1235719755	statistic based on
0.1235641787	in particular
0.1235206939	dt \
0.1235123361	time step
0.1235018553	non robust
0.1235006980	proved to
0.1234882214	$ q_
0.1234277286	also provided
0.1234054237	an efficient algorithm
0.1233162592	a short
0.1233122416	u &
0.1233088050	$ \ pi_
0.1233053239	performance bounds for
0.1232926862	a random walk
0.1232717551	very accurate
0.1232610516	class of markov
0.1231961375	to accomplish
0.1231585878	1 \ sqrt
0.1231206966	key role in
0.1230953165	analogous to
0.1229868999	not only
0.1229681467	^ 2 +
0.1229641921	by exploiting
0.1228686676	$ \ tilde
0.1228227993	used to
0.1228162867	| \ mu
0.1226576548	coincide with
0.1226333204	regularity conditions on
0.1226101074	k \ epsilon
0.1226026536	asymptotic expansion for
0.1225284644	a wide range of
0.1225154939	$ \ overline
0.1224903819	an em
0.1224858362	\ hat \ beta
0.1224640273	\ beta_n
0.1224640273	\ sigma_i
0.1224415597	of clusters in
0.1224373876	under weak conditions
0.1224225045	\ lambda_0
0.1223652837	linear system
0.1223202711	averaged over
0.1223137610	does not imply
0.1222871507	in ultra high
0.1222650974	the asymptotic null
0.1222358787	real data from
0.1221417849	\ mathbb r _ +
0.1221264958	more conventional
0.1221198291	non asymptotic error
0.1220533774	possibly non
0.1220351870	the central subspace
0.1219417888	uncertainty about
0.1218143746	these rates
0.1218121645	this class
0.1217748649	simple proof of
0.1217595744	a self contained
0.1217268610	class of loss
0.1216580279	paid to
0.1216446608	$ f_1
0.1215615053	exact distribution
0.1215152735	this question
0.1214916824	correlation structure of
0.1214854454	a natural extension
0.1214794971	r \
0.1214275517	a theoretical analysis
0.1213842934	large numbers of
0.1213485793	+ \ tau
0.1211922278	the kernel density estimator
0.1211921093	a fundamental
0.1211594167	such as
0.1211502782	$ d_
0.1211403903	used to estimate
0.1211210612	techniques based on
0.1211170530	estimation of high
0.1211003834	of sample covariance matrices
0.1209709752	needs to
0.1209289891	strategy based on
0.1208971596	\ br
0.1208837227	contained in
0.1208684846	the finite sample
0.1208581802	zero coefficients
0.1208350305	variety of
0.1208233714	non asymptotic lower
0.1208033801	+ \ gamma
0.1207928660	exact recovery of
0.1207666819	$ h_1
0.1207527781	these algorithms
0.1207073214	$ \ mbox
0.1207060276	method for high
0.1206879988	the diffusion coefficient
0.1206767201	$ \ mu
0.1206722895	these estimators
0.1206617516	c 0
0.1206529112	a precise characterization
0.1205950586	recent interest
0.1205874305	a general setting
0.1205804479	model selection for
0.1205528126	\ sum_ k
0.1205368753	this paper aims
0.1205178451	$ n ^ \ frac
0.1205079170	two data sets
0.1205001392	a new
0.1204042170	priors based on
0.1203651403	intensity function of
0.1203414137	non linear regression
0.1203277886	$ nearest neighbor
0.1202625914	as well
0.1202402644	= 1 ^
0.1202050435	these conditions
0.1201504372	model with gaussian
0.1201197094	from observational data
0.1200156103	the alternative hypothesis
0.1200132566	and real data sets
0.1199749882	second step
0.1199576934	some numerical examples
0.1199572096	tail probabilities of
0.1199540329	effects under
0.1199467604	not clear
0.1199307607	| n
0.1199299821	form expression for
0.1198936361	data set from
0.1198605666	upper bound of
0.1198582607	families of
0.1198560858	central role in
0.1198477278	random vectors with
0.1198448007	the iid case
0.1197833588	covariance matrix of
0.1197147530	by considering
0.1196767201	$ \ lambda
0.1196622002	a wide class
0.1196608908	minimax rates of
0.1196607108	quadratic forms in
0.1196504069	criteria based on
0.1196349264	$ c 0
0.1196327870	conditioned on
0.1196103502	based method for
0.1195722348	a first step
0.1195437220	estimated from
0.1194415023	strong consistency and asymptotic normality of
0.1193434664	^ k
0.1192666819	$ c_
0.1192421917	optimal rates of
0.1192237139	first order asymptotic
0.1191881600	signal detection in
0.1191840924	looking at
0.1191443708	$ r_0
0.1191183717	\ beta_i
0.1190539089	inference on
0.1190537159	new technique
0.1190395753	^ s
0.1190378943	a common approach
0.1189913332	an instrument
0.1189857644	validated by
0.1189749451	coverage probability of
0.1189430453	$ \ rm
0.1189087197	estimation of covariance
0.1189046652	at high frequency
0.1189015827	to recover
0.1188140703	a fundamental problem
0.1188097334	shrinkage estimation of
0.1187173740	a wavelet based
0.1187100098	studied by
0.1187038204	other methods
0.1186653565	confirmed by
0.1186619362	solved by
0.1186535677	want to
0.1186403362	differential equations with
0.1186310267	constructed using
0.1185918079	in reproducing kernel hilbert
0.1185632349	two state
0.1185630942	the latent positions
0.1185321468	a single parameter
0.1185093485	the main focus
0.1184662772	important applications in
0.1184088949	referred to
0.1182941854	the problem of testing
0.1182912244	the unit circle
0.1182557000	robust estimators for
0.1182392234	function f
0.1182207418	p \ rightarrow \ infty
0.1181707919	maximum likelihood estimators in
0.1181419014	with long memory
0.1181392685	results about
0.1181327006	asymptotically normal with
0.1180938596	the quadratic covariation
0.1180538086	compatible with
0.1180142214	a probability distribution
0.1180020793	collected at
0.1179811980	$ t_n
0.1179669459	statistical methods for
0.1179481809	resulting from
0.1179294350	empirical distribution of
0.1178220329	the dimension increases
0.1178176798	the fact
0.1178049725	the space of probability measures
0.1177897384	$ l_q
0.1177735200	$ \ theta_
0.1177490535	exposed to
0.1177163897	nonparametric inference for
0.1177110487	computed using
0.1177044791	restricted to
0.1176891637	these models
0.1176631720	asymptotic expansions of
0.1175980020	take advantage
0.1175833972	maximum likelihood estimator in
0.1175602583	obtained using
0.1175489241	complemented with
0.1175263742	useful tools
0.1175082149	random graphs with
0.1174958027	0,1 ^
0.1174321263	= \ max
0.1174098158	formulas for
0.1173987483	for linear regression models
0.1173868333	relative efficiency of
0.1173853560	class contains
0.1173798763	a general theorem
0.1173614586	the cumulative distribution function
0.1173372422	likelihood estimation for
0.1173323079	a consequence
0.1172897050	k = 2
0.1172799337	these questions
0.1171874299	asymptotic validity of
0.1171590352	$ \ mathbb r ^ 2
0.1171536211	confidence set for
0.1171279330	$ \ alpha = 1
0.1171252516	$ \ sigma_n
0.1170801019	without loss
0.1170464019	$ \ sigma_
0.1170172433	direction method of
0.1170152986	for stochastic block models
0.1169829483	driven method for
0.1169646767	function defined on
0.1169534598	provided by
0.1169078018	$ convergence
0.1168958339	these methods
0.1168892214	the unknown parameter
0.1168706737	the maximum likelihood estimates
0.1168350816	too large
0.1168322881	state of
0.1168021093	the significant
0.1167990390	= \ theta
0.1167819086	a non asymptotic
0.1167677719	best known
0.1167559914	measure based on
0.1167454151	an unknown matrix
0.1167379166	an important problem
0.1166746131	performance compared to
0.1166540266	of ill posedness
0.1166287124	$ \ bf
0.1166203187	4 \ alpha
0.1166088914	to generate
0.1165999269	procedure proposed by
0.1165684334	a wide variety of
0.1165236784	non existence
0.1165209167	square root of
0.1165129082	the optimal filter
0.1164930957	new procedure
0.1164347490	robust estimators of
0.1164249056	to quantify
0.1164127767	n \ to \ infty
0.1163922221	\ mathbb r ^ +
0.1163010978	the problem of learning
0.1162915567	a low dimensional
0.1162542733	$ d \ geq
0.1162230464	a true
0.1161811551	least concave
0.1161666264	degree d
0.1161545219	efficient algorithm for
0.1161294861	$ \ mathit
0.1161082842	also presented
0.1159276935	much smaller than
0.1158411087	autoregressive model with
0.1158333449	bounded by
0.1157570186	a constructive
0.1157328907	a unified theory
0.1157239978	v _
0.1157129508	approximation method for
0.1156566929	a central limit theorem for
0.1156525600	the posterior measure
0.1156379883	in probability to
0.1156074470	to evaluate
0.1155941014	with applications to
0.1155487118	also considered
0.1155479026	$ o
0.1155462278	data example
0.1155126402	asymptotic normality under
0.1154761096	the origin
0.1154614275	g family
0.1154381054	n t
0.1153833486	$ p_0
0.1153670038	rho ^
0.1153160985	the second stage
0.1152942620	more complex
0.1152892872	through simulations
0.1152874132	= \ sum_ j
0.1152354769	$ \ mathfrak
0.1152007167	formula for
0.1151934219	$ x_i
0.1151799032	sequential detection of
0.1151475764	the identification
0.1151157431	different regimes
0.1150942721	these issues
0.1150775943	to infer
0.1150403444	$ x_0
0.1150351255	gaussian approximation of
0.1150328773	finite mixture of
0.1149681615	value decomposition
0.1149643020	i = 0
0.1149103228	an estimator
0.1149015490	number of support
0.1149011545	to compare
0.1148892214	a stochastic process
0.1148812744	algorithms based on
0.1148714563	to reduce
0.1148637950	$ \ gamma
0.1148463772	handled by
0.1148227993	a novel
0.1148053751	the number of samples
0.1147874270	refer to as
0.1147689925	the nonparametric maximum likelihood
0.1146780265	$ f
0.1146728534	considered as
0.1146711597	models with
0.1146379883	the upper and
0.1146379883	of outliers in
0.1146152804	tail probability of
0.1145752910	simulations show
0.1144962147	most recent
0.1144767776	the main
0.1144342158	least squares approach
0.1143786282	through examples
0.1143699543	e |
0.1143353282	inference under
0.1143112616	not too
0.1143088362	a semi parametric
0.1142440025	an extensive
0.1142244020	also called
0.1142028160	any order
0.1141822811	parameters of interest
0.1141552909	nonparametric approach to
0.1141264717	$ \ mathcal g
0.1140350095	both cases
0.1139916481	in many applications
0.1139524581	$ d = 2
0.1139257887	by adding
0.1139253871	\ delta 0
0.1139099571	the multi armed
0.1138799583	against outliers
0.1138198550	d \ geq 2
0.1137915197	demonstrated via
0.1137575742	j \ leq
0.1137350700	\ tau_
0.1137124520	risk over
0.1136916514	random matrices with
0.1136905346	two samples
0.1136878585	a small subset
0.1136778043	the proof relies
0.1136705030	theta |
0.1136545034	$ \ alpha \ in
0.1136440041	em algorithm for
0.1136220492	through numerical
0.1136030400	markov chain with
0.1135986560	suited for
0.1135471453	sqrt n
0.1135463643	a linear model
0.1135458873	the spiked covariance model
0.1135418822	| \ leq
0.1135127923	complexity bounds for
0.1134898883	these procedures
0.1134683233	$ f_
0.1134680434	of gaussian random fields
0.1134639993	likelihood estimation of
0.1134427310	lasso +
0.1134253006	two populations
0.1134186408	does not need
0.1133831379	allowing for
0.1133786339	$ k_
0.1133609950	oracle inequalities with
0.1132976209	\ theta ^ 0
0.1132853356	more informative
0.1132824911	the true probability
0.1132793715	derive bounds for
0.1132464489	established under
0.1132334726	$ m_0
0.1132301155	full range
0.1132277832	two steps
0.1132220032	the last decade
0.1131556412	sample properties of
0.1131466703	raised by
0.1130767507	some interesting
0.1130755425	consistency results for
0.1130532947	functionals of
0.1129912387	proposed by
0.1129735419	a real life
0.1129564286	a general class
0.1129519644	these quantities
0.1129401713	these theoretical results
0.1129359955	one or more
0.1129093572	some simulations
0.1128607841	model selection via
0.1128379882	a large class of
0.1128353882	emerged as
0.1128321976	\ bf x
0.1128300829	the drift parameter
0.1128211177	inference procedures for
0.1128154998	general assumptions on
0.1128002482	small fraction of
0.1127785938	more recently
0.1127771506	the global optimum
0.1127771288	the phase transition
0.1127764896	also investigate
0.1127330366	an interval
0.1126757136	the fusion center
0.1126102689	a decision theoretic
0.1126010123	derive bounds on
0.1125979571	one group
0.1125808209	introduction to
0.1125629809	singular values of
0.1125118884	converges in probability to
0.1125067209	covariance function of
0.1124852131	an importance sampling
0.1124514480	3 2
0.1124193224	an optimal
0.1123813728	difference in
0.1123736472	estimation of density
0.1123687415	markov chains with
0.1123551865	first moments
0.1123296471	a few
0.1123227165	needed to
0.1122891376	$ \
0.1122658625	of order 1
0.1122631184	appeared in
0.1122526573	the latter
0.1122438872	same asymptotic distribution
0.1121580080	very general
0.1121386336	a central role
0.1121285658	x_i +
0.1121023170	a range
0.1120834254	under weaker assumptions
0.1120482523	covariance matrix from
0.1120482412	no information
0.1120433399	illustrated using
0.1120215314	dependence on
0.1119898883	some examples
0.1119406895	to ensure
0.1119221951	mixtures of
0.1119168722	with missing values
0.1118968955	m = n
0.1118874522	long memory in
0.1118498875	work aims
0.1118334203	asymptotic efficiency of
0.1117910068	the selected estimator
0.1117562808	a linear transformation
0.1117402095	adapt to
0.1117212264	\ tilde \ omega
0.1117177090	$ p
0.1117177090	$ k
0.1117080625	probability 1
0.1116826051	growing interest
0.1116542577	some sense
0.1116256969	the convex hull
0.1116119060	with infinite variance
0.1116035828	also develop
0.1115988656	by employing
0.1115744288	inequalities for
0.1115430448	$ 1
0.1115080778	diffusion process with
0.1114998710	two cases
0.1114610418	kinds of
0.1114233463	structural changes in
0.1114160620	a single sample
0.1113993353	a general result
0.1113433751	unknown number of
0.1113384703	required to
0.1113256755	the main results
0.1113146580	tool for
0.1112788644	possibly different
0.1112641354	bias than
0.1112429235	new test
0.1112295827	a small simulation
0.1112244292	| \ theta
0.1111885037	\ bbb
0.1111862006	$ 1 \ delta
0.1111474573	very recently
0.1111316723	a theoretical perspective
0.1111245318	z estimation
0.1110469388	$ \ varrho
0.1110037355	characteristics of
0.1109524581	$ \ epsilon 0
0.1109192793	played by
0.1108181573	a low rank
0.1107764896	also derived
0.1107583477	two random vectors
0.1107428359	then apply
0.1107310273	adapts to
0.1107177090	$ n
0.1106747948	a challenging problem
0.1106528925	a cross validation
0.1106245710	parametric family of
0.1106212453	based approach to
0.1105737770	regularized least
0.1105671507	relied on
0.1105644094	more stable
0.1105580187	ill posedness of
0.1105002972	a non trivial
0.1104664037	p \ infty
0.1103810688	also illustrate
0.1103702295	imposed by
0.1103609821	also studied
0.1103609821	two important
0.1103267292	choice of
0.1103159115	start by
0.1103123108	fit into
0.1102455343	provide examples of
0.1102131609	very few
0.1102027580	these findings
0.1101810654	all nodes
0.1101487991	parametric families of
0.1101473146	a non parametric
0.1101042822	also present
0.1100881353	very mild
0.1100424115	^ \ nu
0.1100365824	the usual
0.1100253405	invariant under
0.1100181824	\ cal m
0.1099887473	$ x_
0.1099527957	the theoretical results
0.1099000281	no assumptions
0.1098866006	for self normalized
0.1098856432	a natural
0.1098609821	also extend
0.1098036694	two main
0.1097962798	theoretical study of
0.1097602815	to identify
0.1097579142	by projecting
0.1097246885	_n =
0.1097199127	each point
0.1096750518	convergence results for
0.1096662662	\ sqrt \ frac
0.1096496055	$ component
0.1096479123	fields such as
0.1096142375	by providing
0.1095699285	systems with
0.1095598334	theoretical side
0.1095439438	x \ theta
0.1095079489	of nodes
0.1094738675	result regarding
0.1094501706	an empirical
0.1094373610	^ n \ times p
0.1094115778	denote by
0.1093694195	exact distribution of
0.1093564752	powerful tool to
0.1093262211	lambda 0
0.1093125025	best fit
0.1093105933	n \ rightarrow 0
0.1092868317	non asymptotic results
0.1092600342	not always
0.1092296485	copies of
0.1092134382	matching upper and
0.1092011684	illustrated on
0.1091689316	a selective
0.1090979400	applications such as
0.1090960117	statistics based on
0.1090789597	a weighted average
0.1089878498	uniform distribution on
0.1089805773	crucial role in
0.1089712632	some specific
0.1089602041	+ q
0.1089176509	type inequality for
0.1089160828	also demonstrate
0.1088977904	+ b
0.1088906412	r estimators
0.1088736788	means under
0.1088536585	from noisy data
0.1088149653	goodness of fit testing for
0.1087912673	\ mathfrak c
0.1087605781	minimax optimal up to
0.1087512137	led to
0.1087491470	algorithms for
0.1087304226	detect changes
0.1087265509	the covariate space
0.1086912492	three cases
0.1086774824	to analyze
0.1086741515	particularly interested
0.1086736210	not directly
0.1086395330	$ l ^ 1
0.1086325853	in science and
0.1085887997	$ 0
0.1085495388	generalize well
0.1085466281	limiting distributions for
0.1085434165	good practical
0.1085107505	fixed time
0.1084860332	the finite sample behavior
0.1084761282	classification under
0.1084479414	perturbed by
0.1084086919	demonstrated by
0.1083976211	^ 2 5
0.1083735142	$ family
0.1083732616	= \
0.1083523061	also established
0.1083031263	by showing
0.1082408662	$ \ varepsilon 0
0.1082065607	measured in terms of
0.1081978750	cross validation in
0.1081889769	an individual
0.1081531916	zero one
0.1081492604	a rich class
0.1081351693	$ \ mathbb r ^ d
0.1081119326	two approaches
0.1080766947	most important
0.1080282431	different groups
0.1080272879	$ m_n
0.1079946647	solution to
0.1079390019	$ m_
0.1079159173	also apply
0.1079065808	guided by
0.1078289699	order k
0.1077791111	a multivariate distribution
0.1077765929	delta 0
0.1077746332	excess risk of
0.1077176756	a chi square
0.1076939011	a power law
0.1076792935	each observation
0.1076780167	establish consistency of
0.1076769723	\ theta \ in \ theta
0.1076768245	values of
0.1076594167	an extension of
0.1076527213	shrinkage estimators of
0.1076035874	a broad class
0.1075938789	to extract
0.1075489540	many cases
0.1075249264	one component
0.1075155559	the post change
0.1075133591	the sparsity pattern
0.1075061993	not identifiable
0.1075059292	$ p_1
0.1074887240	very simple
0.1074812789	various fields
0.1074753480	q = 1
0.1074166672	an adaptive
0.1073760446	estimated using
0.1073448871	very weak
0.1073069851	^ \ omega
0.1073026870	gaps in
0.1072585594	the left and
0.1072585594	$ independent and
0.1072556468	assumptions made
0.1072549496	phase transition in
0.1072436206	dimension d
0.1072276829	a data set
0.1072265966	integrated mean
0.1072199626	less sensitive to
0.1072170757	+ d
0.1072083263	+ \ xi
0.1072070418	tests for
0.1072049843	by adapting
0.1071980837	_i \
0.1071780112	classical problem of
0.1071768764	each case
0.1071741107	curse of
0.1071659801	a characterization
0.1071588787	1 4
0.1070928669	efficient estimators of
0.1070691102	these approaches
0.1070558594	$ s_n
0.1070547625	this setting
0.1070304725	useful tool
0.1070112870	the number of nodes
0.1069998504	the new test
0.1069991085	f _
0.1069950233	two or more
0.1069880943	does not depend
0.1069671402	exact recovery in
0.1069456876	via simulations
0.1069130713	more efficient
0.1069084118	some well known
0.1068862742	with missing data
0.1068754770	$ \ sqrt
0.1068730606	the problem of constructing
0.1068642650	to address
0.1068560767	class of test
0.1068330456	\ sigma_1
0.1068171834	\ log k
0.1068011239	\ mapsto \ mathbb
0.1067438941	to handle
0.1067238809	also prove
0.1067201615	method for
0.1067077954	ideas from
0.1067063894	computed by
0.1067030476	also derive
0.1066994293	for linear spectral statistics
0.1066843376	the number of parameters
0.1066740868	the supremum norm
0.1066654832	computed from
0.1066626366	obtained through
0.1066602342	pairs of
0.1065744877	the estimation error
0.1065134353	suggested by
0.1065125605	efficient estimators for
0.1064445079	well posedness of
0.1064366499	$ y
0.1064261110	$ i = 1
0.1064167105	the objective function
0.1063898421	approach allows
0.1063850319	up to logarithmic
0.1063213179	understanding of
0.1062983211	the geometric median
0.1062913984	a nearly optimal
0.1062436206	density f
0.1062322261	markov chain on
0.1062073214	$ \ zeta
0.1062037732	special case of
0.1061670950	results obtained by
0.1061085278	very general conditions
0.1060843401	sample of size n
0.1060822247	an intuitive
0.1060472580	$ p n \ rightarrow
0.1060289867	these cases
0.1060090848	constraints on
0.1060035602	rates of convergence for
0.1060018546	parametric inference for
0.1059888739	a max stable
0.1059062453	the hessian
0.1058980363	in sup norm
0.1058956415	weak law of
0.1058878481	a finite
0.1058539132	marginal distributions of
0.1058458063	only slightly
0.1058276309	\ bbb r
0.1057751759	the number of covariates
0.1057679205	ratio between
0.1057412471	further results
0.1057410834	data generated by
0.1057310533	$ n_1
0.1057302406	an essential
0.1057295126	_ i \ in
0.1056714380	| \ cdot
0.1056608993	different types of
0.1056501341	this property
0.1055744877	the regression coefficients
0.1055582183	uniform convergence of
0.1055383872	sensitive to
0.1055234694	the second order
0.1055228129	asymptotic variance of
0.1054911404	new algorithm
0.1054798406	given data set
0.1054769536	the test statistics
0.1054693152	often require
0.1054660033	the linear regression model
0.1054617726	under appropriate conditions
0.1054082684	derive new
0.1054027158	more than
0.1054012336	consistent estimator for
0.1053736472	estimation of regression
0.1053706646	appropriate conditions
0.1053479376	mean residual
0.1052781368	drift coefficient of
0.1052760712	restrictions on
0.1051687663	the literature
0.1051343810	^ r
0.1051167779	different scales
0.1050907645	time complexity
0.1050798624	a geometrical
0.1050771431	two alternative
0.1050751706	this framework
0.1050554627	diffusion processes with
0.1050545198	poisson process with
0.1049884021	dimension reduction for
0.1049246298	with log concave
0.1048802336	$ \ lambda_n
0.1048732055	appears to
0.1048721314	the true underlying
0.1048555961	parametric estimation for
0.1048317339	by deriving
0.1048171662	the weak topology
0.1048140664	suprema of
0.1048128615	an optimization problem
0.1048123195	deduced from
0.1047928689	by utilizing
0.1047856771	certain sense
0.1047769689	the unit ball
0.1047625928	used to obtain
0.1047006430	selection via
0.1046667448	different methods
0.1046609157	holds for
0.1046498770	a so called
0.1046432866	an intriguing
0.1045773758	imposed on
0.1045705131	computational time
0.1045577911	derived by
0.1045543322	q 1
0.1045480793	noisy measurements of
0.1045197325	a heavy tailed
0.1045040126	a convex program
0.1044838621	causal effects in
0.1044582239	some mild
0.1044529377	also shown
0.1044458646	representations of
0.1044231916	certain conditions
0.1043707676	\ geq 2
0.1043693502	a complete
0.1043622817	derived using
0.1043094717	converging to
0.1042948118	treatment effects in
0.1042941540	e ^
0.1042727738	logistic regression with
0.1042700866	distribution of
0.1041601480	full likelihood
0.1041600540	estimation procedure for
0.1041261422	a trade off between
0.1040944288	also obtained
0.1040894200	the problem of parameter estimation
0.1040567626	a fractional brownian
0.1040405710	\ mathbb c ^
0.1040008373	\ geq 3
0.1039858779	in large dimensions
0.1038859093	sensitivity analysis of
0.1038645632	x _n
0.1038597163	c 0,1
0.1038498894	extensions of
0.1038354224	\ ge 2
0.1038274357	$ \ alpha_n
0.1038223320	along with
0.1037912131	critical values of
0.1037841012	an infinite
0.1037508439	$ x_ 1
0.1037466628	dependence structure of
0.1037438941	to build
0.1037071919	networks with
0.1036654832	performed by
0.1036276936	this work proposes
0.1036042127	eigenvalues of
0.1035578448	the chi square
0.1035445593	by virtue of
0.1035057068	robust estimator of
0.1034932277	an oracle
0.1034927501	in contrast to
0.1034884498	= x
0.1034861636	bayes estimator for
0.1034828426	\ boldsymbol \ beta
0.1034665171	$ n \ times
0.1034615858	insensitive to
0.1034489218	the self similarity
0.1034417763	distributed according to
0.1034102342	nature of
0.1034067434	further demonstrate
0.1033942639	n 2
0.1033825681	estimates based on
0.1033812141	$ w_
0.1033264896	also obtain
0.1032968167	the non linear
0.1032862869	than standard
0.1032760263	observations from
0.1032398220	the true covariance
0.1031801465	different approaches
0.1031273759	best invariant
0.1031180581	does not involve
0.1031073625	r ^ m
0.1030835362	based on kernel
0.1030385841	one parameter family of
0.1030042431	obtained under
0.1029615541	$ t ^ 2
0.1029366499	$ g
0.1029309591	does not rely on
0.1029284100	but also
0.1029258790	$ 1 \ alpha
0.1029192567	1 p
0.1029174615	an unknown probability
0.1029167009	an i.i.d
0.1029107697	the sup norm
0.1028963136	high dimensional time
0.1028802336	$ \ beta_
0.1028468737	particular cases
0.1028467495	the memory parameter
0.1028280324	many applications
0.1028260468	$ stable
0.1028129233	framework for
0.1027965978	kind of
0.1027436070	the exact solution
0.1027293770	r = 1
0.1026631813	then extend
0.1026010109	a rigorous
0.1025724645	an initial
0.1025404437	in most cases
0.1024559033	first develop
0.1023868282	methods for
0.1023124537	discrete observations of
0.1023099362	also establish
0.1022823742	theoretical work
0.1022464773	estimators for
0.1022023554	also known as
0.1021956744	first establish
0.1021626410	$ \ xi_
0.1021390441	\ log ^ 2
0.1021264717	$ p \ gg n
0.1021232475	covered by
0.1020945730	results lead to
0.1020416637	more tractable
0.1020363676	signal of interest
0.1019918649	the purpose
0.1019827968	bases for
0.1019781924	best approximation
0.1019703239	the introduction
0.1019050196	procedures under
0.1019017625	$ t_
0.1018932471	$ q
0.1018866886	variable of interest
0.1018808229	an edge
0.1018653846	a finite number
0.1018496433	by proving
0.1018009716	two stage least
0.1017898712	\ log \ log n
0.1017803938	these test statistics
0.1017585594	of components in
0.1017514680	theorems for
0.1015915353	$ p_n
0.1015684292	$ a_n
0.1015457573	stationary distribution of
0.1015455523	$ wasserstein
0.1015140948	\ sqrt n \ log
0.1015041188	much better
0.1014924031	model based on
0.1014909191	$ v_
0.1014865427	model with
0.1014855404	response given
0.1014846235	this estimator
0.1014844483	all cases
0.1014827409	faced with
0.1014517820	^ \ rm
0.1014468258	mean response
0.1014023783	1 + 1
0.1014003999	the null
0.1013980863	to illustrate
0.1013612339	exit time
0.1013484789	built from
0.1013354833	true value
0.1013201810	several interesting
0.1012938263	modelled by
0.1012918111	more important
0.1012358692	by studying
0.1011688185	p 0
0.1011467423	two real data
0.1011244380	encoded by
0.1011096913	m ^ \ star
0.1010867861	a real world
0.1010624461	known procedures
0.1010457524	nonparametric method for
0.1010438103	the unknown density
0.1010325176	$ \ rho_
0.1010304281	any dimension
0.1010267566	advantage of
0.1010047312	growing interest in
0.1009691504	values at
0.1009055881	and v statistics
0.1008901604	general classes of
0.1008737752	asymptotics for
0.1008514590	quality of
0.1008498894	interpretation of
0.1008255816	the number of vertices
0.1008229680	the probability simplex
0.1008207570	the convergence rate
0.1007712619	these assumptions
0.1007628592	to calculate
0.1007524894	this fact
0.1007515648	two types of
0.1007422140	very useful
0.1007403617	causal effect of
0.1007249647	estimation over
0.1007111857	of p values
0.1007013983	bias due to
0.1006932095	= \ sum_ i =
0.1006841373	these problems
0.1006763231	+ \ beta
0.1006605479	large amount of
0.1006449832	statistical inference on
0.1005664160	comparison of
0.1005619115	take advantage of
0.1005353035	well known results
0.1005276970	emphasis on
0.1004911844	well suited to
0.1004248686	$ y_1
0.1004084613	\ mathbb r ^ k
0.1003974310	the most important
0.1003965653	estimator proposed in
0.1003965209	null hypothesis of
0.1003851624	for locally stationary
0.1003801072	\ subset \ mathbb
0.1003745134	an inhomogeneous
0.1003407189	a connection
0.1003195571	empirical application to
0.1003074830	and slab priors
0.1002894560	the beta process
0.1002765673	existence and uniqueness of
0.1002667011	known covariance
0.1002429960	paper aims to
0.1001743643	a gaussian prior
0.1001574258	an abstract
0.1001282207	$ d = 1
0.1000477191	by integrating
0.1000162843	generating function of
0.1000151603	unbiased estimators of
0.1000051976	an important class
0.1000037657	error rates of
0.1000036858	guarantees for
0.0999927501	a variety of
0.0999792127	limits of
0.0999786951	10 ^
0.0999619291	the unknown regression
0.0998685475	the behavior
0.0998570086	less sensitive
0.0998512411	main purpose of
0.0998471086	a chi squared
0.0998217746	bootstrap procedure for
0.0997952097	by discussing
0.0997849393	in spite of
0.0997704676	the slope function
0.0997587636	completely different
0.0997445531	$ \ lim_
0.0997297642	the nuclear norm
0.0997224145	delta =
0.0997123011	two part
0.0997041637	further improve
0.0996874937	exploited to
0.0996791700	recently introduced in
0.0996297932	large numbers for
0.0995962209	do not exist
0.0994728337	investigated through
0.0994276488	studied under
0.0994075632	zero entries
0.0994060280	the log likelihood
0.0993871665	$ p_x
0.0993773717	a finite dimensional
0.0993746449	$ \ mathrm
0.0993403499	selection consistency for
0.0993186521	to implement
0.0992789918	value index
0.0992511305	more likely
0.0992210780	the problem of identifying
0.0991864664	assumption on
0.0991780265	$ m
0.0991570052	a computationally efficient
0.0991468928	stationary processes with
0.0991349770	this assumption
0.0990974908	response y
0.0990856684	two point
0.0990410621	i = 1 ^
0.0990362514	strategy for
0.0990060372	the degree corrected
0.0989968516	but only
0.0989835712	$ \ lambda_i
0.0989738411	oracle inequalities in
0.0989652114	also introduce
0.0989499847	inference for
0.0989465515	then derive
0.0989331330	sample test for
0.0989302264	an additive
0.0989287107	the context of
0.0989113518	many statistical
0.0989026885	heaviness of
0.0988998354	amount of
0.0988958793	sets of
0.0988299879	in \ r ^
0.0988072241	recent work on
0.0988026485	various classes
0.0988005791	give sharp
0.0987668678	d = 1
0.0987082039	an online
0.0986798592	theta \ |
0.0986767942	the empirical copula
0.0986492570	separated by
0.0986486281	the nominal level
0.0986429445	act as
0.0985733361	the basis
0.0985715678	the problem of
0.0985612521	$ n \ gg
0.0985583632	the social sciences
0.0985580319	\ sigma _
0.0985404187	$ \ mu_n
0.0985360696	graphical models with
0.0985209047	aspect of
0.0984988003	\ hat \ psi
0.0984924365	requires only
0.0984857465	square error of
0.0984651224	approximation to
0.0983998388	in many fields
0.0983310533	$ b_n
0.0983161727	leave one
0.0983074019	benefit from
0.0983066575	also compare
0.0983035592	develop new
0.0983017324	+ n
0.0982949790	implemented by
0.0982827135	$ means
0.0982601526	new goodness of fit
0.0982544193	this bound
0.0982268708	| f
0.0981810645	$ \ frac
0.0981546513	proof of
0.0981362656	fundamental problem in
0.0981095804	$ y_i
0.0980435886	parameter value
0.0979947188	the non stationary
0.0979912248	nodes with
0.0979820001	investigated by
0.0979818591	\ sqrt k
0.0979460937	these designs
0.0979362486	the same rate
0.0979102319	in small samples
0.0979100547	a statistical model
0.0979083499	overview of
0.0978886618	the noise variance
0.0978778845	$ statistic
0.0978742614	derived here
0.0978637950	$ \ log
0.0978239365	sample performance of
0.0978174945	theorem for
0.0978068767	the number of components
0.0977956713	for small samples
0.0977955794	to replace
0.0977823680	\ mathbf w
0.0977382246	\ alpha 1 2
0.0977358919	density based on
0.0977192190	= t
0.0977177318	a popular approach
0.0977174510	estimation procedures for
0.0977122541	\ sigma_0
0.0977000599	then propose
0.0976918248	other words
0.0976771925	$ recovery
0.0976656667	optimal design for
0.0976560137	results for
0.0976552051	the finite sample performance of
0.0976511799	designed to
0.0976400566	this gap
0.0976264377	in observational studies
0.0975491604	the graphical lasso
0.0975425280	fail to
0.0975382542	at low
0.0975374082	the em
0.0975293756	the slope parameter
0.0974909191	$ p_k
0.0974782359	algorithm for
0.0974632734	many scientific
0.0974439399	the riemannian
0.0974287107	a class of
0.0974281732	_n \
0.0974276165	used in practice
0.0974138544	an event
0.0973798309	computationally more
0.0973798107	finite set of
0.0973746065	a log concave
0.0973603501	x_t ^
0.0973580035	statistical models for
0.0973514229	some applications
0.0973338109	also proved
0.0973241407	estimator of
0.0973169249	most commonly
0.0972906821	p _n
0.0971771173	combination of
0.0971725209	the principal subspace
0.0971652161	the tail index
0.0971558881	for functional data
0.0971383428	bound for
0.0971249303	these inequalities
0.0971037720	achievable by
0.0970973725	\ hat \ rho
0.0970950452	members of
0.0970873031	full posterior
0.0970768564	also propose
0.0970625460	terms of
0.0970194098	this case
0.0970039160	decomposition of
0.0970033015	by numerical simulations
0.0969927501	a new class of
0.0969346247	involves only
0.0969322801	complete characterization of
0.0969078955	$ \ psi_n
0.0969059747	the horseshoe
0.0968971634	covariance estimation for
0.0968675280	building on
0.0968454999	$ r_n
0.0968198463	dimension p
0.0968168095	various types
0.0967891376	$ d
0.0967766636	$ process
0.0967633445	$ test
0.0967155258	differential equation with
0.0967131905	models based on
0.0966706529	inferred from
0.0966299079	with hurst parameter
0.0966265663	by establishing
0.0966246950	\ mathbb l ^
0.0966209944	\ mathcal f
0.0966123715	the quotient
0.0966098126	n \ log n
0.0966092124	sum of
0.0964956771	three main
0.0964930641	$ d \ ge
0.0964850187	to improve
0.0964673974	good statistical
0.0964627564	depend only
0.0964607092	novel methodology
0.0964543209	$ block
0.0964517625	an outcome
0.0964328674	fixed value
0.0964320568	limit theorems in
0.0964035920	a discretely observed
0.0963954315	computational efficiency of
0.0963914941	an integral
0.0963635372	application of
0.0963622093	considered in detail
0.0963595530	estimated via
0.0963247648	survival function of
0.0963213179	forms of
0.0963009415	l ^ \ infty
0.0962922655	the final
0.0962917676	$ f_n
0.0962265703	a previous paper
0.0962113960	a survey
0.0961941394	+ t
0.0961562795	paper provides
0.0961417369	some constant
0.0961410462	while still
0.0961370799	the non gaussian
0.0961355113	same rate
0.0961253713	a finite number of
0.0961249970	new challenges
0.0961154635	in signal processing
0.0960968292	a real data example
0.0960957847	a random process
0.0960794631	\ mathcal x
0.0960778845	$ distance
0.0960591695	the sample variance
0.0960377041	work extends
0.0960226572	new multivariate
0.0959998504	$ n \ geq
0.0959957049	the internet
0.0959674664	an optimal rate
0.0959620946	well known problem
0.0959537076	an elementary
0.0959499847	estimates of
0.0959283111	$ \ sigma ^ 2
0.0959277018	empirical mean
0.0959137807	sample behavior of
0.0959015615	the model class
0.0958867037	$ \ chi
0.0958742167	any additional
0.0958711838	three parameters
0.0958336232	to discuss
0.0958303734	this family
0.0958269169	the entire
0.0958267121	to alleviate
0.0958241443	known about
0.0957533153	$ type
0.0957457307	theory provides
0.0957294984	empirical process of
0.0957077917	results allow
0.0956976482	control over
0.0956969321	$ risk
0.0956839152	n \ in \ mathbb n
0.0956798592	le p \
0.0956789545	an accurate
0.0956685430	+ \ sqrt
0.0956539181	evaluated by
0.0955915306	advent of
0.0955494258	$ moment
0.0955425280	reduces to
0.0955077923	this approach
0.0954852291	the non parametric
0.0954779537	the problem of finding
0.0954361153	d_ \
0.0954266564	a weighted sum
0.0954160381	theoretical results on
0.0953812141	$ q_n
0.0953730612	powerful than
0.0953647499	processes with
0.0953456977	1 +
0.0953344531	further establish
0.0953339492	first step
0.0953242785	minimax rate of
0.0953184937	\ ge 3
0.0953105719	$ \ sf
0.0953002611	a non asymptotic oracle
0.0952880852	1 f
0.0952448876	marginal distribution of
0.0952182807	$ regular
0.0952151851	x_j \
0.0951826691	different dimensions
0.0951367540	k th
0.0951291127	other problems
0.0951160870	by minimizing
0.0951058791	any parametric
0.0951000734	the influence
0.0950981520	an attractive
0.0950827717	further develop
0.0950778281	increasing interest in
0.0950664192	posed by
0.0950547182	number of non zero
0.0950494538	very close
0.0950469683	relate to
0.0950418980	an inverse problem
0.0949898270	other measures
0.0949887522	f ^ *
0.0949877963	new representation
0.0949839996	provide conditions for
0.0949663592	definitions of
0.0949516373	noisy observations of
0.0949505700	not just
0.0949297637	a practical point of view
0.0949220958	investigate whether
0.0948775206	operator norm of
0.0948454354	the past
0.0948399629	the ill posedness
0.0948338768	underlying distribution of
0.0947934878	correction for
0.0947921996	to represent
0.0947810419	the two sample problem
0.0947711867	some special
0.0947672262	the number of factors
0.0947602607	generalized method of
0.0947397068	derivation of
0.0947307567	= \ sigma
0.0947131146	\ | y
0.0947015571	by incorporating
0.0946736774	known in advance
0.0946684045	but rather
0.0946204457	regression problems with
0.0946075394	the heavy tailed
0.0945860400	for estimating
0.0945430630	th order
0.0945209436	an approximate
0.0945133583	the optimal solution
0.0944970025	$ metric
0.0944955847	deviation from
0.0944899027	significantly more
0.0944743318	each group
0.0944691527	to treat
0.0944620249	integral over
0.0944268972	the gaussian white noise
0.0944000429	the non asymptotic
0.0943428090	any alternative
0.0943306583	the goal
0.0943212476	the current status
0.0942917676	$ h_
0.0942839501	test under
0.0942815939	| b
0.0942562985	$ \ int
0.0942477857	and two sided
0.0942125976	optimal rate of convergence for
0.0941995444	defined over
0.0941730141	o \ left
0.0941714014	agreement with
0.0941599210	depends only
0.0941467167	better performance
0.0941435623	\ theta _
0.0941229332	not unique
0.0941142434	a closed form expression for
0.0940633287	ratio tests for
0.0940536114	probability bounds for
0.0940485093	the geometry
0.0940128358	distribution function of
0.0939986388	common use
0.0939959879	corresponding empirical
0.0939897612	| \ sigma
0.0939755838	not observed
0.0939376352	not yet
0.0939206911	quantities such as
0.0938938555	the true regression
0.0938697708	the latter case
0.0938637489	between nodes
0.0938536537	$ x
0.0938344722	i \ leq n
0.0938277608	this model
0.0937960044	concentrated on
0.0937664521	a finite set
0.0937571070	a positive definite
0.0937429341	an auxiliary
0.0937327878	only requires
0.0937233894	\ theta 0
0.0937184995	order 2
0.0937175757	the new method
0.0936832227	evaluation of
0.0936810214	density estimation with
0.0936672595	by replacing
0.0936664756	\ chi
0.0936527596	results on
0.0936178091	p \ rightarrow
0.0936117621	the input space
0.0936109615	$ t \ to \ infty
0.0936090199	| \ hat
0.0936066921	linear processes with
0.0936038471	first introduce
0.0936026402	this phenomenon
0.0936025423	an extra
0.0935950473	mean regression
0.0935921513	knowledge of
0.0935655103	this paper focuses
0.0935147525	\ int_0 ^ 1
0.0934834554	p = 2
0.0934646631	for binary classification
0.0934327433	approximation of
0.0934262704	\ int f
0.0934226963	unbiased estimator for
0.0934204043	derive rates of
0.0934066850	$ minimization
0.0933611291	learned from
0.0933553438	\ to \
0.0933451286	data from
0.0933150311	a pre specified
0.0933013281	a certain sense
0.0933002561	distribution via
0.0932810952	new paradigm
0.0932667676	$ z_i
0.0932666668	adaptive estimator of
0.0932461821	sub class of
0.0932427178	via convex
0.0932425264	novel approach
0.0931966945	$ fdp
0.0931939507	a high frequency
0.0931871464	absolutely continuous with
0.0931764085	estimators of
0.0930732468	often involves
0.0930393244	sample complexity of
0.0930253269	a small number of
0.0930239524	fisher information in
0.0930136023	but not necessarily
0.0929726947	the upper bound
0.0929526495	testing procedures for
0.0929333496	continues to
0.0928953095	the empirical distribution
0.0928896807	various settings
0.0928884798	any specific
0.0928701540	$ y_
0.0928458920	under very mild
0.0928405560	empirical work
0.0928152709	characterizations of
0.0927562141	$ d_1
0.0927551112	\ phi_p
0.0927333496	contributes to
0.0927333496	believed to
0.0927320158	the robustness
0.0927271342	results indicate
0.0927255273	the signal strength
0.0927219080	offered by
0.0927184111	necessary and sufficient condition
0.0926965293	approaches zero
0.0926799968	the state space
0.0926743836	a riemannian
0.0926685701	for constructing
0.0926411973	other tests
0.0926314456	many algorithms
0.0926117589	fails to
0.0926048111	better performance than
0.0926031569	the preliminary
0.0925432241	a data adaptive
0.0925396152	compared with other
0.0925222787	$ 1,1
0.0924940117	most common
0.0924845520	by allowing
0.0924692857	extreme values of
0.0924569098	this method
0.0924306168	the empirical characteristic
0.0924256952	a general theory
0.0924137710	$ \ alpha 1
0.0923983902	a wide class of
0.0923790337	up to constant
0.0923709818	an algorithm
0.0923662433	observed over
0.0923653464	asymptotic bounds on
0.0923566694	the resulting
0.0923347714	these ideas
0.0923206211	product of two
0.0922658906	new methodology
0.0922352087	consistent under
0.0922336658	an observation
0.0922267885	an asymptotic framework
0.0922241996	$ d \ geq 2
0.0921942322	empirical likelihood for
0.0921680324	$ \ sum_ i = 1
0.0921617049	a strictly stationary
0.0921529902	$ y =
0.0921286926	information criterion for
0.0921225366	a gaussian vector
0.0921144071	model selection by
0.0921041771	the proofs rely
0.0921033432	notions of
0.0920726189	model selection in
0.0920509477	$ p_
0.0920481112	lower bound of
0.0919855841	lower than
0.0919779475	given point
0.0919562473	$ \ x_t
0.0919331780	but different
0.0919204920	with unknown variance
0.0919204551	both synthetic
0.0918806988	eigenvectors of
0.0918698391	two families
0.0918562799	an example
0.0918527966	at random
0.0918474406	$ contamination
0.0918463496	the noise distribution
0.0918433012	sensitivity analysis for
0.0918400021	also reveal
0.0918035192	r ^ 3
0.0917918205	considered here
0.0917826902	y =
0.0917744963	differentiability of
0.0917668230	uniformly most
0.0917553008	directly from
0.0917421806	adaptive estimation for
0.0917338763	by combining
0.0917330827	formulation of
0.0917015571	by developing
0.0916956144	a new test
0.0916905001	a novel approach
0.0916779181	a polynomial rate
0.0916768229	used to illustrate
0.0916375108	from indirect
0.0916350656	starts with
0.0916322550	1 n
0.0916072923	three real
0.0915332676	the classical
0.0915292767	also applicable
0.0915273410	behaviour of
0.0915135674	^ \ theta
0.0915056755	a key
0.0914748383	independent but not
0.0914737736	very fast
0.0914643532	many samples
0.0914631844	by constructing
0.0914414061	corresponding to
0.0914288555	reduced to
0.0913978744	up to constants
0.0913944015	relevant to
0.0913650761	by assuming
0.0913355300	the shape
0.0913131460	$ \ int_
0.0913082501	characteristic function of
0.0913072561	$ l ^ p
0.0912772729	1 \ sqrt n
0.0912541347	the computational burden
0.0912518607	a fairly general
0.0912098469	the high dimensional
0.0911997020	$ \ sum_
0.0911868477	becomes large
0.0911801117	results from
0.0911700412	used to define
0.0911602342	discussion of
0.0911462340	correlation among
0.0911458930	\ rightarrow \ mathbb
0.0911289964	under suitable
0.0911005429	by comparing
0.0910940774	a piecewise constant
0.0910871836	likelihood estimator of
0.0910720294	the number of non zero
0.0910431789	\ leq 2
0.0910273410	identification of
0.0910199220	also investigated
0.0909680660	the drift function
0.0909666031	limit distribution of
0.0909650802	the gaussian
0.0909556048	some basic
0.0909512661	the sample complexity
0.0909337763	$ \ boldsymbol \ theta
0.0909307587	with non linear
0.0909263964	the small ball
0.0909240344	conditions for
0.0909124619	main interest
0.0909022204	$ aggregation
0.0909015346	\ v s
0.0908947784	two applications
0.0908754295	light on
0.0908671007	practical interest
0.0908670550	an adversary
0.0908624724	the population covariance
0.0908399624	not consistent
0.0908112030	a detailed analysis
0.0907817932	to allocate
0.0907714304	posterior mean
0.0907083978	inverse problems in
0.0906797870	+ \ alpha
0.0906687257	asymptotically normal and
0.0906591956	known variance
0.0906573727	the restricted isometry
0.0906535143	many interesting
0.0906426576	the existing literature
0.0906353303	this situation
0.0906343676	nonparametric estimation in
0.0906275792	the difficult
0.0906023270	an extreme
0.0906019506	$ i_
0.0905968132	no prior
0.0905896171	a loss function
0.0905865048	$ sparsity
0.0905757305	mean zero
0.0905493096	$ optimization
0.0905353744	a social network
0.0905335660	various applications
0.0905092563	to simulate
0.0905056506	any restriction
0.0904979067	any continuous
0.0904953573	these indices
0.0904593566	_ i =
0.0904587244	the optimal number
0.0904586055	the number of predictors
0.0904417276	conditioning on
0.0903807294	not true
0.0903714925	the bivariate case
0.0903415125	do not depend on
0.0903093024	type estimators for
0.0903063621	under certain regularity
0.0903013226	computational cost of
0.0902481287	new methods
0.0902372634	quantified by
0.0902362025	an unbiased
0.0902197958	the number of points
0.0901729944	employed to
0.0901628460	the data dimension
0.0901395330	$ \ hat \ beta
0.0901145475	$ r_
0.0900791030	a probability measure
0.0900488172	in order to obtain
0.0900483811	by taking
0.0900383983	dimension reduction in
0.0900374587	detect changes in
0.0900297120	to derive
0.0900065815	definite functions on
0.0899935089	two moments
0.0899880367	quantile regression with
0.0899742542	results show
0.0899646579	the expectation maximization
0.0899299666	cast as
0.0899268182	method uses
0.0899210044	concentrate on
0.0899015346	z ^ d
0.0898997493	normality of
0.0898644269	arise in
0.0898575819	d _
0.0898540969	on spheres
0.0898238801	the current paper
0.0898234772	attention to
0.0898127017	$ z
0.0898089526	these estimates
0.0898029425	\ v
0.0897965978	role in
0.0897633129	methodology based on
0.0897288452	other things
0.0897242011	the sum of squares
0.0897145475	$ d_n
0.0896905768	a sufficient condition
0.0896704063	derived under
0.0896385382	n \ log
0.0896382343	each time point
0.0896238974	0 \ leq
0.0896058137	the number of groups
0.0896039132	absence of
0.0895890104	interaction between
0.0895884788	then applied
0.0895837781	relative error of
0.0895750278	then derived
0.0895512233	$ loss
0.0895484290	dedicated to
0.0895094675	+ \
0.0895021958	parts of
0.0894865707	these measures
0.0894746449	$ \ left
0.0894524062	superior to
0.0894313554	estimation error of
0.0893981912	type estimator for
0.0893947784	some conditions
0.0893396138	a nonparametric test
0.0893366510	recovered from
0.0893289713	the number
0.0893236633	various examples
0.0893234375	the long term
0.0892968395	the out of sample
0.0892967337	the test
0.0892963902	new type
0.0892867430	| \ mathbf
0.0892862514	hypothesis tests for
0.0892776813	the empirical measure
0.0892613416	a non negative
0.0892460239	maximum value
0.0892397178	connected to
0.0892217850	arises in many
0.0892200115	the parametric component
0.0891950114	$ 2
0.0891840855	generally not
0.0891683421	valid under
0.0891546381	theta = \
0.0891515010	some additional
0.0891312093	by analyzing
0.0891041604	appearing in
0.0890719292	give explicit
0.0890635632	used to determine
0.0890530902	the ising
0.0890357691	distribution theory for
0.0890356316	method allows
0.0890209551	a change
0.0890143514	a data dependent
0.0890119288	$ s_
0.0890071761	account for
0.0889880802	used to approximate
0.0889511508	a finite time
0.0889469759	very good
0.0889336823	hypothesis testing on
0.0889219683	roots of
0.0889122722	the standard approach
0.0889010167	conclude by
0.0888749063	a recently developed
0.0888736135	the asymptotic
0.0888734263	used to compare
0.0888667676	$ h_n
0.0888533616	an appropriate choice
0.0888488431	an open
0.0888446827	new algorithms
0.0888408076	the former
0.0888401989	\ arg
0.0887732219	superior performance of
0.0887502421	a polynomial time algorithm
0.0887145475	$ m_1
0.0886995866	an existing
0.0886933677	do not depend
0.0886802134	statistical model for
0.0886769908	prediction error of
0.0886740156	the model
0.0886707700	the well known
0.0886679077	main goal of
0.0886658760	statistical inference in
0.0886612902	several important
0.0886507911	further extend
0.0886449007	\ in \ r ^
0.0886126692	signal from
0.0886073074	some unknown
0.0885852585	$ s
0.0885729393	log ^ 2
0.0885671695	used to quantify
0.0885620525	difference between two
0.0885496128	a large
0.0885402467	a unique
0.0885302558	required for
0.0885275051	alpha 1
0.0885104972	as opposed
0.0884492533	areas such as
0.0884210681	inequality for
0.0884195747	many modern
0.0884180298	p \
0.0884171054	for sample quantiles
0.0884124282	conclude with
0.0883916118	very sensitive
0.0883753304	then establish
0.0883745053	consistent estimation in
0.0883577172	to interpret
0.0883393855	a regularly varying
0.0883248857	two dimensions
0.0883117329	\ frac \ log
0.0882754486	_ 1 \ leq i
0.0882727110	the k th
0.0882663746	non parametric estimation of
0.0882558483	2 \ sqrt
0.0882553619	also valid
0.0882524837	also study
0.0882425240	best possible
0.0882370745	the log density
0.0882351888	a parametric family
0.0881914592	depend only on
0.0881913081	bayesian inference with
0.0881757525	alpha 0
0.0881735147	a random matrix
0.0881689567	kernel methods for
0.0881574788	of order 2
0.0881398544	used to solve
0.0881391993	= \ left
0.0881255050	statistical performance of
0.0881202193	limitations of
0.0881200941	given threshold
0.0881109615	$ x \ in \ mathbb
0.0880936898	the main purpose
0.0880893908	the time dependent
0.0880809780	the regularization parameter
0.0880488057	order than
0.0880482980	$ x =
0.0880246928	convergence rate for
0.0880157498	the asymptotic optimality
0.0880011118	estimator for
0.0879732971	more computationally
0.0879422547	local time
0.0879231067	\ sim \ mathcal
0.0879127071	\ pmb \ theta
0.0878932614	covariance operator of
0.0878919365	a large scale
0.0878738291	the large sample properties
0.0878674902	by simulation studies
0.0878503715	posterior distribution of
0.0878488726	~ \
0.0878211691	asymptotic normality for
0.0878111085	no assumption
0.0877344777	\ theta ^ *
0.0877102745	on cran
0.0876896567	this chapter
0.0876891930	a new criterion
0.0876781615	across different
0.0876568502	by giving
0.0876549497	structure of
0.0876546476	all existing
0.0876462837	to produce
0.0876441329	$ u
0.0876419338	and computationally efficient
0.0876234204	the invariant density
0.0876019955	framework allows
0.0875820526	distribution based on
0.0875780621	$ concave
0.0875717053	other properties
0.0875699591	\ mathbb r ^ p
0.0875671677	under minimal
0.0875640439	used to compute
0.0875627656	inference after
0.0875425274	without additional
0.0875371721	test for
0.0875232361	obtained for
0.0874956771	many times
0.0874935448	$ k \ geq
0.0874744762	problem arises in
0.0874612060	with sub gaussian
0.0874555559	a principal
0.0874451842	more common
0.0874228152	$ x \ mapsto
0.0874073957	then construct
0.0873883266	for community detection
0.0873879188	new light on
0.0873609625	true value of
0.0873351158	$ consistent
0.0873329441	the low degree
0.0873118960	practical applications of
0.0872861342	new procedures
0.0872721418	a separable hilbert
0.0872701218	the corresponding
0.0872604142	the problem of choosing
0.0872430673	improved by
0.0872189426	= x +
0.0872164877	prone to
0.0872155437	other approaches
0.0872101442	$ lipschitz
0.0871997777	framework provides
0.0871992115	efficient way
0.0871984029	through extensive
0.0871462917	large variety of
0.0871449300	unbiased estimate of
0.0871377012	the sub gaussian
0.0871353959	a by product of
0.0871119508	moments of
0.0870825636	through simulation
0.0870544625	algorithm uses
0.0870359572	a finite mixture
0.0870074411	the odds ratio
0.0869929626	necessary condition
0.0869890950	an original
0.0869844722	= \ mathbb e
0.0869823975	realizations of
0.0869781718	rates than
0.0869400980	general theory of
0.0869303973	rejoinder to
0.0869166908	assessment of
0.0869023699	an intermediate
0.0868975731	\ alpha = 1
0.0868589939	this connection
0.0868520512	no additional
0.0868359642	$ bootstrap
0.0868304732	error bounds on
0.0868251432	ratios of
0.0868092752	to provide
0.0867993500	the sphere
0.0867955165	these classes
0.0867931189	to assign
0.0867463617	by letting
0.0867424032	more easily
0.0867377631	the unconditional
0.0867296763	other settings
0.0866869958	the minimax optimal rate of convergence
0.0866799651	two specific
0.0866444899	multivariate time
0.0866253052	asymptotic properties for
0.0865977909	includes many
0.0865896095	a finite state
0.0865824177	two datasets
0.0865728808	an agent
0.0865579364	the failure
0.0865451833	testing for
0.0865438593	little work
0.0865264825	new insight
0.0865128346	the aim of
0.0864969616	for example
0.0864860451	the same order as
0.0864762230	of interest
0.0864756845	no algorithm
0.0864650229	new criterion
0.0864297800	to minimize
0.0864222803	variable selection for
0.0864084298	the average degree
0.0863642659	the error process
0.0863312216	probability distributions on
0.0863146010	an asymptotic analysis
0.0862613138	studied through
0.0862529081	than previously
0.0862484193	the chi squared
0.0862308406	a large number of
0.0862304810	give sufficient
0.0862204201	the heart of
0.0862050807	two decades
0.0861911452	the effective dimension
0.0861759683	subclass of
0.0861702632	other cases
0.0861534813	the problem of recovering
0.0861485147	the null distribution
0.0861395330	$ n \ rightarrow \ infty
0.0861302150	\ partial
0.0861163255	numerical example
0.0861017200	a common
0.0860758515	different levels
0.0860708047	the discrete case
0.0860638106	int \
0.0860518499	no tuning
0.0860488948	$ h
0.0860394447	perform very
0.0860272709	estimated at
0.0859938440	a recently introduced
0.0859932268	the use of
0.0859892384	established for
0.0859852585	$ t
0.0859778236	a special
0.0859662930	first derive
0.0859529890	the signal to noise
0.0859498780	many areas
0.0859195747	many fields
0.0859159201	to use
0.0859135594	natural way
0.0859131960	result gives
0.0859098896	many important
0.0858923233	$ regularization
0.0858814616	covariance matrices with
0.0858679794	not at random
0.0858618772	than sample size
0.0858573054	other components
0.0858369786	the trade off between
0.0858363416	a non gaussian
0.0858193500	the case
0.0858023073	takes into
0.0857999277	the search
0.0857996247	w ^
0.0857992347	techniques from
0.0857853736	the error term
0.0857260468	$ penalty
0.0857118789	to create
0.0857104500	variants of
0.0856962301	model driven by
0.0856961949	n \ ll
0.0856921738	ability to
0.0856918603	prior distributions for
0.0856887239	information geometry of
0.0856845821	$ \ alpha 0
0.0856770315	new observation
0.0856767124	by solving
0.0856594167	an application to
0.0856322702	random field on
0.0855950255	further assumptions
0.0855816641	a random
0.0855755028	used to assess
0.0855473001	many situations
0.0855357473	a robust test
0.0855311635	$ q = 1
0.0855162703	\ le \ infty
0.0855134899	allowed to grow with
0.0855120653	solely on
0.0854922510	the operator norm
0.0854844825	$ vector
0.0854540560	property of
0.0854383713	= \ alpha
0.0854251710	also analyze
0.0854091881	this characterization
0.0853994047	two random variables
0.0853799386	n n
0.0853569936	the full data
0.0853417114	error rate in
0.0853373747	an image
0.0853348131	$ d 1
0.0853104841	$ o \ left
0.0853030364	several existing
0.0852955190	convergence rates in
0.0852844896	the frequency domain
0.0852729224	of nonzero coefficients
0.0852480042	a discrete distribution
0.0852313502	b |
0.0851785461	to pay
0.0851745003	a constant
0.0851651674	$ \ rightarrow
0.0851504545	d = 2
0.0851384921	products of
0.0851374135	= \ mu
0.0850961751	a statistical perspective
0.0850840466	the noisy case
0.0850658768	$ \ mathcal o
0.0850582286	latter case
0.0850531293	literature on
0.0850500524	two versions
0.0850348177	the large scale
0.0850122865	to fit
0.0850059294	= p
0.0850018685	then compared
0.0849973444	$ w
0.0849970671	$ fraction
0.0849657299	selection consistency of
0.0849579899	rate of
0.0849487843	do so
0.0849433392	studied via
0.0849147129	of detecting
0.0849023261	robust to
0.0848953822	consistent with
0.0848890968	with random design
0.0848730714	these rules
0.0848623616	based approach for
0.0848540560	form of
0.0848206127	hypothesis testing with
0.0848092752	to study
0.0847741530	the sample
0.0847685032	t \ in \ mathbb
0.0847257686	coupled with
0.0847091107	conditional distributions of
0.0847029056	distinct from
0.0846962825	even larger
0.0846751710	also include
0.0846597307	$ 0 \ le
0.0846553398	in survival analysis
0.0846374916	bayesian framework for
0.0846233382	mean integrated
0.0846191471	numerical results on
0.0846117295	k \
0.0845490813	hundreds of
0.0845487651	$ projection
0.0845238331	probability distribution of
0.0845237155	sequence of
0.0845174304	the bias variance
0.0844793019	the singular vectors
0.0844779494	each variable
0.0844652618	both synthetic and real
0.0844164140	good properties
0.0843955063	a neural network
0.0843892976	0 \ le
0.0843503190	\ leq i \ leq n
0.0843321499	the extreme value index
0.0843143285	choice between
0.0843050496	further propose
0.0842675771	much lower
0.0842433390	an abrupt
0.0842380403	three types
0.0842275109	good results
0.0842198911	x ^ *
0.0842177090	the number of
0.0841904281	n \ rightarrow
0.0841870808	under fairly
0.0841862736	second moments
0.0841728927	the main contribution
0.0841648053	a minimum distance
0.0841428381	r ^ k
0.0841313712	foundation for
0.0841126048	a convex function
0.0841025349	to circumvent
0.0840908835	justified by
0.0840854391	$ p 1
0.0840817035	spectral norm of
0.0840803489	with regard to
0.0840459880	give rise
0.0840317738	known result
0.0840169231	most popular
0.0839800543	by carefully
0.0839792220	abrupt changes in
0.0839655026	the integrated volatility
0.0839548111	as quickly as
0.0839530526	standard deviation of
0.0839436925	grow at
0.0839333895	arising in
0.0839173977	\ _n
0.0839140855	q \ leq
0.0839035446	to define
0.0839009414	to constant factors
0.0839006998	bands for
0.0838991138	also explore
0.0838853384	new result
0.0838819919	the goodness of fit
0.0838494242	estimation for
0.0838060346	statistical theory for
0.0837889918	take values
0.0837670807	designed for
0.0837566021	available information
0.0836972973	modes of
0.0836927518	present several
0.0836817932	to tune
0.0836490141	a byproduct
0.0835820229	^ h
0.0835647997	a bivariate
0.0835551565	result about
0.0835341846	maxima of
0.0835121840	such methods
0.0834694137	a structural
0.0834383236	a general class of
0.0834265375	and non convex
0.0834071070	= 0,1
0.0833982134	a mean field
0.0833796959	more general result
0.0833771485	to predict
0.0833613057	placed on
0.0833331600	estimation using
0.0833076194	$ consistency
0.0833022133	$ 1 2
0.0832945432	many existing
0.0832830832	distance between two
0.0832571685	the link function
0.0832302724	information from
0.0832006985	connections with
0.0831884825	the optimal
0.0831674470	several numerical
0.0831378409	the well posedness
0.0831319318	e ^ \
0.0831312141	$ a_
0.0831036359	connection with
0.0831035446	to characterize
0.0830993531	very sparse
0.0830843496	the ultra high
0.0830751411	a robust version
0.0830688425	results related to
0.0830559120	the log concave
0.0830544625	algorithm gives
0.0830471634	regression model in
0.0830429565	$ d \ geq 1
0.0830396801	the main result
0.0830284596	the purpose of
0.0830138460	two key
0.0830015487	in detail
0.0829975064	matrices with
0.0829934125	approximations of
0.0829408197	the unknown
0.0829312070	the prior distribution
0.0829132309	much better than
0.0829005585	via simulation
0.0828930209	the first order
0.0828926244	posterior probability of
0.0828898728	a well known
0.0828874967	$ error
0.0828805970	the lasso
0.0828801295	thousands of
0.0828773507	the precision
0.0828740605	a time varying
0.0828505819	\ in \ mathbb n
0.0828460945	such designs
0.0828371948	the number of hidden
0.0828313185	a potential
0.0828140291	not exist
0.0828049332	+ k
0.0828044629	new family
0.0828029423	to construct confidence
0.0827972045	test does not
0.0827748817	a linear space
0.0827492483	of large numbers
0.0827377419	system parameters
0.0827347842	for kernel based
0.0827230782	posterior distributions of
0.0827171695	time series using
0.0826961949	m \ geq
0.0826957504	of phylogenetic trees
0.0826925518	the upper and lower
0.0826773239	other fields
0.0826666878	\ in \
0.0826442669	regardless of whether
0.0826343553	the low rank
0.0826279025	$ penalization
0.0826223193	approximations for
0.0826220182	and van
0.0826129188	the true number
0.0826100835	$ tensor
0.0826054047	these criteria
0.0825940993	a new central limit theorem
0.0825934818	of least squares
0.0825701741	proven to
0.0825635173	guaranteed to
0.0825330647	parameter family of
0.0825310524	method gives
0.0825215329	$ entropy
0.0825138931	the number of nonzero
0.0824959045	a real data
0.0824802269	away from zero
0.0824756343	a prescribed
0.0824409428	the penalty term
0.0824364126	an attempt
0.0824310273	the author
0.0823981611	estimation error for
0.0823979130	many examples
0.0823948607	regression function in
0.0823624632	behaviors of
0.0823448341	other state of
0.0823336901	in turn
0.0823137499	methods such as
0.0823047179	taken into
0.0822962724	propriety of
0.0822837306	$ \ mathrm poly
0.0822755330	on compact
0.0822754081	only depends
0.0822713563	a max
0.0822574035	in terms of estimation
0.0822401853	weak convergence to
0.0822338285	implications for
0.0822187043	regression coefficients in
0.0822030474	a new technique
0.0822015266	framework based on
0.0821706566	other existing
0.0821705412	suffices to
0.0821273148	two nodes
0.0821246950	\ mathbf r ^
0.0821245467	distributions based on
0.0821187178	other common
0.0821104132	absolute value of
0.0821058249	very important
0.0820817365	for right censored
0.0820665842	first moment
0.0820391807	\ sum_ j =
0.0820215715	change point in
0.0820120292	general approach for
0.0819969026	2 5
0.0819877682	a quadratic functional
0.0819872511	likelihood function of
0.0819859572	a linear combination
0.0819826435	while allowing
0.0819679498	^ th
0.0819571384	not satisfied
0.0819287107	the case of
0.0819101065	generalizations of
0.0819015393	i \ geq 1
0.0818923219	_k \
0.0818898106	the trade off
0.0818866150	$ \ textit
0.0818717162	various methods
0.0818654358	the semi parametric
0.0818516104	any prior
0.0818040721	than previous
0.0817892911	likelihood approach for
0.0817858829	choices of
0.0817723859	test whether
0.0817642976	x \ sim
0.0817612180	$ e ^ \
0.0817588664	of independent interest
0.0817463617	by examining
0.0817185214	both simulated
0.0817172464	distribution functions of
0.0817149647	n ^
0.0816955749	an ideal
0.0816951032	a consistent estimate
0.0816911316	many practical
0.0816877802	a non standard
0.0816648121	recovery from
0.0816539635	linear functional of
0.0816404568	a second order
0.0816146612	an asymptotic theory
0.0816062760	of block maxima
0.0815991485	to bring
0.0815745367	an easy
0.0815673515	limit distributions of
0.0815576172	non asymptotic bounds for
0.0815477615	more accurate than
0.0815448732	test statistic for
0.0815356163	a semiparametric
0.0815320825	a hypothesis testing
0.0815273410	validity of
0.0815209303	the long memory
0.0815024353	very low
0.0814975184	used to derive
0.0814669423	possible applications
0.0814261479	x_i \ in
0.0814178351	$ 2 \ times
0.0814109715	order statistics of
0.0814057327	log likelihood of
0.0813890760	markov models with
0.0813829844	approaches based on
0.0813668570	the sense
0.0813287539	to enable
0.0813216375	the law of large numbers
0.0813040415	y given x
0.0812965319	invariance under
0.0812447329	developed for
0.0812265575	two kinds
0.0812260888	$ r = 1
0.0812214298	union of
0.0812198411	the quality
0.0812143328	to find
0.0812120583	an indirect
0.0811962425	the cover
0.0811823769	an overview
0.0811679942	efficient than
0.0811441148	present here
0.0811434293	different types
0.0811413315	c +
0.0811373749	a large set
0.0811238326	many problems
0.0811164202	the unit root
0.0811001423	for high dimensional time
0.0810771877	this task
0.0810721010	results obtained in
0.0810370341	$ close
0.0810201740	posterior distribution on
0.0810097985	different distributions
0.0810052968	likelihood estimation in
0.0809865406	linked to
0.0809465622	a method based
0.0809351244	the coupling
0.0809258789	need to
0.0809225096	a specific
0.0809217964	$ n \ delta_n
0.0809141206	e f
0.0809113840	of extreme events
0.0809074733	then estimate
0.0808443854	x ^ \ rm
0.0808087025	the joint probability
0.0807804555	algorithms such as
0.0807787234	computational complexity of
0.0807699972	\ max_ 1 \ leq
0.0807429433	limited to
0.0807428096	$ n ^ 3
0.0807237497	other parameters
0.0807071808	statistical theory of
0.0806976473	assumptions than
0.0806961167	a semiparametric model
0.0806959125	degrees of
0.0806859834	x ^ \
0.0806496137	the spectral measure
0.0806372630	the empirical
0.0806116383	$ \ text
0.0806043987	part of
0.0805941103	better results
0.0805905018	the approximation error
0.0805324756	the change points
0.0805258790	\ widetilde o
0.0805217073	not hold
0.0805124075	sampling without
0.0805066792	by adopting
0.0804838911	detection problem in
0.0804835236	for achieving
0.0804834429	the most common
0.0804726301	power than
0.0804678411	known results
0.0804658575	x \ mapsto
0.0804624258	the problem of high dimensional
0.0804607624	tools used
0.0804570311	used for
0.0804535380	$ \ 0,1
0.0804289176	the estimator
0.0804231614	built on
0.0803994249	1 + o
0.0803810657	taking into
0.0803796955	several statistical
0.0803421768	the help of
0.0803330051	prediction based on
0.0803251978	the finite dimensional
0.0803234688	sample from
0.0803133876	under reasonable
0.0802935691	error rates for
0.0802664398	$ \ mathcal m
0.0802513887	a scheme
0.0802365008	the observed process
0.0802208422	a good approximation
0.0802206487	the fundamental limits
0.0802152046	highly non
0.0802145494	this area
0.0801971392	inverse problems with
0.0801724076	n \ to \ gamma
0.0801672837	causal inference in
0.0801569448	the maximal
0.0801491023	dual to
0.0801485676	covariance structure of
0.0801388853	mean independence
0.0801312023	possible values
0.0801296673	| t
0.0801229976	t \ geq
0.0801227447	$ x_k
0.0800880840	and massam
0.0800669308	by maximizing
0.0800661169	analogue of
0.0800651263	large family of
0.0800649616	* n
0.0800269003	particular examples
0.0800229723	case of
0.0800188859	given to illustrate
0.0799711060	some situations
0.0799695726	t distributions
0.0799615541	$ \ hat \ theta
0.0799426591	the target
0.0799426240	a popular method
0.0799176462	to enhance
0.0799125489	a phase
0.0798936172	$ m_2
0.0798810845	the deep
0.0798806988	projections of
0.0798804484	the aforementioned
0.0798729086	$ y_i =
0.0798542250	$ p = 2
0.0798485318	$ d_2
0.0798007455	variations of
0.0797960900	the number of particles
0.0797937788	the optimal linear
0.0797907343	an introduction
0.0797681173	the presence of noise
0.0797650869	the effect
0.0797642824	c \ `
0.0797634003	the problem
0.0797425511	y = x \ beta
0.0797269212	testing procedure for
0.0797248085	propose two new
0.0797217758	by presenting
0.0796953774	on simulated and real data
0.0796858137	general theory for
0.0796654727	the tuning
0.0796611564	required by
0.0796421361	distance from
0.0796213617	as corollaries
0.0796137386	$ optimality
0.0795994148	already known
0.0795772738	the delta method
0.0795226422	then introduce
0.0795150937	= 1 2
0.0795047389	this setup
0.0795042804	statistical test for
0.0795032363	r =
0.0794856586	expansions for
0.0794825141	a broad class of
0.0794792149	the optimal choice
0.0794454076	the mean function
0.0794418725	a large range
0.0794218683	the problem of adaptive
0.0794181811	further shown
0.0794049732	the likelihood ratio
0.0793802837	estimation problem for
0.0793752422	$ n \ ll
0.0793657087	mar \
0.0793593879	expense of
0.0793491424	one point
0.0793417520	this kind
0.0793312509	the key
0.0792623610	singular value decomposition of
0.0792554189	\ mathbf t
0.0792553746	two sources
0.0792552431	density estimation under
0.0792379480	non asymptotic analysis of
0.0792344706	a more general result
0.0792242076	by product
0.0791509699	an approximation
0.0791306705	derive novel
0.0791193036	variable selection with
0.0790904736	also give
0.0790874891	the ising model
0.0790851634	the conditional sampling
0.0790812391	linearly with
0.0790809179	the exponent
0.0790797138	any smooth
0.0790776528	subclasses of
0.0790694582	a non central
0.0790658974	| u
0.0790635173	answer to
0.0790491890	with time dependent
0.0790299784	explicitly given
0.0790158275	at infinity
0.0790139990	minimizer of
0.0790058519	distributed according
0.0789978814	true even
0.0789490595	the problem of parameter
0.0789465995	also developed
0.0789433969	$ 2k
0.0789281985	\ in 0
0.0789062448	to pick
0.0789052294	a non linear
0.0788914588	the data points
0.0788815641	the whole
0.0788543094	this condition
0.0788395574	by evaluating
0.0788264972	such models
0.0788050543	with diverging
0.0787960991	the asymptotic covariance
0.0787892458	optimality of
0.0787611438	consistency and asymptotic normality for
0.0787591751	a systematic
0.0787283114	non stationary time
0.0787219425	x ^
0.0787203768	likelihood estimators for
0.0786844547	inference via
0.0786603471	to exist
0.0786586075	$ \ mathbb h
0.0786576565	only require
0.0786571344	the restricted eigenvalue
0.0786481484	a goodness of fit test
0.0786427093	a family
0.0786339245	faithful to
0.0786187764	to draw
0.0785926461	each hypothesis
0.0785671892	$ k_n
0.0785651643	the plug in estimator
0.0785513048	tools for
0.0785250865	k ^
0.0785182166	intended to
0.0785151528	three types of
0.0785128444	very efficient
0.0784851766	instead of
0.0784848398	but not
0.0784845350	$ \ infty
0.0784827203	method provides
0.0784738069	all possible
0.0784730249	the gaussian white
0.0784566118	sure consistency
0.0784441091	these settings
0.0784439279	n \ ge
0.0784296655	establish consistency and
0.0784242890	occurs at
0.0783910440	also construct
0.0783725461	0 \ alpha
0.0783635136	to dominate
0.0783617062	a goodness of fit
0.0783523498	$ \ ell ^ 2
0.0783467204	\ int_ \ mathbb r
0.0783411626	an objective
0.0783288012	density estimation for
0.0783203613	to unity
0.0783035610	the same time
0.0783020421	function of
0.0783003921	each class
0.0782979944	in large samples
0.0782830963	the maximum
0.0782401205	$ x \ sim
0.0782336052	over time
0.0782279311	evaluations of
0.0782033940	t distribution
0.0782011245	$ \ mathbb s ^
0.0781947159	constant over
0.0781906096	than existing
0.0781894114	$ y_t
0.0781760001	hold even
0.0781589438	further provide
0.0781576696	using simulations
0.0781382890	\ cdot \ log
0.0781135763	$ matrix
0.0781114680	elements of
0.0781095189	gaussian processes with
0.0781059120	the rank based
0.0780908498	testing problem for
0.0780828966	identifiability of
0.0780687242	general framework of
0.0780368907	sequences of
0.0780365841	squares estimators of
0.0780302518	general family of
0.0780301680	time series regression
0.0780010944	$ ball
0.0779671892	$ a_i
0.0779593090	as fast as
0.0779576816	concept of
0.0779555521	almost optimal
0.0779555210	unlikely to
0.0779370082	a general procedure
0.0779287107	the presence of
0.0779157531	random sample from
0.0779138031	a new family
0.0779087442	the p values
0.0779055901	functions of
0.0778892976	n \ delta_n
0.0778707695	the problem of approximating
0.0778703022	$ \ boldsymbol \ beta
0.0778661029	one factor
0.0778642813	different fields
0.0778380840	$ separation
0.0778355440	^ m
0.0778313885	perturbations of
0.0777935742	the suggested
0.0777717262	the familywise error
0.0777618224	the posterior
0.0777234421	condition number of
0.0776964217	provide useful
0.0776750318	a formal
0.0776705187	the original data
0.0776348162	over besov
0.0776347189	very high
0.0776293952	the asymptotic normality
0.0776190251	efficient estimation in
0.0776122487	convergence rate under
0.0776115686	an average
0.0775834131	the mediator
0.0775713908	$ 0 \ leq
0.0775668073	x_0 \ in
0.0775654448	time intervals
0.0775522516	in order to avoid
0.0775509830	an isotropic
0.0775432085	also addressed
0.0775281124	likelihood estimates of
0.0775053895	| \
0.0774923132	optimal rate of
0.0774893855	the particle filter
0.0774717758	this letter
0.0774504760	a central limit
0.0774428941	to capture
0.0774426082	\ hat \ gamma
0.0774347058	\ _ t \ in \
0.0774257312	based estimation of
0.0773945286	both low
0.0773910532	a new perspective
0.0773873268	minimax rate for
0.0773815682	estimation problem in
0.0773703228	aim to
0.0773640838	earlier work on
0.0773347737	certain cases
0.0773344091	relates to
0.0773285508	the standard
0.0773255219	most existing
0.0773000088	in such cases
0.0772851614	combinations of
0.0772794783	$ \ mathcal h
0.0771949248	\ hat \ boldsymbol
0.0771713941	a frequentist
0.0771686852	fast rates of
0.0771454076	the new estimator
0.0771083974	$ l ^ \ infty
0.0770897947	unified approach to
0.0770800248	averages of
0.0770726049	involved in
0.0770495957	other estimators
0.0770424337	random number of
0.0770404993	then develop
0.0770392369	a general approach
0.0770262432	the theoretical findings
0.0770139483	for computing
0.0770090794	a plug in estimator
0.0770010743	an estimation method
0.0769887291	particular case
0.0769811206	the minimum
0.0769679948	by investigating
0.0769634003	the method
0.0769543222	to combine
0.0769487766	to discriminate
0.0769424301	the input data
0.0769396485	superiority of
0.0769352142	an equivalent
0.0769277334	$ b_
0.0768968238	stochastic processes with
0.0768818437	unknown but
0.0768770899	segregation and
0.0768770638	not sufficient
0.0768702240	rates of
0.0768679184	the standard bayesian
0.0768571640	with time varying
0.0768472186	$ divergences
0.0768431580	$ r
0.0768281344	used to build
0.0768258707	for nonlinear models
0.0768176641	minimax rates in
0.0768128339	i \ le
0.0767775123	the time varying
0.0767756994	an analogous
0.0767698341	non asymptotic bounds on
0.0767435491	k \ leq
0.0767433842	the hazard rate
0.0767391940	the infinite dimensional
0.0767325285	and wong
0.0767111564	chosen by
0.0766913552	a simple method
0.0766873728	m \ times n
0.0766817459	a thresholding
0.0766683249	sets based on
0.0766647663	$ \ theta_i
0.0766585685	a very simple
0.0766510546	subfamily of
0.0766404288	comparison with
0.0766367337	to optimize
0.0766314955	two different
0.0766238607	relatively large
0.0766221863	any type
0.0766077038	learning with
0.0766026813	the regression parameter
0.0765988738	\ lambda 0
0.0765957615	by extending
0.0765861404	an explicit formula for
0.0765835153	recipe for
0.0765803489	\ mathcal p
0.0765293153	for non stationary
0.0765285236	a statistical test
0.0765204634	this goal
0.0765125866	given by
0.0765055748	conditions than
0.0764805865	connection to
0.0764668824	m \ leq
0.0764473378	the euclidean distance
0.0764470203	a complexity
0.0764302413	gained from
0.0764125279	distributions of
0.0763817536	the singular
0.0763583560	gaussian process with
0.0763558428	the extreme eigenvalues
0.0763072561	$ \ mathbb r ^ m
0.0762914770	value function
0.0762779854	regression model for
0.0762741164	independent but
0.0762698946	the accuracy
0.0762629198	a variety of applications
0.0762610667	$ n_
0.0762592758	an arm
0.0762583784	a simple algorithm
0.0762583049	used to select
0.0762431725	characterized as
0.0762419770	a sub gaussian
0.0762350933	both approaches
0.0762197406	a particular case
0.0762041499	a hypergeometric
0.0762019857	boundedness of
0.0762002011	s \ log
0.0761982177	by computing
0.0761958416	tens of
0.0761718128	\ alpha 0
0.0761627200	on artificial
0.0761578875	eigenvalues and eigenvectors of
0.0761454530	d \
0.0761413844	\ beta ^ 0
0.0761125583	$ k = 2
0.0761038621	estimation in
0.0760773767	the normal approximation
0.0760700126	the celebrated
0.0760698440	n \ geq
0.0760509795	1 \ leq
0.0760219972	justification for
0.0760188859	a very general
0.0760064094	the signal
0.0759603990	to establish
0.0759318011	criterion based on
0.0759213907	i \ leq
0.0759132152	preferable to
0.0759068726	by obtaining
0.0758911607	first prove
0.0758767957	widely used for
0.0758734368	and identically distributed
0.0758640416	only partially
0.0758639693	adaptive over
0.0758500251	m \ times
0.0758145793	thought to
0.0758061319	show empirically
0.0758034753	$ v
0.0757961021	theoretical framework for
0.0757879206	walks on
0.0757826551	to exploit
0.0757697063	$ \ al
0.0757346959	violation of
0.0757057444	for longitudinal data
0.0757055112	$ u_n
0.0756941327	\ ln n
0.0756914833	a comparison
0.0756689734	a major
0.0756628202	\ tilde o
0.0756608500	statistical point of
0.0756440135	an autoregressive
0.0756427876	a generic
0.0756414027	tail index of
0.0756412702	the \ textit
0.0756338731	for count data
0.0756321021	$ 1 \ epsilon
0.0756256050	a wide
0.0756119229	accurate than
0.0756112805	t \ leq
0.0756042887	= \ sqrt
0.0755979097	\ xi ^
0.0755824027	$ 0 \ alpha
0.0755795016	under independence
0.0755408740	w =
0.0755276882	density function of
0.0755244693	uniqueness of
0.0755228703	t 0
0.0755202751	the asymptotic regime
0.0755145954	mixture of
0.0755109665	some new
0.0755106613	just one
0.0755026393	in arbitrary dimension
0.0755019857	minimizers of
0.0755014812	to increase
0.0754960336	the unknown smoothness
0.0754926144	characterisation of
0.0754743829	representations for
0.0754656729	used to test
0.0754439739	also illustrated
0.0754201197	these equations
0.0754146798	further analysis
0.0753956216	any convex
0.0753955652	a slight
0.0753680673	\ 0
0.0753617114	\ gamma 0
0.0753611723	fitted to
0.0753570721	1 t
0.0753519390	the average number
0.0753471615	by leveraging
0.0753388327	^ 1 \
0.0753205182	error bound of
0.0753115311	first provide
0.0752911683	effect on
0.0752902364	calculation of
0.0752630962	= z
0.0752411471	f \ in
0.0752256097	recent results in
0.0751995769	the mutual information
0.0751873878	ergodicity of
0.0751600791	efficiency of
0.0751596992	$ value
0.0751559643	k \ geq
0.0751179188	a model based
0.0751112805	\ epsilon 0
0.0750958166	performed using
0.0750588565	rules for
0.0750525344	parameters based on
0.0750502268	both theoretically
0.0750223946	$ p 2
0.0750160781	the proportional hazards
0.0750069127	a non convex
0.0749968516	all other
0.0749878589	with respect
0.0749875968	law of large numbers for
0.0749818393	the sample covariance
0.0749811270	a near optimal
0.0749788066	in order to estimate
0.0749495563	estimation methods for
0.0749426591	the joint
0.0749317489	not limited
0.0749214395	laws of
0.0748854706	i_ \
0.0748649065	derived for
0.0748383065	the spectral density
0.0748342824	such problems
0.0748315322	the conditional expectation
0.0748185159	$ \ sum
0.0748154518	series based on
0.0747643484	some important
0.0746959125	proportion of
0.0746719852	both discrete
0.0746716775	the number of false
0.0746691443	the most efficient
0.0746691364	the most natural
0.0746317536	the cost
0.0746223725	such situations
0.0746201400	a sufficient statistic
0.0746152537	such approximations
0.0746120201	likelihood estimators of
0.0746117094	$ l
0.0746029143	some assumptions
0.0745967545	discussion on
0.0745943194	availability of
0.0745915078	from incomplete
0.0745786046	expression for
0.0745668343	equality of
0.0745539315	| y
0.0745482980	$ d =
0.0745262633	\ real
0.0745054409	$ \ mathbb e
0.0745053377	efficient estimator of
0.0745040676	\ in \ theta
0.0744860215	unknown parameters of
0.0744816194	an r package
0.0744734053	the limit of large
0.0744659350	the optimal convergence
0.0744587631	z _
0.0744492541	a linear process
0.0744435580	the reverse
0.0744250318	a convenient
0.0744231614	conditionally on
0.0744144573	the conditional variance
0.0743977914	the mean field
0.0743373427	$ \ hat \ psi
0.0743112616	very well
0.0742842679	p values of
0.0742535594	the step size
0.0742451900	convolution of
0.0742362729	sigma =
0.0742334810	procedure provides
0.0741975692	alternative approach to
0.0741858164	two algorithms
0.0741591849	problem of
0.0741500109	derivatives of
0.0741383954	the optimal rates
0.0741258346	analogues of
0.0741228245	minimax risk for
0.0741226943	the conditional quantile
0.0741160107	also conduct
0.0741108293	s +
0.0740990068	graphs with
0.0740878631	previous work on
0.0740867189	n \ to 0
0.0740424187	likelihood estimator in
0.0740058498	the presence
0.0740050727	the mean integrated squared error
0.0739928612	differences in
0.0739890846	compare different
0.0739877462	above results
0.0739756001	to reconstruct
0.0739699525	gradient descent in
0.0739686186	prior on
0.0739650495	the closed form
0.0739321120	and higher order
0.0739297693	models for
0.0739120800	universality of
0.0738913236	of samples required
0.0738588050	for analyzing
0.0738446680	confidence sets in
0.0738397178	to suggest
0.0738269711	minimax risk in
0.0738232177	an algebraic
0.0738167444	new notion
0.0738042250	$ \ delta 0
0.0737731569	an experimental
0.0737584263	for ergodic diffusion
0.0737519489	experiments with
0.0737473356	the truth
0.0737372980	opposed to
0.0737037216	a target distribution
0.0736918222	to incorporate
0.0736914432	competitive with
0.0736823483	conditional expectation of
0.0736808033	likelihood estimate of
0.0736806676	extension to
0.0736792419	the standard deviation
0.0736778096	a reasonable
0.0736768498	this algorithm
0.0736722472	to get
0.0736620018	the missing data
0.0736280353	this work studies
0.0736157444	the global minimum
0.0735977587	the well studied
0.0735808121	adjusting for
0.0734996344	a probabilistic
0.0734822584	the detection boundary
0.0734801875	implemented in
0.0734800515	an iid
0.0734717758	an elliptic
0.0734703151	the continuous case
0.0734646259	using moment
0.0734593067	a new data
0.0734583049	used to evaluate
0.0734525856	tuned to
0.0734500740	x |
0.0734374687	best estimator
0.0734245551	p = 1
0.0734173072	an integrated
0.0733762899	$ n = \ omega
0.0733739822	some common
0.0733598156	more recent
0.0733577316	time observations
0.0733397883	the breakdown point
0.0733312699	to adapt
0.0733061782	an ergodic
0.0732942632	a pair
0.0732781347	levels of
0.0732670045	\ mathbb z ^
0.0732667435	main contribution of
0.0732648709	an asymptotically optimal
0.0732580219	the classical approach
0.0732544942	an array
0.0732273314	an adequate
0.0732271204	a sequence of
0.0732097471	the problem of variable
0.0732000401	existing methods for
0.0731725041	the non convex
0.0731643647	the square root
0.0731600439	lambda =
0.0731493935	an inequality
0.0731276697	adaptation to
0.0731156572	two types
0.0731083651	a great
0.0731062046	or not
0.0730875583	$ p = 1
0.0730871944	an exchangeable
0.0730791892	problems with
0.0730772895	rather general
0.0730737446	regression with
0.0730569787	these functionals
0.0730270494	to check
0.0730265598	\ times \ mathbb r
0.0730244035	empirical performance of
0.0730238566	between two
0.0730073180	2 \ times 2
0.0729800543	to simplify
0.0729782886	different tests
0.0729613352	a regression function
0.0729018698	two popular
0.0728980818	also conducted
0.0728692905	the joint density
0.0728664733	a non stationary
0.0728613345	in contrast
0.0728596177	improve on
0.0728196953	amounts to
0.0727969901	t =
0.0727962424	\ sqrt t
0.0727935392	a parametric model
0.0727832190	also characterize
0.0727786535	likelihood estimator for
0.0727764472	k \ log
0.0727763596	1 1
0.0727750845	the asymptotic behaviour
0.0727352815	both methods
0.0727179257	the joint asymptotic
0.0727094778	encountered in
0.0727003289	the observation times
0.0726948607	normal approximation of
0.0726884409	normal distribution with
0.0726501082	$ z_
0.0726415066	information matrix of
0.0726399580	a strong
0.0726151005	a broad range of
0.0726125224	an illustrative
0.0726080180	general method for
0.0725941842	bayesian inference on
0.0725920510	based inference for
0.0725911229	the same asymptotic
0.0725685460	this quantity
0.0725662338	information between
0.0725594683	$ independent samples
0.0725572715	n \ delta
0.0725565394	$ \ tilde \ mathcal o
0.0725540291	the information theoretic
0.0725491912	on manifolds
0.0725452716	a new estimation
0.0725392867	locally d
0.0725392255	to analyse
0.0725381638	the empirical bayes
0.0725314796	the intrinsic dimension
0.0725026320	a first order
0.0724938251	at level
0.0724808961	m \
0.0724763297	a set of
0.0724724311	= g
0.0724628575	the problem of estimation
0.0724582140	each sample
0.0724550797	an empirical likelihood
0.0724407826	the first hitting
0.0724387079	also enables
0.0724132438	separated from
0.0724089211	problems such as
0.0724063032	to construct asymptotically
0.0723892454	the power law
0.0723819891	a multiple testing
0.0723495362	a general method
0.0723397033	implementation of
0.0723277008	the latent
0.0723200695	also hold
0.0723189670	upper bounds of
0.0723012699	guidance on
0.0722841477	development of
0.0722660181	beta =
0.0722336270	an adjusted
0.0722294227	blocks of
0.0722113083	an advantage
0.0722070561	some typical
0.0722056273	a kernel type
0.0722025182	hold for
0.0721917301	= 1 ^ m
0.0721750318	a rich
0.0721597343	theory for
0.0721453088	m _
0.0721441345	nonstationary time
0.0721208382	theory allows
0.0721118485	identified as
0.0720967703	g \
0.0720949373	mixture model for
0.0720820740	the asymptotic power
0.0720678295	problem of nonparametric estimation of
0.0720576023	likelihood based on
0.0720562815	the number of clusters
0.0720474972	the mean integrated
0.0720408388	the oracle property
0.0720368315	over existing
0.0719905584	not even
0.0719903750	theoretical results with
0.0719822175	_ t \ in \
0.0719817994	estimates for
0.0719772325	employed in
0.0719630240	rise to
0.0719564082	also briefly
0.0719438396	approach uses
0.0719423669	advantages of
0.0719415628	\ 1
0.0719205202	on simulated
0.0719064927	do not rely
0.0719012764	approach provides
0.0718633876	to guide
0.0718607354	then prove
0.0718522087	aggregation of
0.0718443854	weighted average of
0.0718371345	parameter space of
0.0718218708	an input
0.0717898669	complexity of
0.0717510912	the asymptotic distributions
0.0717483110	$ \ gamma 0
0.0717446403	three different
0.0717300360	in favor of
0.0717295019	this survey
0.0717273669	rates for
0.0717205335	not applicable
0.0717089732	a general asymptotic
0.0717061195	associated random
0.0716934007	parametric rate of
0.0716865664	philosophy of
0.0716840543	\ log ^ 2 n
0.0716786011	well as
0.0716725041	\ x_
0.0716648395	several new
0.0716318965	fisher information of
0.0716311903	a multivariate
0.0716183008	accessible to
0.0716173833	an absolute
0.0716119017	modification of
0.0715984126	a shrinkage
0.0715956117	a maximum likelihood
0.0715867059	max \
0.0715847547	of fit
0.0715827710	the population
0.0715317688	such tests
0.0715301940	to cluster
0.0715244249	y = x
0.0715224797	step by
0.0715222293	calculated from
0.0714974552	testing problem of
0.0714913184	uniform over
0.0714749729	this conjecture
0.0714626086	k \ geq 1
0.0714555903	tables with
0.0714451937	the block maxima
0.0714345736	the problem of model selection
0.0714263352	integration by
0.0714210388	a new methodology
0.0714091398	the linear model
0.0714025309	+ e
0.0713868057	the dimensionality
0.0713863004	aiming to
0.0713848832	continue to
0.0713836491	alternative to
0.0713751520	then proposed
0.0713650959	to approximate
0.0713542894	the p value
0.0713534659	$ h 1
0.0713502455	different from
0.0713421934	some natural
0.0713370160	detection of
0.0713266318	$ h \
0.0713241660	line of
0.0713118017	observations per
0.0713041642	full data
0.0712940076	increasing interest
0.0712598350	determination of
0.0712515346	\ gg n
0.0712429433	consequences of
0.0712228406	n \
0.0712227893	these graphs
0.0712014506	the situation
0.0711993790	both settings
0.0711884649	the multiplier bootstrap
0.0711842758	an analog
0.0711569707	numbers of
0.0711548852	these tools
0.0711501124	a sufficiently large
0.0711454223	$ c
0.0711115632	= m
0.0711022714	p \ le
0.0710870035	a coordinate
0.0710862991	limit theorem with
0.0710789228	two major
0.0710776319	than usual
0.0710711607	the method of maximum
0.0710560496	requirement for
0.0710485657	$ k = 1
0.0710383794	by transforming
0.0710351487	a flexible
0.0710296300	$ rate
0.0710279671	begin with
0.0710051091	to monitor
0.0710047968	the scale parameter
0.0709989153	0 q
0.0709916763	the minimax
0.0709695282	$ \ textbf
0.0709475457	this contribution
0.0709381162	not required
0.0709369695	considered by
0.0709357784	certain types
0.0709117803	\ hat \ lambda
0.0708917884	the derivative
0.0708308557	with jumps
0.0707917927	studied in
0.0707911319	an unbounded
0.0707887946	valid for
0.0707757813	only if
0.0707644568	i +
0.0707547081	a large deviation
0.0707519466	\ al
0.0707447920	weighted least
0.0707392655	collected from
0.0707386980	the data generating
0.0707237132	the sample data
0.0706951412	the finite population
0.0706867912	\ log m
0.0706812092	a small
0.0706606138	nu =
0.0706579216	r _ +
0.0706539998	\ beta 0
0.0706535554	^ * \ in \ mathbb
0.0706527669	the empirical risk
0.0706513022	two scenarios
0.0706307052	\ mathbb z _
0.0706194557	the optimal sample
0.0706172894	squared error of
0.0706051548	to tackle
0.0705984744	= r
0.0705922002	the continuous time
0.0705424732	the normal distribution
0.0705293172	arbitrary number of
0.0705288645	for selecting
0.0705255909	amount of information
0.0705116563	a sequence of random variables
0.0705112137	cornerstone of
0.0705057744	two well known
0.0705027411	sort of
0.0704862530	applicability of
0.0704812391	identical to
0.0704674194	these challenges
0.0704673833	an arbitrarily
0.0704658947	two classes
0.0704570229	c ^
0.0704541148	tests against
0.0704350014	examples of
0.0704322520	a comprehensive
0.0704141410	n \ cdot
0.0704128202	\ mathcal q
0.0703952923	this procedure
0.0703703983	the uniform convergence
0.0703518023	1 \
0.0703476998	theory of
0.0703443194	appearance of
0.0703270564	the non zero
0.0703185111	first propose
0.0703098269	even in high
0.0702890416	not fully
0.0702749238	the uniform distribution
0.0702666240	performed on
0.0702624371	the asymptotic expansion
0.0702616657	n \ leq
0.0702518017	substantially more
0.0702437039	contribution to
0.0702285693	an expansion
0.0702093645	average number of
0.0702093008	a popular
0.0701991304	an independent
0.0701924498	not require
0.0701885178	very different
0.0701781347	asymptotics of
0.0701770850	two quantities
0.0701591972	some other
0.0701477618	the total variation distance between
0.0701341953	the most fundamental
0.0701296733	\ in r
0.0701230749	an analogue
0.0701191443	1 \ le
0.0701165602	analyzed using
0.0700984763	two simple
0.0700873446	$ n ^ \
0.0700820554	estimation problem of
0.0700818405	examples from
0.0700762546	many settings
0.0700733300	mixture of two
0.0700429565	$ p \ geq 1
0.0700276349	different classes
0.0700249361	the false alarm
0.0699809388	a continuous
0.0699713748	crossings of
0.0699607994	\ mathbf s
0.0698959936	the seed
0.0698752584	discuss several
0.0698677159	the minimax optimality
0.0698639631	also suggest
0.0698498599	the average treatment
0.0698424883	to reach
0.0698109204	x _
0.0697785693	some recent
0.0697771926	made about
0.0697744012	the strength
0.0697719852	of concordance
0.0697637806	history of
0.0697511109	widely used to
0.0697478828	to verify
0.0697461862	a new method
0.0697455454	function based on
0.0697381779	the original model
0.0697177285	a standard gaussian
0.0697176603	proposed estimators of
0.0697175297	the empirical spectral
0.0697144356	\ &
0.0697108144	feature of
0.0697096506	minors of
0.0696860147	the optimal rate of convergence
0.0696840694	this construction
0.0696818454	$ m \ geq
0.0696723728	the score test
0.0696664019	= e
0.0696632958	the confidence regions
0.0696511634	a prototype
0.0696507730	the thresholded
0.0696486686	= \ mathbb
0.0696461862	a new approach
0.0696286648	an asymptotically efficient
0.0696231214	two new
0.0696199760	apply to
0.0696080449	a minimax optimal
0.0695811363	\ chi ^
0.0695768695	$ m =
0.0695753671	the expectation
0.0695536058	a theoretical point of view
0.0695480351	population mean in
0.0695458943	included in
0.0695104429	the single index
0.0695092288	the large sample
0.0694816897	n =
0.0694800179	graphical models for
0.0694697415	then use
0.0694654145	the beginning
0.0694649538	pair of
0.0694566448	holds under
0.0694507940	fluctuations of
0.0694238061	for detecting
0.0694217023	not exceed
0.0694029775	the problem of statistical
0.0693839957	the oracle
0.0693736402	to construct confidence intervals for
0.0693136660	a gaussian distribution
0.0693104540	any finite
0.0693054699	estimator over
0.0692957607	tools such as
0.0692841477	consequence of
0.0692812308	these approximations
0.0692748201	follow from
0.0692727411	\ leq \ infty
0.0692715418	an upper bound on
0.0692620346	the response
0.0692595610	goodness of fit for
0.0692542459	data set of
0.0692223728	a random graph
0.0691954286	out of
0.0691810126	arises in
0.0691808949	the sparsity
0.0691718685	to develop
0.0691657608	a careful
0.0691481868	some simple
0.0691378700	to answer
0.0691274017	closed under
0.0691183033	modifications of
0.0691129809	also perform
0.0691049259	the drift
0.0691013577	a real
0.0690921755	an increasingly
0.0690910416	merits of
0.0690907156	among other
0.0690800187	a result
0.0690577123	some standard
0.0690554456	new model selection
0.0690383418	\ hat \ mu
0.0690211517	predicted by
0.0690005540	posterior distributions for
0.0689780525	up to order
0.0689607505	the unknown sparsity
0.0689605040	fraction of
0.0689587811	this new class
0.0689472216	any estimator
0.0689420899	analogy with
0.0689140532	bandits with
0.0689102793	the first result
0.0689095525	experiments on
0.0688884940	density at
0.0688871745	the detection delay
0.0688749623	i = 1 ^ n
0.0688729114	an interior
0.0688045911	a white noise
0.0687982089	the theory developed
0.0687885546	problem into
0.0687458244	such estimators
0.0687364648	\ alpha \ leq
0.0687360128	the basic
0.0687178443	the asymptotic analysis
0.0687030748	not possible
0.0686951263	the existence of
0.0686941740	a test statistic
0.0686824602	= k
0.0686799421	search for
0.0686708255	a similar
0.0686671903	limitation of
0.0686521568	an upper bound for
0.0686007527	these authors
0.0685933504	procedure for
0.0685751961	content of
0.0685678202	to clarify
0.0685556199	the curse of dimensionality
0.0685450793	under proper
0.0685325395	of recovering
0.0685093243	the adjacency matrix
0.0685092758	by imposing
0.0685073710	a modified
0.0684886341	1 \ right
0.0684795255	the initial
0.0684732301	an approach
0.0684731185	differ by
0.0684716785	a difference
0.0684529263	with existing methods
0.0684397178	some simulation
0.0684397144	x_n \
0.0684317216	means of two
0.0684223396	illustrated in
0.0684077089	effectiveness of
0.0683986681	more than one
0.0683959709	new generalization
0.0683915883	the main theorem
0.0683807802	derivative of
0.0683787672	said to
0.0683725588	to carry
0.0683619741	the gaussian sequence
0.0683268534	1 d
0.0683252250	the degree of smoothness
0.0683194557	the optimal minimax
0.0683055123	category of
0.0682948171	used in
0.0682818822	a final
0.0682608300	the notion
0.0682603007	advances in
0.0682565642	$ p n
0.0682485173	sample size for
0.0682386177	the number of latent
0.0682289227	a graph
0.0682193194	examination of
0.0682063051	the false discovery
0.0682005582	to prevent
0.0681930176	\ frac 2
0.0681921671	asymptotic distribution as
0.0681809266	these features
0.0681763824	sources of
0.0681620025	this topic
0.0681610688	to maximize
0.0681606265	n +
0.0681522882	the efficacy
0.0681454628	impact of
0.0681396430	tested on
0.0681248788	to investigate
0.0681178134	to reject
0.0681145092	proceed to
0.0681098949	^ * + \
0.0681023788	to aggregate
0.0680933851	the difference
0.0680826793	appears in
0.0680805772	some existing
0.0680803347	selection based on
0.0680780822	needed for
0.0680557187	the joint distribution
0.0680555990	a trade off
0.0680487508	a machine
0.0680411775	information on
0.0680100804	the hardness
0.0680099746	independently from
0.0679936995	a recently proposed
0.0679898671	modeled using
0.0679820990	these priors
0.0679793172	the target density
0.0679625018	random vector with
0.0679462257	z |
0.0679075644	or complex
0.0679059977	simulation results for
0.0679056080	a directed acyclic
0.0678956870	groups of
0.0678853001	the target function
0.0678701425	not converge
0.0678611224	based estimator of
0.0677994207	used for inference
0.0677964360	results in
0.0677614648	n \ rightarrow \ infty
0.0677354374	conjectured by
0.0677237328	\ theta ^ \ star
0.0677221793	to deal with
0.0676977311	an undirected
0.0676910333	to distinguish
0.0676828202	_ n \ in \
0.0676638824	the moderate deviations
0.0676623396	performances of
0.0676621560	far from
0.0676598949	\ sum_ k =
0.0676561774	$ p \ geq
0.0676561758	benefits of
0.0676371490	scales as
0.0676335236	the diameter
0.0676323188	x ^ n
0.0676255883	associated to
0.0675730801	mean value
0.0675709932	$ \ x_
0.0675679145	the new procedure
0.0675630691	of experts
0.0675478690	the topology
0.0675292042	exploration of
0.0675286452	a prior distribution
0.0675015346	\ mathcal m
0.0674865110	empirical measure of
0.0674756292	the posterior contraction
0.0674549002	\ log d
0.0674522834	these metrics
0.0674513979	long as
0.0674407713	the conditional mean estimator
0.0674356388	seems to
0.0674252607	to gain
0.0674163482	to validate
0.0674048975	the ambient
0.0673967141	the statistical estimation
0.0673915566	$ 4
0.0673760432	the divide and conquer
0.0673622358	probability at least
0.0673456683	new method
0.0673189266	member of
0.0673183587	the empirical covariance
0.0673180019	$ 0,1
0.0672957698	to take into account
0.0672860170	the almost sure convergence
0.0672851398	expressed by
0.0672766462	this idea
0.0672728928	not affected
0.0672672362	a link
0.0672541167	\ mathbf v
0.0672454766	a large sample
0.0672397712	an asymptotically
0.0672300980	an extremely
0.0672267897	empirical processes of
0.0672241356	quantile regression in
0.0672146117	covariance matrix with
0.0672099210	k \ times
0.0672014728	by product of
0.0671861640	\ sqrt \ log n
0.0671784079	the marginal likelihood
0.0671330530	and two real
0.0671250281	in \ cite
0.0671182089	_ n \ in
0.0671159733	the bivariate normal
0.0671141101	possible model
0.0670794850	concentrates on
0.0670146524	a detailed
0.0670069243	to relate
0.0670060067	studied using
0.0669911692	to remove
0.0669801308	^ p \
0.0669721030	distribution function for
0.0669632092	several properties
0.0669629482	possible to
0.0669569129	the finite sample properties of
0.0669469676	a class of nonlinear
0.0669223185	convolutions of
0.0669086822	hypothesis testing in
0.0669052011	a uniform distribution
0.0668956870	stability of
0.0668940336	features of
0.0668632791	$ 1 \ leq
0.0668511467	this direction
0.0668481463	a metric space
0.0668467023	first hitting
0.0668442405	x \ in \ mathbb
0.0668264140	helps to
0.0668228316	the degree distribution
0.0668157270	the moment generating
0.0667989822	an estimate of
0.0667906525	modelled as
0.0667642471	$ r ^ 2
0.0667373259	p *
0.0667233498	the asymptotic performance
0.0667195447	$ independent observations
0.0667123660	the paper presents
0.0666989506	an easily
0.0666965772	new robust
0.0666912764	a method
0.0666848639	second method
0.0666728502	neighborhood of
0.0666697186	a large variety of
0.0666562146	a clear
0.0666302816	by reducing
0.0666262295	the minimax rates
0.0666244249	\ cal x
0.0665937077	technique for
0.0665870160	result for
0.0665793172	a convex set
0.0665546128	relation to
0.0665533234	by drawing
0.0665365151	estimation with
0.0665324947	the drift parameters
0.0665285273	most cases
0.0664742042	\ alpha 2
0.0664690455	to impose
0.0664652727	by choosing
0.0664582203	$ term
0.0664497762	an invariance
0.0664494756	a broad
0.0664234848	general case of
0.0664227237	the space of probability
0.0664197186	a large range of
0.0664133541	to express
0.0664105602	as special
0.0664042829	analysis based on
0.0663894292	a tutorial
0.0663554949	positions of
0.0663508179	usefulness of
0.0663356311	proved under
0.0663296766	any knowledge
0.0663286186	known as
0.0663286186	used as
0.0663084298	the recent literature
0.0662836126	different values
0.0662783995	theoretical results for
0.0662772828	the negative log
0.0662728928	not identically
0.0662644109	the mean and variance
0.0662319797	also address
0.0662255849	to accommodate
0.0662230922	the quadratic variation
0.0662230865	the present
0.0662176036	tending to one
0.0661951724	a nonparametric estimator
0.0661802425	^ \
0.0661733807	difference of
0.0661606647	and tao
0.0661455497	various assumptions
0.0661403716	clt for
0.0661253289	a standard normal
0.0661242189	p \ to \ infty
0.0661222368	with prescribed
0.0661060371	signals from
0.0660804684	well even
0.0660692964	and tsybakov
0.0660660915	\ bar x
0.0660552722	statistic under
0.0660524272	of order two
0.0660439289	the number of iterations
0.0660427554	\ ^ o processes
0.0660344812	restriction on
0.0660322584	a random design
0.0660300980	by defining
0.0660284079	the conditional distribution
0.0660149903	squared error in
0.0660144035	the estimated
0.0660144035	the observed
0.0660118441	of fit tests
0.0660070202	$ \ ell ^
0.0659967115	at different
0.0659897892	the local
0.0659871368	changes in
0.0659818294	a theoretical framework
0.0659813150	the characteristic function
0.0659732201	the sample sizes
0.0659652727	by averaging
0.0659448791	change detection in
0.0659435702	refinements of
0.0659384881	a corollary
0.0659163482	to conduct
0.0659065642	$ n =
0.0658927839	the same size
0.0658517721	to \ infty
0.0658496090	the optimal design
0.0658407647	suited to
0.0658349331	a sum of independent
0.0658265631	the first
0.0658102084	constructed under
0.0658074325	to attain
0.0658062929	crucial to
0.0657841044	novel theoretical
0.0657728700	not follow
0.0657727724	usually not
0.0657616568	with immigration
0.0657611359	function from
0.0657561774	$ \ mathbf \ sigma
0.0657551975	x +
0.0657373559	the problem of selecting
0.0657348343	a strong law
0.0657228812	a preliminary
0.0657077267	attention in
0.0656907807	the lasso path
0.0656850326	hold under
0.0656692357	the statistical properties
0.0656683328	autocovariances of
0.0656633003	the estimated parameters
0.0656620650	a statistical analysis
0.0656477369	the graph
0.0656294821	working with
0.0656216273	the proportion
0.0656169849	to adjust
0.0656062349	goodness of fit of
0.0656029504	some covariates
0.0655747260	by generalizing
0.0655617412	the training data
0.0655481614	similarly to
0.0655155976	this challenge
0.0655074183	to maintain
0.0655073033	\ | \ sigma
0.0654952652	described in terms
0.0654904573	a strong law of large
0.0654904037	used to detect
0.0654899980	magnitudes of
0.0654855617	demonstrated on
0.0654589349	equality of two
0.0654556205	a new result
0.0654287183	means of
0.0654171093	by parts
0.0654092994	p value for
0.0654026824	to mitigate
0.0653951425	at zero
0.0653897958	$ q \ in
0.0653783755	closure of
0.0653492042	a newly
0.0653476998	measure of
0.0653437183	the empirical likelihood
0.0653361087	the proof
0.0652844207	by making
0.0652840271	designs with
0.0652698267	a sample of size
0.0652645579	traces of
0.0652356705	these systems
0.0652207516	existing methods in
0.0652054265	a uniform
0.0651961314	a regression model
0.0651944252	composed of
0.0651913238	to construct estimators
0.0651860899	approach does not
0.0651757065	with regard
0.0651729671	to serve
0.0651529076	the distribution
0.0651509776	the conditional
0.0651449682	the invariant measure
0.0651322422	available data
0.0651320571	work provides
0.0651286775	the \ emph
0.0651152262	this technique
0.0650949901	this document
0.0650698396	the most general
0.0650690450	at least one
0.0650507730	the occurrence
0.0650449020	the bias
0.0650351846	the sure screening
0.0650328679	the total
0.0650271546	further show
0.0650242720	the noise
0.0650184352	relaxation of
0.0650141320	the theoretical properties
0.0650105372	s ^ *
0.0649992821	in many areas
0.0649913756	widely used as
0.0649658411	implemented using
0.0649626168	the statistical analysis
0.0649547309	by selecting
0.0649370424	these formulas
0.0649325746	the data matrix
0.0649209449	$ x_n
0.0649114860	available at
0.0649069398	the explanatory variables
0.0648864615	the covariate
0.0648849396	one dimension
0.0648806849	in order to achieve
0.0648750010	q ^
0.0648611871	\ times m
0.0648560335	done by
0.0648471268	to collect
0.0648434491	f \ _
0.0648422029	the support
0.0648399089	\ leq k
0.0648279482	occurrence of
0.0648029504	both classical
0.0647926992	practical performance of
0.0647893464	the bivariate
0.0647841458	a random number
0.0647755432	in many statistical
0.0647616568	this limitation
0.0647241356	bayesian inference in
0.0647154468	transition density of
0.0646914796	type of
0.0646843110	the prior
0.0646713884	some popular
0.0646623396	suitable for
0.0646608389	strong law of
0.0646402494	follows from
0.0646292594	a small set
0.0646157693	compared to other
0.0646151784	the average
0.0646076422	does not rely
0.0645776121	areas of
0.0645716748	in advance
0.0645698426	consistency under
0.0645026979	demonstrated using
0.0644911156	the same convergence
0.0644785693	or negative
0.0644718745	the cdf
0.0644599113	i =
0.0644323738	a proof
0.0644277531	the famous
0.0644201285	certain regularity
0.0644153369	an affine
0.0644046521	mean function
0.0643822736	even without
0.0643768529	a very broad
0.0643547404	by contrast
0.0643435690	\ mathbb s ^
0.0643261871	the respective
0.0643226797	a sequence
0.0643203351	the matrix variate
0.0643192660	a standard
0.0643178724	to test
0.0643176443	the exact
0.0643130321	the growth rate
0.0643094812	consequences for
0.0643085534	an orthogonal
0.0642786847	$ \ mathcal p
0.0642743022	improvements in
0.0642737264	based tests for
0.0642629386	omega =
0.0642624744	a sparse
0.0642542617	a functional
0.0642455858	trained on
0.0642416005	the prediction error
0.0642359426	a family of
0.0642355065	2 ^ k
0.0642227911	criteria for
0.0642197415	not available
0.0642130816	and easy to implement
0.0642070420	process with
0.0642042669	the statistics literature
0.0642033579	to extend
0.0641874472	ubiquitous in
0.0641824034	\ in 1
0.0641784586	in many scientific
0.0641780313	g ^
0.0641680152	the rest
0.0641338290	a stochastic differential
0.0641229863	the number of mixture
0.0641182580	also holds
0.0641091448	duration of
0.0640815753	majority of
0.0640809977	the loss function
0.0640637051	in many situations
0.0640575040	more detail
0.0640466618	a much smaller
0.0640267943	the large deviation
0.0640105189	the empirical performance
0.0639928606	general theory to
0.0639925193	gamma \ in
0.0639872148	$ factor
0.0639695050	the mean residual life
0.0639302649	the tail
0.0639273681	the asymptotic minimax
0.0639245007	t \ to \ infty
0.0639100869	comparisons with
0.0639039354	^ * +
0.0638953351	quantification of
0.0638943423	\ sqrt 2
0.0638935276	the large deviations
0.0638901851	+ +
0.0638794216	on synthetic
0.0638623852	for choosing
0.0638591972	under certain
0.0638588911	testing problems in
0.0638522087	expansion of
0.0638294414	the sparsity level
0.0638288258	a discrete
0.0638287459	to vary
0.0638183779	likelihood estimation with
0.0638149337	to hold
0.0638099219	the case of gaussian
0.0637978732	a refined
0.0637810156	z =
0.0637801062	a subclass
0.0637684138	obtained at
0.0637674830	two independent
0.0637646249	a statistical
0.0637636056	paper uses
0.0637613073	a new distribution
0.0637486896	b ^
0.0637474307	do not need
0.0637309564	regression via
0.0637105459	a well defined
0.0637075286	applied to various
0.0637019539	the paper studies
0.0636719482	with vanishing
0.0636585236	all stationary
0.0636581649	also show
0.0636306549	these techniques
0.0635948497	the regression parameters
0.0635922485	a powerful
0.0635713341	analogs of
0.0635614256	\ mathbf \ sigma
0.0635606199	the frequentist coverage
0.0635544271	each time
0.0635318185	a gaussian mixture
0.0635277703	new approximation
0.0635249410	the size of
0.0635141571	the sampling rate
0.0635071578	the problem of multiple
0.0635068173	hard to
0.0634855617	impossible to
0.0634729431	algorithm provides
0.0634577327	size tends to
0.0634280313	b =
0.0634226797	the critical
0.0634217739	components of
0.0634216596	x = x
0.0634170717	the design points
0.0634117386	statistical inference of
0.0633918854	not known
0.0633745014	designs for
0.0633523614	2 \ times
0.0633503220	used in applications
0.0633472008	$ dx_t =
0.0633241435	to update
0.0633155256	only one
0.0633107681	of large random
0.0633041283	an infinitely
0.0633017225	also proposed
0.0632850064	designs with respect to
0.0632828789	a bootstrap procedure
0.0632629386	hat f
0.0632505132	of magnitude
0.0632358905	= f
0.0632298638	instances of
0.0632250717	examples of such
0.0631989506	as input
0.0631742505	a time series
0.0631640934	only through
0.0631606265	2 +
0.0631590244	a compact
0.0631357605	a large collection of
0.0631335236	the benefit
0.0631302649	the inverse
0.0631291411	a linear
0.0631162937	$ k \ times
0.0630904728	a tractable
0.0630864615	the error
0.0630842632	the performance of
0.0630806343	of estimating
0.0630783907	the finite
0.0630577458	^ 2 n
0.0630546028	\ hat f
0.0630402184	the problem of reconstructing
0.0630389614	density functions of
0.0630184731	replaced with
0.0630173290	the input
0.0630023915	parameters of
0.0630014676	the power
0.0629997691	optimal value
0.0629994932	the asymptotic validity
0.0629755088	to unify
0.0629711728	this perspective
0.0629647675	techniques such as
0.0629629487	an automatic
0.0629570229	| ^
0.0629534913	guarantees on
0.0629496023	metrics for
0.0629346502	pieces of
0.0629059036	the asymptotic bias
0.0628961070	justifications for
0.0628952823	the same set
0.0628948763	grows at
0.0628849516	a scalar
0.0628849278	general approach to
0.0628714720	the spectral gap
0.0628703983	a kernel density
0.0628646661	the current
0.0628634313	an appropriately
0.0628458905	s _n
0.0628381632	an identifiable
0.0628315385	analog of
0.0628303352	performs well in
0.0628243638	under misspecification
0.0628208893	to apply
0.0628113539	s 0
0.0628078702	different estimators
0.0627983414	$ \ min
0.0627772286	\ alpha \ in 0,1
0.0627710003	estimate of
0.0627636056	paper gives
0.0627530715	this extension
0.0627511007	used to analyze
0.0627441789	the mean square
0.0627393852	provides more
0.0627328115	a combination
0.0626880691	the amplitude
0.0626771546	or even
0.0626672564	the proportion of true
0.0626505637	inconsistency of
0.0626400533	a class of multivariate
0.0626349290	some general
0.0626291411	a stochastic
0.0626112556	derived based on
0.0625966770	criterion for
0.0625943194	volumes of
0.0625841249	to balance
0.0625825916	squares estimator for
0.0625658143	vicinity of
0.0625267284	this review
0.0625253174	second part
0.0625178261	random variable with
0.0625138867	named as
0.0625028781	the likelihood principle
0.0624993282	r ^
0.0624988937	loss functions for
0.0624727920	the circle
0.0624632892	| | x
0.0624337540	$ p \ times
0.0624101943	the error rates
0.0624017130	networks via
0.0623980511	the scope
0.0623950056	residuals from
0.0623896259	value statistics
0.0623696686	$ \ sim
0.0623653344	strategies for
0.0623630988	the theoretical
0.0623594812	improves on
0.0623579257	to meet
0.0623436285	nonlinear least
0.0623179828	the consistency
0.0623046961	the posterior density
0.0622826072	proved by
0.0622717685	specification of
0.0622535945	th moment
0.0622503289	the input variables
0.0622281725	an identity
0.0622275117	even more
0.0622110593	recovery via
0.0622107990	\ to c
0.0622033193	scheme for
0.0622030527	a principled
0.0621752413	the random walk
0.0621496678	p \ times p
0.0621200293	to facilitate
0.0621198376	theoretical results by
0.0621149478	densities under
0.0621066128	$ ^
0.0620947514	the earth
0.0620938841	the special case
0.0620911932	the volume
0.0620843512	the principal components
0.0620818281	principal components of
0.0620684489	inversion of
0.0620390953	1 \ log
0.0620316443	$ k \ geq 1
0.0620290048	established by
0.0620144035	the dimension
0.0620113407	the fundamental problem
0.0620097811	observations at
0.0619987645	the smoothness
0.0619893464	a test
0.0619882445	\ ell ^ 2
0.0619726797	a measure
0.0619725750	a significance test
0.0619683107	institute of
0.0619615837	the solution
0.0619577287	$ y = f
0.0619557600	any other
0.0619333097	considered in
0.0619324717	a parametric rate
0.0619274140	a generalised
0.0619210767	\ to \ gamma
0.0619138456	x \
0.0618976136	$ p \ gg
0.0618971966	the parameter
0.0618922123	to calibrate
0.0618811359	eigenfunctions of
0.0618179303	u =
0.0618152262	this methodology
0.0618126733	two real
0.0618089084	a nonparametric bayesian
0.0617689838	of such methods
0.0617635426	asymptotically optimal for
0.0617386804	detecting changes
0.0617206554	$ x_t
0.0617193786	a prominent
0.0617072280	the existence
0.0616964518	of attraction
0.0616871379	the class of functions
0.0616840642	do not make
0.0616788756	the computational efficiency
0.0616695447	the upper tail
0.0616498163	an analytical
0.0616458190	new proof
0.0616406667	asymptotic bounds for
0.0616202878	d +
0.0616118485	satisfied for
0.0616100818	the wavelet coefficients
0.0616097222	pattern of
0.0616094683	the transition density
0.0616019510	a surprising
0.0615966346	the number of blocks
0.0615830484	representation for
0.0615820229	s ^
0.0615818834	the corresponding posterior
0.0615694544	for controlling
0.0615265770	a gaussian
0.0615231836	an expression
0.0615216881	\ sqrt 1
0.0615137837	a useful tool
0.0614850406	assessed by
0.0614777069	body of
0.0614761476	the role of
0.0614556696	the asymptotic efficiency
0.0614497431	tendency of
0.0614493687	size n
0.0614394621	the objective
0.0614086985	an extreme value
0.0614083829	the most commonly
0.0614076024	the error terms
0.0614067719	consideration of
0.0614003289	the mixture components
0.0613855601	also find
0.0613848751	the variance function
0.0613790750	scope of
0.0613653283	the spiked
0.0613538651	with exponent
0.0613512668	$ distance between
0.0613421398	the sum of squared
0.0613418841	j =
0.0613408292	many methods
0.0613369655	the edge
0.0613349704	an issue
0.0613130321	the reconstruction error
0.0612955826	the small sample
0.0612945577	$ p \ in
0.0612680883	expansions of
0.0612598949	\ mathcal h
0.0612564313	$ confidence
0.0612542250	$ n \ ge
0.0612496025	v ^
0.0612339463	the estimation
0.0612092708	the mean squared
0.0611973033	the number of measurements
0.0611756485	to exhibit
0.0611621025	\ mathbb z
0.0611585033	a new type of
0.0611550025	the false
0.0611509776	the design
0.0611504049	the asymptotic theory
0.0611394382	with existing
0.0611366568	an improper
0.0611353222	a definition
0.0611346895	new estimators
0.0611176321	the number of training
0.0611172123	this reason
0.0611167799	necessary and sufficient conditions for
0.0610953808	in statistics and machine
0.0610876255	distributed as
0.0610860326	such as consistency
0.0610828789	for finite samples
0.0610811622	estimators with
0.0610705863	the singular values
0.0610582489	2 \ log
0.0610574325	to explain
0.0610551845	other than
0.0610544360	various statistical
0.0610438575	investigated using
0.0610362390	ratio test for
0.0610262602	the population size
0.0610231836	an ordinary
0.0610188754	law of
0.0610099520	a relatively small
0.0609761753	a new notion
0.0609755400	the differential entropy
0.0609701696	this yields
0.0609675931	the asymptotic behavior
0.0609630675	without using
0.0609610599	a function
0.0609507010	introduced in
0.0609297171	the bulk
0.0609287387	the bandwidth
0.0609106442	the construction of confidence
0.0608765491	the number of observed
0.0608594866	the block bootstrap
0.0608234306	to guarantee
0.0608091223	roughness of
0.0608090528	the probability
0.0608038628	adaptive with respect to
0.0608001948	$ vertices
0.0607957250	generation of
0.0607954530	$ p =
0.0607902636	rate of convergence of
0.0607873557	a fast
0.0607835617	the space of
0.0607756061	a statistician
0.0607548269	features such as
0.0607531282	the covariance
0.0607275780	using tools
0.0607255365	under various
0.0607228448	the receiver
0.0607163495	the score function
0.0607118744	obtained as
0.0607114884	the minimax optimal
0.0607011958	to explore
0.0606791565	this formula
0.0606656034	measures based on
0.0606550661	and asymptotically efficient
0.0606537889	k =
0.0606506562	inference from
0.0606238061	a proper
0.0606131928	a certain threshold
0.0605638479	also demonstrated
0.0605608142	not impose
0.0605541597	allow for
0.0605439513	a conjecture
0.0605389295	and wu
0.0605319630	a sharp
0.0605289308	martingales with
0.0605125583	$ \ | \ hat
0.0605086269	with unknown
0.0605000632	a toric
0.0604842694	by simulations
0.0604785693	to conclude
0.0604654896	both simulated and real
0.0604260859	lie in
0.0604186487	one observation
0.0603980313	the directional
0.0603971321	analogy to
0.0603956870	computation of
0.0603844976	at risk
0.0603833778	also describe
0.0603828339	a closed
0.0603667880	now well
0.0603580308	possible rate
0.0603554949	explanation of
0.0603457344	e \ |
0.0603366510	in many real
0.0603258263	^ v
0.0603185918	$ \ sqrt n
0.0603176443	the assumption
0.0602713388	in such situations
0.0602335461	first part
0.0602321438	m =
0.0602281448	an intractable
0.0602077412	$ b
0.0601997225	e y
0.0601758263	^ +
0.0601590244	a basic
0.0601553369	examined by
0.0601382551	projection on
0.0601316324	estimator does not
0.0601280186	metric on
0.0601198558	geometry of
0.0601082314	some regularity
0.0601066860	a new characterization
0.0600862104	n \ times
0.0600739506	to formulate
0.0600623537	effect of
0.0600614267	extends to
0.0600362169	a fully data
0.0600253236	not satisfy
0.0600140028	more information
0.0600098949	i \ le n
0.0600073532	asymptotic mean
0.0600055593	a new family of
0.0600010129	determined from
0.0599788657	a central
0.0599741269	= |
0.0599680408	many classical
0.0599504570	the degree
0.0599499743	the lse
0.0599498406	the unknown parameters
0.0599265547	under uncertainty
0.0599198834	the extremal
0.0599170538	suitability of
0.0599144393	to demonstrate
0.0599142063	the function class
0.0598957185	for studying
0.0598849715	change in
0.0598818246	transformations of
0.0598728892	a spherically
0.0598576998	the generality
0.0598569720	taken from
0.0598314653	$ exponential
0.0597904312	t |
0.0597903615	the main purpose of
0.0597837387	the local linear
0.0597836878	no polynomial
0.0597801597	this research
0.0597764069	x_i =
0.0597731989	a random field
0.0597710003	applications of
0.0597652437	the maximum entropy
0.0597635982	the rate
0.0597609299	an independence
0.0597583343	= b
0.0597563299	known algorithms
0.0597483991	a novel method
0.0597425064	an active
0.0597402628	gap by
0.0597380889	trees from
0.0597355065	each pair of
0.0597242759	the lack
0.0597208263	a certain
0.0597195280	between two random variables
0.0597100406	primarily on
0.0596902630	available methods
0.0596833300	the actual
0.0596684445	large range of
0.0596671903	lines of
0.0596648314	and nickl
0.0596647505	p \ times
0.0596519821	a polynomial
0.0596234858	f =
0.0596226797	the potential
0.0596114290	adaptive to
0.0596023940	different sets
0.0595876305	behaves as
0.0595862250	the first to
0.0595801010	optimal up to
0.0595793884	p_n \
0.0595792086	ease of
0.0595776121	improvement of
0.0595739095	some aspects
0.0595726797	the unit
0.0595672056	$ c ^
0.0595608572	a joint distribution
0.0595444075	$ x_j
0.0595443888	under dependence
0.0595304269	the conditional density
0.0595275019	principle for
0.0595263003	n \ log p
0.0595079159	the l2
0.0595021154	earlier by
0.0595002248	proved for
0.0594882796	solution of
0.0594755664	suffice to
0.0594331392	priors on
0.0594106242	prior over
0.0593980313	the intermediate
0.0593943606	to examine
0.0593678134	to discover
0.0593649480	a binary
0.0593514311	the sum
0.0593511622	supremum of
0.0593484340	the dual
0.0593445574	$ p_i
0.0593354148	in contrast to previous
0.0593108745	a gaussian random
0.0593107829	the validity
0.0593054799	element of
0.0592723123	prediction under
0.0592690839	a likelihood ratio
0.0592645965	a stationary gaussian
0.0592596076	a new algorithm
0.0592587923	the law of large
0.0592247847	well in practice
0.0592057964	rows of
0.0592017652	the principal component
0.0591957978	the supremum
0.0591931904	in time and space
0.0591914796	applications in
0.0591737979	the inner product
0.0591717739	measures of
0.0591467220	exponentially with
0.0591410621	$ l ^ q
0.0591384265	the standard normal
0.0591241721	the dependence structure
0.0591143690	increases with
0.0590949901	in essence
0.0590898671	tied to
0.0590816996	a precise
0.0590764437	the microergodic
0.0590758554	the minimal
0.0590574354	extrema of
0.0590453669	the analyst
0.0590437916	a robust
0.0590403613	on synthetic and real
0.0590297655	the marginal
0.0590285643	to modify
0.0590255883	allows for
0.0590247949	c \
0.0590188754	degree of
0.0590173290	a positive
0.0590053314	the minimizer
0.0590014676	the univariate
0.0589939598	t +
0.0589934203	formulae for
0.0589836930	the nuisance parameter
0.0589828965	the class
0.0589616723	games with
0.0589559059	the boundary
0.0589486985	to enjoy
0.0589302649	the spectral
0.0589240050	a sensor
0.0589196352	the fractional brownian
0.0588983554	the individual
0.0588964404	discretization of
0.0588922123	to summarize
0.0588839957	a parametric
0.0588508397	the asymptotic properties
0.0588460721	parameterization of
0.0588302769	signals with
0.0588278582	to design
0.0588237102	a new estimator
0.0588094773	a crucial
0.0588041562	the multinomial
0.0588021174	a substantial
0.0587966094	this study
0.0587964360	model for
0.0587893464	a prior
0.0587786723	^ j
0.0587395341	smoothness of
0.0587395190	a probability density
0.0587282028	to do so
0.0587256275	many different
0.0587016344	known to
0.0586989506	this scenario
0.0586981836	an increase
0.0586952309	to exceed
0.0586870827	the generalized pareto
0.0586577652	spectral density of
0.0586368318	x \ beta
0.0586235662	an adaptation
0.0586169766	faces of
0.0586133358	the choice
0.0586040800	n \ sqrt
0.0585903510	arise as
0.0585885357	functions over
0.0585872628	than ever
0.0585792668	all parameters
0.0585610558	even for small
0.0585481771	the observed variables
0.0585468202	becomes more
0.0585454359	y = f
0.0585273035	method to
0.0585179316	defined using
0.0585151119	$ _
0.0585144271	$ 3
0.0585122311	identified by
0.0585102086	important in many
0.0585040999	the singular value decomposition
0.0585020005	random vectors in
0.0584882907	a new concept
0.0584763927	applied to other
0.0584646453	\ times \ mathbb
0.0584634296	verified by
0.0584421722	in many settings
0.0584250448	optimal designs in
0.0584205292	a set
0.0584066490	probability measures in
0.0583767177	the data distribution
0.0583703042	an upper
0.0583393444	correctness of
0.0583369655	the predictor
0.0583272796	the error rate
0.0583073712	a generalization of
0.0583005659	free from
0.0582935018	unknown mean
0.0582902200	presented to
0.0582796325	the interpolation
0.0582728928	and vice
0.0582468992	method of
0.0582351047	specified models
0.0582280313	= c
0.0582276046	risk under
0.0582241269	f ^
0.0582182393	some properties
0.0582164011	achieved under
0.0582128717	an inverse
0.0582043393	from i.i.d
0.0582002208	eta \
0.0581839511	to prove
0.0581749077	the number of communities
0.0581451731	vector from
0.0581439366	second approach
0.0581367719	enables to
0.0581277952	couple of
0.0581197948	the uniform
0.0581183045	of dimensionality
0.0581017858	$ associated with
0.0580966770	techniques for
0.0580919706	the square root of
0.0580854875	specified by
0.0580826452	$ k =
0.0580692044	deviations of
0.0580646426	the exact distribution
0.0580527255	partitions of
0.0580303185	the availability
0.0580239998	a margin
0.0580178310	the ipw
0.0580098691	perspective on
0.0580093052	the fitness
0.0580055867	the number of classes
0.0579910706	the large dimensional
0.0579862697	admissibility of
0.0579843110	the limit
0.0579672446	the prediction risk
0.0579635392	a collection of
0.0579615837	the observation
0.0579597006	evidence for
0.0579538322	one class
0.0579448013	recovery of
0.0579406495	an optimization
0.0579387903	statistics under
0.0579280544	the context
0.0579055662	present work
0.0578988996	methodology to
0.0578878758	2 ^ n
0.0578870010	zeros in
0.0578677202	log n n
0.0578642193	different parameters
0.0578521798	space into
0.0578506040	exp \
0.0578385471	a typical
0.0578324170	commonly used to
0.0578315267	curvature of
0.0578234947	marginals of
0.0578216596	\ sum_ i
0.0578157609	in many practical
0.0578073712	a number of
0.0578041562	the mse
0.0578016277	a species
0.0577989822	a mixture of
0.0577915534	an improvement
0.0577809004	o s
0.0577703531	only available
0.0577653234	the simulation results
0.0577602547	+ o
0.0577515346	x ^ t
0.0577456956	d \ times
0.0577380709	posterior distribution in
0.0577350838	distributions with
0.0577292229	a solution
0.0577262242	p =
0.0577224113	\ min \
0.0577204584	realization of
0.0577173048	the tail probability
0.0577145357	the equality
0.0577050687	the most widely
0.0577042730	this relationship
0.0577003345	volume of
0.0576865292	the outcome
0.0576865292	the integrated
0.0576741512	$ independent and identically
0.0576741355	motivation for
0.0576458446	logarithm for
0.0576385232	this finding
0.0576353038	used to prove
0.0576134769	the strong consistency
0.0576122632	procedures such as
0.0576092744	the white noise
0.0576022467	very sensitive to
0.0575959991	some practical
0.0575860429	the inverse problem
0.0575792668	then provide
0.0575788369	the residual
0.0575754278	an order
0.0575679303	n ^ *
0.0575568768	over graphs
0.0575545212	the minimax lower
0.0575506657	in learning theory
0.0575501978	\ rrr ^ d
0.0575337397	a combinatorial
0.0575263624	the weak convergence
0.0575263106	the rate of convergence
0.0575160136	data into
0.0575129226	in doing so
0.0574930866	the elastic
0.0574869655	the selected
0.0574804793	difficulty in
0.0574756074	points from
0.0574648600	array of
0.0574648600	homogeneity of
0.0574586359	demonstrated in
0.0574568261	metrics on
0.0574440607	new lower
0.0574432439	vector x
0.0574274477	possible to estimate
0.0574192871	many other
0.0574175661	the survival function
0.0574144956	distributions on
0.0574094860	the problem of nonparametric estimation
0.0574011988	connected with
0.0573681343	the performance
0.0573637388	distribution with
0.0573624833	reconstruction of
0.0573592781	$ constraint
0.0573582413	the existing methods
0.0573509776	the statistical
0.0573448017	a weighted
0.0573428310	the saddlepoint
0.0573175661	the confidence sets
0.0573100499	to decompose
0.0573068728	details of
0.0573062929	limits on
0.0573027701	the functional linear
0.0572949839	the tail behavior
0.0572928202	for simulating
0.0572713706	the new algorithm
0.0572552024	distributions via
0.0572547101	mass at
0.0572499859	j \
0.0572446708	in terms of power
0.0572435890	under very general
0.0572171388	for conducting
0.0572167284	the new distribution
0.0572070033	$ optimal designs for
0.0572040681	the most powerful
0.0571945129	many others
0.0571843110	submatrices of
0.0571839447	performs as well
0.0571750401	many commonly
0.0571717739	procedures for
0.0571595827	an almost sure
0.0571564980	to classify
0.0571526274	regression under
0.0571464216	allows to
0.0571303022	then study
0.0571284383	in terms
0.0571149752	different assumptions
0.0571138215	even better
0.0571065271	and asymptotically normal
0.0570992149	the influence function
0.0570984455	to highlight
0.0570925566	lifetimes of
0.0570909135	distribution over
0.0570899281	also consider
0.0570895223	the rotation
0.0570847112	condition for
0.0570837225	the causal effect
0.0570790414	the extremogram
0.0570654306	a smooth
0.0570623537	context of
0.0570580861	p n \ rightarrow
0.0570562965	\ boldsymbol x
0.0570535973	to justify
0.0570485657	$ \ hat \ sigma
0.0570402733	= 0 ^
0.0570229852	the same asymptotic distribution
0.0570153841	an extension
0.0570112774	embedded in
0.0570108527	$ consistency of
0.0570105318	for designing
0.0570070382	the global
0.0570025377	magnitude of
0.0569975641	the random design
0.0569877397	the consistency and asymptotic normality
0.0569853596	the spectrum
0.0569836622	the measurement matrix
0.0569768695	$ \ mathbb r ^
0.0569683335	eigenvector of
0.0569645800	a universal
0.0569613965	process at
0.0569606265	x =
0.0569550661	the nuisance parameters
0.0569464024	the knockoff
0.0569255892	under appropriate
0.0568967123	the form
0.0568921106	by using
0.0568902839	this difficulty
0.0568795737	a new proof
0.0568792943	to decide
0.0568596591	the error density
0.0568453390	^ * =
0.0568388838	an intrinsic
0.0568368947	breaks in
0.0568314653	$ dependent
0.0568220936	the square loss
0.0568165582	value copulas
0.0568122906	two novel
0.0568054354	conjunction with
0.0568050497	influence on
0.0567815753	journal of
0.0567631579	a mixture model
0.0567484907	several other
0.0567419876	^ o
0.0567176113	the dictionary
0.0567168549	this notion
0.0566954656	principles for
0.0566814951	measure on
0.0566802425	$ n ^
0.0566750988	minimization of
0.0566433736	variance of
0.0566397141	matrix of
0.0566390237	of genes
0.0566373787	for proving
0.0566084336	the covariance kernel
0.0566058415	as particular cases
0.0565959502	the error bound
0.0565944189	area of
0.0565779027	the mean squared error
0.0565731873	of change points in
0.0565423743	the limit theory
0.0565355779	the plug in
0.0565353474	list of
0.0565265071	$ i.i.d
0.0565259110	l ^ q
0.0565204558	node in
0.0564853153	to separate
0.0564801520	among variables
0.0564663059	the statistical performance
0.0564636568	d =
0.0564605508	the results obtained
0.0564370057	commonly used in
0.0564370010	zeros of
0.0564297598	an expectation
0.0564220028	transformation of
0.0564145710	the out of
0.0564138337	the quadratic loss
0.0564058490	rates at
0.0563980313	the flexibility
0.0563963844	a sensitivity analysis
0.0563950056	evaluated using
0.0563842853	the context of functional
0.0563781737	fast as
0.0563536440	this observation
0.0563517673	tests under
0.0563255456	in mind
0.0563044062	the multivariate normal
0.0562904584	occurrences of
0.0562866683	a purely
0.0562830221	plugging in
0.0562722182	density with respect to
0.0562670833	\ mathbb r ^
0.0562556407	the primary
0.0562452863	regularization by
0.0562431702	a much larger
0.0562351402	enough to
0.0562316681	errors in
0.0562287757	a model selection
0.0561998256	posterior distribution for
0.0561956558	several different
0.0561883236	the support of
0.0561851108	or more
0.0561847187	the number of data
0.0561791340	a sequence of random
0.0561736303	efficient algorithm to
0.0561552238	i \ in \ mathbb
0.0561525578	the strong law of large numbers
0.0561503378	\ mathcal w
0.0561477434	generalization error of
0.0561454359	\ mathcal c
0.0561098949	1 \ leq i
0.0560892703	in conjunction with
0.0560621025	\ mathcal u
0.0560228359	modulus of
0.0560122311	selected from
0.0560084870	a simplex
0.0560076128	the remainder
0.0559883823	real example
0.0559835881	\ sum
0.0559800028	this inequality
0.0559615501	the link
0.0559408192	graph with
0.0559172050	penalty on
0.0559097533	the domination
0.0559029349	and many others
0.0558813261	between two probability
0.0558704108	the first time
0.0558686808	amounts of
0.0558586105	the relevant
0.0558509776	the variance
0.0558483096	to match
0.0558482530	the parametric rate
0.0558432176	new class
0.0558417067	via extensive
0.0558353675	adapting to
0.0558346957	a nonparametric regression
0.0558265757	a confidence interval
0.0558239506	to cover
0.0558179651	a mixture
0.0557954310	$ y \ in \ mathbb
0.0557899139	a noisy
0.0557707777	an index
0.0557696068	verification of
0.0557510565	trials with
0.0557290096	\ log n n
0.0557220252	stable under
0.0557099617	all variables
0.0557050130	rates of convergence of
0.0557019869	used in statistics
0.0557018440	the result holds
0.0556942057	the second method
0.0556835346	random sample of
0.0556788086	a normal distribution
0.0556550561	a direct
0.0556257502	to devise
0.0556060131	a kernel
0.0556049259	a stationary
0.0555991396	\ sum_ i =
0.0555983640	a lot
0.0555967164	increase with
0.0555921341	each pair
0.0555860640	mixtures of two
0.0555746453	a copula
0.0555698323	build on
0.0555464003	calculus of
0.0555336622	a diffusion process
0.0555187922	a multiscale
0.0555083734	novel technique
0.0555072010	a new statistical
0.0554938651	an ensemble
0.0554836622	the predictive distribution
0.0554727604	a classifier
0.0554678372	the relative entropy
0.0554623760	investigated under
0.0554375224	value at
0.0554304955	well known in
0.0554297357	the necessity
0.0554249432	sum of two
0.0554194718	s &
0.0554191225	used to demonstrate
0.0554174176	for testing
0.0554169930	reduced by
0.0554018578	deconvolution with
0.0553964322	the theory
0.0553889311	the weight
0.0553831121	p values for
0.0553783790	\ mathcal t
0.0553759493	a theoretical
0.0553580594	and bidirected
0.0553503926	a martingale
0.0553246716	any design
0.0553239166	the asymptotic results
0.0553139280	understood as
0.0552925863	the construction
0.0552868268	mu =
0.0552808848	investigation of
0.0552783101	the empirical process
0.0552716314	a discrete time
0.0552670662	this criterion
0.0552598949	\ mathcal l
0.0552509008	a gaussian approximation
0.0552414264	$ \ mathbf x
0.0552320318	a black
0.0552304009	a convex
0.0552219567	two procedures
0.0552179993	the title
0.0551855706	different choices
0.0551839776	an estimate
0.0551770460	presentation of
0.0551727346	the shape parameter
0.0551686555	the nuclear
0.0551494224	\ _ i = 1 ^
0.0551369655	the median
0.0551150520	the new model
0.0551104587	challenging to
0.0551076803	provided to
0.0551010883	^ p \ times
0.0550992214	enumeration of
0.0550982814	the output
0.0550653171	a geometric
0.0550648051	p_ \
0.0550632309	to decide whether
0.0550620458	this equivalence
0.0550479966	only provide
0.0550449751	classification using
0.0550437916	a local
0.0550402733	\ frac |
0.0550389295	the resultant
0.0550227395	a recursive
0.0550138870	to make inference
0.0550119680	a user
0.0550106109	a decision
0.0550103502	n ^ 1 \
0.0549971840	the same order
0.0549950056	vary with
0.0549849028	concavity of
0.0549820318	\ 0,1
0.0549776631	$ \ theta ^ *
0.0549758989	analysis via
0.0549741721	the limit distribution
0.0549698194	no other
0.0549609639	peaks over
0.0549567701	error bounds in
0.0549508994	the nonparametric estimation
0.0549367637	log d
0.0549270460	roles of
0.0548958472	the baseline
0.0548779743	the treatment effect
0.0548658234	any assumption
0.0548652302	$ boosting
0.0548596010	| =
0.0548556303	useful for
0.0548220597	new theoretical
0.0548178000	error rate of
0.0548138998	2 \ beta
0.0548125222	a significant
0.0548121990	a recent
0.0548085122	segments of
0.0548081049	corresponding estimator
0.0547702988	the slope
0.0547684711	the long range
0.0547605552	a minimal
0.0547516813	the second moment
0.0547286783	$ fraction of
0.0547204646	method does not
0.0547186983	guidelines for
0.0547136149	and sun
0.0547095235	the area
0.0546959846	a subset
0.0546856125	concentration of
0.0546843110	sides of
0.0546810841	a neighborhood
0.0546756485	the relevance
0.0546574259	to control
0.0546556686	estimation of parameters in
0.0546533847	\ mathbb r ^ 2
0.0546322349	value of
0.0546208299	main result of
0.0546192736	a convex optimization
0.0546151215	the vertices
0.0546115590	optimal with respect to
0.0545931987	possible to obtain
0.0545919404	very broad
0.0545836107	complicated by
0.0545794955	a graphical model
0.0545793204	discussed in
0.0545789344	the classic
0.0545764211	between different
0.0545633349	the absence
0.0545630523	a multidimensional
0.0545628533	possibility of
0.0545521255	the exposure
0.0545504303	used for estimation
0.0545444126	favorably with
0.0545392966	transition from
0.0545392740	the effective
0.0545136007	some new results
0.0545077617	robust version of
0.0544957463	result from
0.0544954099	for solving
0.0544770166	most commonly used
0.0544724234	processes via
0.0544648607	start with
0.0544560841	a review
0.0544502284	a function of
0.0544321739	an information
0.0544267995	some smoothness
0.0544234947	expectations of
0.0544037584	of freedom
0.0543835885	a hidden markov
0.0543767989	the jackknife
0.0543636734	with drift
0.0543580308	mean measure
0.0543576627	^ \ top \
0.0543485182	the first one
0.0543462542	robust with respect to
0.0543379557	u statistics of
0.0543337928	regret in
0.0543315267	cumulants of
0.0543211083	the action
0.0543142468	method over
0.0543017776	for establishing
0.0542905051	work well
0.0542823919	distribution on
0.0542822931	probability distribution on
0.0542735359	take into
0.0542733921	usage of
0.0542589042	distribution function in
0.0542580658	a sequence of independent
0.0542532623	the metric entropy
0.0542271566	m estimators with
0.0542170721	the covariance structure
0.0542109914	the typical
0.0542091025	the presence of outliers
0.0541833097	obtained in
0.0541824200	the aim
0.0541767498	architecture of
0.0541726300	grows as
0.0541628012	emergence of
0.0541604802	the random vector
0.0541554409	$ \ mathbf m
0.0541342222	any algorithm
0.0541254054	the covariance function
0.0541216429	for calculating
0.0541159652	found to
0.0541107108	diffusions with
0.0541062910	$ e
0.0541028520	the mean residual
0.0540963844	the predictor variables
0.0540825843	matrices from
0.0540785151	interpretations of
0.0540720987	region of
0.0540717182	cases such as
0.0540533999	n \ geq 1
0.0540497345	lie on
0.0540483829	to resolve
0.0540471815	the broad
0.0540269952	a simulation
0.0540208472	the nominal
0.0540156173	to confirm
0.0540067241	only known
0.0540041295	appropriate choice
0.0540032910	optimal rate in
0.0539845196	the excursion
0.0539805947	insights from
0.0539678134	the model's
0.0539649256	to model misspecification
0.0539615070	projections for
0.0539593052	the french
0.0539551406	lens of
0.0539507010	developed in
0.0539469105	\ sqrt m
0.0539376898	to check whether
0.0539366791	the holonomic
0.0539060218	concepts of
0.0538961081	a testing procedure
0.0538924978	a critical
0.0538674427	asymptotic distribution for
0.0538367386	first give
0.0538357374	a promising
0.0538306846	order to make
0.0538241518	problem at
0.0538239983	the future
0.0538226842	like to
0.0538202065	the correct
0.0538198738	the definition
0.0538138212	made by
0.0538020183	the computational cost
0.0537975895	the angular
0.0537972644	the nuisance
0.0537882171	m ^
0.0537764736	with high
0.0537719156	limits for
0.0537702988	the jump
0.0537618423	dynamics of
0.0537573407	descriptions of
0.0537220098	further extended
0.0537197097	variable x
0.0537059945	log p
0.0537051844	a new framework
0.0537000632	$ drawn
0.0536920721	the parameter vector
0.0536911731	and empirically
0.0536769024	\ subset \ mathbb r
0.0536594277	\ r
0.0536537802	of probability densities
0.0536291287	introduction of
0.0536271310	accuracy of
0.0536225679	estimators such as
0.0536184700	by means
0.0536131657	of mixture components
0.0536092476	\ gamma 1
0.0535996042	a rectangular
0.0535937248	the anomaly
0.0535936817	as possible
0.0535914796	probability of
0.0535863918	observed with
0.0535713034	grow with
0.0535469737	records in
0.0535467272	the nonparametric maximum
0.0535454948	this class of models
0.0535423191	and shephard
0.0535406298	to offer
0.0535259197	a class
0.0535225167	directly to
0.0535189094	a projection
0.0535156621	generalized least
0.0535111582	the sum of
0.0535056240	difficulty of
0.0535008838	control under
0.0534912314	log m
0.0534815783	alpha =
0.0534780746	addition to
0.0534761554	the local asymptotic
0.0534758263	l ^
0.0534528085	minimax risk of
0.0534447656	to measure
0.0534346708	in two steps
0.0534094866	$ random matrix
0.0533905531	a plug in
0.0533755514	also introduced
0.0533701966	expressed in
0.0533549175	same problem
0.0533417067	not imply
0.0533234464	the last
0.0533160915	\ mathbf e
0.0533146749	the strong law
0.0533094689	the popular
0.0533087260	the intersection
0.0533052687	converge in
0.0533034694	goodness of
0.0532975186	period of
0.0532950897	solutions of
0.0532847512	chosen from
0.0532773738	probabilities for
0.0532717553	with errors in variables
0.0532690104	the tail dependence
0.0532658838	proofs of
0.0532313847	an immediate
0.0532283084	a wavelet
0.0532005456	a counterexample
0.0531871991	optimal rate for
0.0531753382	a new measure
0.0531509405	control of
0.0531494224	\ | \ sigma \ |
0.0531459745	a nonlinear
0.0531369655	a threshold
0.0531369655	a symmetric
0.0531346555	the extent
0.0531197707	evolution of
0.0531083593	method through
0.0531069614	a multivariate normal
0.0531065438	seem to
0.0530935459	direction of
0.0530934232	jumps in
0.0530884605	the idea
0.0530876179	$ \ pmb
0.0530855956	the problem of sampling
0.0530846477	a minimax lower
0.0530706797	for investigating
0.0530686568	lies on
0.0530616723	calculated by
0.0530431303	a particular
0.0530426386	the division
0.0530349634	1 \ leq p
0.0530196001	for contingency
0.0530112715	several simulation
0.0530052687	decay of
0.0529875131	a periodic
0.0529768695	$ n \ times n
0.0529767776	any assumptions
0.0529683950	for quantifying
0.0529664128	the transition probability
0.0529605630	this new
0.0529525391	$ close to
0.0529511508	lying in
0.0529464131	$ \ mathcal c
0.0529282818	a class of estimators
0.0529254674	e _
0.0529240073	finiteness of
0.0529239998	the boundedness
0.0529238409	feasibility of
0.0529086633	the null and alternative
0.0528890740	particularly well
0.0528781193	a number of applications
0.0528744249	\ mathcal s
0.0528727315	the intensity function
0.0528536348	an entropy
0.0528506040	gg \
0.0528389102	epsilon =
0.0528181621	the explanatory
0.0528133968	the sum of independent
0.0528067261	several methods
0.0527964044	a dynamic
0.0527849678	the asymptotic behavior of
0.0527761902	a response
0.0527411681	robustness of
0.0527346141	flexibility to
0.0527178900	this formulation
0.0527121822	appears as
0.0527060841	the l1
0.0526906665	all probability
0.0526848565	the mean vector
0.0526727038	divergence from
0.0526721076	an overview of
0.0526709581	novel class
0.0526596059	to possess
0.0526572331	heavily on
0.0526473280	a theoretical study
0.0526457170	inequality under
0.0526452533	view of
0.0526442019	the general framework
0.0526386303	segmentation of
0.0526194368	the geometric structure
0.0526126663	a brief
0.0526015386	the pdf
0.0526013010	this strategy
0.0525976538	| x =
0.0525852113	the new class
0.0525838717	constrained to
0.0525818200	variables with
0.0525694626	estimation of mean
0.0525559920	the latent variables
0.0525536673	such algorithms
0.0525389892	the scale parameters
0.0525388052	the unknown distribution
0.0525386166	probability measure on
0.0525381924	q =
0.0525322965	a continuum
0.0525272428	the mode
0.0525270288	derived as
0.0525259291	vectors with
0.0525156665	a game
0.0524948115	a striking
0.0524821964	separability of
0.0524817882	the spherical
0.0524776130	a very
0.0524621503	also given
0.0524549647	a continuous time
0.0524453361	research on
0.0524445466	the statistical problem
0.0524339345	interplay of
0.0524261228	a variety
0.0524222463	time algorithms
0.0524166271	a local linear
0.0524119899	the ordinary
0.0524023670	this feature
0.0523905664	shared by
0.0523856766	not limited to
0.0523822508	a tree
0.0523810841	of particles
0.0523544992	bayesian point of
0.0523541805	the core
0.0523444916	the usefulness of
0.0523438424	used to design
0.0523380950	the diagonal
0.0523181621	the propensity
0.0522968606	other results
0.0522928096	a univariate
0.0522909996	the sharpness
0.0522903319	included to
0.0522834185	a hierarchical
0.0522798208	the intercept
0.0522637434	a reference
0.0522601844	the conventional
0.0522442004	the simplex
0.0522377758	implications of
0.0522145128	permutations of
0.0521985725	i error
0.0521985725	any set
0.0521975159	to grow
0.0521945804	same conditions
0.0521883236	the dimension of
0.0521786678	but still
0.0521655733	motivated by applications in
0.0521613324	model without
0.0521600681	far more
0.0521566396	in various settings
0.0521541597	to make
0.0521509405	power of
0.0521440397	sample complexity for
0.0521409883	constructed as
0.0521216271	the model for
0.0521164011	connected by
0.0520913244	fluctuations in
0.0520404584	foundation of
0.0520263110	problem with
0.0520088685	utilized to
0.0519938651	to employ
0.0519875131	a nonnegative
0.0519846796	\ times 2
0.0519655842	a fractional
0.0519639121	for implementing
0.0519636404	submatrix of
0.0519610079	those results
0.0519485907	or nearly
0.0519391970	small set of
0.0519264892	the dependent variable
0.0519182053	the variability
0.0519152225	the latent process
0.0519135627	to preserve
0.0519076451	certain number
0.0519074603	mean time to
0.0519071953	d ^
0.0518948924	function with respect to
0.0518828976	a trend
0.0518648607	behave as
0.0518640079	the spectral distribution
0.0518549903	the effect of
0.0518513486	a polynomial time
0.0518503263	conducted on
0.0518408348	t ^
0.0518197887	novelty of
0.0518179780	not depend
0.0518158816	the general results
0.0518001774	the second approach
0.0517981336	insights on
0.0517970339	only few
0.0517969500	a convolution
0.0517871003	the spot
0.0517791286	y_i \
0.0517615171	contaminated with
0.0517604276	of galaxies
0.0517500765	the condition number
0.0517293604	the bias and variance
0.0517287741	the spiked covariance
0.0517273227	_ k \ in \
0.0517070634	the interplay
0.0517053133	best model
0.0516996368	the second
0.0516965438	constraint on
0.0516958978	the level sets
0.0516913102	trajectory of
0.0516773494	the traditional
0.0516744409	certain assumptions
0.0516710199	not necessary
0.0516675071	a notion
0.0516574952	for comparing
0.0516528629	the excess
0.0516463270	bayesian approach for
0.0516441032	methodology for
0.0516145285	a piecewise
0.0516138337	the estimation accuracy
0.0516015483	a dense
0.0515921654	a situation
0.0515866639	attraction of
0.0515821465	novel procedure
0.0515798015	the coverage probability
0.0515772428	a subspace
0.0515657678	\ leq n
0.0515619598	hypotheses on
0.0515468212	the hierarchy
0.0515390493	then obtained
0.0515297324	a hybrid
0.0515260002	tests with
0.0515256644	a straightforward
0.0515233829	a delicate
0.0515103749	classification with
0.0515077755	singular value of
0.0515054409	$ \ mathcal f
0.0514893464	a high
0.0514891826	the practitioner
0.0514828920	this representation
0.0514806045	$ z =
0.0514785116	several results
0.0514585374	and lower bounds on
0.0514524281	the best possible
0.0514500332	a composite
0.0514491396	\ tilde \ mathcal o
0.0514325121	a multiplicative
0.0514301370	the expense
0.0514289642	t_ \
0.0514196567	to satisfy
0.0514186547	any statistical
0.0514102401	the maximum likelihood estimator of
0.0514022101	as follows
0.0513983348	space of
0.0513978920	this regime
0.0513886867	$ denote
0.0513857605	the directions of
0.0513848494	reduce to
0.0513747756	1 \ epsilon ^
0.0513686834	$ l ^
0.0513493532	level of
0.0513113117	d n
0.0512975895	the instantaneous
0.0512942539	a monotone
0.0512882016	the unconstrained
0.0512848790	rate over
0.0512614841	both finite
0.0512541635	propose here
0.0512468076	minima of
0.0512319364	a new procedure
0.0512246689	pool of
0.0512168829	the spike
0.0512147023	perform well in
0.0512119026	the incidence
0.0512056143	effort to
0.0511912475	_ 1 \
0.0511912372	an aggregation
0.0511893253	the testing procedure
0.0511885375	a metamodel
0.0511824729	\ arg \
0.0511778249	the framework of
0.0511778249	the impact of
0.0511725895	a shift
0.0511416597	even for
0.0511207764	methods like
0.0511142382	the gap
0.0511106401	the fundamental
0.0511075442	$ var
0.0511071099	the estimation procedure
0.0511045331	the test of
0.0511003378	m \ times m
0.0510975324	new bounds
0.0510785512	the realization
0.0510749035	an observed
0.0510727088	a semi
0.0510612070	commonly used for
0.0510532208	\ mathcal n
0.0510402733	\ theta +
0.0510348138	families with
0.0510348138	field on
0.0510326620	the user
0.0510270564	$ consistent and
0.0510220943	the decay rate
0.0510195196	running time of
0.0510191469	continuity of
0.0510182150	the autocorrelation
0.0509959468	estimation and inference for
0.0509893621	a rank one
0.0509883830	evaluated on
0.0509859549	vector based on
0.0509842882	the marginal distributions
0.0509841234	challenges in
0.0509811842	connectivity of
0.0509802695	the euclidean
0.0509797625	a vast
0.0509532071	the impact
0.0509387587	the full likelihood
0.0509378722	the advantage
0.0509323295	random vector in
0.0509167518	a deterministic
0.0509119715	allows to obtain
0.0509097533	a generalisation
0.0509086508	k \ in \ mathbb n
0.0508961871	fall in
0.0508929677	a benchmark
0.0508811792	the inverse covariance
0.0508787694	position of
0.0508751810	models under
0.0508634197	a low
0.0508574952	to yield
0.0508572283	favorably to
0.0508409537	the trace
0.0508180756	testing via
0.0508143009	inherent in
0.0508103576	function over
0.0508031088	minimisation of
0.0507917436	m estimators of
0.0507441899	the necessary and sufficient
0.0507199695	a novel framework
0.0507194163	converges almost
0.0507145128	parametrization of
0.0507017379	proposed for
0.0506990018	the intrinsic
0.0506988260	a multinomial
0.0506771824	$ \ mathcal q
0.0506639523	\ mathcal d
0.0506611896	$ \ widetilde o
0.0506477005	inference through
0.0506326620	the base
0.0506142069	problem in
0.0505963844	of tuning parameters
0.0505841249	a fairly
0.0505611896	n = o
0.0505377747	the binomial distribution
0.0505320047	the training
0.0505220649	regularity of
0.0505137537	the first exit time
0.0505044126	suffice for
0.0505009338	also allow
0.0504975186	columns of
0.0504967530	a factor
0.0504928992	a fully
0.0504901660	measured in
0.0504807982	no such
0.0504683950	a meaningful
0.0504594993	experiments show
0.0504527322	one important
0.0504440808	the autocovariance
0.0504357091	new ones
0.0504342882	the quantile function
0.0504289642	illusion of
0.0504259827	an empirical example
0.0504169930	limited by
0.0504085060	various estimators
0.0504075355	the periodogram
0.0504069058	to admit
0.0504028703	t n
0.0503983921	ingredient of
0.0503972644	a variational
0.0503968606	also asymptotically
0.0503960345	problems over
0.0503912709	a grid
0.0503857633	an analysis
0.0503704108	the present work
0.0503686798	in various fields
0.0503653523	a dual
0.0503626700	this type
0.0503568456	to introduce
0.0503322508	a regular
0.0502969737	positivity of
0.0502932213	the heritability
0.0502628988	conjectured to
0.0502616798	the differential equation
0.0502576461	the critical values
0.0502549470	g =
0.0502513010	with increasing
0.0502484573	models via
0.0502319860	straightforward to
0.0502236694	amount of data
0.0502173837	$ s ^ *
0.0502160824	statistics such as
0.0502138838	an integer
0.0502100643	matrix estimation for
0.0502096115	the hidden markov
0.0502063166	an operator
0.0502035151	popularity of
0.0501983348	density of
0.0501890989	correlated with
0.0501778249	the validity of
0.0501690336	the newly
0.0501632993	\ sim n
0.0501601246	likelihood estimator with
0.0501576663	a symbolic
0.0501414764	prior for
0.0501221670	the minimax estimation
0.0501123344	for assessing
0.0501105602	a microarray
0.0501034017	factorization of
0.0501003263	improvement on
0.0500879806	$ 2 ^
0.0500849518	i \
0.0500696651	a practical
0.0500485542	loss over
0.0500313896	a concrete
0.0500247949	b \
0.0500054409	$ \ mathbf p
0.0500003289	the rate function
0.0499969814	functional of interest
0.0499654420	intersection of
0.0499517776	in assessing
0.0499515901	testing if
0.0499458152	the mean integrated squared
0.0499337823	contribution of
0.0499329375	in econometrics
0.0499262233	a parametrized
0.0499244356	a directed
0.0499179677	for approximating
0.0499114993	particularly interested in
0.0499105318	for evaluating
0.0498906488	some classical
0.0498881804	a global
0.0498782808	only depend
0.0498667436	addressed in
0.0498468977	$ \ |
0.0498304419	a double
0.0498054506	$ q =
0.0498017776	some prior
0.0497942882	a group
0.0497942666	article provides
0.0497870059	in favor
0.0497786723	\ alpha |
0.0497616614	the strong law of large
0.0497558142	the relation
0.0497526377	this new distribution
0.0497464277	integral of
0.0497192803	the probability distribution
0.0497102857	some sufficient
0.0497035363	k +
0.0497035363	m +
0.0497018788	vectors from
0.0497006313	limit theorem of
0.0496909705	distribution under
0.0496874851	q \
0.0496871224	filter for
0.0496798350	recent work in
0.0496750016	function of interest
0.0496729832	the disorder
0.0496698085	\ leq j
0.0496652391	first introduced
0.0496645000	the primal
0.0496515547	the cube
0.0496466792	the convergence rates
0.0496423364	\ \ frac
0.0496322531	rate than
0.0496300605	composition of
0.0496288593	same asymptotic
0.0496265547	with missing
0.0496126663	likely to
0.0496113804	not assume
0.0495977764	study of
0.0495768446	improving on
0.0495738961	the contrary
0.0495668279	$ norm of
0.0495478031	transforms of
0.0495418589	the unobserved
0.0495337052	consider here
0.0495276856	corresponding posterior
0.0495222683	the corresponding estimators
0.0495219728	a bridge
0.0495209937	first result
0.0495048974	the confidence interval
0.0494997369	the price
0.0494977736	some numerical
0.0494844245	used to model
0.0494831938	regressions with
0.0494645587	a homogeneous
0.0494608456	the mean square error
0.0494572979	growing with
0.0494540403	arrays of
0.0494329375	and li
0.0494117300	counterpart of
0.0493997468	a collection
0.0493841676	the author's
0.0493760402	a stationary time series
0.0493510618	a kernel estimator
0.0493478987	after model
0.0493471491	lo \
0.0493444916	the concept of
0.0493422581	a limited
0.0493409537	the slow
0.0493401660	the tendency
0.0493222510	with varying
0.0493179218	\ | x
0.0493125205	quantiles under
0.0493103756	n \ right
0.0493054441	often not
0.0492949958	several estimators
0.0492925650	alignment of
0.0492881826	the maximum likelihood estimator in
0.0492816419	more power
0.0492808736	problems in
0.0492770564	to state of
0.0492760555	populations with
0.0492672911	u \
0.0492480967	schemes for
0.0492470049	directly on
0.0492465890	the covariance operator
0.0492451423	a realization
0.0492420104	the posterior probability
0.0492411681	defined in
0.0492375035	efficacy of
0.0492324435	the graphon
0.0492109718	both algorithms
0.0492098880	an invariant
0.0492058142	the mutual
0.0491956678	for measuring
0.0491802695	the intensity
0.0491745645	detection in
0.0491713767	procedures do
0.0491702311	these new
0.0491656298	a proxy
0.0491574268	insight on
0.0491491384	the transition matrix
0.0491233537	prevalence of
0.0491156298	the seminal
0.0491054454	for stationary random
0.0490954360	the end
0.0490897406	by fitting
0.0490612949	the book
0.0490539414	second algorithm
0.0490417863	dimension of
0.0490380950	a dataset
0.0490305892	models such as
0.0490291398	the computational complexity
0.0490288195	p \ gg n
0.0490271534	$ s =
0.0490207170	to deduce
0.0490193271	the new tests
0.0490160649	asymptotic normality in
0.0490096668	a new general
0.0490067015	analyses of
0.0490000146	\ tau ^
0.0489948505	arises as
0.0489594106	$ n \ rightarrow
0.0489573928	inherent to
0.0489543418	the practical performance
0.0489489998	to occur
0.0489484716	networks from
0.0489468264	a suitably
0.0489463979	the sample size goes to infinity
0.0489406888	a new nonparametric
0.0489392129	ranges of
0.0489373011	some theoretical
0.0489246604	examples such as
0.0489092447	comparable with
0.0489085389	risk of
0.0489040592	\ theta \ in \ mathbb
0.0489027947	the general setting
0.0488937002	problem of estimation of
0.0488715885	selection for
0.0488573318	the standardized
0.0488441254	datasets from
0.0488121025	\ mathcal g
0.0488061581	\ hat \ alpha
0.0487953225	justification of
0.0487734469	the measurement error
0.0487725397	$ 1 \ leq p \
0.0487705623	desirable to
0.0487654613	to support
0.0487592997	of particular interest
0.0487446933	generators of
0.0487386671	\ mathbb r ^ m
0.0487139673	\ ll n
0.0487100270	the euclidean space
0.0487054320	coefficient of
0.0487016300	\ mathbb l
0.0486824788	occurring in
0.0486801841	hierarchy of
0.0486696539	on simulated and real
0.0486606032	a union
0.0486561985	used to establish
0.0486544961	the same data
0.0486502273	very close to
0.0486372747	under regularity
0.0486285312	simulation study for
0.0486025407	functions with
0.0485972644	the essential
0.0485966515	the type i error
0.0485713991	a heuristic
0.0485635273	to search
0.0485519502	naturally in
0.0485319163	unified way
0.0485100617	for predicting
0.0485037952	expectation of
0.0484997453	$ x \ in
0.0484978304	$ \ x_i
0.0484969728	a nonconvex
0.0484968238	then used
0.0484918962	a sharper
0.0484776631	$ \ beta ^ *
0.0484652391	novel estimator
0.0484620680	then show
0.0484425009	the integrand
0.0484392129	scalability of
0.0484329375	the regressor
0.0484240073	drawback of
0.0484224808	the sign
0.0484182053	the requirement
0.0484156040	violations of
0.0484108223	a manifold
0.0484074665	expression of
0.0484065440	two related
0.0484009549	the cost function
0.0483983348	probabilities of
0.0483889461	extended by
0.0483874981	the exponential family
0.0483676603	| | \
0.0483667449	the forward
0.0483590847	benefit of
0.0483586644	superposition of
0.0483483889	investigated in
0.0483482647	sequences with
0.0483450999	the identity
0.0483333022	several classes
0.0483318166	not restricted
0.0483147850	several models
0.0483118143	influence of
0.0482908999	the state of
0.0482891424	t \ |
0.0482747506	for combining
0.0482640491	estimator under
0.0482576451	as usual
0.0482397861	the correlation structure
0.0482394584	a general framework for
0.0482280471	new efficient
0.0482121025	= \ sum_ i
0.0482110387	a quadratic
0.0482032452	some extensions
0.0482031165	a quantitative
0.0481962295	by taking into
0.0481938623	a perfect
0.0481870782	to zero
0.0481797598	to leverage
0.0481784543	adopted to
0.0481771231	used to study
0.0481666517	z \
0.0481654805	product of
0.0481634853	a second step
0.0481621225	the innovation
0.0481596927	the unique
0.0481519439	whether two
0.0481368235	more than two
0.0481220600	shown by
0.0481193209	mechanism for
0.0481034017	theories of
0.0481028716	the domain of attraction
0.0480860426	to deal
0.0480824152	below by
0.0480785693	to reveal
0.0480772262	$ f =
0.0480742100	the irrepresentable
0.0480686112	a consistent
0.0480417863	points in
0.0480409526	some previous
0.0480329653	this fundamental
0.0480223922	the existing
0.0480115611	incorporated in
0.0480102931	equation with
0.0479916527	a variant
0.0479893509	\ e
0.0479683950	for deriving
0.0479624614	the correctness
0.0479624190	more important than
0.0479556143	ingredient in
0.0479525601	the ordinary least squares
0.0479507258	measures on
0.0479455611	objects in
0.0479351773	the cumulative distribution
0.0479348818	0,1 \
0.0479227508	a permutation
0.0478994632	a desirable
0.0478862154	region for
0.0478857308	$ 1 \
0.0478681343	the computational
0.0478568892	a density function
0.0478551514	to link
0.0478515056	the student
0.0478441762	proxy for
0.0478409784	many real
0.0478395587	a separable
0.0478394263	place of
0.0478336622	the power function
0.0478281838	seek to
0.0478176317	capability of
0.0478152909	a sieve
0.0478002264	illustrated for
0.0477849678	the asymptotic distribution of
0.0477652740	zero components
0.0477605318	a mathematically
0.0477453188	the theoretical analysis
0.0477425468	most natural
0.0477192803	the probability density
0.0477187375	increase in
0.0477081003	focus on two
0.0476966529	a new model
0.0476861052	rate at
0.0476778249	a subset of
0.0476682503	underestimation of
0.0476673853	norms of
0.0476578390	p = o
0.0476568892	the error probability
0.0476496915	\ boldsymbol x ^ \
0.0475976755	to generalize
0.0475963696	the distribution of
0.0475955972	first show
0.0475888659	expansion for
0.0475882366	a perturbation
0.0475847076	the first method
0.0475842882	a point process
0.0475660715	the model of
0.0475622959	contributions of
0.0475577562	t \
0.0475554583	based on continuous time
0.0475503175	$ p n \ to \
0.0475438674	2 \
0.0475351109	for incorporating
0.0475291648	the distribution function
0.0475165916	calibration of
0.0475123344	a pivotal
0.0474964277	output of
0.0474620503	individuals in
0.0474568892	the exponential distribution
0.0474508838	variable given
0.0474497662	the mean
0.0474489431	matrices via
0.0474458187	a nontrivial
0.0474452470	essential to
0.0474419700	and also discuss
0.0474182053	the calculation
0.0474145000	the mesh
0.0474074851	rate under
0.0473859472	a proposal
0.0473691369	estimator with respect to
0.0473665179	algorithm with
0.0473292793	the number of change
0.0473252772	a weak
0.0473023632	implementations of
0.0473014755	the double
0.0472760977	new measure
0.0472661651	the limit distributions
0.0472644498	entries of
0.0472601084	works on
0.0472533886	setting with
0.0472457999	occur in
0.0472227604	the label
0.0472165737	the difference between
0.0472122311	chains with
0.0472109609	trajectories of
0.0472104360	the cumulative
0.0472089102	$ y \
0.0472071639	^ 3 \
0.0471977764	estimators in
0.0471833299	true mean
0.0471776200	and potentially
0.0471773788	and more general
0.0471684378	a subgraph
0.0471682204	quantity of
0.0471651500	various numerical
0.0471553731	a class of functions
0.0471501136	= n ^
0.0471491157	to look
0.0471408170	a greedy
0.0471286201	stated in
0.0471224757	\ frac s
0.0471175258	tool to
0.0471173592	designs under
0.0471151215	a cluster
0.0471065438	none of
0.0471018545	translation of
0.0470830300	to go
0.0470813356	but do not
0.0470764591	the optimization problem
0.0470739506	a naive
0.0470675100	m = o
0.0470624614	a stream
0.0470546803	some asymptotic
0.0470215717	this new method
0.0470213324	estimates from
0.0469970924	the issue
0.0469845408	the good performance
0.0469823149	performance over
0.0469584230	a cost
0.0469249815	a latent
0.0469168386	the recent results
0.0469005419	added to
0.0468958472	the naive
0.0468808730	y \ in \ mathbb r
0.0468765547	the auction
0.0468759827	$ m = o
0.0468742400	and hence
0.0468736324	\ le i
0.0468718786	linearity of
0.0468606029	studied from
0.0468440773	in many problems
0.0468426574	in genomics
0.0468289765	relationship with
0.0468253021	inference using
0.0468239661	the variance of
0.0468078365	$ j =
0.0467980653	the new
0.0467913437	parameters in
0.0467903615	the main contribution of
0.0467819167	the existence and uniqueness
0.0467477005	rates over
0.0467379773	any time
0.0467376898	a unified way
0.0467233038	also lead
0.0467086912	a tight
0.0467064094	the logarithmic
0.0467049218	inference with
0.0467038755	as measured
0.0467032452	at providing
0.0466983745	the problem of nonparametric
0.0466914496	settings with
0.0466778249	the basis of
0.0466661464	elements in
0.0466463422	roles in
0.0466451615	$ d = o
0.0466365785	not involve
0.0466205104	norm of
0.0466185035	note on
0.0466181476	variability of
0.0466145285	a ball
0.0466111370	a target
0.0465752295	the usage
0.0465593923	multiple time
0.0465503176	such cases
0.0465479569	foundations of
0.0465432576	a nuclear
0.0465311165	basis of
0.0465205504	$ l \
0.0465167060	some statistical
0.0465080724	new concentration
0.0464962572	comparison to
0.0464924619	models with many
0.0464687838	the same number
0.0464617859	intervals for
0.0464615367	a modification
0.0464540403	increments of
0.0464480801	z ^
0.0464395731	a summary
0.0464336340	a partition
0.0464156239	the centralized
0.0464056780	requirement of
0.0463870059	both types
0.0463790349	s =
0.0463749544	a rational
0.0463734638	approach for
0.0463497047	sampler for
0.0463486726	the heat
0.0463444916	the notion of
0.0463162494	features from
0.0463142168	not rely
0.0463131313	squares estimator in
0.0462958187	a nice
0.0462908449	constrained least
0.0462891767	demonstrated with
0.0462845889	performance in terms of
0.0462845181	monotonicity of
0.0462817241	then give
0.0462735965	that purpose
0.0462729398	for maximizing
0.0462682213	a coupling
0.0462574952	a feasible
0.0462566756	gaussians with
0.0462494249	\ hat m
0.0462272428	a multi
0.0462265646	\ mathbb h
0.0462261702	estimator with
0.0462206081	an equivalence
0.0462058142	the connection
0.0462045061	the sandwich
0.0461964972	the pre
0.0461889796	the finite sample behavior of
0.0461847113	important to
0.0461843074	neighborhoods of
0.0461778249	an estimator of
0.0461460761	minimax rate in
0.0461450975	article by
0.0461395813	6 \
0.0461349357	suite of
0.0461274106	described as
0.0461259114	attempts to
0.0461249655	z \ in
0.0461190947	a widely used
0.0461084245	need not
0.0460887301	the random forest
0.0460887247	the isotonic regression
0.0460739159	the wrong
0.0460643268	class of models for
0.0460643009	picture of
0.0460554182	a goodness of fit test for
0.0460536726	from observational
0.0460475252	the need of
0.0460310782	for modeling
0.0460252551	estimates to
0.0460157370	a variant of
0.0460100933	this paper focuses on
0.0459821504	properties such as
0.0459768695	$ n \ times p
0.0459732787	expensive to
0.0459709643	in neuroscience
0.0459707884	built in
0.0459682204	vertices of
0.0459512839	a second part
0.0459364273	\ nu \
0.0459362562	specialized to
0.0459120203	consists of two
0.0459069058	for developing
0.0459005419	starting with
0.0458904927	the harmonic
0.0458870822	locations of
0.0458866759	decompositions of
0.0458863406	work studies
0.0458738128	each model
0.0458542009	a convergence rate
0.0458494692	a scale mixture
0.0458401586	examined in
0.0458394263	suggested to
0.0458233264	purpose of
0.0458160329	procedures with
0.0458150076	a new class
0.0458121025	\ mathcal y
0.0458071728	to include
0.0458032208	\ max \
0.0458000297	same limit
0.0457861435	a companion
0.0457783943	\ rho =
0.0457690007	nearly as
0.0457649808	obtained by using
0.0457585122	solved in
0.0457507915	the inductive
0.0457456143	corollary of
0.0457416993	new class of
0.0457416269	performed to
0.0457110785	for bounding
0.0457060589	$ f ^ *
0.0456988320	integration with
0.0456937267	spectrum of
0.0456908286	value distribution
0.0456807982	into two
0.0456535825	$ n n
0.0456324325	the vast
0.0456218786	hardness of
0.0456149313	densities with
0.0456126688	new statistical
0.0456020069	the new methods
0.0455720123	the fr
0.0455639572	ij \
0.0455612949	the subcritical
0.0455522167	the generalization error
0.0455386342	\ right \
0.0455356525	$ independent random
0.0455180446	transform of
0.0455163206	taken at
0.0455144212	the estimation problem
0.0455067995	set of possible
0.0454929392	to decrease
0.0454718745	the heart
0.0454581608	the point process
0.0454369704	topology of
0.0454364930	to take into
0.0454324413	proposals for
0.0454243118	novel bayesian
0.0454178900	a remarkable
0.0454144795	the gaussian distribution
0.0454097186	a tool
0.0454089257	efficiency under
0.0453983348	size of
0.0453899206	the general class
0.0453888940	interval for
0.0453872162	introduced as
0.0453772292	solutions for
0.0453685927	a quantity
0.0453651645	back to
0.0453651645	appear to
0.0453485820	^ t \
0.0453455042	estimates under
0.0453433736	inference in
0.0453348880	for inferring
0.0453215523	the formalism
0.0453212904	the convolution
0.0453156114	recent work of
0.0453014755	the dispersion
0.0452814134	particular interest
0.0452726538	observed in
0.0452660915	\ beta ^ *
0.0452615611	lengths of
0.0452462535	many results
0.0452283084	the discrepancy
0.0452189230	coefficients of
0.0452155533	ways of
0.0452011167	phenomenon in
0.0451944096	spread of
0.0451942474	discussed by
0.0451819153	$ s ^
0.0451662773	logarithm of
0.0451626003	the minimax rate of convergence
0.0451613844	order to
0.0451521568	a unified framework for
0.0451348643	configurations of
0.0451272695	positive or
0.0451260145	reasons for
0.0451180898	a strict
0.0451163348	necessity of
0.0450929677	a nonasymptotic
0.0450899453	insight to
0.0450889846	$ n p
0.0450853853	extent to
0.0450780233	this paper provides
0.0450739899	spectra of
0.0450601109	both theoretical
0.0450489822	a finite set of
0.0450406298	a bit
0.0450308244	a truncated
0.0450291702	generalisation of
0.0450180446	expected to
0.0450132679	the utility of
0.0449999144	the projected
0.0449986193	matrix with
0.0449975186	summary of
0.0449923325	and numerically
0.0449908767	p _
0.0449866960	large set of
0.0449824663	difficulties in
0.0449662312	error of
0.0449403561	as well as under
0.0449369870	estimated with
0.0449246969	most widely used
0.0449142616	communities in
0.0449092134	good finite
0.0448784702	u ^
0.0448690219	used to describe
0.0448261794	\ eta ^
0.0448038480	$ x ^ *
0.0448037489	patterns in
0.0448037489	task in
0.0447868893	different levels of
0.0447803575	implication of
0.0447746494	$ \ x_t \
0.0447585122	dependencies in
0.0447374175	go to
0.0447282028	various types of
0.0447206081	a measurable
0.0447152740	certain threshold
0.0447147648	basis for
0.0447084464	a generalization
0.0446951234	a large set of
0.0446906665	a hierarchy
0.0446643023	$ 1 n
0.0446577255	the hyper
0.0446552131	available from
0.0446285715	the method in
0.0446215092	the distance correlation
0.0446205104	loss of
0.0446201305	met in
0.0446065438	goes to
0.0446044147	\ boldsymbol u
0.0445898930	convergence in
0.0445531911	$ \ mathbb r
0.0445470386	theoretical computer
0.0445388337	the marginal distribution
0.0445250556	property for
0.0445188537	by conditioning
0.0445151391	k \ in
0.0445149159	the sampling distribution
0.0445132679	a new approach to
0.0444941303	\ sqrt p
0.0444844782	the reason
0.0444706081	an importance
0.0444662096	requirements for
0.0444628443	between two random
0.0444553461	\ ll p
0.0444524128	$ f \
0.0444428355	the reciprocal
0.0444375770	the minimax optimal rate of
0.0444360615	the curse
0.0444059481	working in
0.0443971926	essential for
0.0443823351	the ideal
0.0443764636	to describe
0.0443723358	p \ times n
0.0443592611	contrast to
0.0443523923	presented in
0.0443419841	the general problem of
0.0443348880	for practitioners
0.0443310409	reason for
0.0443286699	x \ |
0.0443089775	often used
0.0442962616	the testing problem
0.0442833942	mean estimator
0.0442769301	$ t \
0.0442679961	root of
0.0442643783	2 ^
0.0442642732	converges in
0.0442599729	$ satisfying
0.0442546473	the extent to
0.0442492535	the accuracy of
0.0442339393	a compound
0.0442335864	the ability
0.0442310265	entry of
0.0442263189	developed under
0.0442129130	the response variables
0.0442044201	localization of
0.0441944096	constructions of
0.0441940961	a joint
0.0441893911	the novelty
0.0441889041	refinement of
0.0441768750	cardinality of
0.0441543446	kernels with
0.0441280511	the value of
0.0441178503	as well as for
0.0441173592	graphs under
0.0440651420	the determinant
0.0440556175	evaluated in
0.0440384274	the role
0.0440378562	constructed with
0.0440333400	error in
0.0440293098	the oracle properties
0.0440290345	the model in
0.0440280510	bootstrap for
0.0440160900	balls in
0.0440160746	even in
0.0440147521	the magnitude
0.0439929494	this work provides
0.0439887911	functions under
0.0439859607	vector with
0.0439851153	variability in
0.0439786778	the historical
0.0439776150	the question
0.0439702226	an introduction to
0.0439635547	the correlation matrix
0.0439540503	also applied
0.0439192042	the mean of
0.0439172666	found by
0.0438974430	action of
0.0438949726	relevance to
0.0438865394	the multivariate gaussian
0.0438767776	to lie
0.0438754086	at least two
0.0438432213	a circular
0.0438429677	for recovering
0.0438429677	the inherent
0.0438370561	provide necessary
0.0438356094	by \ cite
0.0438325595	\ sigma ^
0.0438146519	rate of convergence for
0.0438113384	take values in
0.0438019321	extend to
0.0437972422	estimator among
0.0437967530	the margin
0.0437950874	a novel bayesian
0.0437783943	\ leq p
0.0437718044	^ 2 \
0.0437371443	the difficulty
0.0437333037	adapted for
0.0437260042	$ x \
0.0437195384	the time domain
0.0436743118	for checking
0.0436613926	cdf of
0.0436475044	a fundamental problem in
0.0436399964	guarantee for
0.0436372747	to induce
0.0436206763	potential to
0.0436144013	task of
0.0436106758	methods from
0.0435988260	the fourth
0.0435954683	i n
0.0435921049	vectors to
0.0435826533	p n \ to
0.0435801850	bounds in terms of
0.0435602931	naturally to
0.0435315010	the concept
0.0435029698	applied in
0.0434970588	the general theory
0.0434892386	seen to
0.0434884196	domain of attraction of
0.0434749112	topic in
0.0434596931	^ n \
0.0434459516	performance than
0.0434444034	some useful
0.0434269139	for such problems
0.0434253175	n \ to \
0.0434160143	mse of
0.0434128256	equation for
0.0434015868	these theoretical
0.0433989291	result in
0.0433962102	the random effects
0.0433886759	a candidate
0.0433809525	the type i
0.0433784624	minimaxity of
0.0433693960	common to
0.0433677778	$ \ mathcal r
0.0433601109	most general
0.0433530656	grows with
0.0433432323	matrices under
0.0433326707	degrees of freedom of
0.0433276848	a range of
0.0433123591	a necessary and sufficient condition
0.0432876780	copulas with
0.0432810287	$ error of
0.0432524878	with state of
0.0432480397	radius of
0.0432470807	almost surely to
0.0432171658	$ s \
0.0432156238	function at
0.0431870585	recently by
0.0431824729	1 \ le i
0.0431607024	optimal number of
0.0431544446	construction of such
0.0431249655	$ e \
0.0431235121	the regression functions
0.0431181048	the same distribution
0.0431138001	possible if
0.0431045331	m \ in
0.0431003777	\ in
0.0430978987	for describing
0.0430899454	the stochastic block
0.0430880167	the same conditions
0.0430873618	a number
0.0430863406	novel statistical
0.0430845583	questions in
0.0430822938	\ leq i
0.0430808142	the relationship
0.0430676640	determinant of
0.0430647610	proposed in
0.0430489063	reported in
0.0430345862	novel framework
0.0430301899	n p
0.0430056512	the amount
0.0429898773	for exploring
0.0429898663	the pool
0.0429851153	estimations of
0.0429768695	$ \ mathbb r ^ n
0.0429742859	two sets
0.0429590924	$ w \
0.0429498448	considered under
0.0429447349	a good
0.0428995587	a challenge
0.0428989998	of producing
0.0428857539	improvement in
0.0428825130	presented by
0.0428681867	definiteness of
0.0428622201	of such estimators
0.0428536209	the most
0.0428421311	a numerical
0.0428285746	and thus
0.0428134787	first study
0.0428118959	a duality
0.0428041521	a separate
0.0428014863	done with
0.0428004628	empirical best
0.0427995587	a pseudo
0.0427779411	to come
0.0427712870	appear in
0.0427566592	gains in
0.0427537456	a logarithmic
0.0427517266	same time
0.0427492535	the setting of
0.0427489572	the interior
0.0427318037	trace of
0.0426968776	with outliers
0.0426696159	a triangular
0.0426347923	\ frac p
0.0426347624	presented as
0.0426277451	the endpoints
0.0426240394	the determination
0.0426205318	the opposite
0.0426054506	$ g =
0.0425893508	^ n \ times
0.0425559596	the almost sure
0.0425478331	assumptions such as
0.0425454359	\ ell =
0.0425395243	order one
0.0425246494	$ \ r ^ d
0.0425151391	a \ in
0.0425102631	$ 0,1 ^ d
0.0425096059	corresponding results
0.0424964854	such dependence
0.0424784948	any pair of
0.0424731089	| x \
0.0424722438	equivalence of
0.0424595101	methods used in
0.0424499875	invariant to
0.0424467159	the continuum
0.0424459991	this constraint
0.0424264938	$ 1 \ sqrt
0.0424205104	vector of
0.0424013337	the additive model
0.0423971926	choices for
0.0423771534	$ r =
0.0423771474	^ i
0.0423687878	done using
0.0423651645	to fill
0.0423444916	the construction of
0.0423444916	the choice of
0.0423444916	the sense of
0.0423430803	function in terms of
0.0423398862	stratification of
0.0423243118	an elliptical
0.0422948724	the new estimators
0.0422857345	makes use
0.0422829677	in finance
0.0422779471	$ t =
0.0422631748	a meta
0.0422626658	for reducing
0.0422305756	bounded from
0.0422284777	the ground
0.0422230903	a lack
0.0422050826	the landscape
0.0421968776	the increment
0.0421778249	the question of
0.0421684344	developments in
0.0421682213	in designing
0.0421618959	for performing
0.0421610182	the goal of
0.0421554409	$ \ mathcal l
0.0421449771	program for
0.0421260145	adjust for
0.0421110785	for improving
0.0421028188	$ j
0.0421018545	axioms of
0.0420850980	$ \ mathbb z
0.0420825868	the risk of
0.0420660715	h \ in
0.0420587102	the statistical model
0.0420584814	some real
0.0420552197	natural to
0.0420528268	$ \ bf r
0.0420507284	propose to
0.0420391300	\ mu ^
0.0420387520	the full
0.0420286264	equations with
0.0420082016	y ^
0.0420066592	degeneracy of
0.0420044967	$ t ^
0.0420030563	not much
0.0419689464	make use
0.0419681257	$ u =
0.0419568972	to outperform
0.0419561910	rates under
0.0419503175	\ in \ mathcal p
0.0419467325	the need for
0.0419247396	knowledge on
0.0419166635	provided under
0.0419074665	issue of
0.0419048856	the npmle
0.0419006908	an estimated
0.0418916261	new estimator
0.0418857539	challenge in
0.0418769144	corresponding estimators
0.0418728526	\ mathbb x
0.0418634664	the second part
0.0418499544	the driving
0.0417919706	a linear combination of
0.0417891424	\ mu =
0.0417878395	the replica
0.0417829677	the geodesic
0.0417730630	the effectiveness of
0.0417635443	the plane
0.0417378711	an important role in
0.0417318037	speed of
0.0417316411	deviation of
0.0417288089	orders of
0.0417086912	the environment
0.0417044670	an error
0.0417015386	the sieve
0.0416965081	this short
0.0416718222	of two independent
0.0416684378	the angle
0.0416554409	$ \ hat p
0.0416504500	embeddings of
0.0416504015	$ m \ times
0.0416287864	$ x ^
0.0416224757	\ leq t
0.0416015469	for such models
0.0415857539	capacity of
0.0415857539	flexibility of
0.0415758893	e \
0.0415731963	progress in
0.0415567808	\ mathbb c
0.0415461289	= q
0.0415081431	priors for
0.0414947569	the estimation of
0.0414799556	the existing results
0.0414721877	t = \
0.0414557681	indices of
0.0414541521	a coherent
0.0414503175	$ x = \
0.0414410821	the adjacency
0.0414409725	\ mathbf m
0.0414311165	shape of
0.0414216596	\ _ t
0.0414194865	distributed with
0.0414179980	this way
0.0414037804	\ theta =
0.0414024624	log s
0.0413772695	datasets with
0.0413704108	a new method for
0.0413590924	r ^ d \
0.0413589429	suboptimal in
0.0413464948	the first and second order
0.0413452382	the estimate of
0.0413424930	\ beta +
0.0413414943	explanation for
0.0413336131	to play
0.0413327089	comparing with
0.0413282034	a diagonal
0.0413244632	the superiority
0.0413199034	derived in
0.0413113384	necessary condition for
0.0412988260	the success
0.0412891424	\ hat s
0.0412829677	the asymptotical
0.0412656090	p +
0.0412515547	a complementary
0.0412515547	the emission
0.0412492666	a long
0.0412433628	gain in
0.0412428368	mixtures with
0.0412401214	sufficient to
0.0412298794	sample mean of
0.0411956126	well known to
0.0411930360	collected in
0.0411778249	the quality of
0.0411654805	coverage of
0.0411594092	a given set of
0.0411564169	a restricted
0.0411552158	_ \
0.0411394064	consistency for
0.0411191598	success of
0.0411089988	the infinitesimal
0.0411045331	d \ in
0.0411019888	a fraction
0.0411014385	\ ensuremath \
0.0410916993	this type of
0.0410841820	formulation for
0.0410832803	$ d n
0.0410717551	contrast with
0.0410631638	the development
0.0410607455	a complicated
0.0410558907	not assumed
0.0410544665	framework of
0.0410490880	$ being
0.0410349678	with application to
0.0410291521	a dictionary
0.0410262529	most efficient
0.0410151391	u \ in
0.0410006790	a lot of
0.0409967302	* \ in
0.0409848361	well as under
0.0409822919	to account
0.0409784332	the effectiveness
0.0409749112	differ in
0.0409734725	$ \ frac \
0.0409719938	width of
0.0409561486	a residual
0.0409550961	number of available
0.0409513958	computed on
0.0409441540	in developing
0.0409399064	technique to
0.0409337823	goal of
0.0409313578	in polynomial time
0.0409214175	\ varepsilon ^
0.0409162472	a certain class
0.0409059481	perturbations in
0.0409015547	a possibility
0.0408941540	for obtaining
0.0408936469	$ i
0.0408659964	error than
0.0408498853	in place of
0.0408410767	interpreted in
0.0408349729	the autoregression
0.0408267776	a multiplier
0.0408157681	partition of
0.0407928303	to fail
0.0407810181	span of
0.0407752439	to follow
0.0407734618	not asymptotically
0.0407725486	this sense
0.0407689433	results shed
0.0407683091	$ i_ \
0.0407420425	$ g ^
0.0407318037	weakly to
0.0407301208	need for
0.0407058129	to take
0.0406996681	byproduct of
0.0406884105	to shed
0.0406778249	the importance of
0.0406765845	optimal way
0.0406618959	the debiased
0.0406530656	crucial for
0.0406515331	\ lambda ^
0.0406285715	of convergence of
0.0406192542	statistic for
0.0405923087	= n
0.0405809058	the utility
0.0405805756	distributed under
0.0405776391	p \ in
0.0405654258	ability of
0.0405530056	chosen to
0.0405452382	the measure of
0.0405434443	a comparative
0.0405432661	distribution of interest
0.0405351264	exploited in
0.0405226301	to +
0.0405209480	the parametric model
0.0405130428	diverge to
0.0404965558	x_0 \
0.0404958187	a rescaled
0.0404892814	propagation of
0.0404809278	adaptivity of
0.0404769496	k = \
0.0404756633	continuous with respect to
0.0404742859	by varying
0.0404498448	models without
0.0403706872	to observe
0.0403704108	to account for
0.0403568716	scales with
0.0403479201	sure convergence of
0.0403286699	p \ |
0.0403232988	permits to
0.0403185968	$ k \
0.0403174996	the ols
0.0403165150	0 \
0.0403092851	necessary to
0.0402786551	success in
0.0402751801	outcome of
0.0402725397	\ _ n \
0.0402691540	the sdp
0.0402685212	amplitude of
0.0402481933	computed in
0.0402430518	heterogeneity in
0.0402365540	of such models
0.0401610037	occurs in
0.0401527374	and more generally
0.0401453437	$ d ^
0.0401396976	models of interest
0.0401190795	$ m \
0.0401117901	a certain class of
0.0401067951	both continuous
0.0401045331	the lasso in
0.0400942074	algorithm to
0.0400895896	the second one
0.0400867219	generalized to
0.0400746969	useful tool for
0.0400736519	the statistical and
0.0400603637	to test whether
0.0400387537	$ \ mathbf v
0.0400185306	a framework
0.0400158719	boundary of
0.0400088082	a given threshold
0.0400034343	to do
0.0399919975	$ r \
0.0399734725	n = \
0.0399502331	$ \ alpha =
0.0399447120	rates of convergence in
0.0399254561	to converge
0.0398900379	constructed to
0.0398553346	the true mean
0.0398199369	$ n \
0.0398151316	a realistic
0.0397980175	function with
0.0397941540	a distinct
0.0397878711	a numerical example
0.0397840123	a significance test for
0.0397784624	calculus for
0.0397770849	testing under
0.0397758774	element in
0.0397443667	provided with
0.0397264754	\ le n
0.0397241269	\ frac k
0.0397231957	\ mu \
0.0397213746	$ q \
0.0397213746	$ g \
0.0396778249	the parameters of
0.0396732107	by thresholding
0.0396718294	y = \
0.0396643023	a change in
0.0396519301	$ p \
0.0396475044	a large family of
0.0396356389	obtained with
0.0396273699	$ u \
0.0396185212	stated for
0.0396063963	in addition to
0.0396001660	grows to
0.0395999544	the pc
0.0395872369	dataset of
0.0395840123	a central role in
0.0395581329	case of non
0.0395496504	for handling
0.0395473361	the literature in
0.0395413067	the stationary distribution
0.0395395319	a novel algorithm
0.0395286264	works for
0.0395092247	well as other
0.0395089448	the kernel estimator
0.0395041815	succeeds with
0.0394885653	k \ in \ mathbb z
0.0394821701	freedom of
0.0394789821	test does
0.0394647289	bound of
0.0394460477	the best linear
0.0394261024	works with
0.0394254623	directions for
0.0394190960	choice for
0.0394067217	first time
0.0394053484	pi \
0.0393988287	techniques used
0.0393823156	the total number of
0.0393821248	applied to two
0.0393700032	this last
0.0393636759	a considerable
0.0393556202	\ beta =
0.0393452382	the applications of
0.0393444916	the theory of
0.0393444916	the form of
0.0393097852	to show
0.0393050394	singularity of
0.0392960098	the consistency of
0.0392819058	a list
0.0392804736	series with
0.0392791521	a fine
0.0392774873	by modeling
0.0392722577	x_1 \
0.0392642768	and then
0.0392615611	extensively in
0.0392596879	employed for
0.0392453461	\ subseteq \
0.0392321051	certain types of
0.0392143890	$ |
0.0391813603	as well as with
0.0391661505	polynomially in
0.0391660968	location of
0.0391610182	a measure of
0.0391593083	p ^
0.0391585650	tool in
0.0391372747	of normals
0.0391310925	second one
0.0391205104	observation of
0.0391117901	in light of
0.0391110290	law from
0.0391095054	class of non
0.0391082016	v \
0.0390964333	taken as
0.0390949549	with i.i.d
0.0390785626	and subsequently
0.0390755600	quantiles of
0.0390500885	the classical problem
0.0390185212	shifts in
0.0390147521	this means
0.0389910189	result on
0.0389851153	flexibility in
0.0389769496	1 + \
0.0389662312	approximation for
0.0389634160	a conjugate
0.0389623436	approach by
0.0389557681	variances of
0.0389544147	\ delta =
0.0389402305	the system's
0.0389399064	observed on
0.0389397406	a clinical
0.0389229229	a sum of
0.0389227522	setting of
0.0389212092	of y given x
0.0389118959	a surrogate
0.0388906838	$ 0 \
0.0388749544	the tangent
0.0388725542	performance via
0.0388638001	two possible
0.0388536209	the other
0.0388512014	attention on
0.0388440773	to help
0.0388089988	the discretized
0.0388086964	same distribution
0.0388054224	investigated for
0.0387998449	course of
0.0387610695	$ m n
0.0387566158	number of components in
0.0387512250	situation in
0.0387492535	the assumption of
0.0387487592	threshold for
0.0387473936	ignored in
0.0387293106	framework to
0.0387213746	$ \ epsilon \
0.0387176477	\ ^ n
0.0387165653	remains to
0.0387012049	^ * \
0.0386778249	the study of
0.0386778249	the class of
0.0386714453	$ \ gamma ^
0.0386565330	in economics
0.0386535825	\ to
0.0386525824	spaces with
0.0386472413	$ d \
0.0386205104	result of
0.0386120997	infinity with
0.0386082016	w \
0.0386062799	reduction in
0.0386047946	new family of
0.0385912371	relevance of
0.0385862041	y = x \
0.0385666635	predictor with
0.0385581199	to give
0.0385544665	cases of
0.0385454359	\ bf r
0.0385298207	and lower bounds for
0.0385151391	the lasso for
0.0385076130	with finite second
0.0384567189	role of
0.0384453221	convexity of
0.0384418832	a simulation study for
0.0384351035	a new central limit
0.0384059404	time setting
0.0384058642	the sup
0.0383843805	\ leq m
0.0383820078	sets from
0.0383819407	some logarithmic
0.0383677778	$ \ mathbb c
0.0383493757	\ alpha ^
0.0383493697	| p
0.0383489121	this article provides
0.0383424338	any such
0.0383362716	the dominant
0.0383309689	the volume of
0.0383297946	the first part of
0.0383169930	a concept
0.0382956770	process under
0.0382956139	the same way
0.0382560390	studied as
0.0382412471	selection in
0.0382401214	sets for
0.0382217225	performance of such
0.0382104868	$ 0 p
0.0382076760	the problem by
0.0382068972	a semidefinite
0.0381789015	\ mathbb n
0.0381700602	by making use
0.0381694319	univariate time
0.0381666635	errors under
0.0381623507	a generative
0.0381594092	the adequacy of
0.0381559481	meaning of
0.0381176640	fails for
0.0381170039	strength of
0.0380984009	the inner
0.0380768999	a necessary condition
0.0380492762	a non
0.0380439838	uncertainty in
0.0380420791	values for
0.0379954619	importance of
0.0379848361	$ rate of
0.0379776840	of view
0.0379734725	\ in n
0.0379450564	^ * \ in
0.0379425650	place in
0.0379360721	for finding
0.0379285982	\ cdot n
0.0379227522	statistics for
0.0378958948	the above
0.0378877998	established in
0.0378792579	just as
0.0378542159	the new approach
0.0378456686	a useful
0.0378204155	i \ in \
0.0377728477	minimum mean
0.0377423983	a new non
0.0377280073	example based
0.0377233342	published in
0.0377159041	$ \ m
0.0377053461	| _ \
0.0377045052	fill in
0.0376647063	grid of
0.0376635443	the fluctuation
0.0376475044	the main goal of
0.0376441540	and practically
0.0376281228	\ x_t \
0.0376231719	2 =
0.0376104587	recovery with
0.0376089988	the arrival
0.0376029359	a specified
0.0375942074	procedure to
0.0375720554	$ z \
0.0375718398	the derivation
0.0375684555	result by
0.0375640457	guarantees under
0.0375473361	of estimators in
0.0375015547	a batch
0.0374852470	turn to
0.0374851153	formulations of
0.0374610318	a robust version of
0.0374451234	a new concept of
0.0374415785	some known
0.0374358207	a conservative
0.0374335814	\ sigma_n \
0.0374317057	the art in
0.0374254623	inferences for
0.0374229229	$ h \ in
0.0374015547	a countable
0.0373882397	rule for
0.0373768359	applies for
0.0373729149	help to
0.0373704108	new results on
0.0373704108	in comparison to
0.0373633991	the sample complexity of
0.0373455451	almost as
0.0373358207	the geometrical
0.0373340123	in combination with
0.0373313147	g ^ \
0.0373261794	\ mathbf r
0.0373233727	procedure with
0.0373017077	from below
0.0373010510	especially in
0.0372947178	the same as
0.0372792897	significance of
0.0372656665	the enumeration
0.0372652809	do not need to
0.0372388645	computed for
0.0372109264	heart of
0.0372046137	challenge for
0.0372037441	the spirit of
0.0371954155	$ \ | \
0.0371885446	the implicit
0.0371847113	length of
0.0371729012	the large sample properties of
0.0371610182	the absence of
0.0371545752	very useful in
0.0371449097	the maximum likelihood estimator for
0.0371441634	$ \ mathbf y
0.0371404306	rate of convergence in
0.0371373160	the applicability
0.0371281796	spirit of
0.0371128260	a way
0.0371108564	$ \ hat f
0.0370945627	the particular case
0.0370801208	especially for
0.0370789529	laws for
0.0370711645	4 \
0.0370651371	numbers for
0.0370538480	$ \ mathcal u
0.0370515650	also use
0.0370487870	novel method for
0.0370395243	structure from
0.0370275269	intensity of
0.0370151645	a thorough
0.0370138543	^ m \
0.0370132679	a pair of
0.0370109223	normality for
0.0370100042	problems under
0.0370006790	an extension to
0.0369986072	extent of
0.0369967302	y \ in \
0.0369869158	$ m ^
0.0369857144	to focus on
0.0369823979	requires to
0.0369768695	$ \ mathcal n
0.0369726080	$ b ^
0.0369709717	mean squared error for
0.0369672274	a stationary time
0.0369541521	the raw
0.0369285715	the posterior of
0.0369217496	schemes with
0.0369048207	a bayesian approach to
0.0368888543	new notion of
0.0368489998	the majority
0.0368212092	1 ^ n
0.0368163134	view on
0.0368037516	end of
0.0368014234	a moderate
0.0367995645	effects in
0.0367941540	the extra
0.0367885446	for modelling
0.0367791521	a semimartingale
0.0367781078	$ k \ in \
0.0367321394	case of two
0.0367266572	the consistency and asymptotic
0.0366932887	x \ in
0.0366851153	runs in
0.0366733726	this paper gives
0.0366523811	for sequences of
0.0366089429	manifolds with
0.0366023673	rates of convergence under
0.0365757171	\ mathbf p
0.0365734547	median of
0.0365710113	kernels on
0.0365686795	this scheme
0.0365651645	except for
0.0365535184	as well as other
0.0365373891	the rate of
0.0365349678	an alternative to
0.0365286050	proposed to
0.0365046972	regions for
0.0364986075	the center
0.0364941238	arguments for
0.0364915496	the estimator's
0.0364807949	idea of
0.0364758968	t \ in t
0.0364685212	adopted in
0.0364553332	measured with
0.0364525875	solution for
0.0364461540	written in
0.0364433874	graphs from
0.0364304052	process from
0.0364056780	represented in
0.0364042803	\ theta ^
0.0363886342	$ \ mathbb p
0.0363882088	$ s = \
0.0363832259	frequently in
0.0363674909	estimation from
0.0363600788	the overall
0.0363484575	$ x_ i
0.0363414764	applications to
0.0363309689	the density of
0.0363273839	allow to
0.0363230903	value problem
0.0363222510	a nuisance
0.0362963492	in line with
0.0362959182	done in
0.0362881429	\ epsilon ^
0.0362718420	the behavior of
0.0362691540	the claim
0.0362630537	light of
0.0362624787	nodes in
0.0362562563	the relevance of
0.0362518459	the grid
0.0362432894	come with
0.0362407652	a dynamical system
0.0362233342	simplicity of
0.0362135392	the joint distribution of
0.0362100238	2 + \
0.0362083208	optimal up
0.0361958187	that end
0.0361922762	overfitting in
0.0361918202	error between
0.0361836067	the amount of
0.0361813340	aim of
0.0361778249	the cost of
0.0361680901	a pre
0.0361640902	way to
0.0361610182	the second part of
0.0361503300	t \ in \ mathbb r
0.0361254165	distributions under
0.0361112870	novel class of
0.0361031306	than or equal to
0.0360832395	a random sample from
0.0360706820	the special case of
0.0360592409	\ sigma ^ 2 \
0.0360265787	of great interest
0.0360101471	the mean and covariance
0.0360003300	\ theta = \
0.0359996319	to correct
0.0359875770	for linear spectral statistics of
0.0359715422	$ \ x_i \
0.0359554732	the method of moments
0.0359360721	a technical
0.0359251788	satisfied in
0.0359223361	of testing whether
0.0359194865	investigated to
0.0358704108	two classes of
0.0358602995	\ top
0.0358574554	rate up to
0.0358523386	above by
0.0358130409	$ \ bf x
0.0358102146	the language
0.0358053461	\ | \ cdot \ |
0.0358053461	$ s_0 \
0.0358048108	almost sure convergence of
0.0357998988	line with
0.0357909889	\ times p
0.0357836513	analyzed for
0.0357831782	includes as
0.0357824750	works in
0.0357689595	* \
0.0357605861	for determining
0.0357562563	the efficacy of
0.0357512250	mode of
0.0357329326	each such
0.0357287704	into three
0.0357236023	constants for
0.0357236023	thresholds in
0.0357129570	a mathematical
0.0357037952	question of
0.0356528327	eigenvalue of
0.0356445064	analyzed in
0.0356400009	assessed in
0.0356320934	^ * \ in \
0.0356273699	\ delta \
0.0356205104	rate for
0.0356205104	performance in
0.0356175529	the classical one
0.0356136759	the ubiquitous
0.0355870822	$ p n \ to
0.0355672056	$ \ mathcal s
0.0355663260	conditional least
0.0355656563	improved to
0.0355634518	work on
0.0355393204	$ e ^
0.0354983908	the asymptotic properties of
0.0354954619	cost of
0.0354940608	illustration of
0.0354938603	$ o \
0.0354911823	only on
0.0354886342	$ \ mathbb r ^ p
0.0354467325	a modification of
0.0354442346	empirical example
0.0354430360	randomness in
0.0354430360	successful in
0.0354350178	\ theta |
0.0354116270	described in terms of
0.0354100285	regard to
0.0354015547	the union
0.0353957460	$ y = x
0.0353819613	all such
0.0353444916	the power of
0.0353385808	error over
0.0353312723	point of
0.0353276848	the development of
0.0353106261	\ h
0.0353002815	landscape of
0.0352938201	\ rho \
0.0352871967	sensitivity of
0.0352600294	linearly in
0.0352571005	as few
0.0352562563	the idea of
0.0352540838	constructed for
0.0352445627	the amount of data
0.0352425650	proportions of
0.0352398931	$ \ theta \
0.0352219893	of large numbers for
0.0352112293	a necessary and sufficient
0.0351847568	an assumption
0.0351456471	show in particular
0.0351396368	the goodness of fit of
0.0350895896	the limit of
0.0350895896	the issue of
0.0350895896	the probability of
0.0350763047	models used in
0.0350602829	1 n ^
0.0350544665	values in
0.0350177350	exponent of
0.0350169400	the set of
0.0350156065	inclusion of
0.0349857144	for mixtures of
0.0349662312	assumption of
0.0349661417	the rapid
0.0349610318	a small set of
0.0349596931	y \ in
0.0349524281	or equal to
0.0349509201	validation for
0.0349444096	modeled in
0.0349285715	a construction of
0.0349100294	researchers in
0.0349043979	convergence for
0.0348856190	* \ in \ mathbb r
0.0348604587	interval with
0.0348496919	nonlinear time
0.0348336997	or not to
0.0348052206	process over
0.0347836513	policy for
0.0347562563	the efficiency of
0.0347516032	$ \ sqrt \ log
0.0347499062	the practical performance of
0.0347417742	in more detail
0.0347329148	bound under
0.0347256250	not depend on
0.0346938201	\ le \
0.0346931512	$ n +
0.0346910715	i \ in
0.0346831665	j \ in
0.0346819153	$ \ theta ^
0.0346819153	$ \ sigma ^
0.0346651423	the convergence of
0.0346620032	\ times d
0.0346535825	in terms of mean
0.0346482262	1 2 \
0.0346390025	n \ times p
0.0346158897	\ in e
0.0346072474	$ \ theta =
0.0345895896	the posterior mean
0.0345461066	to belong
0.0345325076	holds with
0.0345197427	useful in
0.0345160124	convergence under
0.0345119696	\ lambda =
0.0345088183	$ \ mathbf z
0.0345087092	$ \ delta =
0.0344884401	\ emph et
0.0344857144	and then in
0.0344728391	simple way
0.0344719938	issue in
0.0344705363	chain with
0.0344705363	fields on
0.0344543434	problem over
0.0344521788	an answer
0.0344514385	\ int_ \
0.0344343798	and consequently
0.0344307600	the following
0.0344245004	the logarithm
0.0344195490	continuum of
0.0344171254	theorem under
0.0344089763	the new methodology
0.0344058861	convergence than
0.0344058642	\ b
0.0343950595	used to make
0.0343773052	setup with
0.0343590924	\ phi \
0.0343589429	delay in
0.0343567789	provided for
0.0343567789	presented for
0.0343431766	to contain
0.0343426330	an analogue of
0.0343422791	the l \
0.0343318090	the analysis of
0.0343276848	an analysis of
0.0343219390	q \ in
0.0343154314	$ t_ \
0.0343094057	same way
0.0343015455	simultaneously with
0.0342667058	to know
0.0342494694	many areas of
0.0342493476	interpretation in
0.0342292504	the most widely used
0.0342193210	the asymptotic normality of
0.0342022467	do not rely on
0.0341869374	a new proof of
0.0341538636	\ _ i
0.0341523811	this estimator in
0.0341471161	over h \
0.0341036747	system with
0.0341014995	and widely used
0.0341001660	fields with
0.0340916294	samples with
0.0340895896	the solution of
0.0340768695	$ m \ times m
0.0340699549	the topic
0.0340590123	a useful tool for
0.0340475252	the course of
0.0339978375	the first two moments
0.0339967302	\ in \ z
0.0339922437	possibility to
0.0339826533	d \ to \
0.0339759075	\ omega \
0.0339722719	\ hat p
0.0339492230	v \ in
0.0339250326	the logarithm of
0.0338951369	quantification for
0.0338918036	to ask
0.0338895243	constructed on
0.0338856190	\ log ^
0.0338783642	code for
0.0338783642	tested in
0.0338618959	the familiar
0.0338598887	a new way
0.0338003175	$ \ beta \ in
0.0337959182	made on
0.0337765657	a new type
0.0337710986	as far
0.0337493476	screening for
0.0337446900	then applied to
0.0337291058	suggested for
0.0337213746	$ \ mu \
0.0337213746	\ log \
0.0337210246	performed in
0.0337031911	$ \ mathcal x
0.0336819153	$ \ gamma =
0.0336768111	holds in
0.0336559481	generator of
0.0336530537	set from
0.0336443515	a way to
0.0336257463	signs of
0.0336072677	finite second
0.0335836997	a procedure to
0.0335660715	well as for
0.0335618959	the targeted
0.0335618959	the fractal
0.0335531911	$ 1 \ sqrt n
0.0335425728	effects from
0.0335351719	as well as to
0.0335106962	lot of
0.0334996066	the corresponding estimator
0.0334697400	0 ^
0.0334601301	$ +
0.0334549950	under mild assumptions on
0.0334544201	gap in
0.0334253039	the main result of
0.0334229229	the intensity of
0.0334210372	the possibility
0.0334113926	answers to
0.0334058907	a member
0.0334035389	different choices of
0.0333817923	by making use of
0.0333470092	a pure
0.0333392708	not well
0.0333113030	the compatibility
0.0333078150	$ k ^
0.0333065730	introduced to
0.0332615273	implemented to
0.0332562563	the field of
0.0332512250	suggested in
0.0332509711	to test if
0.0332398931	$ \ alpha \
0.0332377313	considered for
0.0332336513	achieved for
0.0332110403	done for
0.0331994519	then used to
0.0331853650	\ alpha \
0.0331618902	a method for estimating
0.0331472422	convergence over
0.0331312357	to specify
0.0331284624	popularity in
0.0331190947	the relationship between
0.0331133991	an application of
0.0330926330	a necessary and sufficient condition for
0.0330788894	modified to
0.0330596394	use of
0.0330473361	of sampling from
0.0330169400	the structure of
0.0330164015	\ beta ^
0.0329836634	= 1 ^ n \
0.0329714711	a side
0.0329388598	x \ in \
0.0329265787	to distinguish between
0.0329250326	a new approach for
0.0329250326	the core of
0.0329047105	exists for
0.0328925541	\ delta_ \
0.0328878758	\ _ n
0.0328469644	not suffer from
0.0328404576	$ \ lambda \
0.0328300658	the empirical distribution of
0.0328161417	a reliable
0.0327952382	the theory to
0.0327838746	given set of
0.0327450583	key to
0.0327421681	new classes of
0.0327200538	then consider
0.0327186028	only depend on
0.0327111502	happens to
0.0326972714	in such models
0.0326930360	formulated in
0.0326866711	field of
0.0326839405	^ d \
0.0326748678	and only if
0.0326714748	the problem of nonparametric estimation of
0.0326709182	taken to
0.0326661417	the rescaled
0.0326540014	test if
0.0326045331	d \ to
0.0326002295	the lens
0.0325999273	time algorithm for
0.0325919706	a consistent estimator of
0.0325868282	\ eta \
0.0325859798	\ sigma =
0.0325745279	\ alpha =
0.0325522663	a small subset of
0.0325099660	put on
0.0325082012	the description of
0.0325082012	the decomposition of
0.0324922437	reciprocal of
0.0324852033	the regression function in
0.0324828084	the noiseless
0.0324688049	formalism of
0.0324338437	an arbitrary number of
0.0324333013	parallel to
0.0324145156	some finite
0.0324004730	experiment with
0.0323876559	detection under
0.0323830315	a linear regression model with
0.0323785715	the value at
0.0323715192	a theoretical point of
0.0323677397	exist for
0.0323508176	$ \ beta =
0.0323485820	$ v \
0.0323358207	the proximity
0.0323309689	the bias of
0.0323309689	the smoothness of
0.0323223592	appear as
0.0323179218	\ widehat \
0.0323126798	$ i \
0.0323106261	3 \
0.0322824750	perspective of
0.0322512250	needed in
0.0322210199	to put
0.0322100238	^ 2 + \
0.0321962092	$ \ | x \ |
0.0321833500	$ \ lambda =
0.0321748097	domain of
0.0321089429	stream of
0.0320984286	in various applications
0.0320981740	interest in
0.0320981622	under mild conditions on
0.0320903433	allowing to
0.0320895896	the introduction of
0.0320895896	the strength of
0.0320895896	the possibility of
0.0320836997	of one or
0.0320780593	diverges to
0.0320621767	both theoretically and
0.0320539827	to assume
0.0320266220	c \ in
0.0320138543	to zero at
0.0320136759	the logit
0.0320119191	\ | ^
0.0319911356	not affected by
0.0319828871	$ y = x \
0.0319747882	s \
0.0319677724	to infinity with
0.0319661417	the eigen
0.0319640028	$ k \ in
0.0319535342	question in
0.0319452491	$ f ^
0.0319308594	the relation between
0.0319250326	with values in
0.0319213492	a complete characterization of
0.0319082209	but also for
0.0318949771	covariation of
0.0318945886	n ^ \
0.0318838492	often used to
0.0318824942	some particular
0.0318246503	a connection between
0.0318205363	found in
0.0318161417	for identifying
0.0318108870	a unified approach to
0.0317724601	also known
0.0317689595	^ 2 =
0.0317562563	the domain of attraction of
0.0317556175	coordinates of
0.0317512832	\ kappa \
0.0317265879	optimal in terms of
0.0317236023	treated in
0.0317213746	$ \ hat \
0.0317213746	\ infty \
0.0317205796	grow to
0.0317116216	a challenging
0.0317046064	$ \ boldsymbol x
0.0317038633	dimensionality of
0.0316910715	$ \ mathbf \
0.0316819153	\ gamma \
0.0316643023	the inverse of
0.0316571430	first part of
0.0316373875	to depend on
0.0316173096	$ \ x_i \ _ i
0.0316151853	naturally from
0.0316143492	appropriate choice of
0.0316023386	to appear
0.0316013244	the interplay between
0.0315840401	an overall
0.0315704155	s \ in
0.0315641077	only depends on
0.0315533517	considered to
0.0315452382	the convergence in
0.0315450849	\ cdot \
0.0315329917	interest in many
0.0315206872	the frame
0.0315196642	\ mapsto \
0.0315181610	an algorithm for
0.0315152487	new proof of
0.0315042329	the literature as
0.0315014810	support of
0.0314967302	m \ in \
0.0314930210	$ c ^ \
0.0314705796	motion with
0.0314586372	the asymptotic behaviour of
0.0314486774	for example in
0.0314422762	hull of
0.0313800408	$ | \
0.0313747171	the true number of
0.0313695304	mean squared error of
0.0313590924	\ varepsilon \
0.0313541531	much attention in
0.0313276848	a combination of
0.0313112750	least one of
0.0313086964	a plug
0.0312939602	over classes of
0.0312527975	with probability tending to
0.0312420425	a simple way
0.0312295331	$ k = \
0.0312273052	findings with
0.0312214333	this latter
0.0312119049	of distributions on
0.0312119049	a law of
0.0312087457	result to
0.0311734618	the companion
0.0311659866	$ y \ in \
0.0311249655	f \ in \
0.0311081727	hold with
0.0310895896	a vector of
0.0310895896	the ability of
0.0310895896	the supremum of
0.0310870992	show here
0.0310750326	two sets of
0.0310672406	recovery in
0.0310632342	source of
0.0310473361	of view of
0.0310473361	of solutions of
0.0310300658	the conditional distribution of
0.0310206872	the intuition
0.0310138543	\ sqrt n \
0.0310131933	achieved in
0.0309948789	understood in
0.0309628758	$ \ mathbb z ^
0.0309535342	review of
0.0309483917	in order to make
0.0309364141	$ p \ times p
0.0309232342	importance in
0.0309201716	and asymptotic normality for
0.0309123332	new approach for
0.0309089632	demonstrated to
0.0308783642	adjustment for
0.0308777766	reliability of
0.0308704619	introduced for
0.0308704619	studied for
0.0308522810	well studied in
0.0308514944	a neighborhood of
0.0308138543	$ \ nu \
0.0307993757	$ z ^
0.0307888598	$ i \ in
0.0307562563	a notion of
0.0307421943	$ 0,1 ^
0.0307213746	\ theta \
0.0306954155	t \ in
0.0306435526	specification for
0.0306428226	\ in \ r
0.0306409846	problem of testing for
0.0306269496	\ sqrt \
0.0306269496	r ^ n \
0.0306219893	$ \ r ^
0.0306143509	1 ^
0.0305993457	strategy to
0.0305585028	\ cdots \
0.0305475252	the same rate as
0.0305300119	such as lasso
0.0305190248	provided in
0.0305161356	to cope with
0.0304943515	the length of
0.0304866853	both simulated and
0.0304848361	to infinity as
0.0304726309	$ i =
0.0304640028	of decay of
0.0304229229	the sparsity of
0.0304229229	the boundary of
0.0304050713	to derive new
0.0303893177	dimensional mean
0.0303889298	tomography with
0.0303832395	a general approach to
0.0303744678	a very large
0.0303476517	the empirical performance of
0.0303304321	the convergence rate of
0.0303276848	the task of
0.0303223592	comes with
0.0303219390	$ \ sqrt n \
0.0302932894	going to
0.0302824750	conjecture of
0.0302516267	first consider
0.0302448789	benchmark for
0.0302373487	a special case of
0.0301916956	viewpoint of
0.0301841109	\ ell \
0.0301661754	the extreme value
0.0301443875	question by
0.0301428226	$ l ^ \
0.0301056557	y \
0.0300895896	the rate of convergence of
0.0300895896	the difficulty of
0.0300473361	for changes in
0.0300136759	the parent
0.0299758968	$ p n \
0.0299409463	to infinity at
0.0299388598	$ n \ to
0.0299335814	\ exp \
0.0299249206	a real example
0.0299242354	same as
0.0299135802	\ frac n
0.0298862123	order to show
0.0298647857	^ k \
0.0298585499	the minimax rates of
0.0298497348	$ \ mathbf r
0.0298100238	i = 1 ^ n \
0.0298053461	\ widetilde \
0.0297619921	the central limit theorem for
0.0297512250	characterized in
0.0297401574	$ \ delta \
0.0297212092	$ \ hat m
0.0297104868	$ \ mathcal d
0.0297104868	\ lambda \
0.0297027820	$ r ^ d
0.0296867303	p ^ *
0.0296768111	required in
0.0296729868	\ r ^ d
0.0296535825	the least
0.0296482397	proved in
0.0295923745	combination with
0.0295720554	\ beta \
0.0295515709	simple to
0.0295394496	$ \ mathbb l ^
0.0295324603	with zero mean and
0.0295044967	$ \ sigma =
0.0294943515	the shape of
0.0294911519	$ t \ in
0.0294799393	an optimal choice of
0.0294640195	the plug
0.0294600628	$ m \ times n
0.0294486774	this result for
0.0294273330	the covariance matrix in
0.0294259827	a natural way
0.0294253039	the limit distribution of
0.0294229229	a framework for
0.0293493798	the name
0.0293363545	$ \ sum_ i =
0.0293219390	\ log n \
0.0292676698	new characterization of
0.0292583193	the maximum of
0.0292571894	quickly as
0.0292498875	the representation of
0.0292336100	a class of non
0.0292224775	to allow
0.0292219893	a strong law of
0.0292046771	\ leq \
0.0291686997	using tools from
0.0291610182	the magnitude of
0.0291610182	the scope of
0.0291540014	structure between
0.0291303461	not possible to
0.0290932909	missing at
0.0290895896	the degree of
0.0290750316	to lie in
0.0290712092	$ \ mathbb l
0.0290678573	for dealing with
0.0290653853	no assumptions on
0.0290553919	the first part
0.0290487870	\ gamma ^
0.0290444433	adaptation of
0.0290426377	x \ in \ mathbb r
0.0290259827	given samples from
0.0289800658	the test statistic under
0.0289593044	\ subset \
0.0289437563	some properties of
0.0289343044	the aid of
0.0289274008	this problem in
0.0289229229	an estimator for
0.0289223361	\ beta \ in
0.0289049950	an attempt to
0.0289049359	the available data
0.0288989897	challenge of
0.0288903833	this kind of
0.0288788251	without loss of
0.0288647141	a necessary and
0.0288455681	$ 1 \ leq p
0.0288422791	a l \
0.0288164904	often used for
0.0287658454	and therefore
0.0287654558	law for
0.0287562563	the advantage of
0.0287342379	of communities in
0.0287264866	^ \ infty \
0.0287066586	second part of
0.0286869374	a novel approach to
0.0286839405	$ y = \
0.0286613926	normality under
0.0286257463	gaussianity of
0.0285974410	rate as
0.0285735700	a whole
0.0285580998	center of
0.0285211218	value decomposition of
0.0285204072	point of view of
0.0285181610	a kind of
0.0284943515	the location of
0.0284943515	the expectation of
0.0284640028	the necessary and
0.0284590412	to depend
0.0284567706	le \
0.0284549954	a great deal of
0.0284539130	interior of
0.0284467325	a subclass of
0.0284332404	the convex hull of
0.0283945886	n \ in \
0.0283840649	the help
0.0283727965	the average number of
0.0283556369	filters for
0.0283360451	least squares estimator in
0.0283304619	developed to
0.0283168360	certain class of
0.0283090817	of interest in
0.0283052619	$ \ theta_ \
0.0282707209	the signal to
0.0282641177	work by
0.0282448789	paradigm for
0.0282348498	to see
0.0282293764	posed in
0.0282281260	time series with
0.0282035342	hold in
0.0281645316	$ n \ in
0.0281610182	the influence of
0.0281610182	the equality of
0.0281052619	+ 2 \
0.0280895896	the law of
0.0280885040	$ y \ in
0.0280870992	show through
0.0280715730	also used to
0.0280559578	\ big \
0.0280549312	$ \ gamma \
0.0280268662	the tail index of
0.0280259827	as measured by
0.0280077525	\ beta \ |
0.0280076065	fit to
0.0279518048	the mean value
0.0279416956	rest of
0.0279388598	$ x \ in \
0.0279224080	give conditions under
0.0278849042	points to
0.0278381651	the associated
0.0277950516	$ \ rho \
0.0277947178	the complexity of
0.0277930265	known results on
0.0277749206	with probability at least
0.0277562563	the product of
0.0277562563	the computation of
0.0277288046	2 \ log n
0.0277161754	the model to
0.0277144631	a sufficient condition for
0.0276651423	the sequence of
0.0276583649	new approach to
0.0276274337	not based on
0.0276063201	$ x_i \
0.0275898811	for inference in
0.0275692250	to work with
0.0275571776	$ \ theta \ in
0.0275089457	the need to
0.0275082012	the expansion of
0.0275071878	\ tilde \
0.0274958391	autoregressive time
0.0274229229	an example of
0.0274203023	further extended to
0.0273832395	an unbiased estimator of
0.0273729229	the empirical mean
0.0273491718	+ \ sigma \
0.0273480469	infinity at
0.0273381651	the best
0.0273309972	new concept of
0.0273304321	the covariance matrix of
0.0272936832	between pairs of
0.0272771534	\ frac \
0.0272630071	help of
0.0272356992	a second
0.0272212092	$ \ sqrt t
0.0272199549	a difficult
0.0271983480	problem under
0.0271813167	two kinds of
0.0271734618	a tradeoff
0.0271610820	$ \ mathbb x
0.0271609883	by conditioning on
0.0271432550	n \ to
0.0271305677	not lead to
0.0271242182	$ n p \
0.0270963492	this paper aims to
0.0270822926	the fr \
0.0270128758	$ \ mathcal e
0.0270071878	\ mathbf y \
0.0270071878	\ | _ \
0.0270071878	\ boldsymbol \
0.0269967325	the computational complexity of
0.0269836634	$ \ mathbb e \
0.0269697198	\ l
0.0269456360	with at most
0.0269416956	aid of
0.0269343601	the first two
0.0269223361	of goodness of
0.0269083649	to adapt to
0.0268933571	$ \ | \ cdot \
0.0268926377	both parametric and
0.0268878758	\ times n
0.0268626075	more general than
0.0268497348	$ \ mu =
0.0268452382	of groups of
0.0268335822	adequacy of
0.0268285849	grow as
0.0267781078	of order k
0.0267769424	known from
0.0267624152	one way to
0.0267562563	the geometry of
0.0267562563	a method of
0.0267144631	the transition density of
0.0267120822	the diameter of
0.0266869374	a continuum of
0.0266666850	made to
0.0266443515	an approximation of
0.0266424150	the detection of
0.0266126823	$ x_0 \
0.0265832395	a weighted sum of
0.0265696547	the last two
0.0265563883	a serious
0.0265324750	utility of
0.0265286176	the superior performance of
0.0265082012	the variance in
0.0265082012	the point of
0.0265044967	$ \ lambda ^
0.0264943515	a prior on
0.0264581139	the lens of
0.0264116403	this problem with
0.0263832395	the exact distribution of
0.0263683011	in comparison with
0.0263442425	these different
0.0263410858	\ theta \ |
0.0263395672	in \ r
0.0263380410	$ t \ to
0.0263337236	the asymptotic mean
0.0263291834	2 \ log p
0.0263277487	\ hat \
0.0263219390	\ epsilon \
0.0263078365	\ xi \
0.0263011057	t \ to
0.0262741595	no more
0.0262598432	or less
0.0262540014	bounds over
0.0262498875	the control of
0.0262397141	of probability distributions on
0.0262371812	an order of
0.0262046771	\ mathbb r ^ d \
0.0261998875	the method to
0.0261647289	sense of
0.0261610820	$ \ boldsymbol \
0.0261317224	the main interest
0.0261257463	generality of
0.0261238730	give sufficient conditions for
0.0260895896	a test for
0.0260894196	both synthetic and
0.0260741293	any assumptions on
0.0260603637	both types of
0.0260540542	not only for
0.0260412700	this problem by
0.0259850980	$ \ mathbf s
0.0259825407	mean zero and
0.0259498875	the interpretation of
0.0259498875	the extension of
0.0259418661	\ u
0.0259223361	of attraction of
0.0259023811	and uniqueness of
0.0258989897	ball of
0.0258699866	the case of non
0.0258661692	the divide and
0.0258300658	the dependence structure of
0.0257935570	an adaptation of
0.0257888598	the same order of
0.0257821620	but also on
0.0257562563	the proportion of
0.0257423745	impacts of
0.0257144631	a probability measure on
0.0256619853	the optimal value
0.0256601639	the sample size goes to
0.0256469034	\ sigma \
0.0256424150	the method of
0.0256081139	different sets of
0.0256018335	approaches to
0.0255811970	several classes of
0.0255740979	$ f \ in
0.0255477965	the prediction error of
0.0255477965	the generalization error of
0.0255475252	$ x_0 \ in
0.0255339544	described in
0.0255320107	the algorithm to
0.0255214658	not rely on
0.0254964612	a review of
0.0254783620	the main advantage of
0.0254195026	the theoretical side
0.0254022467	no assumption on
0.0253787488	a new notion of
0.0253563201	$ \ ell_ \
0.0253485820	\ times \
0.0253219390	$ \ omega \
0.0253047150	any non
0.0252987300	a necessary
0.0252960098	the eigenvalues of
0.0252939602	new generalization of
0.0252771534	$ c \
0.0252742182	a change of
0.0252640687	$ out of
0.0252492262	the most commonly used
0.0252466034	an empirical application to
0.0252394147	used in many
0.0252384711	$ r ^
0.0252321051	any assumption on
0.0252226080	the true value
0.0252144631	the problem of parameter estimation for
0.0252027110	different approaches to
0.0251946600	the null hypothesis of
0.0251717075	the impacts of
0.0250716621	a crucial role in
0.0250444501	not need to
0.0250371506	\ 0,1 \
0.0250332209	not only on
0.0250169400	the level of
0.0249982948	the other two
0.0249626765	a method for
0.0249416956	language of
0.0249300658	an approximation to
0.0249049393	an important problem in
0.0248574603	both real and
0.0247718849	time algorithms for
0.0247636668	as part of
0.0247144631	a general theory of
0.0247100238	\ mathbb e \
0.0247087312	the test under
0.0246994219	the connection between
0.0246836067	the literature on
0.0246836067	the advantages of
0.0246332012	of products of
0.0245692250	a new framework for
0.0245690823	least squares estimators of
0.0245685814	work well in
0.0245332209	the case with
0.0244711641	the change in
0.0244596931	a number of different
0.0244404598	estimator as well as
0.0244251498	the singular value
0.0243711252	in particular to
0.0243681766	first work
0.0243681766	* where
0.0243609883	also applies to
0.0243064172	the condition number of
0.0242963492	a small fraction of
0.0242898132	the conditional mean
0.0242801784	made for
0.0242678919	the optimal number of
0.0242640687	$ n = \
0.0242635268	the direction of
0.0242200541	to converge at
0.0242016344	this result to
0.0241823453	given to
0.0241755227	these results by
0.0241051377	different values of
0.0240031229	the ordinary least
0.0239909463	with unknown mean
0.0239870822	$ \ mathbb n
0.0239741787	a trade
0.0239711641	the bootstrap for
0.0239701508	\ sim \
0.0239681766	infinity as
0.0239297150	or near
0.0239229229	the topology of
0.0238859877	the statistical properties of
0.0238645259	$ \ log n
0.0238328421	the h \
0.0238105825	least one
0.0237980278	of size n
0.0237562563	the design of
0.0237557407	the tradeoff between
0.0237419126	for model selection and
0.0237162204	\ leq p \
0.0236836067	the definition of
0.0236659866	$ \ mu \ in
0.0236651423	the components of
0.0236637654	the posterior distribution of
0.0236541858	the mean or
0.0236311298	a random number of
0.0236217325	the marginal distribution of
0.0236041321	$ \ theta \ in \
0.0235336641	$ \ log p
0.0235088561	the maximum mean
0.0235003858	known results for
0.0234930210	$ \ chi ^
0.0234911519	the mode of
0.0233372806	give conditions for
0.0233318090	the family of
0.0233297946	the cone of
0.0233295856	often used in
0.0233250347	a general approach for
0.0233216621	under weak assumptions on
0.0233181746	an important class of
0.0233162204	\ lim_ n \ to
0.0233090817	the optimality of
0.0233011057	$ n \ in \
0.0232977965	a parametric family of
0.0232948634	to zero as
0.0232888598	both theoretical and
0.0232640687	$ d \ in
0.0232205170	two versions of
0.0232132450	the probabilities of
0.0231908772	the difference of
0.0231509960	\ star \
0.0231373875	of interest for
0.0231198453	a sub
0.0231149855	\ left \
0.0231066516	the way to
0.0231063201	\ geq \
0.0230540542	a bound for
0.0230432887	the usage of
0.0230361971	as special cases of
0.0230351382	an illustration of
0.0230351382	the bandwidth of
0.0230202500	to many other
0.0230103356	mean square error of
0.0230003094	new methods for
0.0229989593	a formula for
0.0229757484	the distance between
0.0229731268	to grow with
0.0229731268	to increase with
0.0229671628	for testing whether
0.0229397685	the optimal rates of
0.0229397685	the theoretical analysis of
0.0229112554	least squares estimator of
0.0229060564	the asymptotic theory for
0.0228939878	useful to
0.0228647857	\ mathbb p \
0.0228332540	any knowledge of
0.0228328421	the r \
0.0228103465	\ in t
0.0227890109	the nonparametric estimation of
0.0227792313	\ rightarrow \
0.0227612679	new type of
0.0227562563	a consequence of
0.0226836067	a characterization of
0.0226610182	the success of
0.0226269496	\ mathbb r ^ n \
0.0226165542	the target of
0.0225931746	an asymptotic analysis of
0.0225846528	not assumed to
0.0225571776	the language of
0.0225445555	$ \ sum_ i
0.0225273811	for sampling from
0.0224457082	both continuous and
0.0224229229	the superiority of
0.0224161754	the case for
0.0224080546	a form of
0.0224051477	the unknown mean
0.0223992726	second moment of
0.0223873875	the matrix of
0.0223815434	a matrix of
0.0223753679	the sample size n
0.0223682353	with errors in
0.0223502734	the applicability of
0.0223329137	not make
0.0223318090	the application of
0.0223011057	\ mu \ in
0.0223005530	new estimator for
0.0222920412	a recent work
0.0222494694	same rate as
0.0222406510	and sometimes
0.0222132450	the derivative of
0.0221999206	a fundamental role in
0.0221713492	a rich class of
0.0221450286	the statistical performance of
0.0220919706	the asymptotic variance of
0.0220765915	the gap between
0.0220693241	mean function and
0.0220616853	an oracle inequality for
0.0220475252	the cardinality of
0.0220351382	of convergence for
0.0220254316	in relation to
0.0220161519	some results on
0.0219711641	a property of
0.0219647685	the posterior distribution in
0.0219550658	a random sample of
0.0218895896	the sample mean
0.0217893204	a list of
0.0217888598	\ theta \ in
0.0217851382	the case of two
0.0217562563	a result of
0.0217343143	the mean and variance of
0.0217185814	more robust to
0.0217173424	a general theory for
0.0217019927	the benefits of
0.0216836067	the behaviour of
0.0216610182	the reliability of
0.0216444792	the existing literature on
0.0216424150	the proof of
0.0216209831	the case in
0.0216165542	the degrees of
0.0215692250	a new generalization of
0.0215690477	in applications such as
0.0215633022	given in terms of
0.0215373891	the error of
0.0215016267	an associated
0.0214999206	an answer to
0.0214769933	new framework for
0.0214399849	the numbers of
0.0214397685	least squares estimator for
0.0214231018	the loss function and
0.0214229229	a bound on
0.0213918164	the recovery of
0.0213505258	particular case of
0.0213348277	the rate at
0.0212992106	the mean squared error of
0.0212971278	the best known
0.0212445304	a flexible and
0.0212120822	the failure of
0.0211999206	a key role in
0.0211746379	some extensions of
0.0211567517	new method to
0.0211378308	for detection of
0.0211242182	\ gamma \ in
0.0211221931	the cdf of
0.0211212115	for equality of
0.0210895896	the output of
0.0210708524	the median of
0.0210366853	this gap by
0.0209670856	an expression for
0.0209343044	a member of
0.0208970127	the interaction between
0.0208923266	\ ge \
0.0208844390	of convergence under
0.0208656510	example from
0.0208514944	a factor of
0.0208482948	a conjecture of
0.0208422791	the moments of
0.0208203879	an estimation of
0.0207562563	the regularity of
0.0207457540	certain classes of
0.0207251498	the property of
0.0207051698	$ \ sigma \
0.0206836067	the parameter of interest
0.0206664473	in many areas of
0.0206645316	on simulated and
0.0206610182	the perspective of
0.0206436272	good performance of
0.0206431038	with emphasis on
0.0206311298	a general method for
0.0206241877	least squares estimators for
0.0206107490	a corollary of
0.0206009711	a generalisation of
0.0205850097	of interest to
0.0205186594	the tail of
0.0205070887	also applied to
0.0205037488	the first two moments of
0.0204943515	the variability of
0.0204795524	$ 2 \
0.0204711641	the coefficient of
0.0204707029	a survey of
0.0204528637	in order to show
0.0204528637	used to show
0.0204526848	the center of
0.0204342003	a general family of
0.0204229229	the implications of
0.0203787488	a realization of
0.0203759062	quantification in
0.0203753979	the local time
0.0203623875	the decay of
0.0203481284	sense over
0.0203416956	favor of
0.0203328421	a representation of
0.0203322926	the literature for
0.0203283070	the search for
0.0202251498	the dependence on
0.0201938611	by applications to
0.0201654337	cone of
0.0201450286	the conditional expectation of
0.0201449522	an optimal rate of
0.0200916956	beginning of
0.0200895896	the consistency and
0.0200515687	the modulus of
0.0200475252	the precision of
0.0200324603	a stream of
0.0200075439	a way of
0.0200003979	to improve on
0.0199911519	a hierarchy of
0.0199764944	the particular case of
0.0199753979	the goodness of
0.0199343601	new results for
0.0199279953	at zero and
0.0199231018	the minimax rate for
0.0199143204	a long time
0.0199049393	the causal effect of
0.0198992262	necessary conditions for
0.0198992262	then extended to
0.0198681414	work under
0.0198459590	new method for
0.0198256124	the approximation of
0.0197731018	the asymptotic efficiency of
0.0197562563	the entries of
0.0197078421	this approach to
0.0197061272	to belong to
0.0196703879	the basis for
0.0196635031	new algorithm for
0.0196304611	several examples of
0.0196170856	an array of
0.0195765079	a statistical test for
0.0195732253	the first non
0.0195692250	a new estimator for
0.0195571776	the same set of
0.0195515709	derived to
0.0195499206	necessary and sufficient conditions on
0.0195328186	a new algorithm for
0.0195300434	the hessian of
0.0195273811	of independence between
0.0195123875	a space of
0.0194628758	necessary and sufficient condition for
0.0194528637	show consistency of
0.0194399849	the parameters of interest
0.0194365301	a comparison with
0.0194249306	by use of
0.0194231018	a regression model with
0.0194213492	a natural extension of
0.0193695304	to converge to
0.0193623875	the expression of
0.0193620822	the equality of two
0.0193407937	using data from
0.0193395259	the norm of
0.0193345357	first two moments of
0.0192971278	a discussion of
0.0192640687	of nodes in
0.0192363900	to allow for
0.0192336584	the parameter of
0.0192251498	the type of
0.0191571537	the increments of
0.0191398132	the robustness of
0.0191398132	the identifiability of
0.0191311298	a finite mixture of
0.0191161519	the interior of
0.0191161519	the reciprocal of
0.0191125191	the asymptotic normality for
0.0191066516	this method to
0.0190923659	the link between
0.0190346528	some conditions on
0.0190327552	a version of
0.0190123875	a functional of
0.0189756855	to perform well
0.0189626765	the derivation of
0.0189540030	the characteristic function of
0.0189069334	the classical problem of
0.0188796825	the emergence of
0.0188176171	a data set of
0.0188064799	the performances of
0.0187888598	the mle in
0.0187562563	a solution to
0.0187175434	$ \ tilde \
0.0187099554	the generality of
0.0186899849	the dependence between
0.0186790819	\ log p \
0.0186263653	the proof relies on
0.0186090576	a comparison between
0.0185025557	in connection with
0.0184997806	the necessity of
0.0184995087	the derivatives of
0.0184995087	the combination of
0.0184943515	the significance of
0.0184731466	the lack of
0.0184578421	the proofs of
0.0184494853	the light of
0.0184446620	the majority of
0.0183686594	the domain of
0.0183620822	the ratio of two
0.0183503979	the density function of
0.0183396603	the columns of
0.0183295524	the first and second
0.0183295524	the mean square error of
0.0183070887	also shown to
0.0182965783	a method to
0.0182635268	the feasibility of
0.0182132450	the eigenvectors of
0.0181899849	a h \
0.0181331757	a data example
0.0181280511	the dynamics of
0.0181245087	the neighborhood of
0.0181101996	the fundamental limits of
0.0181066516	and robustness of
0.0180711456	of convergence in
0.0180540542	the sample mean and
0.0180454155	the trace of
0.0180353260	the evolution of
0.0180254316	the intersection of
0.0180145316	on synthetic and
0.0180088608	the strong consistency of
0.0179922791	the nature of
0.0179494853	a novel method for
0.0179457639	any number of
0.0179307429	the computational cost of
0.0179279953	an algorithm to
0.0179220002	some form of
0.0179135268	a test of
0.0179069334	the inverse problem of
0.0178922810	a concept of
0.0178873875	the uncertainty in
0.0178660037	the theoretical properties of
0.0178457209	this question in
0.0178422791	the collection of
0.0178328421	the elements of
0.0178296925	to search for
0.0178195518	the coefficients of
0.0178061162	\ sigma = \
0.0177676377	the vicinity of
0.0177636668	in contrast with
0.0177402667	the uniform distribution on
0.0177343143	the inclusion of
0.0176623056	made in
0.0176266220	a question of
0.0176231466	the average of
0.0176015915	the distribution function of
0.0175945887	and many other
0.0175870822	the viewpoint of
0.0175372824	the vector of
0.0175292903	this results in
0.0175186594	an approach to
0.0174943515	the integral of
0.0174389110	an efficient algorithm for
0.0173837523	also apply to
0.0173315667	the asymptotic expansion of
0.0173123875	the bias in
0.0173070887	as compared to
0.0172995087	a choice of
0.0172901463	new way
0.0172315434	the history of
0.0171509505	a confidence interval for
0.0171461538	the convergence rates of
0.0170895896	the objective of
0.0170749206	of practical interest
0.0170632450	the reconstruction of
0.0170480201	the almost sure convergence of
0.0170294790	of convergence as
0.0169966745	the same number of
0.0169922791	the knowledge of
0.0169825407	a loss of
0.0169626765	the fraction of
0.0169414473	two families of
0.0169069334	the spectral distribution of
0.0168422791	the stability of
0.0168328421	the solutions of
0.0168296925	a new method to
0.0167402667	the operator norm of
0.0167343143	the mle for
0.0167343143	the speed of
0.0166670524	two estimators of
0.0166462191	the sum of two
0.0166231466	the observation of
0.0166231466	a proof of
0.0166221043	the singular values of
0.0166206696	the availability of
0.0165870822	the object of
0.0165850097	a part of
0.0165822926	the identification of
0.0165454155	the mse of
0.0165129773	a basis for
0.0165037488	a new characterization of
0.0164995087	the loss of
0.0164731466	the minimization of
0.0164461456	of fit for
0.0164301935	the benefit of
0.0164135268	the population mean
0.0162971278	for sums of
0.0162575744	the excess risk of
0.0162099554	the challenge of
0.0161582486	and sufficient for
0.0161552447	the consistency and asymptotic normality of
0.0161193515	the end of
0.0160863900	the problem of estimation of
0.0160454155	the rows of
0.0159922791	the comparison of
0.0159922791	the solution to
0.0159903440	mean and variance of
0.0159625191	the order statistics of
0.0159208524	the flexibility of
0.0158922810	a byproduct of
0.0158901463	many well
0.0158851382	the width of
0.0158851382	the radius of
0.0158525376	work with
0.0158522810	the data into
0.0158422791	the asymptotics of
0.0158244853	the discrepancy of
0.0157583649	the geometric mean
0.0156727965	a nonparametric estimator of
0.0156676171	the convergence properties of
0.0156325744	the covariance structure of
0.0156231466	a study of
0.0156221043	the spectral density of
0.0155850097	a model for
0.0155454155	the point of view of
0.0155432887	the signs of
0.0154911519	the determinant of
0.0154754190	particular cases of
0.0154731466	the cases of
0.0154731466	the result of
0.0154069334	the standard deviation of
0.0153977688	the weak convergence of
0.0153751568	as functions of
0.0153686594	a sample from
0.0153508022	a lack of
0.0153408772	the drift of
0.0153356449	an estimator based on
0.0152969029	the recent work of
0.0152661646	this class of
0.0152132450	the covariance of
0.0152132450	the implementation of
0.0152120822	the extent of
0.0151980201	a tool for
0.0151892106	the uniqueness of
0.0151471278	the concepts of
0.0151061022	the notions of
0.0150914572	the topic of
0.0150779526	the general framework of
0.0150138195	many applications in
0.0150075439	a comparison of
0.0150033620	in view of
0.0149982948	to sample from
0.0148851382	the inversion of
0.0147873363	the good performance of
0.0147537488	the rest of
0.0147402667	the spectral properties of
0.0147402667	the unknown parameters of
0.0147402667	the posterior probability of
0.0147265915	the asymptotic distributions of
0.0146682887	a group of
0.0146682582	the optimal rate of
0.0146628858	the degrees of freedom of
0.0146250097	the evaluation of
0.0145517747	a portion of
0.0145457961	the equivalence of
0.0145454155	the position of
0.0145454155	the price of
0.0144907937	an ensemble of
0.0144896634	the asymptotic theory of
0.0144795524	a dataset of
0.0144399849	a distribution with
0.0144249306	an approach for
0.0144135268	the outcome of
0.0143850097	the minimum of
0.0143695304	a definition of
0.0143695304	a technique for
0.0143686594	the dimensionality of
0.0143575407	a method based on
0.0143149849	for inference on
0.0142457240	the statistical analysis of
0.0142338192	a type of
0.0141908772	the spectrum of
0.0141866953	a partition of
0.0141492106	the existence and uniqueness of
0.0141161646	the area of
0.0140863900	a new estimator of
0.0140658772	the source of
0.0140385268	a fraction of
0.0139753979	the convexity of
0.0139242411	the tail behavior of
0.0138825439	to test for
0.0138587344	the minimax rate of
0.0138575439	the contribution of
0.0138176171	the minimax risk of
0.0137402667	a theoretical analysis of
0.0137402667	the spectral norm of
0.0137325439	the merits of
0.0136994853	an estimate for
0.0136628858	the hardness of
0.0136265915	the estimation error of
0.0135850097	a procedure for
0.0135600097	the concentration of
0.0135123875	the rate of convergence in
0.0134911519	the sign of
0.0134911519	the action of
0.0134911519	the vertices of
0.0134795524	a new method of
0.0133850097	the error in
0.0133218031	the union of
0.0133051935	in support of
0.0132640457	a methodology for
0.0132635268	the occurrence of
0.0132569029	the foundations of
0.0132363900	the key to
0.0132011479	analyzed to
0.0131908772	the investigation of
0.0131908772	the calculation of
0.0131492106	the specification of
0.0130974096	an adaptive estimator of
0.0130801935	the potential of
0.0130658772	the fluctuations of
0.0130658772	the quantiles of
0.0130194760	to hold in
0.0129301935	a product of
0.0129242411	the probability distribution of
0.0128589049	with applications in
0.0128575439	the difference in
0.0127100097	a theory of
0.0126856449	the error rate of
0.0125372824	the rates of convergence of
0.0123408772	a solution of
0.0123019883	the minimizer of
0.0123019883	the variances of
0.0122635268	the deviation of
0.0122635268	the sensitivity of
0.0122158772	the rate of convergence for
0.0121908772	the ability to
0.0121908772	the determination of
0.0121591312	the curse of
0.0121492106	the locations of
0.0119448122	for model selection in
0.0119287283	the minimax risk for
0.0114135268	the problem of testing for
0.0112635268	the coordinates of
0.0111908772	the consequences of
0.0105974096	the asymptotic validity of
